{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FSOwPvirmzid"
   },
   "source": [
    "# Requirements\n",
    "Specific roles of each group member  \n",
    "An evaluation score and ranked position of your prediction results for the specific competition in Kaggle  \n",
    " \n",
    "Challenges of the problem  \n",
    "Proposed solution in detail (preprocessing, feature engineering/representation learning, methodologies, etc)  \n",
    "Experiments to demonstrate why the solution you proposed is appropriate to solve the problem using experiments  \n",
    "Conclusion: what you have learned from the project\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "y_EbZycGYNN2"
   },
   "source": [
    "# Group Members and Contributions "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "v3eXqcA5YUwc"
   },
   "source": [
    "Zhang Zeyu (1620474K): part of feature encoding, PCA, machine learning model selection, model evaluation and parameter tuning, prediction results analysis "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sgwBhXkUD6HB"
   },
   "source": [
    "# Problem Statement\n",
    "Based on the given features and the causualities of part of the passanger on Titanic, predict whether some other passanger has survied the sinking of Titanic given some of the features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cyiWVPFJfKuW"
   },
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Tcxj7haTfJFG"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sb\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from collections import Counter\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cRM3StI6VBqc"
   },
   "source": [
    "# Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 445,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 341
    },
    "colab_type": "code",
    "id": "QN5sFqILVxn8",
    "outputId": "0160c4fe-d7af-42ea-b44a-78195bd47399"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  ...     Fare Cabin  Embarked\n",
       "0            1         0       3  ...   7.2500   NaN         S\n",
       "1            2         1       1  ...  71.2833   C85         C\n",
       "2            3         1       3  ...   7.9250   NaN         S\n",
       "3            4         1       1  ...  53.1000  C123         S\n",
       "4            5         0       3  ...   8.0500   NaN         S\n",
       "\n",
       "[5 rows x 12 columns]"
      ]
     },
     "execution_count": 445,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import io\n",
    "import requests\n",
    "url = 'https://raw.githubusercontent.com/zyzhang1130/CE9010/master/Titanic/train.csv'\n",
    "df = pd.read_csv(url)\n",
    "#s=requests.get(url).content\n",
    "#df=pd.read_csv(io.StringIO(s.decode('utf-8')))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Cj-S8xiNV1xw"
   },
   "source": [
    "# Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 446,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 294
    },
    "colab_type": "code",
    "id": "ok-f71IthfAC",
    "outputId": "9f8362a7-590b-4d57-d1fe-94b94c549e30"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>714.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>446.000000</td>\n",
       "      <td>0.383838</td>\n",
       "      <td>2.308642</td>\n",
       "      <td>29.699118</td>\n",
       "      <td>0.523008</td>\n",
       "      <td>0.381594</td>\n",
       "      <td>32.204208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>257.353842</td>\n",
       "      <td>0.486592</td>\n",
       "      <td>0.836071</td>\n",
       "      <td>14.526497</td>\n",
       "      <td>1.102743</td>\n",
       "      <td>0.806057</td>\n",
       "      <td>49.693429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.420000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>223.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>20.125000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.910400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>446.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14.454200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>668.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>31.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>891.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>512.329200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       PassengerId    Survived      Pclass  ...       SibSp       Parch        Fare\n",
       "count   891.000000  891.000000  891.000000  ...  891.000000  891.000000  891.000000\n",
       "mean    446.000000    0.383838    2.308642  ...    0.523008    0.381594   32.204208\n",
       "std     257.353842    0.486592    0.836071  ...    1.102743    0.806057   49.693429\n",
       "min       1.000000    0.000000    1.000000  ...    0.000000    0.000000    0.000000\n",
       "25%     223.500000    0.000000    2.000000  ...    0.000000    0.000000    7.910400\n",
       "50%     446.000000    0.000000    3.000000  ...    0.000000    0.000000   14.454200\n",
       "75%     668.500000    1.000000    3.000000  ...    1.000000    0.000000   31.000000\n",
       "max     891.000000    1.000000    3.000000  ...    8.000000    6.000000  512.329200\n",
       "\n",
       "[8 rows x 7 columns]"
      ]
     },
     "execution_count": 446,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wBmSy36aW8JD"
   },
   "source": [
    "## Visualise \"Survived\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 447,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 297
    },
    "colab_type": "code",
    "id": "pw8hu7SGWBeH",
    "outputId": "93c6de31-0caf-412d-ffa2-52347f2d3449"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f43d0125da0>"
      ]
     },
     "execution_count": 447,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sb.countplot(df[\"Survived\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 448,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 87
    },
    "colab_type": "code",
    "id": "aLbMqHd8XbMo",
    "outputId": "a8d864e2-1089-419a-85d1-6770c4731419"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Survived=0 and Survived=1\n",
      "0    549\n",
      "1    342\n",
      "Name: Survived, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of Survived=0 and Survived=1\") \n",
    "print(df[\"Survived\"].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sJPoY1lTXtD3"
   },
   "source": [
    "## Visualise \"Sex\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 449,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 297
    },
    "colab_type": "code",
    "id": "ksROeWseX4NG",
    "outputId": "52d11c35-7cae-4d7e-852a-74af84145a93"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f43cba08898>"
      ]
     },
     "execution_count": 449,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sb.barplot(x=\"Sex\", y=\"Survived\", data=df, palette=\"ch:0.6\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 450,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 69
    },
    "colab_type": "code",
    "id": "GmvMpGsXX-E2",
    "outputId": "7bea7f00-f68c-400a-ddb1-e7359fda61c0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Survival rate:\n",
      "Female:  0.7420382165605095\n",
      "Male:  0.18890814558058924\n"
     ]
    }
   ],
   "source": [
    "print(\"Survival rate:\")\n",
    "print(\"Female: \", df['Survived'][df['Sex'] == \"female\"].value_counts(normalize=True)[1])\n",
    "print(\"Male: \", df['Survived'][df['Sex'] == \"male\"].value_counts(normalize=True)[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "q2m7twelYPmn"
   },
   "source": [
    "## Visualise \"Age\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 451,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 247
    },
    "colab_type": "code",
    "id": "R-ga9Sy8YSl7",
    "outputId": "1e16e9cc-bc1f-4781-dd9d-fe7be90de7f1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f43cb7a2f98>"
      ]
     },
     "execution_count": 451,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1296x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, axis1 = plt.subplots(1,1,figsize=(18,4))\n",
    "sb.barplot(x='Age', y='Survived', data=df[[\"Age\", \"Survived\"]].groupby(['Age'],as_index=False).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 452,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 542
    },
    "colab_type": "code",
    "id": "BP-xQfGlcGHw",
    "outputId": "cf6d0f5b-2ac6-4e3a-9018-1477eca7de7a"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<html>\n",
       "<head><meta charset=\"utf-8\" /></head>\n",
       "<body>\n",
       "    <div>\n",
       "            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>\n",
       "                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
       "        <script src=\"https://cdn.plot.ly/plotly-latest.min.js\"></script>    \n",
       "            <div id=\"4ddd57ca-9778-42c3-a9ff-eae8a0284af9\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>\n",
       "            <script type=\"text/javascript\">\n",
       "                \n",
       "                    window.PLOTLYENV=window.PLOTLYENV || {};\n",
       "                    \n",
       "                if (document.getElementById(\"4ddd57ca-9778-42c3-a9ff-eae8a0284af9\")) {\n",
       "                    Plotly.newPlot(\n",
       "                        '4ddd57ca-9778-42c3-a9ff-eae8a0284af9',\n",
       "                        [{\"coloraxis\": \"coloraxis\", \"hoverlabel\": {\"namelength\": 0}, \"hovertemplate\": \"Age=%{x}<br>Survived=%{y}<br>count=%{z}\", \"name\": \"\", \"type\": \"histogram2d\", \"x\": [22.0, 38.0, 26.0, 35.0, 35.0, null, 54.0, 2.0, 27.0, 14.0, 4.0, 58.0, 20.0, 39.0, 14.0, 55.0, 2.0, null, 31.0, null, 35.0, 34.0, 15.0, 28.0, 8.0, 38.0, null, 19.0, null, null, 40.0, null, null, 66.0, 28.0, 42.0, null, 21.0, 18.0, 14.0, 40.0, 27.0, null, 3.0, 19.0, null, null, null, null, 18.0, 7.0, 21.0, 49.0, 29.0, 65.0, null, 21.0, 28.5, 5.0, 11.0, 22.0, 38.0, 45.0, 4.0, null, null, 29.0, 19.0, 17.0, 26.0, 32.0, 16.0, 21.0, 26.0, 32.0, 25.0, null, null, 0.83, 30.0, 22.0, 29.0, null, 28.0, 17.0, 33.0, 16.0, null, 23.0, 24.0, 29.0, 20.0, 46.0, 26.0, 59.0, null, 71.0, 23.0, 34.0, 34.0, 28.0, null, 21.0, 33.0, 37.0, 28.0, 21.0, null, 38.0, null, 47.0, 14.5, 22.0, 20.0, 17.0, 21.0, 70.5, 29.0, 24.0, 2.0, 21.0, null, 32.5, 32.5, 54.0, 12.0, null, 24.0, null, 45.0, 33.0, 20.0, 47.0, 29.0, 25.0, 23.0, 19.0, 37.0, 16.0, 24.0, null, 22.0, 24.0, 19.0, 18.0, 19.0, 27.0, 9.0, 36.5, 42.0, 51.0, 22.0, 55.5, 40.5, null, 51.0, 16.0, 30.0, null, null, 44.0, 40.0, 26.0, 17.0, 1.0, 9.0, null, 45.0, null, 28.0, 61.0, 4.0, 1.0, 21.0, 56.0, 18.0, null, 50.0, 30.0, 36.0, null, null, 9.0, 1.0, 4.0, null, null, 45.0, 40.0, 36.0, 32.0, 19.0, 19.0, 3.0, 44.0, 58.0, null, 42.0, null, 24.0, 28.0, null, 34.0, 45.5, 18.0, 2.0, 32.0, 26.0, 16.0, 40.0, 24.0, 35.0, 22.0, 30.0, null, 31.0, 27.0, 42.0, 32.0, 30.0, 16.0, 27.0, 51.0, null, 38.0, 22.0, 19.0, 20.5, 18.0, null, 35.0, 29.0, 59.0, 5.0, 24.0, null, 44.0, 8.0, 19.0, 33.0, null, null, 29.0, 22.0, 30.0, 44.0, 25.0, 24.0, 37.0, 54.0, null, 29.0, 62.0, 30.0, 41.0, 29.0, null, 30.0, 35.0, 50.0, null, 3.0, 52.0, 40.0, null, 36.0, 16.0, 25.0, 58.0, 35.0, null, 25.0, 41.0, 37.0, null, 63.0, 45.0, null, 7.0, 35.0, 65.0, 28.0, 16.0, 19.0, null, 33.0, 30.0, 22.0, 42.0, 22.0, 26.0, 19.0, 36.0, 24.0, 24.0, null, 23.5, 2.0, null, 50.0, null, null, 19.0, null, null, 0.92, null, 17.0, 30.0, 30.0, 24.0, 18.0, 26.0, 28.0, 43.0, 26.0, 24.0, 54.0, 31.0, 40.0, 22.0, 27.0, 30.0, 22.0, null, 36.0, 61.0, 36.0, 31.0, 16.0, null, 45.5, 38.0, 16.0, null, null, 29.0, 41.0, 45.0, 45.0, 2.0, 24.0, 28.0, 25.0, 36.0, 24.0, 40.0, null, 3.0, 42.0, 23.0, null, 15.0, 25.0, null, 28.0, 22.0, 38.0, null, null, 40.0, 29.0, 45.0, 35.0, null, 30.0, 60.0, null, null, 24.0, 25.0, 18.0, 19.0, 22.0, 3.0, null, 22.0, 27.0, 20.0, 19.0, 42.0, 1.0, 32.0, 35.0, null, 18.0, 1.0, 36.0, null, 17.0, 36.0, 21.0, 28.0, 23.0, 24.0, 22.0, 31.0, 46.0, 23.0, 28.0, 39.0, 26.0, 21.0, 28.0, 20.0, 34.0, 51.0, 3.0, 21.0, null, null, null, 33.0, null, 44.0, null, 34.0, 18.0, 30.0, 10.0, null, 21.0, 29.0, 28.0, 18.0, null, 28.0, 19.0, null, 32.0, 28.0, null, 42.0, 17.0, 50.0, 14.0, 21.0, 24.0, 64.0, 31.0, 45.0, 20.0, 25.0, 28.0, null, 4.0, 13.0, 34.0, 5.0, 52.0, 36.0, null, 30.0, 49.0, null, 29.0, 65.0, null, 50.0, null, 48.0, 34.0, 47.0, 48.0, null, 38.0, null, 56.0, null, 0.75, null, 38.0, 33.0, 23.0, 22.0, null, 34.0, 29.0, 22.0, 2.0, 9.0, null, 50.0, 63.0, 25.0, null, 35.0, 58.0, 30.0, 9.0, null, 21.0, 55.0, 71.0, 21.0, null, 54.0, null, 25.0, 24.0, 17.0, 21.0, null, 37.0, 16.0, 18.0, 33.0, null, 28.0, 26.0, 29.0, null, 36.0, 54.0, 24.0, 47.0, 34.0, null, 36.0, 32.0, 30.0, 22.0, null, 44.0, null, 40.5, 50.0, null, 39.0, 23.0, 2.0, null, 17.0, null, 30.0, 7.0, 45.0, 30.0, null, 22.0, 36.0, 9.0, 11.0, 32.0, 50.0, 64.0, 19.0, null, 33.0, 8.0, 17.0, 27.0, null, 22.0, 22.0, 62.0, 48.0, null, 39.0, 36.0, null, 40.0, 28.0, null, null, 24.0, 19.0, 29.0, null, 32.0, 62.0, 53.0, 36.0, null, 16.0, 19.0, 34.0, 39.0, null, 32.0, 25.0, 39.0, 54.0, 36.0, null, 18.0, 47.0, 60.0, 22.0, null, 35.0, 52.0, 47.0, null, 37.0, 36.0, null, 49.0, null, 49.0, 24.0, null, null, 44.0, 35.0, 36.0, 30.0, 27.0, 22.0, 40.0, 39.0, null, null, null, 35.0, 24.0, 34.0, 26.0, 4.0, 26.0, 27.0, 42.0, 20.0, 21.0, 21.0, 61.0, 57.0, 21.0, 26.0, null, 80.0, 51.0, 32.0, null, 9.0, 28.0, 32.0, 31.0, 41.0, null, 20.0, 24.0, 2.0, null, 0.75, 48.0, 19.0, 56.0, null, 23.0, null, 18.0, 21.0, null, 18.0, 24.0, null, 32.0, 23.0, 58.0, 50.0, 40.0, 47.0, 36.0, 20.0, 32.0, 25.0, null, 43.0, null, 40.0, 31.0, 70.0, 31.0, null, 18.0, 24.5, 18.0, 43.0, 36.0, null, 27.0, 20.0, 14.0, 60.0, 25.0, 14.0, 19.0, 18.0, 15.0, 31.0, 4.0, null, 25.0, 60.0, 52.0, 44.0, null, 49.0, 42.0, 18.0, 35.0, 18.0, 25.0, 26.0, 39.0, 45.0, 42.0, 22.0, null, 24.0, null, 48.0, 29.0, 52.0, 19.0, 38.0, 27.0, null, 33.0, 6.0, 17.0, 34.0, 50.0, 27.0, 20.0, 30.0, null, 25.0, 25.0, 29.0, 11.0, null, 23.0, 23.0, 28.5, 48.0, 35.0, null, null, null, 36.0, 21.0, 24.0, 31.0, 70.0, 16.0, 30.0, 19.0, 31.0, 4.0, 6.0, 33.0, 23.0, 48.0, 0.67, 28.0, 18.0, 34.0, 33.0, null, 41.0, 20.0, 36.0, 16.0, 51.0, null, 30.5, null, 32.0, 24.0, 48.0, 57.0, null, 54.0, 18.0, null, 5.0, null, 43.0, 13.0, 17.0, 29.0, null, 25.0, 25.0, 18.0, 8.0, 1.0, 46.0, null, 16.0, null, null, 25.0, 39.0, 49.0, 31.0, 30.0, 30.0, 34.0, 31.0, 11.0, 0.42, 27.0, 31.0, 39.0, 18.0, 39.0, 33.0, 26.0, 39.0, 35.0, 6.0, 30.5, null, 23.0, 31.0, 43.0, 10.0, 52.0, 27.0, 38.0, 27.0, 2.0, null, null, 1.0, null, 62.0, 15.0, 0.83, null, 23.0, 18.0, 39.0, 21.0, null, 32.0, null, 20.0, 16.0, 30.0, 34.5, 17.0, 42.0, null, 35.0, 28.0, null, 4.0, 74.0, 9.0, 16.0, 44.0, 18.0, 45.0, 51.0, 24.0, null, 41.0, 21.0, 48.0, null, 24.0, 42.0, 27.0, 31.0, null, 4.0, 26.0, 47.0, 33.0, 47.0, 28.0, 15.0, 20.0, 19.0, null, 56.0, 25.0, 33.0, 22.0, 28.0, 25.0, 39.0, 27.0, 19.0, null, 26.0, 32.0], \"xaxis\": \"x\", \"xbingroup\": \"x\", \"y\": [0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0], \"yaxis\": \"y\", \"ybingroup\": \"y\"}, {\"alignmentgroup\": \"True\", \"bingroup\": \"x\", \"hoverlabel\": {\"namelength\": 0}, \"hovertemplate\": \"Age=%{x}<br>count=%{y}\", \"legendgroup\": \"\", \"marker\": {\"color\": \"#0d0887\"}, \"name\": \"\", \"offsetgroup\": \"\", \"opacity\": 0.5, \"showlegend\": false, \"type\": \"histogram\", \"x\": [22.0, 38.0, 26.0, 35.0, 35.0, null, 54.0, 2.0, 27.0, 14.0, 4.0, 58.0, 20.0, 39.0, 14.0, 55.0, 2.0, null, 31.0, null, 35.0, 34.0, 15.0, 28.0, 8.0, 38.0, null, 19.0, null, null, 40.0, null, null, 66.0, 28.0, 42.0, null, 21.0, 18.0, 14.0, 40.0, 27.0, null, 3.0, 19.0, null, null, null, null, 18.0, 7.0, 21.0, 49.0, 29.0, 65.0, null, 21.0, 28.5, 5.0, 11.0, 22.0, 38.0, 45.0, 4.0, null, null, 29.0, 19.0, 17.0, 26.0, 32.0, 16.0, 21.0, 26.0, 32.0, 25.0, null, null, 0.83, 30.0, 22.0, 29.0, null, 28.0, 17.0, 33.0, 16.0, null, 23.0, 24.0, 29.0, 20.0, 46.0, 26.0, 59.0, null, 71.0, 23.0, 34.0, 34.0, 28.0, null, 21.0, 33.0, 37.0, 28.0, 21.0, null, 38.0, null, 47.0, 14.5, 22.0, 20.0, 17.0, 21.0, 70.5, 29.0, 24.0, 2.0, 21.0, null, 32.5, 32.5, 54.0, 12.0, null, 24.0, null, 45.0, 33.0, 20.0, 47.0, 29.0, 25.0, 23.0, 19.0, 37.0, 16.0, 24.0, null, 22.0, 24.0, 19.0, 18.0, 19.0, 27.0, 9.0, 36.5, 42.0, 51.0, 22.0, 55.5, 40.5, null, 51.0, 16.0, 30.0, null, null, 44.0, 40.0, 26.0, 17.0, 1.0, 9.0, null, 45.0, null, 28.0, 61.0, 4.0, 1.0, 21.0, 56.0, 18.0, null, 50.0, 30.0, 36.0, null, null, 9.0, 1.0, 4.0, null, null, 45.0, 40.0, 36.0, 32.0, 19.0, 19.0, 3.0, 44.0, 58.0, null, 42.0, null, 24.0, 28.0, null, 34.0, 45.5, 18.0, 2.0, 32.0, 26.0, 16.0, 40.0, 24.0, 35.0, 22.0, 30.0, null, 31.0, 27.0, 42.0, 32.0, 30.0, 16.0, 27.0, 51.0, null, 38.0, 22.0, 19.0, 20.5, 18.0, null, 35.0, 29.0, 59.0, 5.0, 24.0, null, 44.0, 8.0, 19.0, 33.0, null, null, 29.0, 22.0, 30.0, 44.0, 25.0, 24.0, 37.0, 54.0, null, 29.0, 62.0, 30.0, 41.0, 29.0, null, 30.0, 35.0, 50.0, null, 3.0, 52.0, 40.0, null, 36.0, 16.0, 25.0, 58.0, 35.0, null, 25.0, 41.0, 37.0, null, 63.0, 45.0, null, 7.0, 35.0, 65.0, 28.0, 16.0, 19.0, null, 33.0, 30.0, 22.0, 42.0, 22.0, 26.0, 19.0, 36.0, 24.0, 24.0, null, 23.5, 2.0, null, 50.0, null, null, 19.0, null, null, 0.92, null, 17.0, 30.0, 30.0, 24.0, 18.0, 26.0, 28.0, 43.0, 26.0, 24.0, 54.0, 31.0, 40.0, 22.0, 27.0, 30.0, 22.0, null, 36.0, 61.0, 36.0, 31.0, 16.0, null, 45.5, 38.0, 16.0, null, null, 29.0, 41.0, 45.0, 45.0, 2.0, 24.0, 28.0, 25.0, 36.0, 24.0, 40.0, null, 3.0, 42.0, 23.0, null, 15.0, 25.0, null, 28.0, 22.0, 38.0, null, null, 40.0, 29.0, 45.0, 35.0, null, 30.0, 60.0, null, null, 24.0, 25.0, 18.0, 19.0, 22.0, 3.0, null, 22.0, 27.0, 20.0, 19.0, 42.0, 1.0, 32.0, 35.0, null, 18.0, 1.0, 36.0, null, 17.0, 36.0, 21.0, 28.0, 23.0, 24.0, 22.0, 31.0, 46.0, 23.0, 28.0, 39.0, 26.0, 21.0, 28.0, 20.0, 34.0, 51.0, 3.0, 21.0, null, null, null, 33.0, null, 44.0, null, 34.0, 18.0, 30.0, 10.0, null, 21.0, 29.0, 28.0, 18.0, null, 28.0, 19.0, null, 32.0, 28.0, null, 42.0, 17.0, 50.0, 14.0, 21.0, 24.0, 64.0, 31.0, 45.0, 20.0, 25.0, 28.0, null, 4.0, 13.0, 34.0, 5.0, 52.0, 36.0, null, 30.0, 49.0, null, 29.0, 65.0, null, 50.0, null, 48.0, 34.0, 47.0, 48.0, null, 38.0, null, 56.0, null, 0.75, null, 38.0, 33.0, 23.0, 22.0, null, 34.0, 29.0, 22.0, 2.0, 9.0, null, 50.0, 63.0, 25.0, null, 35.0, 58.0, 30.0, 9.0, null, 21.0, 55.0, 71.0, 21.0, null, 54.0, null, 25.0, 24.0, 17.0, 21.0, null, 37.0, 16.0, 18.0, 33.0, null, 28.0, 26.0, 29.0, null, 36.0, 54.0, 24.0, 47.0, 34.0, null, 36.0, 32.0, 30.0, 22.0, null, 44.0, null, 40.5, 50.0, null, 39.0, 23.0, 2.0, null, 17.0, null, 30.0, 7.0, 45.0, 30.0, null, 22.0, 36.0, 9.0, 11.0, 32.0, 50.0, 64.0, 19.0, null, 33.0, 8.0, 17.0, 27.0, null, 22.0, 22.0, 62.0, 48.0, null, 39.0, 36.0, null, 40.0, 28.0, null, null, 24.0, 19.0, 29.0, null, 32.0, 62.0, 53.0, 36.0, null, 16.0, 19.0, 34.0, 39.0, null, 32.0, 25.0, 39.0, 54.0, 36.0, null, 18.0, 47.0, 60.0, 22.0, null, 35.0, 52.0, 47.0, null, 37.0, 36.0, null, 49.0, null, 49.0, 24.0, null, null, 44.0, 35.0, 36.0, 30.0, 27.0, 22.0, 40.0, 39.0, null, null, null, 35.0, 24.0, 34.0, 26.0, 4.0, 26.0, 27.0, 42.0, 20.0, 21.0, 21.0, 61.0, 57.0, 21.0, 26.0, null, 80.0, 51.0, 32.0, null, 9.0, 28.0, 32.0, 31.0, 41.0, null, 20.0, 24.0, 2.0, null, 0.75, 48.0, 19.0, 56.0, null, 23.0, null, 18.0, 21.0, null, 18.0, 24.0, null, 32.0, 23.0, 58.0, 50.0, 40.0, 47.0, 36.0, 20.0, 32.0, 25.0, null, 43.0, null, 40.0, 31.0, 70.0, 31.0, null, 18.0, 24.5, 18.0, 43.0, 36.0, null, 27.0, 20.0, 14.0, 60.0, 25.0, 14.0, 19.0, 18.0, 15.0, 31.0, 4.0, null, 25.0, 60.0, 52.0, 44.0, null, 49.0, 42.0, 18.0, 35.0, 18.0, 25.0, 26.0, 39.0, 45.0, 42.0, 22.0, null, 24.0, null, 48.0, 29.0, 52.0, 19.0, 38.0, 27.0, null, 33.0, 6.0, 17.0, 34.0, 50.0, 27.0, 20.0, 30.0, null, 25.0, 25.0, 29.0, 11.0, null, 23.0, 23.0, 28.5, 48.0, 35.0, null, null, null, 36.0, 21.0, 24.0, 31.0, 70.0, 16.0, 30.0, 19.0, 31.0, 4.0, 6.0, 33.0, 23.0, 48.0, 0.67, 28.0, 18.0, 34.0, 33.0, null, 41.0, 20.0, 36.0, 16.0, 51.0, null, 30.5, null, 32.0, 24.0, 48.0, 57.0, null, 54.0, 18.0, null, 5.0, null, 43.0, 13.0, 17.0, 29.0, null, 25.0, 25.0, 18.0, 8.0, 1.0, 46.0, null, 16.0, null, null, 25.0, 39.0, 49.0, 31.0, 30.0, 30.0, 34.0, 31.0, 11.0, 0.42, 27.0, 31.0, 39.0, 18.0, 39.0, 33.0, 26.0, 39.0, 35.0, 6.0, 30.5, null, 23.0, 31.0, 43.0, 10.0, 52.0, 27.0, 38.0, 27.0, 2.0, null, null, 1.0, null, 62.0, 15.0, 0.83, null, 23.0, 18.0, 39.0, 21.0, null, 32.0, null, 20.0, 16.0, 30.0, 34.5, 17.0, 42.0, null, 35.0, 28.0, null, 4.0, 74.0, 9.0, 16.0, 44.0, 18.0, 45.0, 51.0, 24.0, null, 41.0, 21.0, 48.0, null, 24.0, 42.0, 27.0, 31.0, null, 4.0, 26.0, 47.0, 33.0, 47.0, 28.0, 15.0, 20.0, 19.0, null, 56.0, 25.0, 33.0, 22.0, 28.0, 25.0, 39.0, 27.0, 19.0, null, 26.0, 32.0], \"xaxis\": \"x3\", \"yaxis\": \"y3\"}, {\"alignmentgroup\": \"True\", \"bingroup\": \"y\", \"hoverlabel\": {\"namelength\": 0}, \"hovertemplate\": \"Survived=%{y}<br>count=%{x}\", \"legendgroup\": \"\", \"marker\": {\"color\": \"#0d0887\"}, \"name\": \"\", \"offsetgroup\": \"\", \"opacity\": 0.5, \"showlegend\": false, \"type\": \"histogram\", \"xaxis\": \"x2\", \"y\": [0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0], \"yaxis\": \"y2\"}],\n",
       "                        {\"barmode\": \"overlay\", \"coloraxis\": {\"colorbar\": {\"title\": {\"text\": \"count\"}}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]]}, \"legend\": {\"tracegroupgap\": 0}, \"margin\": {\"t\": 60}, \"template\": {\"data\": {\"bar\": [{\"error_x\": {\"color\": \"#2a3f5f\"}, \"error_y\": {\"color\": \"#2a3f5f\"}, \"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"bar\"}], \"barpolar\": [{\"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"barpolar\"}], \"carpet\": [{\"aaxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"baxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"type\": \"carpet\"}], \"choropleth\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"choropleth\"}], \"contour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"contour\"}], \"contourcarpet\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"contourcarpet\"}], \"heatmap\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmap\"}], \"heatmapgl\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmapgl\"}], \"histogram\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"histogram\"}], \"histogram2d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2d\"}], \"histogram2dcontour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2dcontour\"}], \"mesh3d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"mesh3d\"}], \"parcoords\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"parcoords\"}], \"pie\": [{\"automargin\": true, \"type\": \"pie\"}], \"scatter\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter\"}], \"scatter3d\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter3d\"}], \"scattercarpet\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattercarpet\"}], \"scattergeo\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergeo\"}], \"scattergl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergl\"}], \"scattermapbox\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattermapbox\"}], \"scatterpolar\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolar\"}], \"scatterpolargl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolargl\"}], \"scatterternary\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterternary\"}], \"surface\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"surface\"}], \"table\": [{\"cells\": {\"fill\": {\"color\": \"#EBF0F8\"}, \"line\": {\"color\": \"white\"}}, \"header\": {\"fill\": {\"color\": \"#C8D4E3\"}, \"line\": {\"color\": \"white\"}}, \"type\": \"table\"}]}, \"layout\": {\"annotationdefaults\": {\"arrowcolor\": \"#2a3f5f\", \"arrowhead\": 0, \"arrowwidth\": 1}, \"coloraxis\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"colorscale\": {\"diverging\": [[0, \"#8e0152\"], [0.1, \"#c51b7d\"], [0.2, \"#de77ae\"], [0.3, \"#f1b6da\"], [0.4, \"#fde0ef\"], [0.5, \"#f7f7f7\"], [0.6, \"#e6f5d0\"], [0.7, \"#b8e186\"], [0.8, \"#7fbc41\"], [0.9, \"#4d9221\"], [1, \"#276419\"]], \"sequential\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"sequentialminus\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]]}, \"colorway\": [\"#636efa\", \"#EF553B\", \"#00cc96\", \"#ab63fa\", \"#FFA15A\", \"#19d3f3\", \"#FF6692\", \"#B6E880\", \"#FF97FF\", \"#FECB52\"], \"font\": {\"color\": \"#2a3f5f\"}, \"geo\": {\"bgcolor\": \"white\", \"lakecolor\": \"white\", \"landcolor\": \"#E5ECF6\", \"showlakes\": true, \"showland\": true, \"subunitcolor\": \"white\"}, \"hoverlabel\": {\"align\": \"left\"}, \"hovermode\": \"closest\", \"mapbox\": {\"style\": \"light\"}, \"paper_bgcolor\": \"white\", \"plot_bgcolor\": \"#E5ECF6\", \"polar\": {\"angularaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"radialaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"scene\": {\"xaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"yaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"zaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}}, \"shapedefaults\": {\"line\": {\"color\": \"#2a3f5f\"}}, \"ternary\": {\"aaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"baxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"caxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"title\": {\"x\": 0.05}, \"xaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}, \"yaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}}}, \"xaxis\": {\"anchor\": \"y\", \"domain\": [0.0, 0.7363], \"title\": {\"text\": \"Age\"}}, \"xaxis2\": {\"anchor\": \"y2\", \"domain\": [0.7413, 1.0], \"matches\": \"x2\", \"showgrid\": true, \"showline\": false, \"showticklabels\": false, \"ticks\": \"\"}, \"xaxis3\": {\"anchor\": \"y3\", \"domain\": [0.0, 0.7363], \"matches\": \"x\", \"showgrid\": true, \"showticklabels\": false}, \"xaxis4\": {\"anchor\": \"y4\", \"domain\": [0.7413, 1.0], \"matches\": \"x2\", \"showgrid\": true, \"showline\": false, \"showticklabels\": false, \"ticks\": \"\"}, \"yaxis\": {\"anchor\": \"x\", \"domain\": [0.0, 0.7326], \"title\": {\"text\": \"Survived\"}}, \"yaxis2\": {\"anchor\": \"x2\", \"domain\": [0.0, 0.7326], \"matches\": \"y\", \"showgrid\": true, \"showticklabels\": false}, \"yaxis3\": {\"anchor\": \"x3\", \"domain\": [0.7426, 1.0], \"matches\": \"y3\", \"showgrid\": true, \"showline\": false, \"showticklabels\": false, \"ticks\": \"\"}, \"yaxis4\": {\"anchor\": \"x4\", \"domain\": [0.7426, 1.0], \"matches\": \"y3\", \"showgrid\": true, \"showline\": false, \"showticklabels\": false, \"ticks\": \"\"}},\n",
       "                        {\"responsive\": true}\n",
       "                    ).then(function(){\n",
       "                            \n",
       "var gd = document.getElementById('4ddd57ca-9778-42c3-a9ff-eae8a0284af9');\n",
       "var x = new MutationObserver(function (mutations, observer) {{\n",
       "        var display = window.getComputedStyle(gd).display;\n",
       "        if (!display || display === 'none') {{\n",
       "            console.log([gd, 'removed!']);\n",
       "            Plotly.purge(gd);\n",
       "            observer.disconnect();\n",
       "        }}\n",
       "}});\n",
       "\n",
       "// Listen for the removal of the full notebook cells\n",
       "var notebookContainer = gd.closest('#notebook-container');\n",
       "if (notebookContainer) {{\n",
       "    x.observe(notebookContainer, {childList: true});\n",
       "}}\n",
       "\n",
       "// Listen for the clearing of the current output cell\n",
       "var outputEl = gd.closest('.output');\n",
       "if (outputEl) {{\n",
       "    x.observe(outputEl, {childList: true});\n",
       "}}\n",
       "\n",
       "                        })\n",
       "                };\n",
       "                \n",
       "            </script>\n",
       "        </div>\n",
       "</body>\n",
       "</html>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import plotly.express as px\n",
    "\n",
    "fig = px.density_heatmap(df, x=\"Age\", y=\"Survived\", marginal_x=\"histogram\", marginal_y=\"histogram\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pkBsh-8kYr4k"
   },
   "source": [
    "## Visualise \"Pclass\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 453,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 297
    },
    "colab_type": "code",
    "id": "rfywCxCsYu7o",
    "outputId": "cfd5cd48-f5b3-4204-9896-c71bcd2111de"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f43cbd1f128>"
      ]
     },
     "execution_count": 453,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sb.barplot(x=\"Pclass\", y=\"Survived\", data=df, palette=\"ch:0.1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 454,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 87
    },
    "colab_type": "code",
    "id": "zbxFjF9GYw2N",
    "outputId": "1a71a9d1-78fd-4812-94df-71315089699d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Survival rate:\n",
      "Pclass=1:  0.6296296296296297\n",
      "Pclass=2:  0.47282608695652173\n",
      "Pclass=3:  0.24236252545824846\n"
     ]
    }
   ],
   "source": [
    "print(\"Survival rate:\")\n",
    "print(\"Pclass=1: \", df['Survived'][df['Pclass'] == 1].value_counts(normalize=True)[1])\n",
    "print(\"Pclass=2: \", df['Survived'][df['Pclass'] == 2].value_counts(normalize=True)[1])\n",
    "print(\"Pclass=3: \", df['Survived'][df['Pclass'] == 3].value_counts(normalize=True)[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gmuJyfEjD_Gw"
   },
   "source": [
    "# Data Pre-processing\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Drn4vx9bE0JL"
   },
   "source": [
    "The data provided contained a mix of numerical, nominal, ordinal and binary data. We used different encoding methods for the data which will be examined below.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rVdfXYWiFF0n"
   },
   "source": [
    "## Feature Encoding\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-ixJTNgLnaFm"
   },
   "source": [
    "'PassengerId' is the same as index therefore it is not needed in as a feature:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uM10OZZrnU9M"
   },
   "outputs": [],
   "source": [
    "df = df.drop(columns=\"PassengerId\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TC9somNWi7WP"
   },
   "source": [
    "### Binary Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-9Aj8VXPjJSz"
   },
   "source": [
    "Amongst all the fearues given, only 'Sex' is binary. We now use dictionary to map its value 'male' and 'female' to binary value '0' and '1':"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jOVz13LQklVQ"
   },
   "outputs": [],
   "source": [
    "sex_map = {'male': 1, 'female': 0}\n",
    "df['Sex'] = df['Sex'].map(sex_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5Dnaz80SlAyW"
   },
   "source": [
    "### Ordinal Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UT0sOHpmlNbr"
   },
   "source": [
    "'Ticket class' is the only nominal feature given. Since it value is already '1', '2' and '3', no encoding is needed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CVAVh25Al26D"
   },
   "source": [
    "### Nominal Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2KR1c6f5mCHU"
   },
   "source": [
    "'Name', 'Ticket', 'Cabin' and 'Embarked' are nominal features. We think 'Name' has little to do with the survial of the passangers and it is unique for each passanger, therefore it is not a relevant feature. To double check that it is true, we count the number of times every name appeared in the training dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 457,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 124
    },
    "colab_type": "code",
    "id": "YHh2DORoo07T",
    "outputId": "4e66f636-4b96-4e49-eee2-8bf4b7d392e8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'Braund, Mr. Owen Harris': 1, 'Cumings, Mrs. John Bradley (Florence Briggs Thayer)': 1, 'Heikkinen, Miss. Laina': 1, 'Futrelle, Mrs. Jacques Heath (Lily May Peel)': 1, 'Allen, Mr. William Henry': 1, 'Moran, Mr. James': 1, 'McCarthy, Mr. Timothy J': 1, 'Palsson, Master. Gosta Leonard': 1, 'Johnson, Mrs. Oscar W (Elisabeth Vilhelmina Berg)': 1, 'Nasser, Mrs. Nicholas (Adele Achem)': 1, 'Sandstrom, Miss. Marguerite Rut': 1, 'Bonnell, Miss. Elizabeth': 1, 'Saundercock, Mr. William Henry': 1, 'Andersson, Mr. Anders Johan': 1, 'Vestrom, Miss. Hulda Amanda Adolfina': 1, 'Hewlett, Mrs. (Mary D Kingcome) ': 1, 'Rice, Master. Eugene': 1, 'Williams, Mr. Charles Eugene': 1, 'Vander Planke, Mrs. Julius (Emelia Maria Vandemoortele)': 1, 'Masselmani, Mrs. Fatima': 1, 'Fynney, Mr. Joseph J': 1, 'Beesley, Mr. Lawrence': 1, 'McGowan, Miss. Anna \"Annie\"': 1, 'Sloper, Mr. William Thompson': 1, 'Palsson, Miss. Torborg Danira': 1, 'Asplund, Mrs. Carl Oscar (Selma Augusta Emilia Johansson)': 1, 'Emir, Mr. Farred Chehab': 1, 'Fortune, Mr. Charles Alexander': 1, 'O\\'Dwyer, Miss. Ellen \"Nellie\"': 1, 'Todoroff, Mr. Lalio': 1, 'Uruchurtu, Don. Manuel E': 1, 'Spencer, Mrs. William Augustus (Marie Eugenie)': 1, 'Glynn, Miss. Mary Agatha': 1, 'Wheadon, Mr. Edward H': 1, 'Meyer, Mr. Edgar Joseph': 1, 'Holverson, Mr. Alexander Oskar': 1, 'Mamee, Mr. Hanna': 1, 'Cann, Mr. Ernest Charles': 1, 'Vander Planke, Miss. Augusta Maria': 1, 'Nicola-Yarred, Miss. Jamila': 1, 'Ahlin, Mrs. Johan (Johanna Persdotter Larsson)': 1, 'Turpin, Mrs. William John Robert (Dorothy Ann Wonnacott)': 1, 'Kraeff, Mr. Theodor': 1, 'Laroche, Miss. Simonne Marie Anne Andree': 1, 'Devaney, Miss. Margaret Delia': 1, 'Rogers, Mr. William John': 1, 'Lennon, Mr. Denis': 1, \"O'Driscoll, Miss. Bridget\": 1, 'Samaan, Mr. Youssef': 1, 'Arnold-Franchi, Mrs. Josef (Josefine Franchi)': 1, 'Panula, Master. Juha Niilo': 1, 'Nosworthy, Mr. Richard Cater': 1, 'Harper, Mrs. Henry Sleeper (Myna Haxtun)': 1, 'Faunthorpe, Mrs. Lizzie (Elizabeth Anne Wilkinson)': 1, 'Ostby, Mr. Engelhart Cornelius': 1, 'Woolner, Mr. Hugh': 1, 'Rugg, Miss. Emily': 1, 'Novel, Mr. Mansouer': 1, 'West, Miss. Constance Mirium': 1, 'Goodwin, Master. William Frederick': 1, 'Sirayanian, Mr. Orsen': 1, 'Icard, Miss. Amelie': 1, 'Harris, Mr. Henry Birkhardt': 1, 'Skoog, Master. Harald': 1, 'Stewart, Mr. Albert A': 1, 'Moubarek, Master. Gerios': 1, 'Nye, Mrs. (Elizabeth Ramell)': 1, 'Crease, Mr. Ernest James': 1, 'Andersson, Miss. Erna Alexandra': 1, 'Kink, Mr. Vincenz': 1, 'Jenkin, Mr. Stephen Curnow': 1, 'Goodwin, Miss. Lillian Amy': 1, 'Hood, Mr. Ambrose Jr': 1, 'Chronopoulos, Mr. Apostolos': 1, 'Bing, Mr. Lee': 1, 'Moen, Mr. Sigurd Hansen': 1, 'Staneff, Mr. Ivan': 1, 'Moutal, Mr. Rahamin Haim': 1, 'Caldwell, Master. Alden Gates': 1, 'Dowdell, Miss. Elizabeth': 1, 'Waelens, Mr. Achille': 1, 'Sheerlinck, Mr. Jan Baptist': 1, 'McDermott, Miss. Brigdet Delia': 1, 'Carrau, Mr. Francisco M': 1, 'Ilett, Miss. Bertha': 1, 'Backstrom, Mrs. Karl Alfred (Maria Mathilda Gustafsson)': 1, 'Ford, Mr. William Neal': 1, 'Slocovski, Mr. Selman Francis': 1, 'Fortune, Miss. Mabel Helen': 1, 'Celotti, Mr. Francesco': 1, 'Christmann, Mr. Emil': 1, 'Andreasson, Mr. Paul Edvin': 1, 'Chaffee, Mr. Herbert Fuller': 1, 'Dean, Mr. Bertram Frank': 1, 'Coxon, Mr. Daniel': 1, 'Shorney, Mr. Charles Joseph': 1, 'Goldschmidt, Mr. George B': 1, 'Greenfield, Mr. William Bertram': 1, 'Doling, Mrs. John T (Ada Julia Bone)': 1, 'Kantor, Mr. Sinai': 1, 'Petranec, Miss. Matilda': 1, 'Petroff, Mr. Pastcho (\"Pentcho\")': 1, 'White, Mr. Richard Frasar': 1, 'Johansson, Mr. Gustaf Joel': 1, 'Gustafsson, Mr. Anders Vilhelm': 1, 'Mionoff, Mr. Stoytcho': 1, 'Salkjelsvik, Miss. Anna Kristine': 1, 'Moss, Mr. Albert Johan': 1, 'Rekic, Mr. Tido': 1, 'Moran, Miss. Bertha': 1, 'Porter, Mr. Walter Chamberlain': 1, 'Zabour, Miss. Hileni': 1, 'Barton, Mr. David John': 1, 'Jussila, Miss. Katriina': 1, 'Attalah, Miss. Malake': 1, 'Pekoniemi, Mr. Edvard': 1, 'Connors, Mr. Patrick': 1, 'Turpin, Mr. William John Robert': 1, 'Baxter, Mr. Quigg Edmond': 1, 'Andersson, Miss. Ellis Anna Maria': 1, 'Hickman, Mr. Stanley George': 1, 'Moore, Mr. Leonard Charles': 1, 'Nasser, Mr. Nicholas': 1, 'Webber, Miss. Susan': 1, 'White, Mr. Percival Wayland': 1, 'Nicola-Yarred, Master. Elias': 1, 'McMahon, Mr. Martin': 1, 'Madsen, Mr. Fridtjof Arne': 1, 'Peter, Miss. Anna': 1, 'Ekstrom, Mr. Johan': 1, 'Drazenoic, Mr. Jozef': 1, 'Coelho, Mr. Domingos Fernandeo': 1, 'Robins, Mrs. Alexander A (Grace Charity Laury)': 1, 'Weisz, Mrs. Leopold (Mathilde Francoise Pede)': 1, 'Sobey, Mr. Samuel James Hayden': 1, 'Richard, Mr. Emile': 1, 'Newsom, Miss. Helen Monypeny': 1, 'Futrelle, Mr. Jacques Heath': 1, 'Osen, Mr. Olaf Elon': 1, 'Giglio, Mr. Victor': 1, 'Boulos, Mrs. Joseph (Sultana)': 1, 'Nysten, Miss. Anna Sofia': 1, 'Hakkarainen, Mrs. Pekka Pietari (Elin Matilda Dolck)': 1, 'Burke, Mr. Jeremiah': 1, 'Andrew, Mr. Edgardo Samuel': 1, 'Nicholls, Mr. Joseph Charles': 1, 'Andersson, Mr. August Edvard (\"Wennerstrom\")': 1, 'Ford, Miss. Robina Maggie \"Ruby\"': 1, 'Navratil, Mr. Michel (\"Louis M Hoffman\")': 1, 'Byles, Rev. Thomas Roussel Davids': 1, 'Bateman, Rev. Robert James': 1, 'Pears, Mrs. Thomas (Edith Wearne)': 1, 'Meo, Mr. Alfonzo': 1, 'van Billiard, Mr. Austin Blyler': 1, 'Olsen, Mr. Ole Martin': 1, 'Williams, Mr. Charles Duane': 1, 'Gilnagh, Miss. Katherine \"Katie\"': 1, 'Corn, Mr. Harry': 1, 'Smiljanic, Mr. Mile': 1, 'Sage, Master. Thomas Henry': 1, 'Cribb, Mr. John Hatfield': 1, 'Watt, Mrs. James (Elizabeth \"Bessie\" Inglis Milne)': 1, 'Bengtsson, Mr. John Viktor': 1, 'Calic, Mr. Jovo': 1, 'Panula, Master. Eino Viljami': 1, 'Goldsmith, Master. Frank John William \"Frankie\"': 1, 'Chibnall, Mrs. (Edith Martha Bowerman)': 1, 'Skoog, Mrs. William (Anna Bernhardina Karlsson)': 1, 'Baumann, Mr. John D': 1, 'Ling, Mr. Lee': 1, 'Van der hoef, Mr. Wyckoff': 1, 'Rice, Master. Arthur': 1, 'Johnson, Miss. Eleanor Ileen': 1, 'Sivola, Mr. Antti Wilhelm': 1, 'Smith, Mr. James Clinch': 1, 'Klasen, Mr. Klas Albin': 1, 'Lefebre, Master. Henry Forbes': 1, 'Isham, Miss. Ann Elizabeth': 1, 'Hale, Mr. Reginald': 1, 'Leonard, Mr. Lionel': 1, 'Sage, Miss. Constance Gladys': 1, 'Pernot, Mr. Rene': 1, 'Asplund, Master. Clarence Gustaf Hugo': 1, 'Becker, Master. Richard F': 1, 'Kink-Heilmann, Miss. Luise Gretchen': 1, 'Rood, Mr. Hugh Roscoe': 1, 'O\\'Brien, Mrs. Thomas (Johanna \"Hannah\" Godfrey)': 1, 'Romaine, Mr. Charles Hallace (\"Mr C Rolmane\")': 1, 'Bourke, Mr. John': 1, 'Turcin, Mr. Stjepan': 1, 'Pinsky, Mrs. (Rosa)': 1, 'Carbines, Mr. William': 1, 'Andersen-Jensen, Miss. Carla Christine Nielsine': 1, 'Navratil, Master. Michel M': 1, 'Brown, Mrs. James Joseph (Margaret Tobin)': 1, 'Lurette, Miss. Elise': 1, 'Mernagh, Mr. Robert': 1, 'Olsen, Mr. Karl Siegwart Andreas': 1, 'Madigan, Miss. Margaret \"Maggie\"': 1, 'Yrois, Miss. Henriette (\"Mrs Harbeck\")': 1, 'Vande Walle, Mr. Nestor Cyriel': 1, 'Sage, Mr. Frederick': 1, 'Johanson, Mr. Jakob Alfred': 1, 'Youseff, Mr. Gerious': 1, 'Cohen, Mr. Gurshon \"Gus\"': 1, 'Strom, Miss. Telma Matilda': 1, 'Backstrom, Mr. Karl Alfred': 1, 'Albimona, Mr. Nassef Cassem': 1, 'Carr, Miss. Helen \"Ellen\"': 1, 'Blank, Mr. Henry': 1, 'Ali, Mr. Ahmed': 1, 'Cameron, Miss. Clear Annie': 1, 'Perkin, Mr. John Henry': 1, 'Givard, Mr. Hans Kristensen': 1, 'Kiernan, Mr. Philip': 1, 'Newell, Miss. Madeleine': 1, 'Honkanen, Miss. Eliina': 1, 'Jacobsohn, Mr. Sidney Samuel': 1, 'Bazzani, Miss. Albina': 1, 'Harris, Mr. Walter': 1, 'Sunderland, Mr. Victor Francis': 1, 'Bracken, Mr. James H': 1, 'Green, Mr. George Henry': 1, 'Nenkoff, Mr. Christo': 1, 'Hoyt, Mr. Frederick Maxfield': 1, 'Berglund, Mr. Karl Ivar Sven': 1, 'Mellors, Mr. William John': 1, 'Lovell, Mr. John Hall (\"Henry\")': 1, 'Fahlstrom, Mr. Arne Jonas': 1, 'Lefebre, Miss. Mathilde': 1, 'Harris, Mrs. Henry Birkhardt (Irene Wallach)': 1, 'Larsson, Mr. Bengt Edvin': 1, 'Sjostedt, Mr. Ernst Adolf': 1, 'Asplund, Miss. Lillian Gertrud': 1, 'Leyson, Mr. Robert William Norman': 1, 'Harknett, Miss. Alice Phoebe': 1, 'Hold, Mr. Stephen': 1, 'Collyer, Miss. Marjorie \"Lottie\"': 1, 'Pengelly, Mr. Frederick William': 1, 'Hunt, Mr. George Henry': 1, 'Zabour, Miss. Thamine': 1, 'Murphy, Miss. Katherine \"Kate\"': 1, 'Coleridge, Mr. Reginald Charles': 1, 'Maenpaa, Mr. Matti Alexanteri': 1, 'Attalah, Mr. Sleiman': 1, 'Minahan, Dr. William Edward': 1, 'Lindahl, Miss. Agda Thorilda Viktoria': 1, 'Hamalainen, Mrs. William (Anna)': 1, 'Beckwith, Mr. Richard Leonard': 1, 'Carter, Rev. Ernest Courtenay': 1, 'Reed, Mr. James George': 1, 'Strom, Mrs. Wilhelm (Elna Matilda Persson)': 1, 'Stead, Mr. William Thomas': 1, 'Lobb, Mr. William Arthur': 1, 'Rosblom, Mrs. Viktor (Helena Wilhelmina)': 1, 'Touma, Mrs. Darwis (Hanne Youssef Razi)': 1, 'Thorne, Mrs. Gertrude Maybelle': 1, 'Cherry, Miss. Gladys': 1, 'Ward, Miss. Anna': 1, 'Parrish, Mrs. (Lutie Davis)': 1, 'Smith, Mr. Thomas': 1, 'Asplund, Master. Edvin Rojj Felix': 1, 'Taussig, Mr. Emil': 1, 'Harrison, Mr. William': 1, 'Henry, Miss. Delia': 1, 'Reeves, Mr. David': 1, 'Panula, Mr. Ernesti Arvid': 1, 'Persson, Mr. Ernst Ulrik': 1, 'Graham, Mrs. William Thompson (Edith Junkins)': 1, 'Bissette, Miss. Amelia': 1, 'Cairns, Mr. Alexander': 1, 'Tornquist, Mr. William Henry': 1, 'Mellinger, Mrs. (Elizabeth Anne Maidment)': 1, 'Natsch, Mr. Charles H': 1, 'Healy, Miss. Hanora \"Nora\"': 1, 'Andrews, Miss. Kornelia Theodosia': 1, 'Lindblom, Miss. Augusta Charlotta': 1, 'Parkes, Mr. Francis \"Frank\"': 1, 'Rice, Master. Eric': 1, 'Abbott, Mrs. Stanton (Rosa Hunt)': 1, 'Duane, Mr. Frank': 1, 'Olsson, Mr. Nils Johan Goransson': 1, 'de Pelsmaeker, Mr. Alfons': 1, 'Dorking, Mr. Edward Arthur': 1, 'Smith, Mr. Richard William': 1, 'Stankovic, Mr. Ivan': 1, 'de Mulder, Mr. Theodore': 1, 'Naidenoff, Mr. Penko': 1, 'Hosono, Mr. Masabumi': 1, 'Connolly, Miss. Kate': 1, 'Barber, Miss. Ellen \"Nellie\"': 1, 'Bishop, Mrs. Dickinson H (Helen Walton)': 1, 'Levy, Mr. Rene Jacques': 1, 'Haas, Miss. Aloisia': 1, 'Mineff, Mr. Ivan': 1, 'Lewy, Mr. Ervin G': 1, 'Hanna, Mr. Mansour': 1, 'Allison, Miss. Helen Loraine': 1, 'Saalfeld, Mr. Adolphe': 1, 'Baxter, Mrs. James (Helene DeLaudeniere Chaput)': 1, 'Kelly, Miss. Anna Katherine \"Annie Kate\"': 1, 'McCoy, Mr. Bernard': 1, 'Johnson, Mr. William Cahoone Jr': 1, 'Keane, Miss. Nora A': 1, 'Williams, Mr. Howard Hugh \"Harry\"': 1, 'Allison, Master. Hudson Trevor': 1, 'Fleming, Miss. Margaret': 1, 'Penasco y Castellana, Mrs. Victor de Satode (Maria Josefa Perez de Soto y Vallejo)': 1, 'Abelson, Mr. Samuel': 1, 'Francatelli, Miss. Laura Mabel': 1, 'Hays, Miss. Margaret Bechstein': 1, 'Ryerson, Miss. Emily Borie': 1, 'Lahtinen, Mrs. William (Anna Sylfven)': 1, 'Hendekovic, Mr. Ignjac': 1, 'Hart, Mr. Benjamin': 1, 'Nilsson, Miss. Helmina Josefina': 1, 'Kantor, Mrs. Sinai (Miriam Sternin)': 1, 'Moraweck, Dr. Ernest': 1, 'Wick, Miss. Mary Natalie': 1, 'Spedden, Mrs. Frederic Oakley (Margaretta Corning Stone)': 1, 'Dennis, Mr. Samuel': 1, 'Danoff, Mr. Yoto': 1, 'Slayter, Miss. Hilda Mary': 1, 'Caldwell, Mrs. Albert Francis (Sylvia Mae Harbaugh)': 1, 'Sage, Mr. George John Jr': 1, 'Young, Miss. Marie Grice': 1, 'Nysveen, Mr. Johan Hansen': 1, 'Ball, Mrs. (Ada E Hall)': 1, 'Goldsmith, Mrs. Frank John (Emily Alice Brown)': 1, 'Hippach, Miss. Jean Gertrude': 1, 'McCoy, Miss. Agnes': 1, 'Partner, Mr. Austen': 1, 'Graham, Mr. George Edward': 1, 'Vander Planke, Mr. Leo Edmondus': 1, 'Frauenthal, Mrs. Henry William (Clara Heinsheimer)': 1, 'Denkoff, Mr. Mitto': 1, 'Pears, Mr. Thomas Clinton': 1, 'Burns, Miss. Elizabeth Margaret': 1, 'Dahl, Mr. Karl Edwart': 1, 'Blackwell, Mr. Stephen Weart': 1, 'Navratil, Master. Edmond Roger': 1, 'Fortune, Miss. Alice Elizabeth': 1, 'Collander, Mr. Erik Gustaf': 1, 'Sedgwick, Mr. Charles Frederick Waddington': 1, 'Fox, Mr. Stanley Hubert': 1, 'Brown, Miss. Amelia \"Mildred\"': 1, 'Smith, Miss. Marion Elsie': 1, 'Davison, Mrs. Thomas Henry (Mary E Finck)': 1, 'Coutts, Master. William Loch \"William\"': 1, 'Dimic, Mr. Jovan': 1, 'Odahl, Mr. Nils Martin': 1, 'Williams-Lambert, Mr. Fletcher Fellows': 1, 'Elias, Mr. Tannous': 1, 'Arnold-Franchi, Mr. Josef': 1, 'Yousif, Mr. Wazli': 1, 'Vanden Steen, Mr. Leo Peter': 1, 'Bowerman, Miss. Elsie Edith': 1, 'Funk, Miss. Annie Clemmer': 1, 'McGovern, Miss. Mary': 1, 'Mockler, Miss. Helen Mary \"Ellie\"': 1, 'Skoog, Mr. Wilhelm': 1, 'del Carlo, Mr. Sebastiano': 1, 'Barbara, Mrs. (Catherine David)': 1, 'Asim, Mr. Adola': 1, \"O'Brien, Mr. Thomas\": 1, 'Adahl, Mr. Mauritz Nils Martin': 1, 'Warren, Mrs. Frank Manley (Anna Sophia Atkinson)': 1, 'Moussa, Mrs. (Mantoura Boulos)': 1, 'Jermyn, Miss. Annie': 1, 'Aubart, Mme. Leontine Pauline': 1, 'Harder, Mr. George Achilles': 1, 'Wiklund, Mr. Jakob Alfred': 1, 'Beavan, Mr. William Thomas': 1, 'Ringhini, Mr. Sante': 1, 'Palsson, Miss. Stina Viola': 1, 'Meyer, Mrs. Edgar Joseph (Leila Saks)': 1, 'Landergren, Miss. Aurora Adelia': 1, 'Widener, Mr. Harry Elkins': 1, 'Betros, Mr. Tannous': 1, 'Gustafsson, Mr. Karl Gideon': 1, 'Bidois, Miss. Rosalie': 1, 'Nakid, Miss. Maria (\"Mary\")': 1, 'Tikkanen, Mr. Juho': 1, 'Holverson, Mrs. Alexander Oskar (Mary Aline Towner)': 1, 'Plotcharsky, Mr. Vasil': 1, 'Davies, Mr. Charles Henry': 1, 'Goodwin, Master. Sidney Leonard': 1, 'Buss, Miss. Kate': 1, 'Sadlier, Mr. Matthew': 1, 'Lehmann, Miss. Bertha': 1, 'Carter, Mr. William Ernest': 1, 'Jansson, Mr. Carl Olof': 1, 'Gustafsson, Mr. Johan Birger': 1, 'Newell, Miss. Marjorie': 1, 'Sandstrom, Mrs. Hjalmar (Agnes Charlotta Bengtsson)': 1, 'Johansson, Mr. Erik': 1, 'Olsson, Miss. Elina': 1, 'McKane, Mr. Peter David': 1, 'Pain, Dr. Alfred': 1, 'Trout, Mrs. William H (Jessie L)': 1, 'Niskanen, Mr. Juha': 1, 'Adams, Mr. John': 1, 'Jussila, Miss. Mari Aina': 1, 'Hakkarainen, Mr. Pekka Pietari': 1, 'Oreskovic, Miss. Marija': 1, 'Gale, Mr. Shadrach': 1, 'Widegren, Mr. Carl/Charles Peter': 1, 'Richards, Master. William Rowe': 1, 'Birkeland, Mr. Hans Martin Monsen': 1, 'Lefebre, Miss. Ida': 1, 'Sdycoff, Mr. Todor': 1, 'Hart, Mr. Henry': 1, 'Minahan, Miss. Daisy E': 1, 'Cunningham, Mr. Alfred Fleming': 1, 'Sundman, Mr. Johan Julian': 1, 'Meek, Mrs. Thomas (Annie Louise Rowley)': 1, 'Drew, Mrs. James Vivian (Lulu Thorne Christian)': 1, 'Silven, Miss. Lyyli Karoliina': 1, 'Matthews, Mr. William John': 1, 'Van Impe, Miss. Catharina': 1, 'Gheorgheff, Mr. Stanio': 1, 'Charters, Mr. David': 1, 'Zimmerman, Mr. Leo': 1, 'Danbom, Mrs. Ernst Gilbert (Anna Sigrid Maria Brogren)': 1, 'Rosblom, Mr. Viktor Richard': 1, 'Wiseman, Mr. Phillippe': 1, 'Clarke, Mrs. Charles V (Ada Maria Winfield)': 1, 'Phillips, Miss. Kate Florence (\"Mrs Kate Louise Phillips Marshall\")': 1, 'Flynn, Mr. James': 1, 'Pickard, Mr. Berk (Berk Trembisky)': 1, 'Bjornstrom-Steffansson, Mr. Mauritz Hakan': 1, 'Thorneycroft, Mrs. Percival (Florence Kate White)': 1, 'Louch, Mrs. Charles Alexander (Alice Adelaide Slow)': 1, 'Kallio, Mr. Nikolai Erland': 1, 'Silvey, Mr. William Baird': 1, 'Carter, Miss. Lucile Polk': 1, 'Ford, Miss. Doolina Margaret \"Daisy\"': 1, 'Richards, Mrs. Sidney (Emily Hocking)': 1, 'Fortune, Mr. Mark': 1, 'Kvillner, Mr. Johan Henrik Johannesson': 1, 'Hart, Mrs. Benjamin (Esther Ada Bloomfield)': 1, 'Hampe, Mr. Leon': 1, 'Petterson, Mr. Johan Emil': 1, 'Reynaldo, Ms. Encarnacion': 1, 'Johannesen-Bratthammer, Mr. Bernt': 1, 'Dodge, Master. Washington': 1, 'Mellinger, Miss. Madeleine Violet': 1, 'Seward, Mr. Frederic Kimber': 1, 'Baclini, Miss. Marie Catherine': 1, 'Peuchen, Major. Arthur Godfrey': 1, 'West, Mr. Edwy Arthur': 1, 'Hagland, Mr. Ingvald Olai Olsen': 1, 'Foreman, Mr. Benjamin Laventall': 1, 'Goldenberg, Mr. Samuel L': 1, 'Peduzzi, Mr. Joseph': 1, 'Jalsevac, Mr. Ivan': 1, 'Millet, Mr. Francis Davis': 1, 'Kenyon, Mrs. Frederick R (Marion)': 1, 'Toomey, Miss. Ellen': 1, \"O'Connor, Mr. Maurice\": 1, 'Anderson, Mr. Harry': 1, 'Morley, Mr. William': 1, 'Gee, Mr. Arthur H': 1, 'Milling, Mr. Jacob Christian': 1, 'Maisner, Mr. Simon': 1, 'Goncalves, Mr. Manuel Estanslas': 1, 'Campbell, Mr. William': 1, 'Smart, Mr. John Montgomery': 1, 'Scanlan, Mr. James': 1, 'Baclini, Miss. Helene Barbara': 1, 'Keefe, Mr. Arthur': 1, 'Cacic, Mr. Luka': 1, 'West, Mrs. Edwy Arthur (Ada Mary Worth)': 1, 'Jerwan, Mrs. Amin S (Marie Marthe Thuillard)': 1, 'Strandberg, Miss. Ida Sofia': 1, 'Clifford, Mr. George Quincy': 1, 'Renouf, Mr. Peter Henry': 1, 'Braund, Mr. Lewis Richard': 1, 'Karlsson, Mr. Nils August': 1, 'Hirvonen, Miss. Hildur E': 1, 'Goodwin, Master. Harold Victor': 1, 'Frost, Mr. Anthony Wood \"Archie\"': 1, 'Rouse, Mr. Richard Henry': 1, 'Turkula, Mrs. (Hedwig)': 1, 'Bishop, Mr. Dickinson H': 1, 'Lefebre, Miss. Jeannie': 1, 'Hoyt, Mrs. Frederick Maxfield (Jane Anne Forby)': 1, 'Kent, Mr. Edward Austin': 1, 'Somerton, Mr. Francis William': 1, 'Coutts, Master. Eden Leslie \"Neville\"': 1, 'Hagland, Mr. Konrad Mathias Reiersen': 1, 'Windelov, Mr. Einar': 1, 'Molson, Mr. Harry Markland': 1, 'Artagaveytia, Mr. Ramon': 1, 'Stanley, Mr. Edward Roland': 1, 'Yousseff, Mr. Gerious': 1, 'Eustis, Miss. Elizabeth Mussey': 1, 'Shellard, Mr. Frederick William': 1, 'Allison, Mrs. Hudson J C (Bessie Waldo Daniels)': 1, 'Svensson, Mr. Olof': 1, 'Calic, Mr. Petar': 1, 'Canavan, Miss. Mary': 1, \"O'Sullivan, Miss. Bridget Mary\": 1, 'Laitinen, Miss. Kristina Sofia': 1, 'Maioni, Miss. Roberta': 1, 'Penasco y Castellana, Mr. Victor de Satode': 1, 'Quick, Mrs. Frederick Charles (Jane Richards)': 1, 'Bradley, Mr. George (\"George Arthur Brayton\")': 1, 'Olsen, Mr. Henry Margido': 1, 'Lang, Mr. Fang': 1, 'Daly, Mr. Eugene Patrick': 1, 'Webber, Mr. James': 1, 'McGough, Mr. James Robert': 1, 'Rothschild, Mrs. Martin (Elizabeth L. Barrett)': 1, 'Coleff, Mr. Satio': 1, 'Walker, Mr. William Anderson': 1, 'Lemore, Mrs. (Amelia Milley)': 1, 'Ryan, Mr. Patrick': 1, 'Angle, Mrs. William A (Florence \"Mary\" Agnes Hughes)': 1, 'Pavlovic, Mr. Stefo': 1, 'Perreault, Miss. Anne': 1, 'Vovk, Mr. Janko': 1, 'Lahoud, Mr. Sarkis': 1, 'Hippach, Mrs. Louis Albert (Ida Sophia Fischer)': 1, 'Kassem, Mr. Fared': 1, 'Farrell, Mr. James': 1, 'Ridsdale, Miss. Lucy': 1, 'Farthing, Mr. John': 1, 'Salonen, Mr. Johan Werner': 1, 'Hocking, Mr. Richard George': 1, 'Quick, Miss. Phyllis May': 1, 'Toufik, Mr. Nakli': 1, 'Elias, Mr. Joseph Jr': 1, 'Peter, Mrs. Catherine (Catherine Rizk)': 1, 'Cacic, Miss. Marija': 1, 'Hart, Miss. Eva Miriam': 1, 'Butt, Major. Archibald Willingham': 1, 'LeRoy, Miss. Bertha': 1, 'Risien, Mr. Samuel Beard': 1, 'Frolicher, Miss. Hedwig Margaritha': 1, 'Crosby, Miss. Harriet R': 1, 'Andersson, Miss. Ingeborg Constanzia': 1, 'Andersson, Miss. Sigrid Elisabeth': 1, 'Beane, Mr. Edward': 1, 'Douglas, Mr. Walter Donald': 1, 'Nicholson, Mr. Arthur Ernest': 1, 'Beane, Mrs. Edward (Ethel Clarke)': 1, 'Padro y Manent, Mr. Julian': 1, 'Goldsmith, Mr. Frank John': 1, 'Davies, Master. John Morgan Jr': 1, 'Thayer, Mr. John Borland Jr': 1, 'Sharp, Mr. Percival James R': 1, \"O'Brien, Mr. Timothy\": 1, 'Leeni, Mr. Fahim (\"Philip Zenni\")': 1, 'Ohman, Miss. Velin': 1, 'Wright, Mr. George': 1, 'Duff Gordon, Lady. (Lucille Christiana Sutherland) (\"Mrs Morgan\")': 1, 'Robbins, Mr. Victor': 1, 'Taussig, Mrs. Emil (Tillie Mandelbaum)': 1, 'de Messemaeker, Mrs. Guillaume Joseph (Emma)': 1, 'Morrow, Mr. Thomas Rowan': 1, 'Sivic, Mr. Husein': 1, 'Norman, Mr. Robert Douglas': 1, 'Simmons, Mr. John': 1, 'Meanwell, Miss. (Marion Ogden)': 1, 'Davies, Mr. Alfred J': 1, 'Stoytcheff, Mr. Ilia': 1, 'Palsson, Mrs. Nils (Alma Cornelia Berglund)': 1, 'Doharr, Mr. Tannous': 1, 'Jonsson, Mr. Carl': 1, 'Harris, Mr. George': 1, 'Appleton, Mrs. Edward Dale (Charlotte Lamson)': 1, 'Flynn, Mr. John Irwin (\"Irving\")': 1, 'Kelly, Miss. Mary': 1, 'Rush, Mr. Alfred George John': 1, 'Patchett, Mr. George': 1, 'Garside, Miss. Ethel': 1, 'Silvey, Mrs. William Baird (Alice Munger)': 1, 'Caram, Mrs. Joseph (Maria Elias)': 1, 'Jussila, Mr. Eiriik': 1, 'Christy, Miss. Julie Rachel': 1, 'Thayer, Mrs. John Borland (Marian Longstreth Morris)': 1, 'Downton, Mr. William James': 1, 'Ross, Mr. John Hugo': 1, 'Paulner, Mr. Uscher': 1, 'Taussig, Miss. Ruth': 1, 'Jarvis, Mr. John Denzil': 1, 'Frolicher-Stehli, Mr. Maxmillian': 1, 'Gilinski, Mr. Eliezer': 1, 'Murdlin, Mr. Joseph': 1, 'Rintamaki, Mr. Matti': 1, 'Stephenson, Mrs. Walter Bertram (Martha Eustis)': 1, 'Elsbury, Mr. William James': 1, 'Bourke, Miss. Mary': 1, 'Chapman, Mr. John Henry': 1, 'Van Impe, Mr. Jean Baptiste': 1, 'Leitch, Miss. Jessie Wills': 1, 'Johnson, Mr. Alfred': 1, 'Boulos, Mr. Hanna': 1, 'Duff Gordon, Sir. Cosmo Edmund (\"Mr Morgan\")': 1, 'Jacobsohn, Mrs. Sidney Samuel (Amy Frances Christy)': 1, 'Slabenoff, Mr. Petco': 1, 'Harrington, Mr. Charles H': 1, 'Torber, Mr. Ernst William': 1, 'Homer, Mr. Harry (\"Mr E Haven\")': 1, 'Lindell, Mr. Edvard Bengtsson': 1, 'Karaic, Mr. Milan': 1, 'Daniel, Mr. Robert Williams': 1, 'Laroche, Mrs. Joseph (Juliette Marie Louise Lafargue)': 1, 'Shutes, Miss. Elizabeth W': 1, 'Andersson, Mrs. Anders Johan (Alfrida Konstantia Brogren)': 1, 'Jardin, Mr. Jose Neto': 1, 'Murphy, Miss. Margaret Jane': 1, 'Horgan, Mr. John': 1, 'Brocklebank, Mr. William Alfred': 1, 'Herman, Miss. Alice': 1, 'Danbom, Mr. Ernst Gilbert': 1, 'Lobb, Mrs. William Arthur (Cordelia K Stanlick)': 1, 'Becker, Miss. Marion Louise': 1, 'Gavey, Mr. Lawrence': 1, 'Yasbeck, Mr. Antoni': 1, 'Kimball, Mr. Edwin Nelson Jr': 1, 'Nakid, Mr. Sahid': 1, 'Hansen, Mr. Henry Damsgaard': 1, 'Bowen, Mr. David John \"Dai\"': 1, 'Sutton, Mr. Frederick': 1, 'Kirkland, Rev. Charles Leonard': 1, 'Longley, Miss. Gretchen Fiske': 1, 'Bostandyeff, Mr. Guentcho': 1, \"O'Connell, Mr. Patrick D\": 1, 'Barkworth, Mr. Algernon Henry Wilson': 1, 'Lundahl, Mr. Johan Svensson': 1, 'Stahelin-Maeglin, Dr. Max': 1, 'Parr, Mr. William Henry Marsh': 1, 'Skoog, Miss. Mabel': 1, 'Davis, Miss. Mary': 1, 'Leinonen, Mr. Antti Gustaf': 1, 'Collyer, Mr. Harvey': 1, 'Panula, Mrs. Juha (Maria Emilia Ojala)': 1, 'Thorneycroft, Mr. Percival': 1, 'Jensen, Mr. Hans Peder': 1, 'Sagesser, Mlle. Emma': 1, 'Skoog, Miss. Margit Elizabeth': 1, 'Foo, Mr. Choong': 1, 'Baclini, Miss. Eugenie': 1, 'Harper, Mr. Henry Sleeper': 1, 'Cor, Mr. Liudevit': 1, 'Simonius-Blumer, Col. Oberst Alfons': 1, 'Willey, Mr. Edward': 1, 'Stanley, Miss. Amy Zillah Elsie': 1, 'Mitkoff, Mr. Mito': 1, 'Doling, Miss. Elsie': 1, 'Kalvik, Mr. Johannes Halvorsen': 1, 'O\\'Leary, Miss. Hanora \"Norah\"': 1, 'Hegarty, Miss. Hanora \"Nora\"': 1, 'Hickman, Mr. Leonard Mark': 1, 'Radeff, Mr. Alexander': 1, 'Bourke, Mrs. John (Catherine)': 1, 'Eitemiller, Mr. George Floyd': 1, 'Newell, Mr. Arthur Webster': 1, 'Frauenthal, Dr. Henry William': 1, 'Badt, Mr. Mohamed': 1, 'Colley, Mr. Edward Pomeroy': 1, 'Coleff, Mr. Peju': 1, 'Lindqvist, Mr. Eino William': 1, 'Hickman, Mr. Lewis': 1, 'Butler, Mr. Reginald Fenton': 1, 'Rommetvedt, Mr. Knud Paust': 1, 'Cook, Mr. Jacob': 1, 'Taylor, Mrs. Elmer Zebley (Juliet Cummins Wright)': 1, 'Brown, Mrs. Thomas William Solomon (Elizabeth Catherine Ford)': 1, 'Davidson, Mr. Thornton': 1, 'Mitchell, Mr. Henry Michael': 1, 'Wilhelms, Mr. Charles': 1, 'Watson, Mr. Ennis Hastings': 1, 'Edvardsson, Mr. Gustaf Hjalmar': 1, 'Sawyer, Mr. Frederick Charles': 1, 'Turja, Miss. Anna Sofia': 1, 'Goodwin, Mrs. Frederick (Augusta Tyler)': 1, 'Cardeza, Mr. Thomas Drake Martinez': 1, 'Peters, Miss. Katie': 1, 'Hassab, Mr. Hammad': 1, 'Olsvigen, Mr. Thor Anderson': 1, 'Goodwin, Mr. Charles Edward': 1, 'Brown, Mr. Thomas William Solomon': 1, 'Laroche, Mr. Joseph Philippe Lemercier': 1, 'Panula, Mr. Jaako Arnold': 1, 'Dakic, Mr. Branko': 1, 'Fischer, Mr. Eberhard Thelander': 1, 'Madill, Miss. Georgette Alexandra': 1, 'Dick, Mr. Albert Adrian': 1, 'Karun, Miss. Manca': 1, 'Lam, Mr. Ali': 1, 'Saad, Mr. Khalil': 1, 'Weir, Col. John': 1, 'Chapman, Mr. Charles Henry': 1, 'Kelly, Mr. James': 1, 'Mullens, Miss. Katherine \"Katie\"': 1, 'Thayer, Mr. John Borland': 1, 'Humblen, Mr. Adolf Mathias Nicolai Olsen': 1, 'Astor, Mrs. John Jacob (Madeleine Talmadge Force)': 1, 'Silverthorne, Mr. Spencer Victor': 1, 'Barbara, Miss. Saiide': 1, 'Gallagher, Mr. Martin': 1, 'Hansen, Mr. Henrik Juul': 1, 'Morley, Mr. Henry Samuel (\"Mr Henry Marshall\")': 1, 'Kelly, Mrs. Florence \"Fannie\"': 1, 'Calderhead, Mr. Edward Pennington': 1, 'Cleaver, Miss. Alice': 1, 'Moubarek, Master. Halim Gonios (\"William George\")': 1, 'Mayne, Mlle. Berthe Antonine (\"Mrs de Villiers\")': 1, 'Klaber, Mr. Herman': 1, 'Taylor, Mr. Elmer Zebley': 1, 'Larsson, Mr. August Viktor': 1, 'Greenberg, Mr. Samuel': 1, 'Soholt, Mr. Peter Andreas Lauritz Andersen': 1, 'Endres, Miss. Caroline Louise': 1, 'Troutt, Miss. Edwina Celia \"Winnie\"': 1, 'McEvoy, Mr. Michael': 1, 'Johnson, Mr. Malkolm Joackim': 1, 'Harper, Miss. Annie Jessie \"Nina\"': 1, 'Jensen, Mr. Svend Lauritz': 1, 'Gillespie, Mr. William Henry': 1, 'Hodges, Mr. Henry Price': 1, 'Chambers, Mr. Norman Campbell': 1, 'Oreskovic, Mr. Luka': 1, 'Renouf, Mrs. Peter Henry (Lillian Jefferys)': 1, 'Mannion, Miss. Margareth': 1, 'Bryhl, Mr. Kurt Arnold Gottfrid': 1, 'Ilmakangas, Miss. Pieta Sofia': 1, 'Allen, Miss. Elisabeth Walton': 1, 'Hassan, Mr. Houssein G N': 1, 'Knight, Mr. Robert J': 1, 'Berriman, Mr. William John': 1, 'Troupiansky, Mr. Moses Aaron': 1, 'Williams, Mr. Leslie': 1, 'Ford, Mrs. Edward (Margaret Ann Watson)': 1, 'Lesurer, Mr. Gustave J': 1, 'Ivanoff, Mr. Kanio': 1, 'Nankoff, Mr. Minko': 1, 'Hawksford, Mr. Walter James': 1, 'Cavendish, Mr. Tyrell William': 1, 'Ryerson, Miss. Susan Parker \"Suzette\"': 1, 'McNamee, Mr. Neal': 1, 'Stranden, Mr. Juho': 1, 'Crosby, Capt. Edward Gifford': 1, 'Abbott, Mr. Rossmore Edward': 1, 'Sinkkonen, Miss. Anna': 1, 'Marvin, Mr. Daniel Warner': 1, 'Connaghton, Mr. Michael': 1, 'Wells, Miss. Joan': 1, 'Moor, Master. Meier': 1, 'Vande Velde, Mr. Johannes Joseph': 1, 'Jonkoff, Mr. Lalio': 1, 'Herman, Mrs. Samuel (Jane Laver)': 1, 'Hamalainen, Master. Viljo': 1, 'Carlsson, Mr. August Sigfrid': 1, 'Bailey, Mr. Percy Andrew': 1, 'Theobald, Mr. Thomas Leonard': 1, 'Rothes, the Countess. of (Lucy Noel Martha Dyer-Edwards)': 1, 'Garfirth, Mr. John': 1, 'Nirva, Mr. Iisakki Antino Aijo': 1, 'Barah, Mr. Hanna Assi': 1, 'Carter, Mrs. William Ernest (Lucile Polk)': 1, 'Eklund, Mr. Hans Linus': 1, 'Hogeboom, Mrs. John C (Anna Andrews)': 1, 'Brewe, Dr. Arthur Jackson': 1, 'Mangan, Miss. Mary': 1, 'Moran, Mr. Daniel J': 1, 'Gronnestad, Mr. Daniel Danielsen': 1, 'Lievens, Mr. Rene Aime': 1, 'Jensen, Mr. Niels Peder': 1, 'Mack, Mrs. (Mary)': 1, 'Elias, Mr. Dibo': 1, 'Hocking, Mrs. Elizabeth (Eliza Needs)': 1, 'Myhrman, Mr. Pehr Fabian Oliver Malkolm': 1, 'Tobin, Mr. Roger': 1, 'Emanuel, Miss. Virginia Ethel': 1, 'Kilgannon, Mr. Thomas J': 1, 'Robert, Mrs. Edward Scott (Elisabeth Walton McMillan)': 1, 'Ayoub, Miss. Banoura': 1, 'Dick, Mrs. Albert Adrian (Vera Gillespie)': 1, 'Long, Mr. Milton Clyde': 1, 'Johnston, Mr. Andrew G': 1, 'Ali, Mr. William': 1, 'Harmer, Mr. Abraham (David Lishin)': 1, 'Sjoblom, Miss. Anna Sofia': 1, 'Rice, Master. George Hugh': 1, 'Dean, Master. Bertram Vere': 1, 'Guggenheim, Mr. Benjamin': 1, 'Keane, Mr. Andrew \"Andy\"': 1, 'Gaskell, Mr. Alfred': 1, 'Sage, Miss. Stella Anna': 1, 'Hoyt, Mr. William Fisher': 1, 'Dantcheff, Mr. Ristiu': 1, 'Otter, Mr. Richard': 1, 'Leader, Dr. Alice (Farnham)': 1, 'Osman, Mrs. Mara': 1, 'Ibrahim Shawah, Mr. Yousseff': 1, 'Van Impe, Mrs. Jean Baptiste (Rosalie Paula Govaert)': 1, 'Ponesell, Mr. Martin': 1, 'Collyer, Mrs. Harvey (Charlotte Annie Tate)': 1, 'Carter, Master. William Thornton II': 1, 'Thomas, Master. Assad Alexander': 1, 'Hedman, Mr. Oskar Arvid': 1, 'Johansson, Mr. Karl Johan': 1, 'Andrews, Mr. Thomas Jr': 1, 'Pettersson, Miss. Ellen Natalia': 1, 'Meyer, Mr. August': 1, 'Chambers, Mrs. Norman Campbell (Bertha Griggs)': 1, 'Alexander, Mr. William': 1, 'Lester, Mr. James': 1, 'Slemen, Mr. Richard James': 1, 'Andersson, Miss. Ebba Iris Alfrida': 1, 'Tomlin, Mr. Ernest Portage': 1, 'Fry, Mr. Richard': 1, 'Heininen, Miss. Wendla Maria': 1, 'Mallet, Mr. Albert': 1, 'Holm, Mr. John Fredrik Alexander': 1, 'Skoog, Master. Karl Thorsten': 1, 'Hays, Mrs. Charles Melville (Clara Jennings Gregg)': 1, 'Lulic, Mr. Nikola': 1, 'Reuchlin, Jonkheer. John George': 1, 'Moor, Mrs. (Beila)': 1, 'Panula, Master. Urho Abraham': 1, 'Flynn, Mr. John': 1, 'Lam, Mr. Len': 1, 'Mallet, Master. Andre': 1, 'McCormack, Mr. Thomas Joseph': 1, 'Stone, Mrs. George Nelson (Martha Evelyn)': 1, 'Yasbeck, Mrs. Antoni (Selini Alexander)': 1, 'Richards, Master. George Sibley': 1, 'Saad, Mr. Amin': 1, 'Augustsson, Mr. Albert': 1, 'Allum, Mr. Owen George': 1, 'Compton, Miss. Sara Rebecca': 1, 'Pasic, Mr. Jakob': 1, 'Sirota, Mr. Maurice': 1, 'Chip, Mr. Chang': 1, 'Marechal, Mr. Pierre': 1, 'Alhomaki, Mr. Ilmari Rudolf': 1, 'Mudd, Mr. Thomas Charles': 1, 'Serepeca, Miss. Augusta': 1, 'Lemberopolous, Mr. Peter L': 1, 'Culumovic, Mr. Jeso': 1, 'Abbing, Mr. Anthony': 1, 'Sage, Mr. Douglas Bullen': 1, 'Markoff, Mr. Marin': 1, 'Harper, Rev. John': 1, 'Goldenberg, Mrs. Samuel L (Edwiga Grabowska)': 1, 'Andersson, Master. Sigvard Harald Elias': 1, 'Svensson, Mr. Johan': 1, 'Boulos, Miss. Nourelain': 1, 'Lines, Miss. Mary Conover': 1, 'Carter, Mrs. Ernest Courtenay (Lilian Hughes)': 1, 'Aks, Mrs. Sam (Leah Rosen)': 1, 'Wick, Mrs. George Dennick (Mary Hitchcock)': 1, 'Daly, Mr. Peter Denis ': 1, 'Baclini, Mrs. Solomon (Latifa Qurban)': 1, 'Razi, Mr. Raihed': 1, 'Hansen, Mr. Claus Peter': 1, 'Giles, Mr. Frederick Edward': 1, 'Swift, Mrs. Frederick Joel (Margaret Welles Barron)': 1, 'Sage, Miss. Dorothy Edith \"Dolly\"': 1, 'Gill, Mr. John William': 1, 'Bystrom, Mrs. (Karolina)': 1, 'Duran y More, Miss. Asuncion': 1, 'Roebling, Mr. Washington Augustus II': 1, 'van Melkebeke, Mr. Philemon': 1, 'Johnson, Master. Harold Theodor': 1, 'Balkic, Mr. Cerin': 1, 'Beckwith, Mrs. Richard Leonard (Sallie Monypeny)': 1, 'Carlsson, Mr. Frans Olof': 1, 'Vander Cruyssen, Mr. Victor': 1, 'Abelson, Mrs. Samuel (Hannah Wizosky)': 1, 'Najib, Miss. Adele Kiamie \"Jane\"': 1, 'Gustafsson, Mr. Alfred Ossian': 1, 'Petroff, Mr. Nedelio': 1, 'Laleff, Mr. Kristo': 1, 'Potter, Mrs. Thomas Jr (Lily Alexenia Wilson)': 1, 'Shelley, Mrs. William (Imanita Parrish Hall)': 1, 'Markun, Mr. Johann': 1, 'Dahlberg, Miss. Gerda Ulrika': 1, 'Banfield, Mr. Frederick James': 1, 'Sutehall, Mr. Henry Jr': 1, 'Rice, Mrs. William (Margaret Norton)': 1, 'Montvila, Rev. Juozas': 1, 'Graham, Miss. Margaret Edith': 1, 'Johnston, Miss. Catherine Helen \"Carrie\"': 1, 'Behr, Mr. Karl Howell': 1, 'Dooley, Mr. Patrick': 1})\n",
      "number of the instances: 891\n",
      "number of unique names: 891\n",
      "most frequently appeared name: van Melkebeke, Mr. Philemon\n",
      "maximum number of appearance: 1\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "count_no=[]\n",
    "count = Counter(df['Name'])\n",
    "for i in count:\n",
    "    count_no.append(count[i])\n",
    "print(count)\n",
    "print('number of the instances:',len(df['Name']))\n",
    "print('number of unique names:',len(count))\n",
    "print('most frequently appeared name:',max(count))\n",
    "print('maximum number of appearance:',max(count_no))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZlXGioiHsNs_"
   },
   "source": [
    "Which is what we expected. We drop 'Name':"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "K9g-mMFPsTkB"
   },
   "outputs": [],
   "source": [
    "df = df.drop(columns=\"Name\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RST5RERoq4pk"
   },
   "source": [
    "We check the feature 'Ticket' which is supposed to be similar to 'Name':"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 459,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 124
    },
    "colab_type": "code",
    "id": "S6iY5ohCobqj",
    "outputId": "df6d3bd6-cbce-474d-fc4e-cd4825586d23"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'347082': 7, '1601': 7, 'CA. 2343': 7, '3101295': 6, 'CA 2144': 6, '347088': 6, '382652': 5, 'S.O.C. 14879': 5, '349909': 4, '347077': 4, '19950': 4, 'W./C. 6608': 4, '4133': 4, 'LINE': 4, '113781': 4, '17421': 4, 'PC 17757': 4, '113760': 4, '2666': 4, '347742': 3, 'SC/Paris 2123': 3, 'PC 17572': 3, 'C.A. 34651': 3, '371110': 3, '230080': 3, '363291': 3, '35273': 3, 'C.A. 31921': 3, '110152': 3, 'PC 17755': 3, '110413': 3, 'PC 17582': 3, 'PC 17760': 3, '13502': 3, '239853': 3, 'F.C.C. 13529': 3, '29106': 3, '345773': 3, '248727': 3, '24160': 3, '113803': 2, '237736': 2, 'PP 9549': 2, '239865': 2, 'PC 17569': 2, 'PC 17604': 2, '113789': 2, '345764': 2, '2651': 2, '11668': 2, '349237': 2, '113572': 2, '36973': 2, '2661': 2, '248738': 2, '364516': 2, '3101278': 2, 'C.A. 2315': 2, '231919': 2, '244367': 2, '35281': 2, '110465': 2, '2665': 2, '2627': 2, 'PC 17558': 2, '2668': 2, '7534': 2, 'PC 17593': 2, '2678': 2, 'STON/O2. 3101279': 2, 'C.A. 33112': 2, '113776': 2, '113505': 2, '230136': 2, '370365': 2, '364849': 2, '347054': 2, '2699': 2, '243847': 2, '19943': 2, '367230': 2, '19928': 2, '250649': 2, '11751': 2, '244252': 2, 'A/5. 3336': 2, '370129': 2, '230433': 2, '113798': 2, '250644': 2, 'C.A. 2673': 2, '19877': 2, '11967': 2, '367226': 2, 'PC 17758': 2, 'P/PP 3381': 2, 'PC 17485': 2, '11767': 2, 'PC 17608': 2, '36928': 2, '16966': 2, '111361': 2, 'PC 17611': 2, 'C.A. 37671': 2, '2691': 2, 'PC 17477': 2, '2653': 2, '28403': 2, '347080': 2, '250655': 2, '376564': 2, '13507': 2, '17453': 2, '31027': 2, '36947': 2, '26360': 2, '12749': 2, 'PC 17761': 2, 'WE/P 5735': 2, '2908': 2, 'A/4 48871': 2, '358585': 2, '220845': 2, '2659': 2, '54636': 2, '19996': 2, '29750': 2, '17474': 2, '250647': 2, '113806': 2, '392096': 2, 'S.O./P.P. 3': 2, 'W./C. 6607': 2, 'S.C./PARIS 2079': 2, 'A/5 21171': 1, 'PC 17599': 1, 'STON/O2. 3101282': 1, '373450': 1, '330877': 1, '17463': 1, '113783': 1, 'A/5. 2151': 1, '350406': 1, '248706': 1, '244373': 1, '345763': 1, '2649': 1, '248698': 1, '330923': 1, '113788': 1, '2631': 1, '330959': 1, '349216': 1, 'PC 17601': 1, '335677': 1, 'C.A. 24579': 1, '2677': 1, 'A./5. 2152': 1, '7546': 1, '349253': 1, '330958': 1, 'S.C./A.4. 23567': 1, '370371': 1, '14311': 1, '2662': 1, 'A/4. 39886': 1, '2926': 1, '113509': 1, '19947': 1, 'C.A. 31026': 1, '2697': 1, '2669': 1, 'PC 17605': 1, 'C.A. 29395': 1, 'S.P. 3464': 1, '3101281': 1, '315151': 1, 'C.A. 33111': 1, '2680': 1, '348123': 1, '349208': 1, '374746': 1, '345767': 1, '345779': 1, '330932': 1, '113059': 1, 'SO/C 14885': 1, 'SOTON/OQ 392086': 1, '343275': 1, '343276': 1, '347466': 1, 'W.E.P. 5734': 1, '364500': 1, '374910': 1, 'PC 17754': 1, 'PC 17759': 1, '349245': 1, '349215': 1, '7540': 1, '3101276': 1, '349207': 1, '343120': 1, '312991': 1, '349249': 1, '324669': 1, '4136': 1, 'STON/O 2. 3101294': 1, '370369': 1, 'A4. 54510': 1, '27267': 1, '370372': 1, 'C 17369': 1, '347061': 1, '349241': 1, 'SOTON/O.Q. 3101307': 1, 'A/5. 3337': 1, '228414': 1, 'C.A. 29178': 1, 'SC/PARIS 2133': 1, '11752': 1, '347081': 1, '365222': 1, '231945': 1, '350043': 1, '244310': 1, 'S.O.P. 1166': 1, 'A.5. 11206': 1, 'A/5. 851': 1, 'Fa 265302': 1, 'PC 17597': 1, '35851': 1, 'SOTON/OQ 392090': 1, '315037': 1, '371362': 1, 'C.A. 33595': 1, '347068': 1, '315093': 1, 'PC 17318': 1, '111240': 1, 'STON/O 2. 3101280': 1, '17764': 1, '350404': 1, 'PC 17595': 1, '250653': 1, 'SC/PARIS 2131': 1, '315153': 1, '113767': 1, '111428': 1, '349247': 1, '234604': 1, '28424': 1, '350046': 1, 'PC 17610': 1, '368703': 1, '4579': 1, '370370': 1, '248747': 1, '345770': 1, '3101264': 1, '2628': 1, 'A/5 3540': 1, '367231': 1, '112277': 1, 'SOTON/O.Q. 3101311': 1, 'F.C.C. 13528': 1, 'A/5 21174': 1, '250646': 1, '367229': 1, 'STON/O2. 3101283': 1, '11813': 1, 'W/C 14208': 1, 'SOTON/OQ 392089': 1, '220367': 1, '21440': 1, '349234': 1, 'PP 4348': 1, 'SW/PP 751': 1, 'A/5 21173': 1, '236171': 1, '347067': 1, '237442': 1, 'C.A. 29566': 1, 'W./C. 6609': 1, '26707': 1, '28665': 1, 'SCO/W 1585': 1, 'W./C. 14263': 1, 'STON/O 2. 3101275': 1, '2694': 1, '347071': 1, '362316': 1, '113514': 1, '2650': 1, 'PC 17585': 1, '384461': 1, '112059': 1, '382649': 1, 'C.A. 17248': 1, '347083': 1, 'PC 17596': 1, '370375': 1, '347073': 1, '336439': 1, '347464': 1, '345778': 1, 'A/5. 10482': 1, '113056': 1, '349239': 1, '345774': 1, '349206': 1, '237798': 1, '370373': 1, 'SC/Paris 2163': 1, '349236': 1, '349233': 1, 'PC 17612': 1, '2693': 1, '19988': 1, '9234': 1, '226593': 1, 'A/5 2466': 1, '250651': 1, '349243': 1, '347470': 1, '29011': 1, 'A/5 21172': 1, '349219': 1, '234818': 1, '345364': 1, '28551': 1, '113043': 1, '349225': 1, '7598': 1, '113784': 1, '248740': 1, '244361': 1, '229236': 1, '248733': 1, '31418': 1, '386525': 1, '315088': 1, '7267': 1, '113510': 1, '2695': 1, '2647': 1, '345783': 1, '237671': 1, '330931': 1, '330980': 1, 'SC/PARIS 2167': 1, 'SOTON/O.Q. 3101310': 1, 'C 7076': 1, '110813': 1, '2626': 1, '14313': 1, '11765': 1, '3101267': 1, '323951': 1, 'C 7077': 1, '113503': 1, '2648': 1, '347069': 1, 'STON/O 2. 3101293': 1, '349227': 1, '27849': 1, '367655': 1, 'SC 1748': 1, '350034': 1, '3101277': 1, '350052': 1, '350407': 1, '244278': 1, '240929': 1, 'STON/O 2. 3101289': 1, '341826': 1, '4137': 1, '315096': 1, '28664': 1, '347064': 1, '312992': 1, '349222': 1, '394140': 1, 'STON/O 2. 3101269': 1, '343095': 1, '28220': 1, '250652': 1, '28228': 1, '349254': 1, 'A/5. 13032': 1, '315082': 1, 'A/4. 34244': 1, '2003': 1, '364851': 1, 'SOTON/O.Q. 392078': 1, '110564': 1, 'SC/AH 3085': 1, 'STON/O 2. 3101274': 1, 'C.A. 18723': 1, '345769': 1, '347076': 1, '230434': 1, '65306': 1, '33638': 1, '113794': 1, '113786': 1, '65303': 1, '113051': 1, 'A/5 2817': 1, '349240': 1, '13509': 1, '17464': 1, 'F.C.C. 13531': 1, '371060': 1, '19952': 1, '364506': 1, '111320': 1, '234360': 1, 'A/S 2816': 1, 'SOTON/O.Q. 3101306': 1, '113792': 1, '36209': 1, '323592': 1, '315089': 1, 'SC/AH Basle 541': 1, '7553': 1, '3460': 1, '350060': 1, '3101298': 1, '239854': 1, 'A/5 3594': 1, '4134': 1, '11771': 1, 'A.5. 18509': 1, '65304': 1, 'SOTON/OQ 3101317': 1, '113787': 1, 'PC 17609': 1, 'A/4 45380': 1, 'C.A. 6212': 1, '350035': 1, '315086': 1, '364846': 1, '330909': 1, '4135': 1, '111427': 1, 'C 4001': 1, '382651': 1, 'SOTON/OQ 3101316': 1, 'PC 17473': 1, 'PC 17603': 1, '349209': 1, '36967': 1, 'C.A. 34260': 1, '226875': 1, '349242': 1, '349252': 1, '2624': 1, '2700': 1, '367232': 1, 'W./C. 14258': 1, 'PC 17483': 1, '3101296': 1, '29104': 1, '2641': 1, '2690': 1, '315084': 1, '113050': 1, '364498': 1, '13568': 1, '693': 1, 'SC/PARIS 2146': 1, '244358': 1, '330979': 1, '2620': 1, '347085': 1, '113807': 1, '11755': 1, '345572': 1, '372622': 1, '349251': 1, '218629': 1, 'SOTON/OQ 392082': 1, 'SOTON/O.Q. 392087': 1, '349205': 1, '2686': 1, '350417': 1, 'S.W./PP 752': 1, '11769': 1, 'PC 17474': 1, '14312': 1, 'A/4. 20589': 1, '243880': 1, '2689': 1, 'STON/O 2. 3101286': 1, '237789': 1, '13049': 1, '3411': 1, '237565': 1, '13567': 1, '14973': 1, 'A./5. 3235': 1, 'STON/O 2. 3101273': 1, 'A/5 3902': 1, '364848': 1, 'SC/AH 29037': 1, '2664': 1, '349214': 1, '113796': 1, '364511': 1, '111426': 1, '349910': 1, '349246': 1, '113804': 1, 'SOTON/O.Q. 3101305': 1, '370377': 1, '364512': 1, '31028': 1, '11753': 1, '350029': 1, '36963': 1, '219533': 1, '349224': 1, '334912': 1, '27042': 1, '347743': 1, '13214': 1, '112052': 1, '237668': 1, 'STON/O 2. 3101292': 1, '350050': 1, '349231': 1, '13213': 1, 'S.O./P.P. 751': 1, 'CA. 2314': 1, '349221': 1, '8475': 1, '330919': 1, '365226': 1, '349223': 1, '29751': 1, '2623': 1, '5727': 1, '349210': 1, 'STON/O 2. 3101285': 1, '234686': 1, '312993': 1, 'A/5 3536': 1, 'F.C. 12750': 1, 'C.A. 24580': 1, '244270': 1, '239856': 1, '349912': 1, '342826': 1, '4138': 1, '330935': 1, '6563': 1, '349228': 1, '350036': 1, '349256': 1, '2672': 1, '113800': 1, '248731': 1, '363592': 1, '35852': 1, '348121': 1, 'PC 17475': 1, '36864': 1, '350025': 1, '223596': 1, 'PC 17476': 1, 'PC 17482': 1, '113028': 1, '7545': 1, '348124': 1, '34218': 1, '36568': 1, '347062': 1, '350048': 1, '12233': 1, '250643': 1, '315094': 1, '36866': 1, '236853': 1, 'STON/O2. 3101271': 1, '239855': 1, '28425': 1, '233639': 1, '349201': 1, '349218': 1, '16988': 1, '376566': 1, 'STON/O 2. 3101288': 1, '250648': 1, '113773': 1, '335097': 1, '29103': 1, '345780': 1, '349204': 1, '350042': 1, '29108': 1, '363294': 1, 'SOTON/O2 3101272': 1, '2663': 1, '347074': 1, '112379': 1, '364850': 1, '8471': 1, '345781': 1, '350047': 1, '2674': 1, '29105': 1, '347078': 1, '383121': 1, '36865': 1, '2687': 1, '113501': 1, 'SOTON/O.Q. 3101312': 1, '374887': 1, '3101265': 1, '12460': 1, 'PC 17600': 1, '349203': 1, '28213': 1, '17465': 1, '349244': 1, '2685': 1, '2625': 1, '347089': 1, '347063': 1, '112050': 1, '347087': 1, '248723': 1, '3474': 1, '28206': 1, '364499': 1, '112058': 1, 'STON/O2. 3101290': 1, 'C 7075': 1, '315098': 1, '19972': 1, '368323': 1, '367228': 1, '2671': 1, '347468': 1, '2223': 1, 'PC 17756': 1, '315097': 1, '392092': 1, '11774': 1, 'SOTON/O2 3101287': 1, '2683': 1, '315090': 1, 'C.A. 5547': 1, '349213': 1, '347060': 1, 'PC 17592': 1, '392091': 1, '113055': 1, '2629': 1, '350026': 1, '28134': 1, '17466': 1, '233866': 1, '236852': 1, 'SC/PARIS 2149': 1, 'PC 17590': 1, '345777': 1, '349248': 1, '695': 1, '345765': 1, '2667': 1, '349212': 1, '349217': 1, '349257': 1, '7552': 1, 'C.A./SOTON 34068': 1, 'SOTON/OQ 392076': 1, '211536': 1, '112053': 1, '111369': 1, '370376': 1})\n",
      "number of the instances: 891\n",
      "number of unique tickets: 681\n",
      "most frequently appeared ticket: WE/P 5735\n",
      "maximum number of apperance: 7\n"
     ]
    }
   ],
   "source": [
    "count_no=[]\n",
    "count = Counter(df['Ticket'])\n",
    "for i in count:\n",
    "    count_no.append(count[i])\n",
    "print(count)\n",
    "print('number of the instances:',len(df['Ticket']))\n",
    "print('number of unique tickets:',len(count))\n",
    "print('most frequently appeared ticket:',max(count))\n",
    "print('maximum number of apperance:',max(count_no))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "c-ZKuGCKtMzV"
   },
   "source": [
    "So 'Ticket' is a sparse feature rather than unique for every instance. But since it is difficult to generalize (understand the similarities betweeen instances), we drop it for now:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tuMK2l6hnqd2"
   },
   "outputs": [],
   "source": [
    "df = df.drop(columns=\"Ticket\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-92cGLjse2Pu"
   },
   "source": [
    "We treat 'Cabin' as a nominal feature for now and investigate it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 461,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 107
    },
    "colab_type": "code",
    "id": "KWFh0hi-oA7d",
    "outputId": "bfb973c7-3cfc-4379-b52b-61110e2f341e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({nan: 687, 'G6': 4, 'C23 C25 C27': 4, 'B96 B98': 4, 'F33': 3, 'E101': 3, 'F2': 3, 'D': 3, 'C22 C26': 3, 'C123': 2, 'D33': 2, 'C52': 2, 'B28': 2, 'C83': 2, 'F G73': 2, 'D26': 2, 'B58 B60': 2, 'C2': 2, 'E33': 2, 'F4': 2, 'D36': 2, 'C93': 2, 'C78': 2, 'D35': 2, 'B77': 2, 'E67': 2, 'C125': 2, 'B49': 2, 'C65': 2, 'B57 B59 B63 B66': 2, 'B18': 2, 'C124': 2, 'B35': 2, 'E44': 2, 'C92': 2, 'D20': 2, 'E25': 2, 'B22': 2, 'C68': 2, 'C126': 2, 'B51 B53 B55': 2, 'B5': 2, 'B20': 2, 'E24': 2, 'E8': 2, 'E121': 2, 'D17': 2, 'C85': 1, 'E46': 1, 'C103': 1, 'D56': 1, 'A6': 1, 'B78': 1, 'B30': 1, 'E31': 1, 'A5': 1, 'D10 D12': 1, 'C110': 1, 'F E69': 1, 'D47': 1, 'B86': 1, 'B19': 1, 'A7': 1, 'C49': 1, 'A32': 1, 'B4': 1, 'B80': 1, 'A31': 1, 'D15': 1, 'C87': 1, 'B94': 1, 'C99': 1, 'C118': 1, 'D7': 1, 'A19': 1, 'C106': 1, 'E36': 1, 'C54': 1, 'C7': 1, 'E34': 1, 'C32': 1, 'C91': 1, 'E40': 1, 'T': 1, 'C128': 1, 'D37': 1, 'E50': 1, 'C82': 1, 'E10': 1, 'A34': 1, 'C104': 1, 'C111': 1, 'E38': 1, 'D21': 1, 'E12': 1, 'E63': 1, 'A14': 1, 'B37': 1, 'C30': 1, 'B79': 1, 'D46': 1, 'B73': 1, 'C95': 1, 'B38': 1, 'B39': 1, 'C86': 1, 'C70': 1, 'A16': 1, 'C101': 1, 'A10': 1, 'E68': 1, 'B41': 1, 'A20': 1, 'D19': 1, 'D50': 1, 'D9': 1, 'A23': 1, 'B50': 1, 'A26': 1, 'D48': 1, 'E58': 1, 'B71': 1, 'D49': 1, 'F G63': 1, 'C62 C64': 1, 'C90': 1, 'C45': 1, 'B101': 1, 'D45': 1, 'C46': 1, 'D30': 1, 'D11': 1, 'E77': 1, 'F38': 1, 'B3': 1, 'D6': 1, 'B82 B84': 1, 'A36': 1, 'B102': 1, 'B69': 1, 'E49': 1, 'C47': 1, 'D28': 1, 'E17': 1, 'A24': 1, 'C50': 1, 'B42': 1, 'C148': 1})\n",
      "number of the instances: 891\n",
      "number of unique cabins: 148\n",
      "maximum number of apperance: 687\n"
     ]
    }
   ],
   "source": [
    "count_no=[]\n",
    "count = Counter(df['Cabin'])\n",
    "for i in count:\n",
    "    count_no.append(count[i])\n",
    "print(count)\n",
    "print('number of the instances:',len(df['Cabin']))\n",
    "print('number of unique cabins:',len(count))\n",
    "print('maximum number of apperance:',max(count_no))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "k_-ejR83ghUE"
   },
   "source": [
    "We can see that this feature is also quite sqarse and there are a lot of missing values for many instances.\n",
    "Therefore, we use the first alphabet appeared as the value of the feature and label the missing value with a different string. After that, we use one-hot encoding to encode this featrue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "b7Cx_ACghLaR"
   },
   "outputs": [],
   "source": [
    "df['Cabin'] = df['Cabin'].replace(np.nan, 'U', regex=True)\n",
    "for i in range(df.shape[0]):\n",
    "    df.loc[i,'Cabin'] = df.loc[i,'Cabin'][0]\n",
    "df = pd.concat([df,pd.get_dummies(df['Cabin'], prefix='Cabin')],axis=1)\n",
    "df = df.drop(columns=\"Cabin\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RTKCNkxWhr6_"
   },
   "source": [
    "It is worth noting that, after checking the test data, there is no value 'T' ('Cabin' started with alphabet 'T'). Therefore, we drop the 'T' column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MIHvvTvMiFv1"
   },
   "outputs": [],
   "source": [
    "df = df.drop(columns=\"Cabin_T\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FWKnRsy6iQa7"
   },
   "source": [
    "### Numerical Feature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NF6hbaLTijuc"
   },
   "source": [
    "'Age', 'SibSp'(no. of siblings / spouses aboard the Titanic), 'Parch'(no. of parents / children aboard the Titanic) and 'Fare'(Passenger fare) have numerical values, some are integers while others are can be non-integers. They can be directly used as labels but there are again missing values. After trial and error, we cound that it is most effective by filling those missing values with the median of all values in that that particalr feature:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "J9yiIDpqiYMc"
   },
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer \n",
    "imputer = SimpleImputer(missing_values=np.nan, strategy='median')\n",
    "df[['Age']] = imputer.fit_transform(df[['Age']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AgYSk51d0dDL"
   },
   "source": [
    "### Exception"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wOgQDvPl0lJ9"
   },
   "source": [
    "'Embarked' fearture is supposed to be a nominal featrue; however, we discovered that it will give a higher accuracy if it is encoded as a ordinal feature (is misisng values under 'embarked' is encoded as another integer as well): "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JE8dlvpN0487"
   },
   "outputs": [],
   "source": [
    "Embarked_map = {'S':0, 'C': 1, 'Q': 2}\n",
    "df['Embarked'] = df['Embarked'].map(Embarked_map)\n",
    "df['Embarked'] = df['Embarked'].replace(np.nan, 3, regex=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Cu6mpBatlR3s"
   },
   "source": [
    "move the label to the last column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "udpyfbty4DY7"
   },
   "outputs": [],
   "source": [
    "Survived = df[\"Survived\"]\n",
    "df = df.drop(columns=\"Survived\")\n",
    "df = pd.concat([df,Survived],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 467,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 222
    },
    "colab_type": "code",
    "id": "w7ob0kzs0T-n",
    "outputId": "560bd965-43f3-4184-8d5b-64cd59483d54"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>Cabin_A</th>\n",
       "      <th>Cabin_B</th>\n",
       "      <th>Cabin_C</th>\n",
       "      <th>Cabin_D</th>\n",
       "      <th>Cabin_E</th>\n",
       "      <th>Cabin_F</th>\n",
       "      <th>Cabin_G</th>\n",
       "      <th>Cabin_U</th>\n",
       "      <th>Survived</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pclass  Sex   Age  SibSp  ...  Cabin_F  Cabin_G  Cabin_U  Survived\n",
       "0       3    1  22.0      1  ...        0        0        1         0\n",
       "1       1    0  38.0      1  ...        0        0        0         1\n",
       "2       3    0  26.0      0  ...        0        0        1         1\n",
       "3       1    0  35.0      1  ...        0        0        0         1\n",
       "4       3    1  35.0      0  ...        0        0        1         0\n",
       "\n",
       "[5 rows x 16 columns]"
      ]
     },
     "execution_count": 467,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FAjQDjpar1Bc"
   },
   "source": [
    "## Feature scaling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "s8Yjk_fb1iRq"
   },
   "source": [
    "We tried different order. Applyinh z-scoring first then max normalization gives better prediction accuracy for this dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CLTXUVfSz0u6"
   },
   "source": [
    "###z-scoring"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "X8YhbUCf5L4R"
   },
   "source": [
    "We considered the possibility of only doing z-scoreing for numerical freatures while leaving categorical features unchanged. However, z-scoring all features gives a better accuracy for this dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xkGpfTIqr5WY"
   },
   "outputs": [],
   "source": [
    "data=df.to_numpy()\n",
    "n1 = data.shape[0]\n",
    "n2 = data.shape[1]\n",
    "m=int(0.8*n1)\n",
    "for i in range(n2-1):\n",
    "    data[:,i] = (data[:,i] - data[:,i].mean())/data[:,i].std()  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7NnGC2jUsXig"
   },
   "source": [
    "### Max normalization\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ABOyayKo2pzz"
   },
   "source": [
    "We considered the possibility of doing max normalization for all freaturesd. However, only applying max normalization for numerical freatures while leaving categorical features unchanged gives a better accuracy for this dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9e9CyU4v7m9N"
   },
   "outputs": [],
   "source": [
    "for i in range(n1):\n",
    "        data[i,2]=data[i,2]/abs(max(data[:,2]))\n",
    "        data[i,5]=data[i,5]/abs(max(data[:,5]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iXKrktUdCx-x"
   },
   "source": [
    "To double check if there are still NaN enties in that dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 471,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "_qCY4-6r2O9f",
    "outputId": "a66f01f7-3c7e-483f-e3ee-41b5109eddbd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 471,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.isnan(data).any()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "B9poF9qpCskW"
   },
   "source": [
    "To check which entries is/are NaN if there is any:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 472,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "Nme_E6kh2vfI",
    "outputId": "4a02d25d-cca2-4988-aab3-70e2c3be2721"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "nan=[]\n",
    "for i in range(n1):\n",
    "    for j in range(n2):\n",
    "        if np.isnan(data[i,j]):\n",
    "            nan.append([i,j])\n",
    "print(nan)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0or6pt2Zsb7C"
   },
   "source": [
    "#Split into training set and testing set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "r74QzXdwiMc9"
   },
   "outputs": [],
   "source": [
    "train=data[:m,:]\n",
    "test=data[m:-1,:]\n",
    "X = data[:,0:(n2-1)]\n",
    "y = data[:,(n2-1)]\n",
    "X_train = train[:,0:(n2-1)]\n",
    "y_train = train[:,(n2-1)]\n",
    "X_test = test[:,0:(n2-1)]\n",
    "y_test = test[:,(n2-1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "b89XZF52Gxi5"
   },
   "source": [
    "# Machine Learning Model Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sNd4Ujx7HEuy"
   },
   "source": [
    "We tried a variety of machine learning (ML) models to see which one suits our task the most. \n",
    "This models include:\n",
    "K nearest neighbors classifier,\n",
    "Support vector machine,\n",
    "Gaussian process classifier,\n",
    "Decision tree classifier,\n",
    "Random forest classifier,\n",
    "Multilayer perceptron classifier,\n",
    "Artificial neural network classifier,\n",
    "Logistic regression classifier,\n",
    "AdaBoost classifier,\n",
    "Naive Bayes classifier,\n",
    "Quadratic discriminant analysis classifier,\n",
    "XGBoost classifier,\n",
    "Gradient boost classifier,\n",
    "Ensemble learning classifier (by voting)\n",
    "Ensemble learning classifier (by stacking)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "X1MBCOewHKv7"
   },
   "source": [
    "The available data are splitted into training data and test data first with 8:2 ratio after encoding phase. Then all models are given the identical encoded training data and certain metric to compare which one is better at the given task after being optimized.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "orDMv2o3HWYd"
   },
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.experimental import enable_hist_gradient_boosting\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "\n",
    "names = [\"Nearest Neighbors\", \"Linear SVM\", \"RBF SVM\", \"Gaussian Process\",\n",
    "          \"Decision Tree\", \"Random Forest\", \"Neural Net\", \"AdaBoost\",\n",
    "          \"Naive Bayes\", \"QDA\",\"GradientBoosting\",\"HistGradientBoosting\",\"LogisticRegression\"]\n",
    "\n",
    "\n",
    "\n",
    "classifiers = [\n",
    "    KNeighborsClassifier(n_neighbors=7,weights='distance'),\n",
    "    SVC(kernel=\"linear\", C=0.025),\n",
    "    SVC(gamma=2, C=1),\n",
    "    GaussianProcessClassifier(1.0 * RBF(1.0)),\n",
    "    DecisionTreeClassifier(max_depth=5),\n",
    "    RandomForestClassifier(max_depth=5, n_estimators=10, max_features=1),\n",
    "    MLPClassifier(alpha=1, max_iter=1000),\n",
    "    AdaBoostClassifier(),\n",
    "    GaussianNB(),\n",
    "    QuadraticDiscriminantAnalysis(),\n",
    "    GradientBoostingClassifier(n_estimators=100, learning_rate=1.0,max_depth=1, random_state=0),\n",
    "    HistGradientBoostingClassifier(max_iter=100),\n",
    "    LogisticRegression(C=0.123456789, solver=\"lbfgs\", max_iter=5000)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NnkqmbwtG6ZG"
   },
   "source": [
    "# Parameter Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "m9I1CW5YHSBs"
   },
   "source": [
    "The optimization is done by tuning the hyperparameters of the given ML model. The selection of the optimal set of hyperparameters is done through grid search. \n",
    "\n",
    "Grid search is a brute force method to find the optimal set of hyper parameters. Basically, for a given ML model, assume it has n number of adjustable hyperparameters, then we have a search space of n dimensions, in which any point corresponds to a specific set of hyperparameters. The hyperparameters can be either continuous or discrete. For example, for support vector machine (SVM), we can choose its kernel type and the strength of the regularization as dimension x and y, where x is discrete with values linear, poly, rbf, sigmoid, precomputed or callable and y a positive real number. If we discretize y then the search space is the 2-dimensional grid formed by all possible combinations of x and y. The idea of grid search is to execute all possible instances in the grids and to select the best set of hyperparameters. Just like the strength of the regularization for SVM, many hyperparameters are continuous and the interval is infinitely large, therefore practically there is no way to exhaust all possible combinations. A trick is used here to make such a formidable task possible. For continuous parameters, we try to find  the optimal order of magnitude first. Still use SVM as an example, we can try all the combination of all values of x with y set to 10^-3,10^-2,10^-1,10^0,10^1,10^2,10^3, when the best set amongst the combinations of these values are selected, say 101, then set y to from 1 to 100 and choose the best y. This approach can drastically reduce the amount of computations needed to be done without missing the optimal solution, assuming the performance of the ML model does not change abruptly with respect to the values of its hyperparameters within the same order of magnitude.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 418
    },
    "colab_type": "code",
    "id": "t233dbIsriRn",
    "outputId": "4ec47b0f-d9cc-4a55-9ebd-2892904d27d6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-197-d4a65cf6b8c0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mSVC\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuned_parameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m )\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Best parameters set found on development set:\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    708\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    709\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 710\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    711\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    712\u001b[0m         \u001b[0;31m# For multi-metric evaluation, store the best_index_, best_params_ and\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1149\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1150\u001b[0m         \u001b[0;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1151\u001b[0;31m         \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1152\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[0;34m(candidate_params)\u001b[0m\n\u001b[1;32m    687\u001b[0m                                \u001b[0;32mfor\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    688\u001b[0m                                in product(candidate_params,\n\u001b[0;32m--> 689\u001b[0;31m                                           cv.split(X, y, groups)))\n\u001b[0m\u001b[1;32m    690\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    691\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1005\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1006\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1007\u001b[0;31m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1008\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1009\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    833\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    834\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 835\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    836\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    837\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    752\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    753\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 754\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    755\u001b[0m             \u001b[0;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    756\u001b[0m             \u001b[0;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    207\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 209\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    210\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    588\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    589\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 590\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    591\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    592\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    254\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 256\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    257\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    258\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    254\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 256\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    257\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    258\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, error_score)\u001b[0m\n\u001b[1;32m    513\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    514\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 515\u001b[0;31m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    516\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    517\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/svm/_base.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    197\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m         \u001b[0mseed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrnd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miinfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'i'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m         \u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msolver_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_seed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m         \u001b[0;31m# see comment on the other call to np.iinfo in this file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/svm/_base.py\u001b[0m in \u001b[0;36m_dense_fit\u001b[0;34m(self, X, y, sample_weight, solver_type, kernel, random_seed)\u001b[0m\n\u001b[1;32m    256\u001b[0m                 \u001b[0mcache_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcache_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcoef0\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoef0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    257\u001b[0m                 \u001b[0mgamma\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gamma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepsilon\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepsilon\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 258\u001b[0;31m                 max_iter=self.max_iter, random_seed=random_seed)\n\u001b[0m\u001b[1;32m    259\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    260\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_warn_from_fit_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "tuned_parameters = [{'kernel': ['rbf'], 'gamma': [10, 1, 1e-1,1e-2, 1e-3],\n",
    "                     'C': [1, 10, 100, 1000, 10000]},\n",
    "                    {'kernel': ['linear'], 'C': [1, 10, 100, 1000, 10000]}]\n",
    "\n",
    "\n",
    "print()\n",
    "\n",
    "clf = GridSearchCV(\n",
    "    SVC(), tuned_parameters, scoring='accuracy',cv=10\n",
    ")\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best parameters set found on development set:\")\n",
    "print()\n",
    "print(clf.best_params_)\n",
    "print()\n",
    "print(\"Grid scores on development set:\")\n",
    "print()\n",
    "means = clf.cv_results_['mean_test_score']\n",
    "stds = clf.cv_results_['std_test_score']\n",
    "for mean, std, params in zip(means, stds, clf.cv_results_['params']):\n",
    "    print(\"%0.3f (+/-%0.03f) for %r\"\n",
    "          % (mean, std * 2, params))\n",
    "print()\n",
    "\n",
    "print(\"Detailed classification report:\")\n",
    "print()\n",
    "print(\"The model is trained on the full development set.\")\n",
    "print(\"The scores are computed on the full evaluation set.\")\n",
    "print()\n",
    "y_true, y_pred = y_test, clf.predict(X_test)\n",
    "print(classification_report(y_true, y_pred))\n",
    "print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "pQ5I9bVkrJvq",
    "outputId": "6a4e5ff8-2f82-46cf-bb56-09bedd0d9afe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best parameters set found on development set:\n",
      "\n",
      "{'C': 0.5, 'gamma': 0.004, 'kernel': 'rbf', 'probability': True}\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "0.615 (+/-0.034) for {'C': 0.4, 'gamma': 0.001, 'kernel': 'rbf', 'probability': True}\n",
      "0.615 (+/-0.034) for {'C': 0.4, 'gamma': 0.001, 'kernel': 'rbf', 'probability': False}\n",
      "0.701 (+/-0.071) for {'C': 0.4, 'gamma': 0.002, 'kernel': 'rbf', 'probability': True}\n",
      "0.701 (+/-0.071) for {'C': 0.4, 'gamma': 0.002, 'kernel': 'rbf', 'probability': False}\n",
      "0.768 (+/-0.098) for {'C': 0.4, 'gamma': 0.003, 'kernel': 'rbf', 'probability': True}\n",
      "0.768 (+/-0.098) for {'C': 0.4, 'gamma': 0.003, 'kernel': 'rbf', 'probability': False}\n",
      "0.775 (+/-0.090) for {'C': 0.4, 'gamma': 0.004, 'kernel': 'rbf', 'probability': True}\n",
      "0.775 (+/-0.090) for {'C': 0.4, 'gamma': 0.004, 'kernel': 'rbf', 'probability': False}\n",
      "0.674 (+/-0.032) for {'C': 0.5, 'gamma': 0.001, 'kernel': 'rbf', 'probability': True}\n",
      "0.674 (+/-0.032) for {'C': 0.5, 'gamma': 0.001, 'kernel': 'rbf', 'probability': False}\n",
      "0.756 (+/-0.136) for {'C': 0.5, 'gamma': 0.002, 'kernel': 'rbf', 'probability': True}\n",
      "0.756 (+/-0.136) for {'C': 0.5, 'gamma': 0.002, 'kernel': 'rbf', 'probability': False}\n",
      "0.775 (+/-0.089) for {'C': 0.5, 'gamma': 0.003, 'kernel': 'rbf', 'probability': True}\n",
      "0.775 (+/-0.089) for {'C': 0.5, 'gamma': 0.003, 'kernel': 'rbf', 'probability': False}\n",
      "0.781 (+/-0.090) for {'C': 0.5, 'gamma': 0.004, 'kernel': 'rbf', 'probability': True}\n",
      "0.781 (+/-0.090) for {'C': 0.5, 'gamma': 0.004, 'kernel': 'rbf', 'probability': False}\n",
      "0.695 (+/-0.069) for {'C': 0.6, 'gamma': 0.001, 'kernel': 'rbf', 'probability': True}\n",
      "0.695 (+/-0.069) for {'C': 0.6, 'gamma': 0.001, 'kernel': 'rbf', 'probability': False}\n",
      "0.767 (+/-0.096) for {'C': 0.6, 'gamma': 0.002, 'kernel': 'rbf', 'probability': True}\n",
      "0.767 (+/-0.096) for {'C': 0.6, 'gamma': 0.002, 'kernel': 'rbf', 'probability': False}\n",
      "0.781 (+/-0.090) for {'C': 0.6, 'gamma': 0.003, 'kernel': 'rbf', 'probability': True}\n",
      "0.781 (+/-0.090) for {'C': 0.6, 'gamma': 0.003, 'kernel': 'rbf', 'probability': False}\n",
      "0.781 (+/-0.090) for {'C': 0.6, 'gamma': 0.004, 'kernel': 'rbf', 'probability': True}\n",
      "0.781 (+/-0.090) for {'C': 0.6, 'gamma': 0.004, 'kernel': 'rbf', 'probability': False}\n",
      "0.684 (+/-0.079) for {'C': 0.7, 'gamma': 0.001, 'kernel': 'rbf', 'probability': True}\n",
      "0.684 (+/-0.079) for {'C': 0.7, 'gamma': 0.001, 'kernel': 'rbf', 'probability': False}\n",
      "0.775 (+/-0.091) for {'C': 0.7, 'gamma': 0.002, 'kernel': 'rbf', 'probability': True}\n",
      "0.775 (+/-0.091) for {'C': 0.7, 'gamma': 0.002, 'kernel': 'rbf', 'probability': False}\n",
      "0.781 (+/-0.090) for {'C': 0.7, 'gamma': 0.003, 'kernel': 'rbf', 'probability': True}\n",
      "0.781 (+/-0.090) for {'C': 0.7, 'gamma': 0.003, 'kernel': 'rbf', 'probability': False}\n",
      "0.781 (+/-0.090) for {'C': 0.7, 'gamma': 0.004, 'kernel': 'rbf', 'probability': True}\n",
      "0.781 (+/-0.090) for {'C': 0.7, 'gamma': 0.004, 'kernel': 'rbf', 'probability': False}\n",
      "0.704 (+/-0.079) for {'C': 0.8, 'gamma': 0.001, 'kernel': 'rbf', 'probability': True}\n",
      "0.704 (+/-0.079) for {'C': 0.8, 'gamma': 0.001, 'kernel': 'rbf', 'probability': False}\n",
      "0.781 (+/-0.090) for {'C': 0.8, 'gamma': 0.002, 'kernel': 'rbf', 'probability': True}\n",
      "0.781 (+/-0.090) for {'C': 0.8, 'gamma': 0.002, 'kernel': 'rbf', 'probability': False}\n",
      "0.781 (+/-0.090) for {'C': 0.8, 'gamma': 0.003, 'kernel': 'rbf', 'probability': True}\n",
      "0.781 (+/-0.090) for {'C': 0.8, 'gamma': 0.003, 'kernel': 'rbf', 'probability': False}\n",
      "0.781 (+/-0.090) for {'C': 0.8, 'gamma': 0.004, 'kernel': 'rbf', 'probability': True}\n",
      "0.781 (+/-0.090) for {'C': 0.8, 'gamma': 0.004, 'kernel': 'rbf', 'probability': False}\n",
      "0.714 (+/-0.094) for {'C': 0.9, 'gamma': 0.001, 'kernel': 'rbf', 'probability': True}\n",
      "0.714 (+/-0.094) for {'C': 0.9, 'gamma': 0.001, 'kernel': 'rbf', 'probability': False}\n",
      "0.781 (+/-0.090) for {'C': 0.9, 'gamma': 0.002, 'kernel': 'rbf', 'probability': True}\n",
      "0.781 (+/-0.090) for {'C': 0.9, 'gamma': 0.002, 'kernel': 'rbf', 'probability': False}\n",
      "0.781 (+/-0.090) for {'C': 0.9, 'gamma': 0.003, 'kernel': 'rbf', 'probability': True}\n",
      "0.781 (+/-0.090) for {'C': 0.9, 'gamma': 0.003, 'kernel': 'rbf', 'probability': False}\n",
      "0.781 (+/-0.090) for {'C': 0.9, 'gamma': 0.004, 'kernel': 'rbf', 'probability': True}\n",
      "0.781 (+/-0.090) for {'C': 0.9, 'gamma': 0.004, 'kernel': 'rbf', 'probability': False}\n",
      "0.753 (+/-0.115) for {'C': 1, 'gamma': 0.001, 'kernel': 'rbf', 'probability': True}\n",
      "0.753 (+/-0.115) for {'C': 1, 'gamma': 0.001, 'kernel': 'rbf', 'probability': False}\n",
      "0.781 (+/-0.090) for {'C': 1, 'gamma': 0.002, 'kernel': 'rbf', 'probability': True}\n",
      "0.781 (+/-0.090) for {'C': 1, 'gamma': 0.002, 'kernel': 'rbf', 'probability': False}\n",
      "0.781 (+/-0.090) for {'C': 1, 'gamma': 0.003, 'kernel': 'rbf', 'probability': True}\n",
      "0.781 (+/-0.090) for {'C': 1, 'gamma': 0.003, 'kernel': 'rbf', 'probability': False}\n",
      "0.781 (+/-0.090) for {'C': 1, 'gamma': 0.004, 'kernel': 'rbf', 'probability': True}\n",
      "0.781 (+/-0.090) for {'C': 1, 'gamma': 0.004, 'kernel': 'rbf', 'probability': False}\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.82      0.87      0.85       114\n",
      "         1.0       0.74      0.67      0.70        64\n",
      "\n",
      "    accuracy                           0.80       178\n",
      "   macro avg       0.78      0.77      0.78       178\n",
      "weighted avg       0.79      0.80      0.80       178\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score\n",
    "tuned_parameters = [{'kernel': ['rbf'], 'gamma': [0.001,0.002,0.003,0.004],\n",
    "                     'C': [0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1],'probability':[True,False]}]\n",
    "\n",
    "\n",
    "print()\n",
    "\n",
    "clf = GridSearchCV(\n",
    "    SVC(), tuned_parameters, scoring='accuracy',cv=10\n",
    ")\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best parameters set found on development set:\")\n",
    "print()\n",
    "print(clf.best_params_)\n",
    "print()\n",
    "print(\"Grid scores on development set:\")\n",
    "print()\n",
    "means = clf.cv_results_['mean_test_score']\n",
    "stds = clf.cv_results_['std_test_score']\n",
    "for mean, std, params in zip(means, stds, clf.cv_results_['params']):\n",
    "    print(\"%0.3f (+/-%0.03f) for %r\"\n",
    "          % (mean, std * 2, params))\n",
    "print()\n",
    "\n",
    "print(\"Detailed classification report:\")\n",
    "print()\n",
    "print(\"The model is trained on the full development set.\")\n",
    "print(\"The scores are computed on the full evaluation set.\")\n",
    "print()\n",
    "y_true, y_pred = y_test, clf.predict(X_test)\n",
    "print(classification_report(y_true, y_pred))\n",
    "print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xdciB29yG9F6"
   },
   "source": [
    "# Model Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QF0XFLC7HaAh"
   },
   "source": [
    "In the grid search phase, the optimal set of hyperparameters are selected based on the accuracy on the pre-split test data result. The models are trained using the splited traning set earlier. Afterwards, the model with selected hyperparameters are evaluated with 10-fold cross-validation to provide a benchmark to compare to the real submission scores. For the sake of practicality and the interest of time limit, the grid search is not done exhuastively with respect to all adjustable hyperparameters the some of  the ranges for numerical values are more based on educated guess and intuition."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nKPs8jvGXtTr"
   },
   "source": [
    "##Import Test Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VWUjBvZsXw20"
   },
   "outputs": [],
   "source": [
    "url2 = 'https://raw.githubusercontent.com/zyzhang1130/CE9010/master/Titanic/test.csv'\n",
    "df2 = pd.read_csv(url2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 484,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 237
    },
    "colab_type": "code",
    "id": "Z1PvK7GLpCyt",
    "outputId": "a8a3e8bd-b2aa-4ca0-85b8-ca62d504dbca"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>892</td>\n",
       "      <td>3</td>\n",
       "      <td>Kelly, Mr. James</td>\n",
       "      <td>male</td>\n",
       "      <td>34.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>330911</td>\n",
       "      <td>7.8292</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>893</td>\n",
       "      <td>3</td>\n",
       "      <td>Wilkes, Mrs. James (Ellen Needs)</td>\n",
       "      <td>female</td>\n",
       "      <td>47.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>363272</td>\n",
       "      <td>7.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>894</td>\n",
       "      <td>2</td>\n",
       "      <td>Myles, Mr. Thomas Francis</td>\n",
       "      <td>male</td>\n",
       "      <td>62.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>240276</td>\n",
       "      <td>9.6875</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>895</td>\n",
       "      <td>3</td>\n",
       "      <td>Wirz, Mr. Albert</td>\n",
       "      <td>male</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>315154</td>\n",
       "      <td>8.6625</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>896</td>\n",
       "      <td>3</td>\n",
       "      <td>Hirvonen, Mrs. Alexander (Helga E Lindqvist)</td>\n",
       "      <td>female</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3101298</td>\n",
       "      <td>12.2875</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Pclass  ... Cabin Embarked\n",
       "0          892       3  ...   NaN        Q\n",
       "1          893       3  ...   NaN        S\n",
       "2          894       2  ...   NaN        Q\n",
       "3          895       3  ...   NaN        S\n",
       "4          896       3  ...   NaN        S\n",
       "\n",
       "[5 rows x 11 columns]"
      ]
     },
     "execution_count": 484,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BUX2hWHQhdBB"
   },
   "source": [
    "## Test Set Pre-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hS9DoqADhQBf"
   },
   "source": [
    "we preprocess the testset in exactally the same manner as training set: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 485,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 222
    },
    "colab_type": "code",
    "id": "iybum0d9hiQn",
    "outputId": "42ca9c3a-0795-4556-f22b-5864e4adc7a5"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>Cabin_A</th>\n",
       "      <th>Cabin_B</th>\n",
       "      <th>Cabin_C</th>\n",
       "      <th>Cabin_D</th>\n",
       "      <th>Cabin_E</th>\n",
       "      <th>Cabin_F</th>\n",
       "      <th>Cabin_G</th>\n",
       "      <th>Cabin_U</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>34.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.8292</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>62.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9.6875</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.6625</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>12.2875</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pclass  Sex   Age  SibSp  Parch  ...  Cabin_D  Cabin_E  Cabin_F  Cabin_G  Cabin_U\n",
       "0       3    1  34.5      0      0  ...        0        0        0        0        1\n",
       "1       3    0  47.0      1      0  ...        0        0        0        0        1\n",
       "2       2    1  62.0      0      0  ...        0        0        0        0        1\n",
       "3       3    1  27.0      0      0  ...        0        0        0        0        1\n",
       "4       3    0  22.0      1      1  ...        0        0        0        0        1\n",
       "\n",
       "[5 rows x 15 columns]"
      ]
     },
     "execution_count": 485,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Embarked_map = {'S':0, 'C': 1, 'Q': 2}\n",
    "sex_map = {'male': 1, 'female': 0}\n",
    "\n",
    "\n",
    "df2['Embarked'] = df2['Embarked'].map(Embarked_map)\n",
    "df2['Sex'] = df2['Sex'].map(sex_map)\n",
    "\n",
    "\n",
    "df2 = df2.drop(columns=\"PassengerId\")\n",
    "df2 = df2.drop(columns=\"Name\")\n",
    "df2 = df2.drop(columns=\"Ticket\")\n",
    "\n",
    "#data cleaning (replace this missing numerical feature entries with the median of that entry. Can try other methods)\n",
    "imputer = SimpleImputer(missing_values=np.nan, strategy='median')\n",
    "df2[['Age']] = imputer.fit_transform(df2[['Age']])\n",
    "df2[['Fare']] = imputer.fit_transform(df2[['Fare']])\n",
    "\n",
    "\n",
    "#data cleaning (replace NaN in categorical features with the same string can try other methods)\n",
    "df2['Embarked'] = df2['Embarked'].replace(np.nan, 3, regex=True)\n",
    "df2['Cabin'] = df2['Cabin'].replace(np.nan, 'U', regex=True)\n",
    "for i in range(df2.shape[0]):\n",
    "    df2.loc[i,'Cabin'] = df2.loc[i,'Cabin'][0]\n",
    "df2 = pd.concat([df2,pd.get_dummies(df2['Cabin'], prefix='Cabin')],axis=1)\n",
    "df2 = df2.drop(columns=\"Cabin\")\n",
    "\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 486,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "VfWNhvqAoLnW",
    "outputId": "64dac7b5-3799-454f-db22-64ac244ad743"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "data2=df2.to_numpy()\n",
    "n1 = data2.shape[0]\n",
    "n2 = data2.shape[1]\n",
    "print(np.isnan(data2).any())\n",
    "nan=[]\n",
    "for i in range(n1):\n",
    "    for j in range(n2):\n",
    "        if np.isnan(data2[i,j]):\n",
    "            nan.append([i,j])\n",
    "print(nan)\n",
    "\n",
    "for i in range(n2-1):\n",
    "    data2[:,i] = (data2[:,i] - data2[:,i].mean())/data2[:,i].std()  \n",
    "for i in range(n1):\n",
    "        data2[i,2]=data2[i,2]/abs(max(data2[:,2]))\n",
    "        data2[i,5]=data2[i,5]/abs(max(data2[:,5]))\n",
    "X_test2=data2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "faRkqkeo6lxC"
   },
   "source": [
    "## Support Vector Machine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hNQP5lDWTd0I"
   },
   "source": [
    "###Cross-validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NkYDXjQY6rIj"
   },
   "source": [
    "Support vector machine is already tuned as an example in the previous section"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dxDJEfMzZb6U"
   },
   "source": [
    "### Generating Predicion Result for submission in .csv format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "wudR6ySwTW8j",
    "outputId": "584d3e3d-b6e2-44b2-d8e2-ad11890df451"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.784494\n"
     ]
    }
   ],
   "source": [
    "clf = SVC(C= 0.5, gamma= 0.004, kernel= 'rbf', probability= True)\n",
    "score=cross_validate(clf, X, y, cv=10, scoring=\"accuracy\")[\"test_score\"].mean()\n",
    "print(f\"{score:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WnXdlR9eZTZB"
   },
   "outputs": [],
   "source": [
    "df2 = pd.read_csv(url2)\n",
    "clf = SVC(C= 0.5, gamma= 0.004, kernel= 'rbf', probability= True)\n",
    "clf.fit(X, y)\n",
    "pred=clf.predict(X_test2)\n",
    "pd.DataFrame({\"PassengerId\": df2[\"PassengerId\"], \"Survived\": pred}).to_csv(\"svm_submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZmMz70SH4vW9"
   },
   "source": [
    "## Logistic Regression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "BXriifFZ4247",
    "outputId": "eccc1146-81ba-4cf6-dec9-7bc47bfeb5a0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n",
      "\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: l1_ratio must be between 0 and 1; got (l1_ratio=None)\n",
      "\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: penalty='none' is not supported for the liblinear solver\n",
      "\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n",
      "\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: l1_ratio must be between 0 and 1; got (l1_ratio=None)\n",
      "\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: penalty='none' is not supported for the liblinear solver\n",
      "\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n",
      "\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: l1_ratio must be between 0 and 1; got (l1_ratio=None)\n",
      "\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: penalty='none' is not supported for the liblinear solver\n",
      "\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n",
      "\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: l1_ratio must be between 0 and 1; got (l1_ratio=None)\n",
      "\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: penalty='none' is not supported for the liblinear solver\n",
      "\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n",
      "\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: l1_ratio must be between 0 and 1; got (l1_ratio=None)\n",
      "\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: penalty='none' is not supported for the liblinear solver\n",
      "\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n",
      "\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: l1_ratio must be between 0 and 1; got (l1_ratio=None)\n",
      "\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: penalty='none' is not supported for the liblinear solver\n",
      "\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n",
      "\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: l1_ratio must be between 0 and 1; got (l1_ratio=None)\n",
      "\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: penalty='none' is not supported for the liblinear solver\n",
      "\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set found on development set:\n",
      "\n",
      "{'C': 10, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': False}\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "0.773 (+/-0.074) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': True}\n",
      "0.773 (+/-0.074) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': False}\n",
      "0.773 (+/-0.074) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': True}\n",
      "0.773 (+/-0.074) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': False}\n",
      "0.773 (+/-0.074) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': True}\n",
      "0.773 (+/-0.074) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': False}\n",
      "0.773 (+/-0.074) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': True}\n",
      "0.773 (+/-0.074) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': False}\n",
      "0.774 (+/-0.071) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': True}\n",
      "0.774 (+/-0.071) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': False}\n",
      "0.785 (+/-0.084) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 1e-05, 'warm_start': True}\n",
      "0.785 (+/-0.084) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 1e-05, 'warm_start': False}\n",
      "0.785 (+/-0.084) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.0001, 'warm_start': True}\n",
      "0.785 (+/-0.084) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.0001, 'warm_start': False}\n",
      "0.785 (+/-0.084) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.001, 'warm_start': True}\n",
      "0.785 (+/-0.084) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.001, 'warm_start': False}\n",
      "0.785 (+/-0.084) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.01, 'warm_start': True}\n",
      "0.785 (+/-0.084) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.01, 'warm_start': False}\n",
      "0.785 (+/-0.084) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.1, 'warm_start': True}\n",
      "0.785 (+/-0.084) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.1, 'warm_start': False}\n",
      "0.785 (+/-0.084) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 1e-05, 'warm_start': True}\n",
      "0.785 (+/-0.084) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 1e-05, 'warm_start': False}\n",
      "0.785 (+/-0.084) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.0001, 'warm_start': True}\n",
      "0.785 (+/-0.084) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.0001, 'warm_start': False}\n",
      "0.785 (+/-0.084) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.001, 'warm_start': True}\n",
      "0.785 (+/-0.084) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.001, 'warm_start': False}\n",
      "0.785 (+/-0.084) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.01, 'warm_start': True}\n",
      "0.785 (+/-0.084) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.01, 'warm_start': False}\n",
      "0.785 (+/-0.084) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.1, 'warm_start': True}\n",
      "0.785 (+/-0.084) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.1, 'warm_start': False}\n",
      "0.785 (+/-0.084) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l2', 'solver': 'sag', 'tol': 1e-05, 'warm_start': True}\n",
      "0.785 (+/-0.084) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l2', 'solver': 'sag', 'tol': 1e-05, 'warm_start': False}\n",
      "0.785 (+/-0.084) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.0001, 'warm_start': True}\n",
      "0.785 (+/-0.084) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.0001, 'warm_start': False}\n",
      "0.785 (+/-0.084) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.001, 'warm_start': True}\n",
      "0.784 (+/-0.085) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.001, 'warm_start': False}\n",
      "0.788 (+/-0.090) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.01, 'warm_start': True}\n",
      "0.787 (+/-0.088) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.01, 'warm_start': False}\n",
      "0.796 (+/-0.091) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.1, 'warm_start': True}\n",
      "0.796 (+/-0.101) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.1, 'warm_start': False}\n",
      "0.785 (+/-0.084) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l2', 'solver': 'saga', 'tol': 1e-05, 'warm_start': True}\n",
      "0.785 (+/-0.084) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l2', 'solver': 'saga', 'tol': 1e-05, 'warm_start': False}\n",
      "0.785 (+/-0.084) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.0001, 'warm_start': True}\n",
      "0.785 (+/-0.084) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.0001, 'warm_start': False}\n",
      "0.785 (+/-0.084) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.001, 'warm_start': True}\n",
      "0.785 (+/-0.084) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.001, 'warm_start': False}\n",
      "0.785 (+/-0.088) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.01, 'warm_start': True}\n",
      "0.785 (+/-0.084) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.01, 'warm_start': False}\n",
      "0.775 (+/-0.084) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.1, 'warm_start': True}\n",
      "0.781 (+/-0.080) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.1, 'warm_start': False}\n",
      "0.773 (+/-0.074) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': True}\n",
      "0.773 (+/-0.074) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': False}\n",
      "0.773 (+/-0.074) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': True}\n",
      "0.773 (+/-0.074) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': False}\n",
      "0.773 (+/-0.074) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': True}\n",
      "0.773 (+/-0.074) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': False}\n",
      "0.773 (+/-0.074) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': True}\n",
      "0.773 (+/-0.074) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': False}\n",
      "0.774 (+/-0.071) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': True}\n",
      "0.774 (+/-0.071) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': False}\n",
      "0.785 (+/-0.084) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 1e-05, 'warm_start': True}\n",
      "0.785 (+/-0.084) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 1e-05, 'warm_start': False}\n",
      "0.785 (+/-0.084) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.0001, 'warm_start': True}\n",
      "0.785 (+/-0.084) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.0001, 'warm_start': False}\n",
      "0.785 (+/-0.084) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.001, 'warm_start': True}\n",
      "0.785 (+/-0.084) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.001, 'warm_start': False}\n",
      "0.785 (+/-0.084) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.01, 'warm_start': True}\n",
      "0.785 (+/-0.084) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.01, 'warm_start': False}\n",
      "0.785 (+/-0.084) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.1, 'warm_start': True}\n",
      "0.785 (+/-0.084) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.1, 'warm_start': False}\n",
      "0.785 (+/-0.084) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 1e-05, 'warm_start': True}\n",
      "0.785 (+/-0.084) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 1e-05, 'warm_start': False}\n",
      "0.785 (+/-0.084) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.0001, 'warm_start': True}\n",
      "0.785 (+/-0.084) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.0001, 'warm_start': False}\n",
      "0.785 (+/-0.084) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.001, 'warm_start': True}\n",
      "0.785 (+/-0.084) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.001, 'warm_start': False}\n",
      "0.785 (+/-0.084) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.01, 'warm_start': True}\n",
      "0.785 (+/-0.084) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.01, 'warm_start': False}\n",
      "0.785 (+/-0.084) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.1, 'warm_start': True}\n",
      "0.785 (+/-0.084) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.1, 'warm_start': False}\n",
      "0.785 (+/-0.084) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l2', 'solver': 'sag', 'tol': 1e-05, 'warm_start': True}\n",
      "0.785 (+/-0.084) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l2', 'solver': 'sag', 'tol': 1e-05, 'warm_start': False}\n",
      "0.785 (+/-0.084) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.0001, 'warm_start': True}\n",
      "0.785 (+/-0.084) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.0001, 'warm_start': False}\n",
      "0.785 (+/-0.084) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.001, 'warm_start': True}\n",
      "0.785 (+/-0.084) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.001, 'warm_start': False}\n",
      "0.787 (+/-0.086) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.01, 'warm_start': True}\n",
      "0.780 (+/-0.100) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.01, 'warm_start': False}\n",
      "0.795 (+/-0.088) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.1, 'warm_start': True}\n",
      "0.780 (+/-0.085) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.1, 'warm_start': False}\n",
      "0.785 (+/-0.084) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l2', 'solver': 'saga', 'tol': 1e-05, 'warm_start': True}\n",
      "0.785 (+/-0.084) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l2', 'solver': 'saga', 'tol': 1e-05, 'warm_start': False}\n",
      "0.785 (+/-0.084) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.0001, 'warm_start': True}\n",
      "0.785 (+/-0.084) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.0001, 'warm_start': False}\n",
      "0.785 (+/-0.089) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.001, 'warm_start': True}\n",
      "0.785 (+/-0.084) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.001, 'warm_start': False}\n",
      "0.785 (+/-0.084) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.01, 'warm_start': True}\n",
      "0.785 (+/-0.081) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.01, 'warm_start': False}\n",
      "0.778 (+/-0.076) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.1, 'warm_start': True}\n",
      "0.775 (+/-0.075) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.1, 'warm_start': False}\n",
      "0.773 (+/-0.074) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': True}\n",
      "0.773 (+/-0.074) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': False}\n",
      "0.773 (+/-0.074) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': True}\n",
      "0.773 (+/-0.074) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': False}\n",
      "0.773 (+/-0.074) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': True}\n",
      "0.773 (+/-0.074) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': False}\n",
      "0.773 (+/-0.074) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': True}\n",
      "0.773 (+/-0.074) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': False}\n",
      "0.774 (+/-0.071) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': True}\n",
      "0.774 (+/-0.071) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': False}\n",
      "0.785 (+/-0.084) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 1e-05, 'warm_start': True}\n",
      "0.785 (+/-0.084) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 1e-05, 'warm_start': False}\n",
      "0.785 (+/-0.084) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.0001, 'warm_start': True}\n",
      "0.785 (+/-0.084) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.0001, 'warm_start': False}\n",
      "0.785 (+/-0.084) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.001, 'warm_start': True}\n",
      "0.785 (+/-0.084) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.001, 'warm_start': False}\n",
      "0.785 (+/-0.084) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.01, 'warm_start': True}\n",
      "0.785 (+/-0.084) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.01, 'warm_start': False}\n",
      "0.785 (+/-0.084) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.1, 'warm_start': True}\n",
      "0.785 (+/-0.084) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.1, 'warm_start': False}\n",
      "0.785 (+/-0.084) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 1e-05, 'warm_start': True}\n",
      "0.785 (+/-0.084) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 1e-05, 'warm_start': False}\n",
      "0.785 (+/-0.084) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.0001, 'warm_start': True}\n",
      "0.785 (+/-0.084) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.0001, 'warm_start': False}\n",
      "0.785 (+/-0.084) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.001, 'warm_start': True}\n",
      "0.785 (+/-0.084) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.001, 'warm_start': False}\n",
      "0.785 (+/-0.084) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.01, 'warm_start': True}\n",
      "0.785 (+/-0.084) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.01, 'warm_start': False}\n",
      "0.785 (+/-0.084) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.1, 'warm_start': True}\n",
      "0.785 (+/-0.084) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.1, 'warm_start': False}\n",
      "0.785 (+/-0.084) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'sag', 'tol': 1e-05, 'warm_start': True}\n",
      "0.785 (+/-0.084) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'sag', 'tol': 1e-05, 'warm_start': False}\n",
      "0.785 (+/-0.084) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.0001, 'warm_start': True}\n",
      "0.785 (+/-0.084) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.0001, 'warm_start': False}\n",
      "0.785 (+/-0.084) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.001, 'warm_start': True}\n",
      "0.785 (+/-0.084) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.001, 'warm_start': False}\n",
      "0.781 (+/-0.087) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.01, 'warm_start': True}\n",
      "0.784 (+/-0.084) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.01, 'warm_start': False}\n",
      "0.791 (+/-0.102) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.1, 'warm_start': True}\n",
      "0.791 (+/-0.086) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.1, 'warm_start': False}\n",
      "0.785 (+/-0.084) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'saga', 'tol': 1e-05, 'warm_start': True}\n",
      "0.785 (+/-0.084) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'saga', 'tol': 1e-05, 'warm_start': False}\n",
      "0.785 (+/-0.084) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.0001, 'warm_start': True}\n",
      "0.785 (+/-0.084) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.0001, 'warm_start': False}\n",
      "0.785 (+/-0.084) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.001, 'warm_start': True}\n",
      "0.784 (+/-0.085) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.001, 'warm_start': False}\n",
      "0.785 (+/-0.080) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.01, 'warm_start': True}\n",
      "0.785 (+/-0.089) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.01, 'warm_start': False}\n",
      "0.777 (+/-0.074) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.1, 'warm_start': True}\n",
      "0.775 (+/-0.088) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.1, 'warm_start': False}\n",
      "0.773 (+/-0.074) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': True}\n",
      "0.773 (+/-0.074) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': False}\n",
      "0.773 (+/-0.074) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': True}\n",
      "0.773 (+/-0.074) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': False}\n",
      "0.773 (+/-0.074) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': True}\n",
      "0.773 (+/-0.074) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': False}\n",
      "0.773 (+/-0.074) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': True}\n",
      "0.773 (+/-0.074) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': False}\n",
      "0.774 (+/-0.071) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': True}\n",
      "0.774 (+/-0.071) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': False}\n",
      "0.785 (+/-0.084) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 1e-05, 'warm_start': True}\n",
      "0.785 (+/-0.084) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 1e-05, 'warm_start': False}\n",
      "0.785 (+/-0.084) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.0001, 'warm_start': True}\n",
      "0.785 (+/-0.084) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.0001, 'warm_start': False}\n",
      "0.785 (+/-0.084) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.001, 'warm_start': True}\n",
      "0.785 (+/-0.084) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.001, 'warm_start': False}\n",
      "0.785 (+/-0.084) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.01, 'warm_start': True}\n",
      "0.785 (+/-0.084) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.01, 'warm_start': False}\n",
      "0.785 (+/-0.084) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.1, 'warm_start': True}\n",
      "0.785 (+/-0.084) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.1, 'warm_start': False}\n",
      "0.785 (+/-0.084) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 1e-05, 'warm_start': True}\n",
      "0.785 (+/-0.084) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 1e-05, 'warm_start': False}\n",
      "0.785 (+/-0.084) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.0001, 'warm_start': True}\n",
      "0.785 (+/-0.084) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.0001, 'warm_start': False}\n",
      "0.785 (+/-0.084) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.001, 'warm_start': True}\n",
      "0.785 (+/-0.084) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.001, 'warm_start': False}\n",
      "0.785 (+/-0.084) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.01, 'warm_start': True}\n",
      "0.785 (+/-0.084) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.01, 'warm_start': False}\n",
      "0.785 (+/-0.084) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.1, 'warm_start': True}\n",
      "0.785 (+/-0.084) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.1, 'warm_start': False}\n",
      "0.785 (+/-0.084) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'sag', 'tol': 1e-05, 'warm_start': True}\n",
      "0.785 (+/-0.084) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'sag', 'tol': 1e-05, 'warm_start': False}\n",
      "0.785 (+/-0.084) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.0001, 'warm_start': True}\n",
      "0.785 (+/-0.084) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.0001, 'warm_start': False}\n",
      "0.787 (+/-0.088) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.001, 'warm_start': True}\n",
      "0.784 (+/-0.084) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.001, 'warm_start': False}\n",
      "0.784 (+/-0.084) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.01, 'warm_start': True}\n",
      "0.785 (+/-0.089) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.01, 'warm_start': False}\n",
      "0.785 (+/-0.094) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.1, 'warm_start': True}\n",
      "0.785 (+/-0.101) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.1, 'warm_start': False}\n",
      "0.785 (+/-0.084) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'saga', 'tol': 1e-05, 'warm_start': True}\n",
      "0.785 (+/-0.084) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'saga', 'tol': 1e-05, 'warm_start': False}\n",
      "0.785 (+/-0.084) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.0001, 'warm_start': True}\n",
      "0.785 (+/-0.084) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.0001, 'warm_start': False}\n",
      "0.785 (+/-0.084) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.001, 'warm_start': True}\n",
      "0.782 (+/-0.087) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.001, 'warm_start': False}\n",
      "0.785 (+/-0.084) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.01, 'warm_start': True}\n",
      "0.778 (+/-0.084) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.01, 'warm_start': False}\n",
      "0.771 (+/-0.080) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.1, 'warm_start': True}\n",
      "0.778 (+/-0.087) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.1, 'warm_start': False}\n",
      "0.773 (+/-0.074) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': True}\n",
      "0.773 (+/-0.074) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': False}\n",
      "0.773 (+/-0.074) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': True}\n",
      "0.773 (+/-0.074) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': False}\n",
      "0.773 (+/-0.074) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': True}\n",
      "0.773 (+/-0.074) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': False}\n",
      "0.773 (+/-0.074) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': True}\n",
      "0.773 (+/-0.074) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': False}\n",
      "0.774 (+/-0.071) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': True}\n",
      "0.774 (+/-0.071) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': False}\n",
      "0.785 (+/-0.084) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 1e-05, 'warm_start': True}\n",
      "0.785 (+/-0.084) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 1e-05, 'warm_start': False}\n",
      "0.785 (+/-0.084) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.0001, 'warm_start': True}\n",
      "0.785 (+/-0.084) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.0001, 'warm_start': False}\n",
      "0.785 (+/-0.084) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.001, 'warm_start': True}\n",
      "0.785 (+/-0.084) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.001, 'warm_start': False}\n",
      "0.785 (+/-0.084) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.01, 'warm_start': True}\n",
      "0.785 (+/-0.084) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.01, 'warm_start': False}\n",
      "0.785 (+/-0.084) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.1, 'warm_start': True}\n",
      "0.785 (+/-0.084) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.1, 'warm_start': False}\n",
      "0.785 (+/-0.084) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 1e-05, 'warm_start': True}\n",
      "0.785 (+/-0.084) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 1e-05, 'warm_start': False}\n",
      "0.785 (+/-0.084) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.0001, 'warm_start': True}\n",
      "0.785 (+/-0.084) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.0001, 'warm_start': False}\n",
      "0.785 (+/-0.084) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.001, 'warm_start': True}\n",
      "0.785 (+/-0.084) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.001, 'warm_start': False}\n",
      "0.785 (+/-0.084) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.01, 'warm_start': True}\n",
      "0.785 (+/-0.084) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.01, 'warm_start': False}\n",
      "0.785 (+/-0.084) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.1, 'warm_start': True}\n",
      "0.785 (+/-0.084) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.1, 'warm_start': False}\n",
      "0.785 (+/-0.084) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'sag', 'tol': 1e-05, 'warm_start': True}\n",
      "0.785 (+/-0.084) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'sag', 'tol': 1e-05, 'warm_start': False}\n",
      "0.785 (+/-0.084) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.0001, 'warm_start': True}\n",
      "0.785 (+/-0.084) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.0001, 'warm_start': False}\n",
      "0.787 (+/-0.088) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.001, 'warm_start': True}\n",
      "0.788 (+/-0.091) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.001, 'warm_start': False}\n",
      "0.784 (+/-0.086) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.01, 'warm_start': True}\n",
      "0.785 (+/-0.080) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.01, 'warm_start': False}\n",
      "0.788 (+/-0.096) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.1, 'warm_start': True}\n",
      "0.785 (+/-0.090) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.1, 'warm_start': False}\n",
      "0.785 (+/-0.084) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'saga', 'tol': 1e-05, 'warm_start': True}\n",
      "0.785 (+/-0.084) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'saga', 'tol': 1e-05, 'warm_start': False}\n",
      "0.785 (+/-0.084) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.0001, 'warm_start': True}\n",
      "0.785 (+/-0.084) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.0001, 'warm_start': False}\n",
      "0.787 (+/-0.088) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.001, 'warm_start': True}\n",
      "0.785 (+/-0.084) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.001, 'warm_start': False}\n",
      "0.785 (+/-0.083) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.01, 'warm_start': True}\n",
      "0.785 (+/-0.084) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.01, 'warm_start': False}\n",
      "0.778 (+/-0.102) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.1, 'warm_start': True}\n",
      "0.778 (+/-0.068) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.1, 'warm_start': False}\n",
      "0.763 (+/-0.084) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': True}\n",
      "0.763 (+/-0.084) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': False}\n",
      "0.763 (+/-0.084) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': True}\n",
      "0.763 (+/-0.084) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': False}\n",
      "0.763 (+/-0.084) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': True}\n",
      "0.763 (+/-0.084) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': False}\n",
      "0.763 (+/-0.084) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': True}\n",
      "0.763 (+/-0.084) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': False}\n",
      "0.764 (+/-0.088) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': True}\n",
      "0.764 (+/-0.088) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': False}\n",
      "0.763 (+/-0.084) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 1e-05, 'warm_start': True}\n",
      "0.763 (+/-0.084) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 1e-05, 'warm_start': False}\n",
      "0.763 (+/-0.084) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.0001, 'warm_start': True}\n",
      "0.763 (+/-0.084) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.0001, 'warm_start': False}\n",
      "0.763 (+/-0.084) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.001, 'warm_start': True}\n",
      "0.763 (+/-0.084) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.001, 'warm_start': False}\n",
      "0.763 (+/-0.084) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.01, 'warm_start': True}\n",
      "0.763 (+/-0.084) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.01, 'warm_start': False}\n",
      "0.763 (+/-0.084) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.1, 'warm_start': True}\n",
      "0.763 (+/-0.084) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.1, 'warm_start': False}\n",
      "0.763 (+/-0.084) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 1e-05, 'warm_start': True}\n",
      "0.763 (+/-0.084) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 1e-05, 'warm_start': False}\n",
      "0.763 (+/-0.084) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.0001, 'warm_start': True}\n",
      "0.763 (+/-0.084) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.0001, 'warm_start': False}\n",
      "0.763 (+/-0.084) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.001, 'warm_start': True}\n",
      "0.763 (+/-0.084) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.001, 'warm_start': False}\n",
      "0.763 (+/-0.084) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.01, 'warm_start': True}\n",
      "0.763 (+/-0.084) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.01, 'warm_start': False}\n",
      "0.763 (+/-0.084) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.1, 'warm_start': True}\n",
      "0.763 (+/-0.084) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.1, 'warm_start': False}\n",
      "0.763 (+/-0.084) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l2', 'solver': 'sag', 'tol': 1e-05, 'warm_start': True}\n",
      "0.763 (+/-0.084) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l2', 'solver': 'sag', 'tol': 1e-05, 'warm_start': False}\n",
      "0.763 (+/-0.084) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.0001, 'warm_start': True}\n",
      "0.763 (+/-0.084) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.0001, 'warm_start': False}\n",
      "0.763 (+/-0.084) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.001, 'warm_start': True}\n",
      "0.763 (+/-0.084) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.001, 'warm_start': False}\n",
      "0.764 (+/-0.088) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.01, 'warm_start': True}\n",
      "0.763 (+/-0.084) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.01, 'warm_start': False}\n",
      "0.765 (+/-0.082) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.1, 'warm_start': True}\n",
      "0.764 (+/-0.086) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.1, 'warm_start': False}\n",
      "0.763 (+/-0.084) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l2', 'solver': 'saga', 'tol': 1e-05, 'warm_start': True}\n",
      "0.763 (+/-0.084) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l2', 'solver': 'saga', 'tol': 1e-05, 'warm_start': False}\n",
      "0.763 (+/-0.084) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.0001, 'warm_start': True}\n",
      "0.763 (+/-0.084) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.0001, 'warm_start': False}\n",
      "0.763 (+/-0.084) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.001, 'warm_start': True}\n",
      "0.763 (+/-0.084) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.001, 'warm_start': False}\n",
      "0.763 (+/-0.084) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.01, 'warm_start': True}\n",
      "0.763 (+/-0.087) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.01, 'warm_start': False}\n",
      "0.763 (+/-0.075) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.1, 'warm_start': True}\n",
      "0.770 (+/-0.085) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.1, 'warm_start': False}\n",
      "0.763 (+/-0.084) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': True}\n",
      "0.763 (+/-0.084) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': False}\n",
      "0.763 (+/-0.084) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': True}\n",
      "0.763 (+/-0.084) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': False}\n",
      "0.763 (+/-0.084) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': True}\n",
      "0.763 (+/-0.084) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': False}\n",
      "0.763 (+/-0.084) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': True}\n",
      "0.763 (+/-0.084) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': False}\n",
      "0.764 (+/-0.088) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': True}\n",
      "0.764 (+/-0.088) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': False}\n",
      "0.763 (+/-0.084) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 1e-05, 'warm_start': True}\n",
      "0.763 (+/-0.084) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 1e-05, 'warm_start': False}\n",
      "0.763 (+/-0.084) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.0001, 'warm_start': True}\n",
      "0.763 (+/-0.084) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.0001, 'warm_start': False}\n",
      "0.763 (+/-0.084) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.001, 'warm_start': True}\n",
      "0.763 (+/-0.084) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.001, 'warm_start': False}\n",
      "0.763 (+/-0.084) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.01, 'warm_start': True}\n",
      "0.763 (+/-0.084) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.01, 'warm_start': False}\n",
      "0.763 (+/-0.084) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.1, 'warm_start': True}\n",
      "0.763 (+/-0.084) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.1, 'warm_start': False}\n",
      "0.763 (+/-0.084) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 1e-05, 'warm_start': True}\n",
      "0.763 (+/-0.084) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 1e-05, 'warm_start': False}\n",
      "0.763 (+/-0.084) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.0001, 'warm_start': True}\n",
      "0.763 (+/-0.084) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.0001, 'warm_start': False}\n",
      "0.763 (+/-0.084) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.001, 'warm_start': True}\n",
      "0.763 (+/-0.084) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.001, 'warm_start': False}\n",
      "0.763 (+/-0.084) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.01, 'warm_start': True}\n",
      "0.763 (+/-0.084) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.01, 'warm_start': False}\n",
      "0.763 (+/-0.084) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.1, 'warm_start': True}\n",
      "0.763 (+/-0.084) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.1, 'warm_start': False}\n",
      "0.763 (+/-0.084) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l2', 'solver': 'sag', 'tol': 1e-05, 'warm_start': True}\n",
      "0.763 (+/-0.084) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l2', 'solver': 'sag', 'tol': 1e-05, 'warm_start': False}\n",
      "0.763 (+/-0.084) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.0001, 'warm_start': True}\n",
      "0.763 (+/-0.084) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.0001, 'warm_start': False}\n",
      "0.763 (+/-0.084) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.001, 'warm_start': True}\n",
      "0.763 (+/-0.084) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.001, 'warm_start': False}\n",
      "0.764 (+/-0.088) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.01, 'warm_start': True}\n",
      "0.764 (+/-0.088) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.01, 'warm_start': False}\n",
      "0.761 (+/-0.082) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.1, 'warm_start': True}\n",
      "0.761 (+/-0.077) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.1, 'warm_start': False}\n",
      "0.763 (+/-0.084) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l2', 'solver': 'saga', 'tol': 1e-05, 'warm_start': True}\n",
      "0.763 (+/-0.084) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l2', 'solver': 'saga', 'tol': 1e-05, 'warm_start': False}\n",
      "0.763 (+/-0.084) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.0001, 'warm_start': True}\n",
      "0.763 (+/-0.084) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.0001, 'warm_start': False}\n",
      "0.763 (+/-0.084) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.001, 'warm_start': True}\n",
      "0.763 (+/-0.084) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.001, 'warm_start': False}\n",
      "0.764 (+/-0.088) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.01, 'warm_start': True}\n",
      "0.763 (+/-0.084) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.01, 'warm_start': False}\n",
      "0.763 (+/-0.083) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.1, 'warm_start': True}\n",
      "0.760 (+/-0.075) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.1, 'warm_start': False}\n",
      "0.763 (+/-0.084) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': True}\n",
      "0.763 (+/-0.084) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': False}\n",
      "0.763 (+/-0.084) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': True}\n",
      "0.763 (+/-0.084) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': False}\n",
      "0.763 (+/-0.084) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': True}\n",
      "0.763 (+/-0.084) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': False}\n",
      "0.763 (+/-0.084) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': True}\n",
      "0.763 (+/-0.084) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': False}\n",
      "0.764 (+/-0.088) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': True}\n",
      "0.764 (+/-0.088) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': False}\n",
      "0.763 (+/-0.084) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 1e-05, 'warm_start': True}\n",
      "0.763 (+/-0.084) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 1e-05, 'warm_start': False}\n",
      "0.763 (+/-0.084) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.0001, 'warm_start': True}\n",
      "0.763 (+/-0.084) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.0001, 'warm_start': False}\n",
      "0.763 (+/-0.084) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.001, 'warm_start': True}\n",
      "0.763 (+/-0.084) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.001, 'warm_start': False}\n",
      "0.763 (+/-0.084) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.01, 'warm_start': True}\n",
      "0.763 (+/-0.084) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.01, 'warm_start': False}\n",
      "0.763 (+/-0.084) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.1, 'warm_start': True}\n",
      "0.763 (+/-0.084) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.1, 'warm_start': False}\n",
      "0.763 (+/-0.084) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 1e-05, 'warm_start': True}\n",
      "0.763 (+/-0.084) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 1e-05, 'warm_start': False}\n",
      "0.763 (+/-0.084) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.0001, 'warm_start': True}\n",
      "0.763 (+/-0.084) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.0001, 'warm_start': False}\n",
      "0.763 (+/-0.084) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.001, 'warm_start': True}\n",
      "0.763 (+/-0.084) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.001, 'warm_start': False}\n",
      "0.763 (+/-0.084) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.01, 'warm_start': True}\n",
      "0.763 (+/-0.084) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.01, 'warm_start': False}\n",
      "0.763 (+/-0.084) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.1, 'warm_start': True}\n",
      "0.763 (+/-0.084) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.1, 'warm_start': False}\n",
      "0.763 (+/-0.084) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'sag', 'tol': 1e-05, 'warm_start': True}\n",
      "0.763 (+/-0.084) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'sag', 'tol': 1e-05, 'warm_start': False}\n",
      "0.763 (+/-0.084) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.0001, 'warm_start': True}\n",
      "0.763 (+/-0.084) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.0001, 'warm_start': False}\n",
      "0.763 (+/-0.084) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.001, 'warm_start': True}\n",
      "0.763 (+/-0.084) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.001, 'warm_start': False}\n",
      "0.763 (+/-0.084) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.01, 'warm_start': True}\n",
      "0.763 (+/-0.084) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.01, 'warm_start': False}\n",
      "0.761 (+/-0.081) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.1, 'warm_start': True}\n",
      "0.765 (+/-0.081) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.1, 'warm_start': False}\n",
      "0.763 (+/-0.084) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'saga', 'tol': 1e-05, 'warm_start': True}\n",
      "0.763 (+/-0.084) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'saga', 'tol': 1e-05, 'warm_start': False}\n",
      "0.763 (+/-0.084) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.0001, 'warm_start': True}\n",
      "0.763 (+/-0.084) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.0001, 'warm_start': False}\n",
      "0.763 (+/-0.084) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.001, 'warm_start': True}\n",
      "0.763 (+/-0.084) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.001, 'warm_start': False}\n",
      "0.763 (+/-0.084) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.01, 'warm_start': True}\n",
      "0.764 (+/-0.088) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.01, 'warm_start': False}\n",
      "0.761 (+/-0.065) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.1, 'warm_start': True}\n",
      "0.764 (+/-0.080) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.1, 'warm_start': False}\n",
      "0.763 (+/-0.084) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': True}\n",
      "0.763 (+/-0.084) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': False}\n",
      "0.763 (+/-0.084) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': True}\n",
      "0.763 (+/-0.084) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': False}\n",
      "0.763 (+/-0.084) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': True}\n",
      "0.763 (+/-0.084) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': False}\n",
      "0.763 (+/-0.084) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': True}\n",
      "0.763 (+/-0.084) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': False}\n",
      "0.764 (+/-0.088) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': True}\n",
      "0.764 (+/-0.088) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': False}\n",
      "0.763 (+/-0.084) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 1e-05, 'warm_start': True}\n",
      "0.763 (+/-0.084) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 1e-05, 'warm_start': False}\n",
      "0.763 (+/-0.084) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.0001, 'warm_start': True}\n",
      "0.763 (+/-0.084) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.0001, 'warm_start': False}\n",
      "0.763 (+/-0.084) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.001, 'warm_start': True}\n",
      "0.763 (+/-0.084) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.001, 'warm_start': False}\n",
      "0.763 (+/-0.084) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.01, 'warm_start': True}\n",
      "0.763 (+/-0.084) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.01, 'warm_start': False}\n",
      "0.763 (+/-0.084) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.1, 'warm_start': True}\n",
      "0.763 (+/-0.084) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.1, 'warm_start': False}\n",
      "0.763 (+/-0.084) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 1e-05, 'warm_start': True}\n",
      "0.763 (+/-0.084) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 1e-05, 'warm_start': False}\n",
      "0.763 (+/-0.084) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.0001, 'warm_start': True}\n",
      "0.763 (+/-0.084) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.0001, 'warm_start': False}\n",
      "0.763 (+/-0.084) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.001, 'warm_start': True}\n",
      "0.763 (+/-0.084) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.001, 'warm_start': False}\n",
      "0.763 (+/-0.084) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.01, 'warm_start': True}\n",
      "0.763 (+/-0.084) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.01, 'warm_start': False}\n",
      "0.763 (+/-0.084) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.1, 'warm_start': True}\n",
      "0.763 (+/-0.084) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.1, 'warm_start': False}\n",
      "0.763 (+/-0.084) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'sag', 'tol': 1e-05, 'warm_start': True}\n",
      "0.763 (+/-0.084) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'sag', 'tol': 1e-05, 'warm_start': False}\n",
      "0.763 (+/-0.084) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.0001, 'warm_start': True}\n",
      "0.763 (+/-0.084) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.0001, 'warm_start': False}\n",
      "0.763 (+/-0.084) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.001, 'warm_start': True}\n",
      "0.763 (+/-0.084) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.001, 'warm_start': False}\n",
      "0.763 (+/-0.084) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.01, 'warm_start': True}\n",
      "0.764 (+/-0.088) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.01, 'warm_start': False}\n",
      "0.764 (+/-0.083) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.1, 'warm_start': True}\n",
      "0.765 (+/-0.077) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.1, 'warm_start': False}\n",
      "0.763 (+/-0.084) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'saga', 'tol': 1e-05, 'warm_start': True}\n",
      "0.763 (+/-0.084) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'saga', 'tol': 1e-05, 'warm_start': False}\n",
      "0.763 (+/-0.084) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.0001, 'warm_start': True}\n",
      "0.763 (+/-0.084) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.0001, 'warm_start': False}\n",
      "0.763 (+/-0.084) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.001, 'warm_start': True}\n",
      "0.763 (+/-0.084) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.001, 'warm_start': False}\n",
      "0.763 (+/-0.087) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.01, 'warm_start': True}\n",
      "0.763 (+/-0.084) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.01, 'warm_start': False}\n",
      "0.760 (+/-0.068) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.1, 'warm_start': True}\n",
      "0.761 (+/-0.082) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.1, 'warm_start': False}\n",
      "0.763 (+/-0.084) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': True}\n",
      "0.763 (+/-0.084) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': False}\n",
      "0.763 (+/-0.084) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': True}\n",
      "0.763 (+/-0.084) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': False}\n",
      "0.763 (+/-0.084) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': True}\n",
      "0.763 (+/-0.084) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': False}\n",
      "0.763 (+/-0.084) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': True}\n",
      "0.763 (+/-0.084) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': False}\n",
      "0.764 (+/-0.088) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': True}\n",
      "0.764 (+/-0.088) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': False}\n",
      "0.763 (+/-0.084) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 1e-05, 'warm_start': True}\n",
      "0.763 (+/-0.084) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 1e-05, 'warm_start': False}\n",
      "0.763 (+/-0.084) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.0001, 'warm_start': True}\n",
      "0.763 (+/-0.084) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.0001, 'warm_start': False}\n",
      "0.763 (+/-0.084) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.001, 'warm_start': True}\n",
      "0.763 (+/-0.084) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.001, 'warm_start': False}\n",
      "0.763 (+/-0.084) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.01, 'warm_start': True}\n",
      "0.763 (+/-0.084) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.01, 'warm_start': False}\n",
      "0.763 (+/-0.084) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.1, 'warm_start': True}\n",
      "0.763 (+/-0.084) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.1, 'warm_start': False}\n",
      "0.763 (+/-0.084) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 1e-05, 'warm_start': True}\n",
      "0.763 (+/-0.084) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 1e-05, 'warm_start': False}\n",
      "0.763 (+/-0.084) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.0001, 'warm_start': True}\n",
      "0.763 (+/-0.084) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.0001, 'warm_start': False}\n",
      "0.763 (+/-0.084) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.001, 'warm_start': True}\n",
      "0.763 (+/-0.084) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.001, 'warm_start': False}\n",
      "0.763 (+/-0.084) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.01, 'warm_start': True}\n",
      "0.763 (+/-0.084) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.01, 'warm_start': False}\n",
      "0.763 (+/-0.084) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.1, 'warm_start': True}\n",
      "0.763 (+/-0.084) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.1, 'warm_start': False}\n",
      "0.763 (+/-0.084) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'sag', 'tol': 1e-05, 'warm_start': True}\n",
      "0.763 (+/-0.084) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'sag', 'tol': 1e-05, 'warm_start': False}\n",
      "0.763 (+/-0.084) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.0001, 'warm_start': True}\n",
      "0.763 (+/-0.084) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.0001, 'warm_start': False}\n",
      "0.763 (+/-0.084) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.001, 'warm_start': True}\n",
      "0.763 (+/-0.084) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.001, 'warm_start': False}\n",
      "0.764 (+/-0.088) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.01, 'warm_start': True}\n",
      "0.764 (+/-0.088) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.01, 'warm_start': False}\n",
      "0.771 (+/-0.080) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.1, 'warm_start': True}\n",
      "0.761 (+/-0.077) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.1, 'warm_start': False}\n",
      "0.763 (+/-0.084) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'saga', 'tol': 1e-05, 'warm_start': True}\n",
      "0.763 (+/-0.084) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'saga', 'tol': 1e-05, 'warm_start': False}\n",
      "0.763 (+/-0.084) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.0001, 'warm_start': True}\n",
      "0.763 (+/-0.084) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.0001, 'warm_start': False}\n",
      "0.763 (+/-0.084) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.001, 'warm_start': True}\n",
      "0.763 (+/-0.084) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.001, 'warm_start': False}\n",
      "0.764 (+/-0.088) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.01, 'warm_start': True}\n",
      "0.764 (+/-0.088) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.01, 'warm_start': False}\n",
      "0.763 (+/-0.077) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.1, 'warm_start': True}\n",
      "0.764 (+/-0.083) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.1, 'warm_start': False}\n",
      "0.780 (+/-0.081) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': True}\n",
      "0.780 (+/-0.081) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': False}\n",
      "0.780 (+/-0.081) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': True}\n",
      "0.780 (+/-0.081) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': False}\n",
      "0.780 (+/-0.081) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': True}\n",
      "0.780 (+/-0.081) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': False}\n",
      "0.780 (+/-0.081) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': True}\n",
      "0.780 (+/-0.081) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': False}\n",
      "0.780 (+/-0.079) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': True}\n",
      "0.780 (+/-0.079) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': False}\n",
      "0.791 (+/-0.070) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 1e-05, 'warm_start': True}\n",
      "0.791 (+/-0.070) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 1e-05, 'warm_start': False}\n",
      "0.791 (+/-0.070) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.0001, 'warm_start': True}\n",
      "0.791 (+/-0.070) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.0001, 'warm_start': False}\n",
      "0.791 (+/-0.070) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.001, 'warm_start': True}\n",
      "0.791 (+/-0.070) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.001, 'warm_start': False}\n",
      "0.791 (+/-0.070) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.01, 'warm_start': True}\n",
      "0.791 (+/-0.070) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.01, 'warm_start': False}\n",
      "0.791 (+/-0.070) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.1, 'warm_start': True}\n",
      "0.791 (+/-0.070) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.1, 'warm_start': False}\n",
      "0.791 (+/-0.070) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 1e-05, 'warm_start': True}\n",
      "0.791 (+/-0.070) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 1e-05, 'warm_start': False}\n",
      "0.791 (+/-0.070) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.0001, 'warm_start': True}\n",
      "0.791 (+/-0.070) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.0001, 'warm_start': False}\n",
      "0.791 (+/-0.070) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.001, 'warm_start': True}\n",
      "0.791 (+/-0.070) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.001, 'warm_start': False}\n",
      "0.791 (+/-0.070) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.01, 'warm_start': True}\n",
      "0.791 (+/-0.070) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.01, 'warm_start': False}\n",
      "0.791 (+/-0.070) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.1, 'warm_start': True}\n",
      "0.791 (+/-0.070) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.1, 'warm_start': False}\n",
      "0.791 (+/-0.070) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l2', 'solver': 'sag', 'tol': 1e-05, 'warm_start': True}\n",
      "0.791 (+/-0.070) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l2', 'solver': 'sag', 'tol': 1e-05, 'warm_start': False}\n",
      "0.791 (+/-0.070) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.0001, 'warm_start': True}\n",
      "0.791 (+/-0.070) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.0001, 'warm_start': False}\n",
      "0.791 (+/-0.070) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.001, 'warm_start': True}\n",
      "0.791 (+/-0.070) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.001, 'warm_start': False}\n",
      "0.789 (+/-0.068) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.01, 'warm_start': True}\n",
      "0.788 (+/-0.074) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.01, 'warm_start': False}\n",
      "0.780 (+/-0.074) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.1, 'warm_start': True}\n",
      "0.792 (+/-0.089) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.1, 'warm_start': False}\n",
      "0.791 (+/-0.070) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l2', 'solver': 'saga', 'tol': 1e-05, 'warm_start': True}\n",
      "0.791 (+/-0.070) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l2', 'solver': 'saga', 'tol': 1e-05, 'warm_start': False}\n",
      "0.791 (+/-0.070) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.0001, 'warm_start': True}\n",
      "0.791 (+/-0.070) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.0001, 'warm_start': False}\n",
      "0.791 (+/-0.070) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.001, 'warm_start': True}\n",
      "0.791 (+/-0.070) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.001, 'warm_start': False}\n",
      "0.782 (+/-0.077) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.01, 'warm_start': True}\n",
      "0.782 (+/-0.077) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.01, 'warm_start': False}\n",
      "0.771 (+/-0.082) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.1, 'warm_start': True}\n",
      "0.780 (+/-0.070) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.1, 'warm_start': False}\n",
      "0.780 (+/-0.081) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': True}\n",
      "0.780 (+/-0.081) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': False}\n",
      "0.780 (+/-0.081) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': True}\n",
      "0.780 (+/-0.081) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': False}\n",
      "0.780 (+/-0.081) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': True}\n",
      "0.780 (+/-0.081) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': False}\n",
      "0.780 (+/-0.081) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': True}\n",
      "0.780 (+/-0.081) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': False}\n",
      "0.780 (+/-0.079) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': True}\n",
      "0.780 (+/-0.079) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': False}\n",
      "0.791 (+/-0.070) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 1e-05, 'warm_start': True}\n",
      "0.791 (+/-0.070) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 1e-05, 'warm_start': False}\n",
      "0.791 (+/-0.070) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.0001, 'warm_start': True}\n",
      "0.791 (+/-0.070) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.0001, 'warm_start': False}\n",
      "0.791 (+/-0.070) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.001, 'warm_start': True}\n",
      "0.791 (+/-0.070) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.001, 'warm_start': False}\n",
      "0.791 (+/-0.070) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.01, 'warm_start': True}\n",
      "0.791 (+/-0.070) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.01, 'warm_start': False}\n",
      "0.791 (+/-0.070) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.1, 'warm_start': True}\n",
      "0.791 (+/-0.070) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.1, 'warm_start': False}\n",
      "0.791 (+/-0.070) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 1e-05, 'warm_start': True}\n",
      "0.791 (+/-0.070) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 1e-05, 'warm_start': False}\n",
      "0.791 (+/-0.070) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.0001, 'warm_start': True}\n",
      "0.791 (+/-0.070) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.0001, 'warm_start': False}\n",
      "0.791 (+/-0.070) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.001, 'warm_start': True}\n",
      "0.791 (+/-0.070) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.001, 'warm_start': False}\n",
      "0.791 (+/-0.070) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.01, 'warm_start': True}\n",
      "0.791 (+/-0.070) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.01, 'warm_start': False}\n",
      "0.791 (+/-0.070) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.1, 'warm_start': True}\n",
      "0.791 (+/-0.070) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.1, 'warm_start': False}\n",
      "0.791 (+/-0.070) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l2', 'solver': 'sag', 'tol': 1e-05, 'warm_start': True}\n",
      "0.791 (+/-0.070) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l2', 'solver': 'sag', 'tol': 1e-05, 'warm_start': False}\n",
      "0.791 (+/-0.070) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.0001, 'warm_start': True}\n",
      "0.791 (+/-0.070) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.0001, 'warm_start': False}\n",
      "0.791 (+/-0.070) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.001, 'warm_start': True}\n",
      "0.791 (+/-0.070) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.001, 'warm_start': False}\n",
      "0.789 (+/-0.073) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.01, 'warm_start': True}\n",
      "0.788 (+/-0.069) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.01, 'warm_start': False}\n",
      "0.780 (+/-0.077) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.1, 'warm_start': True}\n",
      "0.788 (+/-0.071) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.1, 'warm_start': False}\n",
      "0.791 (+/-0.070) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l2', 'solver': 'saga', 'tol': 1e-05, 'warm_start': True}\n",
      "0.791 (+/-0.070) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l2', 'solver': 'saga', 'tol': 1e-05, 'warm_start': False}\n",
      "0.791 (+/-0.070) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.0001, 'warm_start': True}\n",
      "0.791 (+/-0.070) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.0001, 'warm_start': False}\n",
      "0.791 (+/-0.070) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.001, 'warm_start': True}\n",
      "0.791 (+/-0.070) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.001, 'warm_start': False}\n",
      "0.782 (+/-0.077) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.01, 'warm_start': True}\n",
      "0.784 (+/-0.075) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.01, 'warm_start': False}\n",
      "0.774 (+/-0.080) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.1, 'warm_start': True}\n",
      "0.777 (+/-0.079) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.1, 'warm_start': False}\n",
      "0.780 (+/-0.081) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': True}\n",
      "0.780 (+/-0.081) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': False}\n",
      "0.780 (+/-0.081) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': True}\n",
      "0.780 (+/-0.081) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': False}\n",
      "0.780 (+/-0.081) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': True}\n",
      "0.780 (+/-0.081) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': False}\n",
      "0.780 (+/-0.081) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': True}\n",
      "0.780 (+/-0.081) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': False}\n",
      "0.780 (+/-0.079) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': True}\n",
      "0.780 (+/-0.079) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': False}\n",
      "0.791 (+/-0.070) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 1e-05, 'warm_start': True}\n",
      "0.791 (+/-0.070) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 1e-05, 'warm_start': False}\n",
      "0.791 (+/-0.070) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.0001, 'warm_start': True}\n",
      "0.791 (+/-0.070) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.0001, 'warm_start': False}\n",
      "0.791 (+/-0.070) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.001, 'warm_start': True}\n",
      "0.791 (+/-0.070) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.001, 'warm_start': False}\n",
      "0.791 (+/-0.070) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.01, 'warm_start': True}\n",
      "0.791 (+/-0.070) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.01, 'warm_start': False}\n",
      "0.791 (+/-0.070) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.1, 'warm_start': True}\n",
      "0.791 (+/-0.070) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.1, 'warm_start': False}\n",
      "0.791 (+/-0.070) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 1e-05, 'warm_start': True}\n",
      "0.791 (+/-0.070) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 1e-05, 'warm_start': False}\n",
      "0.791 (+/-0.070) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.0001, 'warm_start': True}\n",
      "0.791 (+/-0.070) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.0001, 'warm_start': False}\n",
      "0.791 (+/-0.070) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.001, 'warm_start': True}\n",
      "0.791 (+/-0.070) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.001, 'warm_start': False}\n",
      "0.791 (+/-0.070) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.01, 'warm_start': True}\n",
      "0.791 (+/-0.070) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.01, 'warm_start': False}\n",
      "0.791 (+/-0.070) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.1, 'warm_start': True}\n",
      "0.791 (+/-0.070) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.1, 'warm_start': False}\n",
      "0.791 (+/-0.070) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'sag', 'tol': 1e-05, 'warm_start': True}\n",
      "0.791 (+/-0.070) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'sag', 'tol': 1e-05, 'warm_start': False}\n",
      "0.791 (+/-0.070) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.0001, 'warm_start': True}\n",
      "0.791 (+/-0.070) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.0001, 'warm_start': False}\n",
      "0.791 (+/-0.070) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.001, 'warm_start': True}\n",
      "0.791 (+/-0.070) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.001, 'warm_start': False}\n",
      "0.791 (+/-0.070) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.01, 'warm_start': True}\n",
      "0.788 (+/-0.074) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.01, 'warm_start': False}\n",
      "0.789 (+/-0.083) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.1, 'warm_start': True}\n",
      "0.784 (+/-0.084) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.1, 'warm_start': False}\n",
      "0.791 (+/-0.070) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'saga', 'tol': 1e-05, 'warm_start': True}\n",
      "0.791 (+/-0.070) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'saga', 'tol': 1e-05, 'warm_start': False}\n",
      "0.791 (+/-0.070) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.0001, 'warm_start': True}\n",
      "0.791 (+/-0.070) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.0001, 'warm_start': False}\n",
      "0.791 (+/-0.070) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.001, 'warm_start': True}\n",
      "0.791 (+/-0.070) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.001, 'warm_start': False}\n",
      "0.785 (+/-0.076) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.01, 'warm_start': True}\n",
      "0.782 (+/-0.077) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.01, 'warm_start': False}\n",
      "0.771 (+/-0.083) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.1, 'warm_start': True}\n",
      "0.778 (+/-0.073) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.1, 'warm_start': False}\n",
      "0.780 (+/-0.081) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': True}\n",
      "0.780 (+/-0.081) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': False}\n",
      "0.780 (+/-0.081) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': True}\n",
      "0.780 (+/-0.081) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': False}\n",
      "0.780 (+/-0.081) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': True}\n",
      "0.780 (+/-0.081) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': False}\n",
      "0.780 (+/-0.081) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': True}\n",
      "0.780 (+/-0.081) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': False}\n",
      "0.780 (+/-0.079) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': True}\n",
      "0.780 (+/-0.079) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': False}\n",
      "0.791 (+/-0.070) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 1e-05, 'warm_start': True}\n",
      "0.791 (+/-0.070) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 1e-05, 'warm_start': False}\n",
      "0.791 (+/-0.070) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.0001, 'warm_start': True}\n",
      "0.791 (+/-0.070) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.0001, 'warm_start': False}\n",
      "0.791 (+/-0.070) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.001, 'warm_start': True}\n",
      "0.791 (+/-0.070) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.001, 'warm_start': False}\n",
      "0.791 (+/-0.070) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.01, 'warm_start': True}\n",
      "0.791 (+/-0.070) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.01, 'warm_start': False}\n",
      "0.791 (+/-0.070) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.1, 'warm_start': True}\n",
      "0.791 (+/-0.070) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.1, 'warm_start': False}\n",
      "0.791 (+/-0.070) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 1e-05, 'warm_start': True}\n",
      "0.791 (+/-0.070) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 1e-05, 'warm_start': False}\n",
      "0.791 (+/-0.070) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.0001, 'warm_start': True}\n",
      "0.791 (+/-0.070) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.0001, 'warm_start': False}\n",
      "0.791 (+/-0.070) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.001, 'warm_start': True}\n",
      "0.791 (+/-0.070) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.001, 'warm_start': False}\n",
      "0.791 (+/-0.070) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.01, 'warm_start': True}\n",
      "0.791 (+/-0.070) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.01, 'warm_start': False}\n",
      "0.791 (+/-0.070) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.1, 'warm_start': True}\n",
      "0.791 (+/-0.070) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.1, 'warm_start': False}\n",
      "0.791 (+/-0.070) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'sag', 'tol': 1e-05, 'warm_start': True}\n",
      "0.791 (+/-0.070) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'sag', 'tol': 1e-05, 'warm_start': False}\n",
      "0.791 (+/-0.070) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.0001, 'warm_start': True}\n",
      "0.791 (+/-0.070) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.0001, 'warm_start': False}\n",
      "0.791 (+/-0.070) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.001, 'warm_start': True}\n",
      "0.791 (+/-0.070) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.001, 'warm_start': False}\n",
      "0.788 (+/-0.074) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.01, 'warm_start': True}\n",
      "0.788 (+/-0.072) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.01, 'warm_start': False}\n",
      "0.781 (+/-0.074) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.1, 'warm_start': True}\n",
      "0.781 (+/-0.081) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.1, 'warm_start': False}\n",
      "0.791 (+/-0.070) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'saga', 'tol': 1e-05, 'warm_start': True}\n",
      "0.791 (+/-0.070) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'saga', 'tol': 1e-05, 'warm_start': False}\n",
      "0.791 (+/-0.070) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.0001, 'warm_start': True}\n",
      "0.791 (+/-0.070) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.0001, 'warm_start': False}\n",
      "0.791 (+/-0.070) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.001, 'warm_start': True}\n",
      "0.791 (+/-0.070) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.001, 'warm_start': False}\n",
      "0.782 (+/-0.077) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.01, 'warm_start': True}\n",
      "0.782 (+/-0.077) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.01, 'warm_start': False}\n",
      "0.775 (+/-0.068) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.1, 'warm_start': True}\n",
      "0.777 (+/-0.082) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.1, 'warm_start': False}\n",
      "0.780 (+/-0.081) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': True}\n",
      "0.780 (+/-0.081) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': False}\n",
      "0.780 (+/-0.081) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': True}\n",
      "0.780 (+/-0.081) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': False}\n",
      "0.780 (+/-0.081) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': True}\n",
      "0.780 (+/-0.081) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': False}\n",
      "0.780 (+/-0.081) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': True}\n",
      "0.780 (+/-0.081) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': False}\n",
      "0.780 (+/-0.079) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': True}\n",
      "0.780 (+/-0.079) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': False}\n",
      "0.791 (+/-0.070) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 1e-05, 'warm_start': True}\n",
      "0.791 (+/-0.070) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 1e-05, 'warm_start': False}\n",
      "0.791 (+/-0.070) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.0001, 'warm_start': True}\n",
      "0.791 (+/-0.070) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.0001, 'warm_start': False}\n",
      "0.791 (+/-0.070) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.001, 'warm_start': True}\n",
      "0.791 (+/-0.070) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.001, 'warm_start': False}\n",
      "0.791 (+/-0.070) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.01, 'warm_start': True}\n",
      "0.791 (+/-0.070) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.01, 'warm_start': False}\n",
      "0.791 (+/-0.070) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.1, 'warm_start': True}\n",
      "0.791 (+/-0.070) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.1, 'warm_start': False}\n",
      "0.791 (+/-0.070) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 1e-05, 'warm_start': True}\n",
      "0.791 (+/-0.070) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 1e-05, 'warm_start': False}\n",
      "0.791 (+/-0.070) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.0001, 'warm_start': True}\n",
      "0.791 (+/-0.070) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.0001, 'warm_start': False}\n",
      "0.791 (+/-0.070) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.001, 'warm_start': True}\n",
      "0.791 (+/-0.070) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.001, 'warm_start': False}\n",
      "0.791 (+/-0.070) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.01, 'warm_start': True}\n",
      "0.791 (+/-0.070) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.01, 'warm_start': False}\n",
      "0.791 (+/-0.070) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.1, 'warm_start': True}\n",
      "0.791 (+/-0.070) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.1, 'warm_start': False}\n",
      "0.791 (+/-0.070) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'sag', 'tol': 1e-05, 'warm_start': True}\n",
      "0.791 (+/-0.070) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'sag', 'tol': 1e-05, 'warm_start': False}\n",
      "0.791 (+/-0.070) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.0001, 'warm_start': True}\n",
      "0.791 (+/-0.070) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.0001, 'warm_start': False}\n",
      "0.791 (+/-0.070) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.001, 'warm_start': True}\n",
      "0.791 (+/-0.070) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.001, 'warm_start': False}\n",
      "0.792 (+/-0.069) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.01, 'warm_start': True}\n",
      "0.789 (+/-0.073) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.01, 'warm_start': False}\n",
      "0.791 (+/-0.063) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.1, 'warm_start': True}\n",
      "0.780 (+/-0.087) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.1, 'warm_start': False}\n",
      "0.791 (+/-0.070) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'saga', 'tol': 1e-05, 'warm_start': True}\n",
      "0.791 (+/-0.070) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'saga', 'tol': 1e-05, 'warm_start': False}\n",
      "0.791 (+/-0.070) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.0001, 'warm_start': True}\n",
      "0.791 (+/-0.070) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.0001, 'warm_start': False}\n",
      "0.791 (+/-0.070) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.001, 'warm_start': True}\n",
      "0.791 (+/-0.070) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.001, 'warm_start': False}\n",
      "0.782 (+/-0.077) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.01, 'warm_start': True}\n",
      "0.782 (+/-0.077) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.01, 'warm_start': False}\n",
      "0.781 (+/-0.077) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.1, 'warm_start': True}\n",
      "0.771 (+/-0.086) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.1, 'warm_start': False}\n",
      "0.767 (+/-0.067) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': True}\n",
      "0.767 (+/-0.067) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': False}\n",
      "0.767 (+/-0.067) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': True}\n",
      "0.767 (+/-0.067) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': False}\n",
      "0.767 (+/-0.067) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': True}\n",
      "0.767 (+/-0.067) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': False}\n",
      "0.767 (+/-0.067) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': True}\n",
      "0.767 (+/-0.067) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': False}\n",
      "0.766 (+/-0.068) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': True}\n",
      "0.766 (+/-0.068) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': False}\n",
      "0.767 (+/-0.067) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 1e-05, 'warm_start': True}\n",
      "0.767 (+/-0.067) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 1e-05, 'warm_start': False}\n",
      "0.767 (+/-0.067) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.0001, 'warm_start': True}\n",
      "0.767 (+/-0.067) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.0001, 'warm_start': False}\n",
      "0.767 (+/-0.067) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.001, 'warm_start': True}\n",
      "0.767 (+/-0.067) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.001, 'warm_start': False}\n",
      "0.767 (+/-0.067) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.01, 'warm_start': True}\n",
      "0.767 (+/-0.067) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.01, 'warm_start': False}\n",
      "0.767 (+/-0.067) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.1, 'warm_start': True}\n",
      "0.767 (+/-0.067) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.1, 'warm_start': False}\n",
      "0.767 (+/-0.067) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 1e-05, 'warm_start': True}\n",
      "0.767 (+/-0.067) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 1e-05, 'warm_start': False}\n",
      "0.767 (+/-0.067) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.0001, 'warm_start': True}\n",
      "0.767 (+/-0.067) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.0001, 'warm_start': False}\n",
      "0.767 (+/-0.067) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.001, 'warm_start': True}\n",
      "0.767 (+/-0.067) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.001, 'warm_start': False}\n",
      "0.767 (+/-0.067) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.01, 'warm_start': True}\n",
      "0.767 (+/-0.067) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.01, 'warm_start': False}\n",
      "0.767 (+/-0.067) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.1, 'warm_start': True}\n",
      "0.767 (+/-0.067) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.1, 'warm_start': False}\n",
      "0.767 (+/-0.067) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l2', 'solver': 'sag', 'tol': 1e-05, 'warm_start': True}\n",
      "0.767 (+/-0.067) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l2', 'solver': 'sag', 'tol': 1e-05, 'warm_start': False}\n",
      "0.767 (+/-0.067) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.0001, 'warm_start': True}\n",
      "0.767 (+/-0.067) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.0001, 'warm_start': False}\n",
      "0.767 (+/-0.067) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.001, 'warm_start': True}\n",
      "0.767 (+/-0.067) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.001, 'warm_start': False}\n",
      "0.767 (+/-0.067) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.01, 'warm_start': True}\n",
      "0.767 (+/-0.067) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.01, 'warm_start': False}\n",
      "0.766 (+/-0.058) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.1, 'warm_start': True}\n",
      "0.763 (+/-0.071) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.1, 'warm_start': False}\n",
      "0.767 (+/-0.067) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l2', 'solver': 'saga', 'tol': 1e-05, 'warm_start': True}\n",
      "0.767 (+/-0.067) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l2', 'solver': 'saga', 'tol': 1e-05, 'warm_start': False}\n",
      "0.767 (+/-0.067) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.0001, 'warm_start': True}\n",
      "0.767 (+/-0.067) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.0001, 'warm_start': False}\n",
      "0.767 (+/-0.067) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.001, 'warm_start': True}\n",
      "0.767 (+/-0.067) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.001, 'warm_start': False}\n",
      "0.767 (+/-0.067) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.01, 'warm_start': True}\n",
      "0.767 (+/-0.067) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.01, 'warm_start': False}\n",
      "0.768 (+/-0.053) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.1, 'warm_start': True}\n",
      "0.771 (+/-0.078) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.1, 'warm_start': False}\n",
      "0.767 (+/-0.067) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': True}\n",
      "0.767 (+/-0.067) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': False}\n",
      "0.767 (+/-0.067) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': True}\n",
      "0.767 (+/-0.067) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': False}\n",
      "0.767 (+/-0.067) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': True}\n",
      "0.767 (+/-0.067) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': False}\n",
      "0.767 (+/-0.067) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': True}\n",
      "0.767 (+/-0.067) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': False}\n",
      "0.766 (+/-0.068) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': True}\n",
      "0.766 (+/-0.068) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': False}\n",
      "0.767 (+/-0.067) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 1e-05, 'warm_start': True}\n",
      "0.767 (+/-0.067) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 1e-05, 'warm_start': False}\n",
      "0.767 (+/-0.067) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.0001, 'warm_start': True}\n",
      "0.767 (+/-0.067) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.0001, 'warm_start': False}\n",
      "0.767 (+/-0.067) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.001, 'warm_start': True}\n",
      "0.767 (+/-0.067) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.001, 'warm_start': False}\n",
      "0.767 (+/-0.067) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.01, 'warm_start': True}\n",
      "0.767 (+/-0.067) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.01, 'warm_start': False}\n",
      "0.767 (+/-0.067) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.1, 'warm_start': True}\n",
      "0.767 (+/-0.067) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.1, 'warm_start': False}\n",
      "0.767 (+/-0.067) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 1e-05, 'warm_start': True}\n",
      "0.767 (+/-0.067) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 1e-05, 'warm_start': False}\n",
      "0.767 (+/-0.067) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.0001, 'warm_start': True}\n",
      "0.767 (+/-0.067) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.0001, 'warm_start': False}\n",
      "0.767 (+/-0.067) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.001, 'warm_start': True}\n",
      "0.767 (+/-0.067) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.001, 'warm_start': False}\n",
      "0.767 (+/-0.067) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.01, 'warm_start': True}\n",
      "0.767 (+/-0.067) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.01, 'warm_start': False}\n",
      "0.767 (+/-0.067) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.1, 'warm_start': True}\n",
      "0.767 (+/-0.067) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.1, 'warm_start': False}\n",
      "0.767 (+/-0.067) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l2', 'solver': 'sag', 'tol': 1e-05, 'warm_start': True}\n",
      "0.767 (+/-0.067) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l2', 'solver': 'sag', 'tol': 1e-05, 'warm_start': False}\n",
      "0.767 (+/-0.067) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.0001, 'warm_start': True}\n",
      "0.767 (+/-0.067) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.0001, 'warm_start': False}\n",
      "0.767 (+/-0.067) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.001, 'warm_start': True}\n",
      "0.767 (+/-0.067) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.001, 'warm_start': False}\n",
      "0.767 (+/-0.067) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.01, 'warm_start': True}\n",
      "0.768 (+/-0.068) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.01, 'warm_start': False}\n",
      "0.763 (+/-0.059) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.1, 'warm_start': True}\n",
      "0.764 (+/-0.059) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.1, 'warm_start': False}\n",
      "0.767 (+/-0.067) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l2', 'solver': 'saga', 'tol': 1e-05, 'warm_start': True}\n",
      "0.767 (+/-0.067) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l2', 'solver': 'saga', 'tol': 1e-05, 'warm_start': False}\n",
      "0.767 (+/-0.067) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.0001, 'warm_start': True}\n",
      "0.767 (+/-0.067) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.0001, 'warm_start': False}\n",
      "0.767 (+/-0.067) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.001, 'warm_start': True}\n",
      "0.767 (+/-0.067) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.001, 'warm_start': False}\n",
      "0.767 (+/-0.067) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.01, 'warm_start': True}\n",
      "0.767 (+/-0.067) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.01, 'warm_start': False}\n",
      "0.770 (+/-0.065) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.1, 'warm_start': True}\n",
      "0.774 (+/-0.068) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.1, 'warm_start': False}\n",
      "0.767 (+/-0.067) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': True}\n",
      "0.767 (+/-0.067) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': False}\n",
      "0.767 (+/-0.067) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': True}\n",
      "0.767 (+/-0.067) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': False}\n",
      "0.767 (+/-0.067) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': True}\n",
      "0.767 (+/-0.067) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': False}\n",
      "0.767 (+/-0.067) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': True}\n",
      "0.767 (+/-0.067) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': False}\n",
      "0.766 (+/-0.068) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': True}\n",
      "0.766 (+/-0.068) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': False}\n",
      "0.767 (+/-0.067) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 1e-05, 'warm_start': True}\n",
      "0.767 (+/-0.067) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 1e-05, 'warm_start': False}\n",
      "0.767 (+/-0.067) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.0001, 'warm_start': True}\n",
      "0.767 (+/-0.067) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.0001, 'warm_start': False}\n",
      "0.767 (+/-0.067) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.001, 'warm_start': True}\n",
      "0.767 (+/-0.067) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.001, 'warm_start': False}\n",
      "0.767 (+/-0.067) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.01, 'warm_start': True}\n",
      "0.767 (+/-0.067) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.01, 'warm_start': False}\n",
      "0.767 (+/-0.067) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.1, 'warm_start': True}\n",
      "0.767 (+/-0.067) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.1, 'warm_start': False}\n",
      "0.767 (+/-0.067) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 1e-05, 'warm_start': True}\n",
      "0.767 (+/-0.067) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 1e-05, 'warm_start': False}\n",
      "0.767 (+/-0.067) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.0001, 'warm_start': True}\n",
      "0.767 (+/-0.067) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.0001, 'warm_start': False}\n",
      "0.767 (+/-0.067) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.001, 'warm_start': True}\n",
      "0.767 (+/-0.067) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.001, 'warm_start': False}\n",
      "0.767 (+/-0.067) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.01, 'warm_start': True}\n",
      "0.767 (+/-0.067) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.01, 'warm_start': False}\n",
      "0.767 (+/-0.067) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.1, 'warm_start': True}\n",
      "0.767 (+/-0.067) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.1, 'warm_start': False}\n",
      "0.767 (+/-0.067) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'sag', 'tol': 1e-05, 'warm_start': True}\n",
      "0.767 (+/-0.067) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'sag', 'tol': 1e-05, 'warm_start': False}\n",
      "0.767 (+/-0.067) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.0001, 'warm_start': True}\n",
      "0.767 (+/-0.067) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.0001, 'warm_start': False}\n",
      "0.767 (+/-0.067) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.001, 'warm_start': True}\n",
      "0.767 (+/-0.067) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.001, 'warm_start': False}\n",
      "0.768 (+/-0.068) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.01, 'warm_start': True}\n",
      "0.767 (+/-0.067) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.01, 'warm_start': False}\n",
      "0.766 (+/-0.068) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.1, 'warm_start': True}\n",
      "0.765 (+/-0.063) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.1, 'warm_start': False}\n",
      "0.767 (+/-0.067) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'saga', 'tol': 1e-05, 'warm_start': True}\n",
      "0.767 (+/-0.067) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'saga', 'tol': 1e-05, 'warm_start': False}\n",
      "0.767 (+/-0.067) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.0001, 'warm_start': True}\n",
      "0.767 (+/-0.067) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.0001, 'warm_start': False}\n",
      "0.767 (+/-0.067) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.001, 'warm_start': True}\n",
      "0.767 (+/-0.067) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.001, 'warm_start': False}\n",
      "0.767 (+/-0.067) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.01, 'warm_start': True}\n",
      "0.767 (+/-0.067) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.01, 'warm_start': False}\n",
      "0.771 (+/-0.061) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.1, 'warm_start': True}\n",
      "0.774 (+/-0.064) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.1, 'warm_start': False}\n",
      "0.767 (+/-0.067) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': True}\n",
      "0.767 (+/-0.067) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': False}\n",
      "0.767 (+/-0.067) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': True}\n",
      "0.767 (+/-0.067) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': False}\n",
      "0.767 (+/-0.067) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': True}\n",
      "0.767 (+/-0.067) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': False}\n",
      "0.767 (+/-0.067) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': True}\n",
      "0.767 (+/-0.067) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': False}\n",
      "0.766 (+/-0.068) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': True}\n",
      "0.766 (+/-0.068) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': False}\n",
      "0.767 (+/-0.067) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 1e-05, 'warm_start': True}\n",
      "0.767 (+/-0.067) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 1e-05, 'warm_start': False}\n",
      "0.767 (+/-0.067) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.0001, 'warm_start': True}\n",
      "0.767 (+/-0.067) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.0001, 'warm_start': False}\n",
      "0.767 (+/-0.067) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.001, 'warm_start': True}\n",
      "0.767 (+/-0.067) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.001, 'warm_start': False}\n",
      "0.767 (+/-0.067) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.01, 'warm_start': True}\n",
      "0.767 (+/-0.067) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.01, 'warm_start': False}\n",
      "0.767 (+/-0.067) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.1, 'warm_start': True}\n",
      "0.767 (+/-0.067) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.1, 'warm_start': False}\n",
      "0.767 (+/-0.067) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 1e-05, 'warm_start': True}\n",
      "0.767 (+/-0.067) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 1e-05, 'warm_start': False}\n",
      "0.767 (+/-0.067) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.0001, 'warm_start': True}\n",
      "0.767 (+/-0.067) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.0001, 'warm_start': False}\n",
      "0.767 (+/-0.067) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.001, 'warm_start': True}\n",
      "0.767 (+/-0.067) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.001, 'warm_start': False}\n",
      "0.767 (+/-0.067) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.01, 'warm_start': True}\n",
      "0.767 (+/-0.067) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.01, 'warm_start': False}\n",
      "0.767 (+/-0.067) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.1, 'warm_start': True}\n",
      "0.767 (+/-0.067) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.1, 'warm_start': False}\n",
      "0.767 (+/-0.067) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'sag', 'tol': 1e-05, 'warm_start': True}\n",
      "0.767 (+/-0.067) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'sag', 'tol': 1e-05, 'warm_start': False}\n",
      "0.767 (+/-0.067) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.0001, 'warm_start': True}\n",
      "0.767 (+/-0.067) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.0001, 'warm_start': False}\n",
      "0.767 (+/-0.067) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.001, 'warm_start': True}\n",
      "0.767 (+/-0.067) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.001, 'warm_start': False}\n",
      "0.765 (+/-0.065) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.01, 'warm_start': True}\n",
      "0.767 (+/-0.067) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.01, 'warm_start': False}\n",
      "0.765 (+/-0.062) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.1, 'warm_start': True}\n",
      "0.764 (+/-0.053) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.1, 'warm_start': False}\n",
      "0.767 (+/-0.067) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'saga', 'tol': 1e-05, 'warm_start': True}\n",
      "0.767 (+/-0.067) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'saga', 'tol': 1e-05, 'warm_start': False}\n",
      "0.767 (+/-0.067) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.0001, 'warm_start': True}\n",
      "0.767 (+/-0.067) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.0001, 'warm_start': False}\n",
      "0.767 (+/-0.067) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.001, 'warm_start': True}\n",
      "0.767 (+/-0.067) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.001, 'warm_start': False}\n",
      "0.767 (+/-0.067) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.01, 'warm_start': True}\n",
      "0.767 (+/-0.067) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.01, 'warm_start': False}\n",
      "0.768 (+/-0.070) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.1, 'warm_start': True}\n",
      "0.767 (+/-0.071) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.1, 'warm_start': False}\n",
      "0.767 (+/-0.067) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': True}\n",
      "0.767 (+/-0.067) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': False}\n",
      "0.767 (+/-0.067) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': True}\n",
      "0.767 (+/-0.067) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': False}\n",
      "0.767 (+/-0.067) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': True}\n",
      "0.767 (+/-0.067) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': False}\n",
      "0.767 (+/-0.067) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': True}\n",
      "0.767 (+/-0.067) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': False}\n",
      "0.766 (+/-0.068) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': True}\n",
      "0.766 (+/-0.068) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': False}\n",
      "0.767 (+/-0.067) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 1e-05, 'warm_start': True}\n",
      "0.767 (+/-0.067) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 1e-05, 'warm_start': False}\n",
      "0.767 (+/-0.067) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.0001, 'warm_start': True}\n",
      "0.767 (+/-0.067) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.0001, 'warm_start': False}\n",
      "0.767 (+/-0.067) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.001, 'warm_start': True}\n",
      "0.767 (+/-0.067) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.001, 'warm_start': False}\n",
      "0.767 (+/-0.067) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.01, 'warm_start': True}\n",
      "0.767 (+/-0.067) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.01, 'warm_start': False}\n",
      "0.767 (+/-0.067) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.1, 'warm_start': True}\n",
      "0.767 (+/-0.067) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.1, 'warm_start': False}\n",
      "0.767 (+/-0.067) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 1e-05, 'warm_start': True}\n",
      "0.767 (+/-0.067) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 1e-05, 'warm_start': False}\n",
      "0.767 (+/-0.067) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.0001, 'warm_start': True}\n",
      "0.767 (+/-0.067) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.0001, 'warm_start': False}\n",
      "0.767 (+/-0.067) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.001, 'warm_start': True}\n",
      "0.767 (+/-0.067) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.001, 'warm_start': False}\n",
      "0.767 (+/-0.067) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.01, 'warm_start': True}\n",
      "0.767 (+/-0.067) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.01, 'warm_start': False}\n",
      "0.767 (+/-0.067) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.1, 'warm_start': True}\n",
      "0.767 (+/-0.067) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.1, 'warm_start': False}\n",
      "0.767 (+/-0.067) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'sag', 'tol': 1e-05, 'warm_start': True}\n",
      "0.767 (+/-0.067) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'sag', 'tol': 1e-05, 'warm_start': False}\n",
      "0.767 (+/-0.067) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.0001, 'warm_start': True}\n",
      "0.767 (+/-0.067) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.0001, 'warm_start': False}\n",
      "0.767 (+/-0.067) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.001, 'warm_start': True}\n",
      "0.767 (+/-0.067) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.001, 'warm_start': False}\n",
      "0.768 (+/-0.068) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.01, 'warm_start': True}\n",
      "0.768 (+/-0.068) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.01, 'warm_start': False}\n",
      "0.763 (+/-0.075) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.1, 'warm_start': True}\n",
      "0.760 (+/-0.060) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.1, 'warm_start': False}\n",
      "0.767 (+/-0.067) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'saga', 'tol': 1e-05, 'warm_start': True}\n",
      "0.767 (+/-0.067) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'saga', 'tol': 1e-05, 'warm_start': False}\n",
      "0.767 (+/-0.067) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.0001, 'warm_start': True}\n",
      "0.767 (+/-0.067) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.0001, 'warm_start': False}\n",
      "0.767 (+/-0.067) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.001, 'warm_start': True}\n",
      "0.767 (+/-0.067) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.001, 'warm_start': False}\n",
      "0.767 (+/-0.067) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.01, 'warm_start': True}\n",
      "0.767 (+/-0.067) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.01, 'warm_start': False}\n",
      "0.765 (+/-0.065) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.1, 'warm_start': True}\n",
      "0.772 (+/-0.075) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.1, 'warm_start': False}\n",
      "0.794 (+/-0.077) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': True}\n",
      "0.794 (+/-0.077) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': False}\n",
      "0.794 (+/-0.077) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': True}\n",
      "0.794 (+/-0.077) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': False}\n",
      "0.794 (+/-0.077) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': True}\n",
      "0.794 (+/-0.077) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': False}\n",
      "0.795 (+/-0.076) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': True}\n",
      "0.795 (+/-0.076) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': False}\n",
      "0.792 (+/-0.076) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': True}\n",
      "0.792 (+/-0.076) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': False}\n",
      "0.794 (+/-0.077) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 1e-05, 'warm_start': True}\n",
      "0.794 (+/-0.077) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 1e-05, 'warm_start': False}\n",
      "0.794 (+/-0.077) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.0001, 'warm_start': True}\n",
      "0.794 (+/-0.077) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.0001, 'warm_start': False}\n",
      "0.794 (+/-0.077) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.001, 'warm_start': True}\n",
      "0.794 (+/-0.077) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.001, 'warm_start': False}\n",
      "0.794 (+/-0.077) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.01, 'warm_start': True}\n",
      "0.794 (+/-0.077) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.01, 'warm_start': False}\n",
      "0.792 (+/-0.070) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.1, 'warm_start': True}\n",
      "0.792 (+/-0.070) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.1, 'warm_start': False}\n",
      "0.794 (+/-0.077) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 1e-05, 'warm_start': True}\n",
      "0.794 (+/-0.077) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 1e-05, 'warm_start': False}\n",
      "0.794 (+/-0.077) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.0001, 'warm_start': True}\n",
      "0.794 (+/-0.077) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.0001, 'warm_start': False}\n",
      "0.794 (+/-0.077) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.001, 'warm_start': True}\n",
      "0.794 (+/-0.077) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.001, 'warm_start': False}\n",
      "0.794 (+/-0.077) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.01, 'warm_start': True}\n",
      "0.794 (+/-0.077) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.01, 'warm_start': False}\n",
      "0.794 (+/-0.077) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.1, 'warm_start': True}\n",
      "0.794 (+/-0.077) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.1, 'warm_start': False}\n",
      "0.794 (+/-0.077) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l2', 'solver': 'sag', 'tol': 1e-05, 'warm_start': True}\n",
      "0.794 (+/-0.077) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l2', 'solver': 'sag', 'tol': 1e-05, 'warm_start': False}\n",
      "0.794 (+/-0.077) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.0001, 'warm_start': True}\n",
      "0.794 (+/-0.077) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.0001, 'warm_start': False}\n",
      "0.792 (+/-0.070) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.001, 'warm_start': True}\n",
      "0.792 (+/-0.070) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.001, 'warm_start': False}\n",
      "0.795 (+/-0.070) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.01, 'warm_start': True}\n",
      "0.795 (+/-0.070) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.01, 'warm_start': False}\n",
      "0.787 (+/-0.083) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.1, 'warm_start': True}\n",
      "0.788 (+/-0.082) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.1, 'warm_start': False}\n",
      "0.792 (+/-0.070) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l2', 'solver': 'saga', 'tol': 1e-05, 'warm_start': True}\n",
      "0.792 (+/-0.070) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l2', 'solver': 'saga', 'tol': 1e-05, 'warm_start': False}\n",
      "0.792 (+/-0.070) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.0001, 'warm_start': True}\n",
      "0.792 (+/-0.070) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.0001, 'warm_start': False}\n",
      "0.794 (+/-0.069) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.001, 'warm_start': True}\n",
      "0.794 (+/-0.069) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.001, 'warm_start': False}\n",
      "0.795 (+/-0.067) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.01, 'warm_start': True}\n",
      "0.795 (+/-0.067) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.01, 'warm_start': False}\n",
      "0.774 (+/-0.076) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.1, 'warm_start': True}\n",
      "0.777 (+/-0.086) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.1, 'warm_start': False}\n",
      "0.794 (+/-0.077) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': True}\n",
      "0.794 (+/-0.077) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': False}\n",
      "0.794 (+/-0.077) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': True}\n",
      "0.794 (+/-0.077) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': False}\n",
      "0.794 (+/-0.077) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': True}\n",
      "0.794 (+/-0.077) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': False}\n",
      "0.795 (+/-0.076) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': True}\n",
      "0.795 (+/-0.076) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': False}\n",
      "0.792 (+/-0.076) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': True}\n",
      "0.792 (+/-0.076) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': False}\n",
      "0.794 (+/-0.077) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 1e-05, 'warm_start': True}\n",
      "0.794 (+/-0.077) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 1e-05, 'warm_start': False}\n",
      "0.794 (+/-0.077) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.0001, 'warm_start': True}\n",
      "0.794 (+/-0.077) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.0001, 'warm_start': False}\n",
      "0.794 (+/-0.077) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.001, 'warm_start': True}\n",
      "0.794 (+/-0.077) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.001, 'warm_start': False}\n",
      "0.794 (+/-0.077) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.01, 'warm_start': True}\n",
      "0.794 (+/-0.077) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.01, 'warm_start': False}\n",
      "0.792 (+/-0.070) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.1, 'warm_start': True}\n",
      "0.792 (+/-0.070) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.1, 'warm_start': False}\n",
      "0.794 (+/-0.077) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 1e-05, 'warm_start': True}\n",
      "0.794 (+/-0.077) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 1e-05, 'warm_start': False}\n",
      "0.794 (+/-0.077) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.0001, 'warm_start': True}\n",
      "0.794 (+/-0.077) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.0001, 'warm_start': False}\n",
      "0.794 (+/-0.077) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.001, 'warm_start': True}\n",
      "0.794 (+/-0.077) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.001, 'warm_start': False}\n",
      "0.794 (+/-0.077) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.01, 'warm_start': True}\n",
      "0.794 (+/-0.077) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.01, 'warm_start': False}\n",
      "0.794 (+/-0.077) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.1, 'warm_start': True}\n",
      "0.794 (+/-0.077) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.1, 'warm_start': False}\n",
      "0.794 (+/-0.077) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l2', 'solver': 'sag', 'tol': 1e-05, 'warm_start': True}\n",
      "0.794 (+/-0.077) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l2', 'solver': 'sag', 'tol': 1e-05, 'warm_start': False}\n",
      "0.794 (+/-0.077) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.0001, 'warm_start': True}\n",
      "0.794 (+/-0.077) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.0001, 'warm_start': False}\n",
      "0.792 (+/-0.070) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.001, 'warm_start': True}\n",
      "0.792 (+/-0.070) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.001, 'warm_start': False}\n",
      "0.795 (+/-0.070) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.01, 'warm_start': True}\n",
      "0.794 (+/-0.069) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.01, 'warm_start': False}\n",
      "0.784 (+/-0.080) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.1, 'warm_start': True}\n",
      "0.785 (+/-0.071) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.1, 'warm_start': False}\n",
      "0.794 (+/-0.077) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l2', 'solver': 'saga', 'tol': 1e-05, 'warm_start': True}\n",
      "0.794 (+/-0.077) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l2', 'solver': 'saga', 'tol': 1e-05, 'warm_start': False}\n",
      "0.794 (+/-0.077) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.0001, 'warm_start': True}\n",
      "0.794 (+/-0.077) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.0001, 'warm_start': False}\n",
      "0.794 (+/-0.069) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.001, 'warm_start': True}\n",
      "0.794 (+/-0.069) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.001, 'warm_start': False}\n",
      "0.795 (+/-0.067) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.01, 'warm_start': True}\n",
      "0.795 (+/-0.067) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.01, 'warm_start': False}\n",
      "0.775 (+/-0.075) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.1, 'warm_start': True}\n",
      "0.782 (+/-0.078) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.1, 'warm_start': False}\n",
      "0.794 (+/-0.077) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': True}\n",
      "0.794 (+/-0.077) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': False}\n",
      "0.794 (+/-0.077) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': True}\n",
      "0.794 (+/-0.077) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': False}\n",
      "0.794 (+/-0.077) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': True}\n",
      "0.794 (+/-0.077) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': False}\n",
      "0.795 (+/-0.076) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': True}\n",
      "0.795 (+/-0.076) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': False}\n",
      "0.792 (+/-0.076) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': True}\n",
      "0.792 (+/-0.076) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': False}\n",
      "0.794 (+/-0.077) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 1e-05, 'warm_start': True}\n",
      "0.794 (+/-0.077) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 1e-05, 'warm_start': False}\n",
      "0.794 (+/-0.077) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.0001, 'warm_start': True}\n",
      "0.794 (+/-0.077) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.0001, 'warm_start': False}\n",
      "0.794 (+/-0.077) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.001, 'warm_start': True}\n",
      "0.794 (+/-0.077) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.001, 'warm_start': False}\n",
      "0.794 (+/-0.077) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.01, 'warm_start': True}\n",
      "0.794 (+/-0.077) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.01, 'warm_start': False}\n",
      "0.792 (+/-0.070) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.1, 'warm_start': True}\n",
      "0.792 (+/-0.070) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.1, 'warm_start': False}\n",
      "0.794 (+/-0.077) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 1e-05, 'warm_start': True}\n",
      "0.794 (+/-0.077) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 1e-05, 'warm_start': False}\n",
      "0.794 (+/-0.077) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.0001, 'warm_start': True}\n",
      "0.794 (+/-0.077) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.0001, 'warm_start': False}\n",
      "0.794 (+/-0.077) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.001, 'warm_start': True}\n",
      "0.794 (+/-0.077) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.001, 'warm_start': False}\n",
      "0.794 (+/-0.077) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.01, 'warm_start': True}\n",
      "0.794 (+/-0.077) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.01, 'warm_start': False}\n",
      "0.794 (+/-0.077) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.1, 'warm_start': True}\n",
      "0.794 (+/-0.077) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.1, 'warm_start': False}\n",
      "0.794 (+/-0.077) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'sag', 'tol': 1e-05, 'warm_start': True}\n",
      "0.794 (+/-0.077) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'sag', 'tol': 1e-05, 'warm_start': False}\n",
      "0.794 (+/-0.077) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.0001, 'warm_start': True}\n",
      "0.794 (+/-0.077) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.0001, 'warm_start': False}\n",
      "0.792 (+/-0.070) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.001, 'warm_start': True}\n",
      "0.792 (+/-0.070) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.001, 'warm_start': False}\n",
      "0.795 (+/-0.070) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.01, 'warm_start': True}\n",
      "0.794 (+/-0.069) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.01, 'warm_start': False}\n",
      "0.787 (+/-0.076) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.1, 'warm_start': True}\n",
      "0.785 (+/-0.070) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.1, 'warm_start': False}\n",
      "0.794 (+/-0.077) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'saga', 'tol': 1e-05, 'warm_start': True}\n",
      "0.794 (+/-0.077) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'saga', 'tol': 1e-05, 'warm_start': False}\n",
      "0.794 (+/-0.077) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.0001, 'warm_start': True}\n",
      "0.794 (+/-0.077) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.0001, 'warm_start': False}\n",
      "0.794 (+/-0.069) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.001, 'warm_start': True}\n",
      "0.794 (+/-0.069) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.001, 'warm_start': False}\n",
      "0.795 (+/-0.067) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.01, 'warm_start': True}\n",
      "0.795 (+/-0.067) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.01, 'warm_start': False}\n",
      "0.775 (+/-0.082) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.1, 'warm_start': True}\n",
      "0.778 (+/-0.076) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.1, 'warm_start': False}\n",
      "0.794 (+/-0.077) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': True}\n",
      "0.794 (+/-0.077) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': False}\n",
      "0.794 (+/-0.077) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': True}\n",
      "0.794 (+/-0.077) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': False}\n",
      "0.794 (+/-0.077) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': True}\n",
      "0.794 (+/-0.077) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': False}\n",
      "0.795 (+/-0.076) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': True}\n",
      "0.795 (+/-0.076) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': False}\n",
      "0.792 (+/-0.076) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': True}\n",
      "0.792 (+/-0.076) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': False}\n",
      "0.794 (+/-0.077) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 1e-05, 'warm_start': True}\n",
      "0.794 (+/-0.077) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 1e-05, 'warm_start': False}\n",
      "0.794 (+/-0.077) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.0001, 'warm_start': True}\n",
      "0.794 (+/-0.077) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.0001, 'warm_start': False}\n",
      "0.794 (+/-0.077) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.001, 'warm_start': True}\n",
      "0.794 (+/-0.077) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.001, 'warm_start': False}\n",
      "0.794 (+/-0.077) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.01, 'warm_start': True}\n",
      "0.794 (+/-0.077) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.01, 'warm_start': False}\n",
      "0.792 (+/-0.070) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.1, 'warm_start': True}\n",
      "0.792 (+/-0.070) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.1, 'warm_start': False}\n",
      "0.794 (+/-0.077) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 1e-05, 'warm_start': True}\n",
      "0.794 (+/-0.077) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 1e-05, 'warm_start': False}\n",
      "0.794 (+/-0.077) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.0001, 'warm_start': True}\n",
      "0.794 (+/-0.077) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.0001, 'warm_start': False}\n",
      "0.794 (+/-0.077) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.001, 'warm_start': True}\n",
      "0.794 (+/-0.077) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.001, 'warm_start': False}\n",
      "0.794 (+/-0.077) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.01, 'warm_start': True}\n",
      "0.794 (+/-0.077) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.01, 'warm_start': False}\n",
      "0.794 (+/-0.077) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.1, 'warm_start': True}\n",
      "0.794 (+/-0.077) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.1, 'warm_start': False}\n",
      "0.794 (+/-0.077) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'sag', 'tol': 1e-05, 'warm_start': True}\n",
      "0.794 (+/-0.077) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'sag', 'tol': 1e-05, 'warm_start': False}\n",
      "0.794 (+/-0.077) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.0001, 'warm_start': True}\n",
      "0.794 (+/-0.077) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.0001, 'warm_start': False}\n",
      "0.792 (+/-0.070) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.001, 'warm_start': True}\n",
      "0.792 (+/-0.070) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.001, 'warm_start': False}\n",
      "0.795 (+/-0.070) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.01, 'warm_start': True}\n",
      "0.795 (+/-0.070) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.01, 'warm_start': False}\n",
      "0.789 (+/-0.083) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.1, 'warm_start': True}\n",
      "0.782 (+/-0.080) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.1, 'warm_start': False}\n",
      "0.794 (+/-0.077) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'saga', 'tol': 1e-05, 'warm_start': True}\n",
      "0.794 (+/-0.077) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'saga', 'tol': 1e-05, 'warm_start': False}\n",
      "0.794 (+/-0.077) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.0001, 'warm_start': True}\n",
      "0.794 (+/-0.077) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.0001, 'warm_start': False}\n",
      "0.794 (+/-0.069) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.001, 'warm_start': True}\n",
      "0.794 (+/-0.069) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.001, 'warm_start': False}\n",
      "0.795 (+/-0.067) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.01, 'warm_start': True}\n",
      "0.795 (+/-0.067) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.01, 'warm_start': False}\n",
      "0.781 (+/-0.075) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.1, 'warm_start': True}\n",
      "0.777 (+/-0.081) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.1, 'warm_start': False}\n",
      "0.794 (+/-0.077) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': True}\n",
      "0.794 (+/-0.077) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': False}\n",
      "0.794 (+/-0.077) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': True}\n",
      "0.794 (+/-0.077) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': False}\n",
      "0.794 (+/-0.077) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': True}\n",
      "0.794 (+/-0.077) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': False}\n",
      "0.795 (+/-0.076) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': True}\n",
      "0.795 (+/-0.076) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': False}\n",
      "0.792 (+/-0.076) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': True}\n",
      "0.792 (+/-0.076) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': False}\n",
      "0.794 (+/-0.077) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 1e-05, 'warm_start': True}\n",
      "0.794 (+/-0.077) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 1e-05, 'warm_start': False}\n",
      "0.794 (+/-0.077) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.0001, 'warm_start': True}\n",
      "0.794 (+/-0.077) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.0001, 'warm_start': False}\n",
      "0.794 (+/-0.077) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.001, 'warm_start': True}\n",
      "0.794 (+/-0.077) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.001, 'warm_start': False}\n",
      "0.794 (+/-0.077) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.01, 'warm_start': True}\n",
      "0.794 (+/-0.077) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.01, 'warm_start': False}\n",
      "0.792 (+/-0.070) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.1, 'warm_start': True}\n",
      "0.792 (+/-0.070) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.1, 'warm_start': False}\n",
      "0.794 (+/-0.077) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 1e-05, 'warm_start': True}\n",
      "0.794 (+/-0.077) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 1e-05, 'warm_start': False}\n",
      "0.794 (+/-0.077) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.0001, 'warm_start': True}\n",
      "0.794 (+/-0.077) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.0001, 'warm_start': False}\n",
      "0.794 (+/-0.077) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.001, 'warm_start': True}\n",
      "0.794 (+/-0.077) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.001, 'warm_start': False}\n",
      "0.794 (+/-0.077) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.01, 'warm_start': True}\n",
      "0.794 (+/-0.077) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.01, 'warm_start': False}\n",
      "0.794 (+/-0.077) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.1, 'warm_start': True}\n",
      "0.794 (+/-0.077) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.1, 'warm_start': False}\n",
      "0.794 (+/-0.077) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'sag', 'tol': 1e-05, 'warm_start': True}\n",
      "0.794 (+/-0.077) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'sag', 'tol': 1e-05, 'warm_start': False}\n",
      "0.794 (+/-0.077) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.0001, 'warm_start': True}\n",
      "0.794 (+/-0.077) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.0001, 'warm_start': False}\n",
      "0.792 (+/-0.070) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.001, 'warm_start': True}\n",
      "0.792 (+/-0.070) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.001, 'warm_start': False}\n",
      "0.795 (+/-0.070) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.01, 'warm_start': True}\n",
      "0.795 (+/-0.070) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.01, 'warm_start': False}\n",
      "0.788 (+/-0.079) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.1, 'warm_start': True}\n",
      "0.785 (+/-0.071) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.1, 'warm_start': False}\n",
      "0.794 (+/-0.077) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'saga', 'tol': 1e-05, 'warm_start': True}\n",
      "0.794 (+/-0.077) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'saga', 'tol': 1e-05, 'warm_start': False}\n",
      "0.794 (+/-0.077) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.0001, 'warm_start': True}\n",
      "0.794 (+/-0.077) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.0001, 'warm_start': False}\n",
      "0.794 (+/-0.069) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.001, 'warm_start': True}\n",
      "0.794 (+/-0.069) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.001, 'warm_start': False}\n",
      "0.795 (+/-0.067) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.01, 'warm_start': True}\n",
      "0.795 (+/-0.067) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.01, 'warm_start': False}\n",
      "0.774 (+/-0.076) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.1, 'warm_start': True}\n",
      "0.771 (+/-0.076) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.1, 'warm_start': False}\n",
      "0.761 (+/-0.064) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': True}\n",
      "0.761 (+/-0.064) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': False}\n",
      "0.761 (+/-0.064) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': True}\n",
      "0.761 (+/-0.064) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': False}\n",
      "0.761 (+/-0.064) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': True}\n",
      "0.761 (+/-0.064) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': False}\n",
      "0.763 (+/-0.065) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': True}\n",
      "0.763 (+/-0.065) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': False}\n",
      "0.758 (+/-0.068) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': True}\n",
      "0.758 (+/-0.068) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': False}\n",
      "0.761 (+/-0.064) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 1e-05, 'warm_start': True}\n",
      "0.761 (+/-0.064) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 1e-05, 'warm_start': False}\n",
      "0.761 (+/-0.064) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.0001, 'warm_start': True}\n",
      "0.761 (+/-0.064) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.0001, 'warm_start': False}\n",
      "0.761 (+/-0.064) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.001, 'warm_start': True}\n",
      "0.761 (+/-0.064) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.001, 'warm_start': False}\n",
      "0.761 (+/-0.064) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.01, 'warm_start': True}\n",
      "0.761 (+/-0.064) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.01, 'warm_start': False}\n",
      "0.763 (+/-0.069) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.1, 'warm_start': True}\n",
      "0.763 (+/-0.069) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.1, 'warm_start': False}\n",
      "0.761 (+/-0.064) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 1e-05, 'warm_start': True}\n",
      "0.761 (+/-0.064) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 1e-05, 'warm_start': False}\n",
      "0.761 (+/-0.064) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.0001, 'warm_start': True}\n",
      "0.761 (+/-0.064) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.0001, 'warm_start': False}\n",
      "0.761 (+/-0.064) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.001, 'warm_start': True}\n",
      "0.761 (+/-0.064) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.001, 'warm_start': False}\n",
      "0.761 (+/-0.064) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.01, 'warm_start': True}\n",
      "0.761 (+/-0.064) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.01, 'warm_start': False}\n",
      "0.761 (+/-0.064) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.1, 'warm_start': True}\n",
      "0.761 (+/-0.064) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.1, 'warm_start': False}\n",
      "0.761 (+/-0.064) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l2', 'solver': 'sag', 'tol': 1e-05, 'warm_start': True}\n",
      "0.761 (+/-0.064) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l2', 'solver': 'sag', 'tol': 1e-05, 'warm_start': False}\n",
      "0.761 (+/-0.064) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.0001, 'warm_start': True}\n",
      "0.761 (+/-0.064) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.0001, 'warm_start': False}\n",
      "0.761 (+/-0.064) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.001, 'warm_start': True}\n",
      "0.761 (+/-0.064) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.001, 'warm_start': False}\n",
      "0.763 (+/-0.069) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.01, 'warm_start': True}\n",
      "0.763 (+/-0.069) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.01, 'warm_start': False}\n",
      "0.763 (+/-0.066) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.1, 'warm_start': True}\n",
      "0.764 (+/-0.081) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.1, 'warm_start': False}\n",
      "0.761 (+/-0.064) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l2', 'solver': 'saga', 'tol': 1e-05, 'warm_start': True}\n",
      "0.761 (+/-0.064) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l2', 'solver': 'saga', 'tol': 1e-05, 'warm_start': False}\n",
      "0.761 (+/-0.064) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.0001, 'warm_start': True}\n",
      "0.761 (+/-0.064) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.0001, 'warm_start': False}\n",
      "0.761 (+/-0.064) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.001, 'warm_start': True}\n",
      "0.761 (+/-0.064) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.001, 'warm_start': False}\n",
      "0.760 (+/-0.071) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.01, 'warm_start': True}\n",
      "0.760 (+/-0.071) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.01, 'warm_start': False}\n",
      "0.768 (+/-0.056) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.1, 'warm_start': True}\n",
      "0.775 (+/-0.070) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.1, 'warm_start': False}\n",
      "0.761 (+/-0.064) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': True}\n",
      "0.761 (+/-0.064) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': False}\n",
      "0.761 (+/-0.064) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': True}\n",
      "0.761 (+/-0.064) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': False}\n",
      "0.761 (+/-0.064) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': True}\n",
      "0.761 (+/-0.064) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': False}\n",
      "0.763 (+/-0.065) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': True}\n",
      "0.763 (+/-0.065) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': False}\n",
      "0.758 (+/-0.068) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': True}\n",
      "0.758 (+/-0.068) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': False}\n",
      "0.761 (+/-0.064) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 1e-05, 'warm_start': True}\n",
      "0.761 (+/-0.064) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 1e-05, 'warm_start': False}\n",
      "0.761 (+/-0.064) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.0001, 'warm_start': True}\n",
      "0.761 (+/-0.064) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.0001, 'warm_start': False}\n",
      "0.761 (+/-0.064) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.001, 'warm_start': True}\n",
      "0.761 (+/-0.064) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.001, 'warm_start': False}\n",
      "0.761 (+/-0.064) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.01, 'warm_start': True}\n",
      "0.761 (+/-0.064) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.01, 'warm_start': False}\n",
      "0.763 (+/-0.069) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.1, 'warm_start': True}\n",
      "0.763 (+/-0.069) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.1, 'warm_start': False}\n",
      "0.761 (+/-0.064) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 1e-05, 'warm_start': True}\n",
      "0.761 (+/-0.064) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 1e-05, 'warm_start': False}\n",
      "0.761 (+/-0.064) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.0001, 'warm_start': True}\n",
      "0.761 (+/-0.064) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.0001, 'warm_start': False}\n",
      "0.761 (+/-0.064) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.001, 'warm_start': True}\n",
      "0.761 (+/-0.064) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.001, 'warm_start': False}\n",
      "0.761 (+/-0.064) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.01, 'warm_start': True}\n",
      "0.761 (+/-0.064) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.01, 'warm_start': False}\n",
      "0.761 (+/-0.064) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.1, 'warm_start': True}\n",
      "0.761 (+/-0.064) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.1, 'warm_start': False}\n",
      "0.761 (+/-0.064) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l2', 'solver': 'sag', 'tol': 1e-05, 'warm_start': True}\n",
      "0.761 (+/-0.064) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l2', 'solver': 'sag', 'tol': 1e-05, 'warm_start': False}\n",
      "0.761 (+/-0.064) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.0001, 'warm_start': True}\n",
      "0.761 (+/-0.064) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.0001, 'warm_start': False}\n",
      "0.761 (+/-0.064) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.001, 'warm_start': True}\n",
      "0.761 (+/-0.064) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.001, 'warm_start': False}\n",
      "0.763 (+/-0.069) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.01, 'warm_start': True}\n",
      "0.763 (+/-0.069) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.01, 'warm_start': False}\n",
      "0.767 (+/-0.065) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.1, 'warm_start': True}\n",
      "0.761 (+/-0.074) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.1, 'warm_start': False}\n",
      "0.761 (+/-0.064) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l2', 'solver': 'saga', 'tol': 1e-05, 'warm_start': True}\n",
      "0.761 (+/-0.064) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l2', 'solver': 'saga', 'tol': 1e-05, 'warm_start': False}\n",
      "0.761 (+/-0.064) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.0001, 'warm_start': True}\n",
      "0.761 (+/-0.064) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.0001, 'warm_start': False}\n",
      "0.761 (+/-0.064) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.001, 'warm_start': True}\n",
      "0.761 (+/-0.064) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.001, 'warm_start': False}\n",
      "0.761 (+/-0.071) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.01, 'warm_start': True}\n",
      "0.760 (+/-0.071) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.01, 'warm_start': False}\n",
      "0.771 (+/-0.079) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.1, 'warm_start': True}\n",
      "0.775 (+/-0.075) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.1, 'warm_start': False}\n",
      "0.761 (+/-0.064) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': True}\n",
      "0.761 (+/-0.064) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': False}\n",
      "0.761 (+/-0.064) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': True}\n",
      "0.761 (+/-0.064) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': False}\n",
      "0.761 (+/-0.064) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': True}\n",
      "0.761 (+/-0.064) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': False}\n",
      "0.763 (+/-0.065) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': True}\n",
      "0.763 (+/-0.065) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': False}\n",
      "0.758 (+/-0.068) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': True}\n",
      "0.758 (+/-0.068) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': False}\n",
      "0.761 (+/-0.064) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 1e-05, 'warm_start': True}\n",
      "0.761 (+/-0.064) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 1e-05, 'warm_start': False}\n",
      "0.761 (+/-0.064) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.0001, 'warm_start': True}\n",
      "0.761 (+/-0.064) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.0001, 'warm_start': False}\n",
      "0.761 (+/-0.064) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.001, 'warm_start': True}\n",
      "0.761 (+/-0.064) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.001, 'warm_start': False}\n",
      "0.761 (+/-0.064) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.01, 'warm_start': True}\n",
      "0.761 (+/-0.064) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.01, 'warm_start': False}\n",
      "0.763 (+/-0.069) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.1, 'warm_start': True}\n",
      "0.763 (+/-0.069) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.1, 'warm_start': False}\n",
      "0.761 (+/-0.064) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 1e-05, 'warm_start': True}\n",
      "0.761 (+/-0.064) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 1e-05, 'warm_start': False}\n",
      "0.761 (+/-0.064) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.0001, 'warm_start': True}\n",
      "0.761 (+/-0.064) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.0001, 'warm_start': False}\n",
      "0.761 (+/-0.064) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.001, 'warm_start': True}\n",
      "0.761 (+/-0.064) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.001, 'warm_start': False}\n",
      "0.761 (+/-0.064) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.01, 'warm_start': True}\n",
      "0.761 (+/-0.064) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.01, 'warm_start': False}\n",
      "0.761 (+/-0.064) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.1, 'warm_start': True}\n",
      "0.761 (+/-0.064) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.1, 'warm_start': False}\n",
      "0.761 (+/-0.064) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'sag', 'tol': 1e-05, 'warm_start': True}\n",
      "0.761 (+/-0.064) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'sag', 'tol': 1e-05, 'warm_start': False}\n",
      "0.761 (+/-0.064) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.0001, 'warm_start': True}\n",
      "0.761 (+/-0.064) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.0001, 'warm_start': False}\n",
      "0.761 (+/-0.064) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.001, 'warm_start': True}\n",
      "0.761 (+/-0.064) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.001, 'warm_start': False}\n",
      "0.763 (+/-0.069) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.01, 'warm_start': True}\n",
      "0.763 (+/-0.069) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.01, 'warm_start': False}\n",
      "0.761 (+/-0.079) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.1, 'warm_start': True}\n",
      "0.765 (+/-0.062) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.1, 'warm_start': False}\n",
      "0.761 (+/-0.064) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'saga', 'tol': 1e-05, 'warm_start': True}\n",
      "0.761 (+/-0.064) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'saga', 'tol': 1e-05, 'warm_start': False}\n",
      "0.761 (+/-0.064) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.0001, 'warm_start': True}\n",
      "0.761 (+/-0.064) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.0001, 'warm_start': False}\n",
      "0.761 (+/-0.064) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.001, 'warm_start': True}\n",
      "0.761 (+/-0.064) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.001, 'warm_start': False}\n",
      "0.761 (+/-0.071) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.01, 'warm_start': True}\n",
      "0.760 (+/-0.071) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.01, 'warm_start': False}\n",
      "0.771 (+/-0.059) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.1, 'warm_start': True}\n",
      "0.763 (+/-0.056) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.1, 'warm_start': False}\n",
      "0.761 (+/-0.064) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': True}\n",
      "0.761 (+/-0.064) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': False}\n",
      "0.761 (+/-0.064) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': True}\n",
      "0.761 (+/-0.064) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': False}\n",
      "0.761 (+/-0.064) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': True}\n",
      "0.761 (+/-0.064) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': False}\n",
      "0.763 (+/-0.065) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': True}\n",
      "0.763 (+/-0.065) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': False}\n",
      "0.758 (+/-0.068) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': True}\n",
      "0.758 (+/-0.068) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': False}\n",
      "0.761 (+/-0.064) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 1e-05, 'warm_start': True}\n",
      "0.761 (+/-0.064) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 1e-05, 'warm_start': False}\n",
      "0.761 (+/-0.064) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.0001, 'warm_start': True}\n",
      "0.761 (+/-0.064) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.0001, 'warm_start': False}\n",
      "0.761 (+/-0.064) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.001, 'warm_start': True}\n",
      "0.761 (+/-0.064) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.001, 'warm_start': False}\n",
      "0.761 (+/-0.064) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.01, 'warm_start': True}\n",
      "0.761 (+/-0.064) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.01, 'warm_start': False}\n",
      "0.763 (+/-0.069) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.1, 'warm_start': True}\n",
      "0.763 (+/-0.069) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.1, 'warm_start': False}\n",
      "0.761 (+/-0.064) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 1e-05, 'warm_start': True}\n",
      "0.761 (+/-0.064) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 1e-05, 'warm_start': False}\n",
      "0.761 (+/-0.064) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.0001, 'warm_start': True}\n",
      "0.761 (+/-0.064) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.0001, 'warm_start': False}\n",
      "0.761 (+/-0.064) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.001, 'warm_start': True}\n",
      "0.761 (+/-0.064) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.001, 'warm_start': False}\n",
      "0.761 (+/-0.064) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.01, 'warm_start': True}\n",
      "0.761 (+/-0.064) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.01, 'warm_start': False}\n",
      "0.761 (+/-0.064) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.1, 'warm_start': True}\n",
      "0.761 (+/-0.064) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.1, 'warm_start': False}\n",
      "0.761 (+/-0.064) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'sag', 'tol': 1e-05, 'warm_start': True}\n",
      "0.761 (+/-0.064) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'sag', 'tol': 1e-05, 'warm_start': False}\n",
      "0.761 (+/-0.064) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.0001, 'warm_start': True}\n",
      "0.761 (+/-0.064) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.0001, 'warm_start': False}\n",
      "0.761 (+/-0.064) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.001, 'warm_start': True}\n",
      "0.761 (+/-0.064) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.001, 'warm_start': False}\n",
      "0.763 (+/-0.069) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.01, 'warm_start': True}\n",
      "0.763 (+/-0.069) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.01, 'warm_start': False}\n",
      "0.757 (+/-0.074) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.1, 'warm_start': True}\n",
      "0.766 (+/-0.069) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.1, 'warm_start': False}\n",
      "0.761 (+/-0.064) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'saga', 'tol': 1e-05, 'warm_start': True}\n",
      "0.761 (+/-0.064) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'saga', 'tol': 1e-05, 'warm_start': False}\n",
      "0.761 (+/-0.064) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.0001, 'warm_start': True}\n",
      "0.761 (+/-0.064) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.0001, 'warm_start': False}\n",
      "0.761 (+/-0.064) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.001, 'warm_start': True}\n",
      "0.761 (+/-0.064) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.001, 'warm_start': False}\n",
      "0.760 (+/-0.071) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.01, 'warm_start': True}\n",
      "0.760 (+/-0.071) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.01, 'warm_start': False}\n",
      "0.773 (+/-0.062) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.1, 'warm_start': True}\n",
      "0.771 (+/-0.085) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.1, 'warm_start': False}\n",
      "0.761 (+/-0.064) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': True}\n",
      "0.761 (+/-0.064) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': False}\n",
      "0.761 (+/-0.064) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': True}\n",
      "0.761 (+/-0.064) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': False}\n",
      "0.761 (+/-0.064) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': True}\n",
      "0.761 (+/-0.064) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': False}\n",
      "0.763 (+/-0.065) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': True}\n",
      "0.763 (+/-0.065) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': False}\n",
      "0.758 (+/-0.068) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': True}\n",
      "0.758 (+/-0.068) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': False}\n",
      "0.761 (+/-0.064) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 1e-05, 'warm_start': True}\n",
      "0.761 (+/-0.064) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 1e-05, 'warm_start': False}\n",
      "0.761 (+/-0.064) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.0001, 'warm_start': True}\n",
      "0.761 (+/-0.064) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.0001, 'warm_start': False}\n",
      "0.761 (+/-0.064) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.001, 'warm_start': True}\n",
      "0.761 (+/-0.064) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.001, 'warm_start': False}\n",
      "0.761 (+/-0.064) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.01, 'warm_start': True}\n",
      "0.761 (+/-0.064) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.01, 'warm_start': False}\n",
      "0.763 (+/-0.069) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.1, 'warm_start': True}\n",
      "0.763 (+/-0.069) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.1, 'warm_start': False}\n",
      "0.761 (+/-0.064) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 1e-05, 'warm_start': True}\n",
      "0.761 (+/-0.064) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 1e-05, 'warm_start': False}\n",
      "0.761 (+/-0.064) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.0001, 'warm_start': True}\n",
      "0.761 (+/-0.064) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.0001, 'warm_start': False}\n",
      "0.761 (+/-0.064) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.001, 'warm_start': True}\n",
      "0.761 (+/-0.064) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.001, 'warm_start': False}\n",
      "0.761 (+/-0.064) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.01, 'warm_start': True}\n",
      "0.761 (+/-0.064) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.01, 'warm_start': False}\n",
      "0.761 (+/-0.064) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.1, 'warm_start': True}\n",
      "0.761 (+/-0.064) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.1, 'warm_start': False}\n",
      "0.761 (+/-0.064) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'sag', 'tol': 1e-05, 'warm_start': True}\n",
      "0.761 (+/-0.064) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'sag', 'tol': 1e-05, 'warm_start': False}\n",
      "0.761 (+/-0.064) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.0001, 'warm_start': True}\n",
      "0.761 (+/-0.064) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.0001, 'warm_start': False}\n",
      "0.761 (+/-0.064) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.001, 'warm_start': True}\n",
      "0.761 (+/-0.064) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.001, 'warm_start': False}\n",
      "0.763 (+/-0.069) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.01, 'warm_start': True}\n",
      "0.763 (+/-0.069) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.01, 'warm_start': False}\n",
      "0.770 (+/-0.069) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.1, 'warm_start': True}\n",
      "0.771 (+/-0.068) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.1, 'warm_start': False}\n",
      "0.761 (+/-0.064) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'saga', 'tol': 1e-05, 'warm_start': True}\n",
      "0.761 (+/-0.064) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'saga', 'tol': 1e-05, 'warm_start': False}\n",
      "0.761 (+/-0.064) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.0001, 'warm_start': True}\n",
      "0.761 (+/-0.064) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.0001, 'warm_start': False}\n",
      "0.761 (+/-0.064) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.001, 'warm_start': True}\n",
      "0.761 (+/-0.064) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.001, 'warm_start': False}\n",
      "0.760 (+/-0.071) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.01, 'warm_start': True}\n",
      "0.760 (+/-0.071) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.01, 'warm_start': False}\n",
      "0.771 (+/-0.065) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.1, 'warm_start': True}\n",
      "0.774 (+/-0.081) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.1, 'warm_start': False}\n",
      "0.794 (+/-0.085) for {'C': 10, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': True}\n",
      "0.794 (+/-0.085) for {'C': 10, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': False}\n",
      "0.794 (+/-0.085) for {'C': 10, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': True}\n",
      "0.794 (+/-0.085) for {'C': 10, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': False}\n",
      "0.791 (+/-0.087) for {'C': 10, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': True}\n",
      "0.791 (+/-0.087) for {'C': 10, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': False}\n",
      "0.794 (+/-0.085) for {'C': 10, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': True}\n",
      "0.794 (+/-0.085) for {'C': 10, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': False}\n",
      "0.795 (+/-0.076) for {'C': 10, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': True}\n",
      "0.795 (+/-0.076) for {'C': 10, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': False}\n",
      "0.794 (+/-0.085) for {'C': 10, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 1e-05, 'warm_start': True}\n",
      "0.794 (+/-0.085) for {'C': 10, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 1e-05, 'warm_start': False}\n",
      "0.794 (+/-0.085) for {'C': 10, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.0001, 'warm_start': True}\n",
      "0.794 (+/-0.085) for {'C': 10, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.0001, 'warm_start': False}\n",
      "0.794 (+/-0.085) for {'C': 10, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.001, 'warm_start': True}\n",
      "0.794 (+/-0.085) for {'C': 10, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.001, 'warm_start': False}\n",
      "0.794 (+/-0.085) for {'C': 10, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.01, 'warm_start': True}\n",
      "0.794 (+/-0.085) for {'C': 10, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.01, 'warm_start': False}\n",
      "0.794 (+/-0.085) for {'C': 10, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.1, 'warm_start': True}\n",
      "0.794 (+/-0.085) for {'C': 10, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.1, 'warm_start': False}\n",
      "0.794 (+/-0.085) for {'C': 10, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 1e-05, 'warm_start': True}\n",
      "0.794 (+/-0.085) for {'C': 10, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 1e-05, 'warm_start': False}\n",
      "0.794 (+/-0.085) for {'C': 10, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.0001, 'warm_start': True}\n",
      "0.794 (+/-0.085) for {'C': 10, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.0001, 'warm_start': False}\n",
      "0.794 (+/-0.085) for {'C': 10, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.001, 'warm_start': True}\n",
      "0.794 (+/-0.085) for {'C': 10, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.001, 'warm_start': False}\n",
      "0.794 (+/-0.085) for {'C': 10, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.01, 'warm_start': True}\n",
      "0.794 (+/-0.085) for {'C': 10, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.01, 'warm_start': False}\n",
      "0.791 (+/-0.087) for {'C': 10, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.1, 'warm_start': True}\n",
      "0.791 (+/-0.087) for {'C': 10, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.1, 'warm_start': False}\n",
      "0.796 (+/-0.080) for {'C': 10, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l2', 'solver': 'sag', 'tol': 1e-05, 'warm_start': True}\n",
      "0.796 (+/-0.080) for {'C': 10, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l2', 'solver': 'sag', 'tol': 1e-05, 'warm_start': False}\n",
      "0.796 (+/-0.080) for {'C': 10, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.0001, 'warm_start': True}\n",
      "0.796 (+/-0.080) for {'C': 10, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.0001, 'warm_start': False}\n",
      "0.796 (+/-0.080) for {'C': 10, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.001, 'warm_start': True}\n",
      "0.796 (+/-0.080) for {'C': 10, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.001, 'warm_start': False}\n",
      "0.795 (+/-0.078) for {'C': 10, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.01, 'warm_start': True}\n",
      "0.794 (+/-0.077) for {'C': 10, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.01, 'warm_start': False}\n",
      "0.794 (+/-0.071) for {'C': 10, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.1, 'warm_start': True}\n",
      "0.789 (+/-0.066) for {'C': 10, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.1, 'warm_start': False}\n",
      "0.796 (+/-0.080) for {'C': 10, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l2', 'solver': 'saga', 'tol': 1e-05, 'warm_start': True}\n",
      "0.796 (+/-0.080) for {'C': 10, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l2', 'solver': 'saga', 'tol': 1e-05, 'warm_start': False}\n",
      "0.796 (+/-0.080) for {'C': 10, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.0001, 'warm_start': True}\n",
      "0.796 (+/-0.080) for {'C': 10, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.0001, 'warm_start': False}\n",
      "0.796 (+/-0.080) for {'C': 10, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.001, 'warm_start': True}\n",
      "0.796 (+/-0.080) for {'C': 10, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.001, 'warm_start': False}\n",
      "0.795 (+/-0.070) for {'C': 10, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.01, 'warm_start': True}\n",
      "0.795 (+/-0.070) for {'C': 10, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.01, 'warm_start': False}\n",
      "0.781 (+/-0.079) for {'C': 10, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.1, 'warm_start': True}\n",
      "0.781 (+/-0.075) for {'C': 10, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.1, 'warm_start': False}\n",
      "0.794 (+/-0.085) for {'C': 10, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': True}\n",
      "0.794 (+/-0.085) for {'C': 10, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': False}\n",
      "0.794 (+/-0.085) for {'C': 10, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': True}\n",
      "0.794 (+/-0.085) for {'C': 10, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': False}\n",
      "0.791 (+/-0.087) for {'C': 10, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': True}\n",
      "0.791 (+/-0.087) for {'C': 10, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': False}\n",
      "0.794 (+/-0.085) for {'C': 10, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': True}\n",
      "0.794 (+/-0.085) for {'C': 10, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': False}\n",
      "0.795 (+/-0.076) for {'C': 10, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': True}\n",
      "0.795 (+/-0.076) for {'C': 10, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': False}\n",
      "0.794 (+/-0.085) for {'C': 10, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 1e-05, 'warm_start': True}\n",
      "0.794 (+/-0.085) for {'C': 10, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 1e-05, 'warm_start': False}\n",
      "0.794 (+/-0.085) for {'C': 10, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.0001, 'warm_start': True}\n",
      "0.794 (+/-0.085) for {'C': 10, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.0001, 'warm_start': False}\n",
      "0.794 (+/-0.085) for {'C': 10, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.001, 'warm_start': True}\n",
      "0.794 (+/-0.085) for {'C': 10, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.001, 'warm_start': False}\n",
      "0.794 (+/-0.085) for {'C': 10, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.01, 'warm_start': True}\n",
      "0.794 (+/-0.085) for {'C': 10, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.01, 'warm_start': False}\n",
      "0.794 (+/-0.085) for {'C': 10, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.1, 'warm_start': True}\n",
      "0.794 (+/-0.085) for {'C': 10, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.1, 'warm_start': False}\n",
      "0.794 (+/-0.085) for {'C': 10, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 1e-05, 'warm_start': True}\n",
      "0.794 (+/-0.085) for {'C': 10, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 1e-05, 'warm_start': False}\n",
      "0.794 (+/-0.085) for {'C': 10, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.0001, 'warm_start': True}\n",
      "0.794 (+/-0.085) for {'C': 10, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.0001, 'warm_start': False}\n",
      "0.794 (+/-0.085) for {'C': 10, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.001, 'warm_start': True}\n",
      "0.794 (+/-0.085) for {'C': 10, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.001, 'warm_start': False}\n",
      "0.794 (+/-0.085) for {'C': 10, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.01, 'warm_start': True}\n",
      "0.794 (+/-0.085) for {'C': 10, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.01, 'warm_start': False}\n",
      "0.791 (+/-0.087) for {'C': 10, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.1, 'warm_start': True}\n",
      "0.791 (+/-0.087) for {'C': 10, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.1, 'warm_start': False}\n",
      "0.794 (+/-0.085) for {'C': 10, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l2', 'solver': 'sag', 'tol': 1e-05, 'warm_start': True}\n",
      "0.794 (+/-0.085) for {'C': 10, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l2', 'solver': 'sag', 'tol': 1e-05, 'warm_start': False}\n",
      "0.794 (+/-0.085) for {'C': 10, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.0001, 'warm_start': True}\n",
      "0.794 (+/-0.085) for {'C': 10, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.0001, 'warm_start': False}\n",
      "0.794 (+/-0.085) for {'C': 10, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.001, 'warm_start': True}\n",
      "0.794 (+/-0.085) for {'C': 10, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.001, 'warm_start': False}\n",
      "0.795 (+/-0.076) for {'C': 10, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.01, 'warm_start': True}\n",
      "0.795 (+/-0.078) for {'C': 10, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.01, 'warm_start': False}\n",
      "0.787 (+/-0.081) for {'C': 10, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.1, 'warm_start': True}\n",
      "0.791 (+/-0.089) for {'C': 10, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.1, 'warm_start': False}\n",
      "0.794 (+/-0.085) for {'C': 10, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l2', 'solver': 'saga', 'tol': 1e-05, 'warm_start': True}\n",
      "0.794 (+/-0.085) for {'C': 10, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l2', 'solver': 'saga', 'tol': 1e-05, 'warm_start': False}\n",
      "0.794 (+/-0.085) for {'C': 10, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.0001, 'warm_start': True}\n",
      "0.794 (+/-0.085) for {'C': 10, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.0001, 'warm_start': False}\n",
      "0.796 (+/-0.080) for {'C': 10, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.001, 'warm_start': True}\n",
      "0.796 (+/-0.080) for {'C': 10, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.001, 'warm_start': False}\n",
      "0.795 (+/-0.070) for {'C': 10, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.01, 'warm_start': True}\n",
      "0.795 (+/-0.070) for {'C': 10, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.01, 'warm_start': False}\n",
      "0.778 (+/-0.084) for {'C': 10, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.1, 'warm_start': True}\n",
      "0.773 (+/-0.081) for {'C': 10, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.1, 'warm_start': False}\n",
      "0.794 (+/-0.085) for {'C': 10, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': True}\n",
      "0.794 (+/-0.085) for {'C': 10, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': False}\n",
      "0.794 (+/-0.085) for {'C': 10, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': True}\n",
      "0.794 (+/-0.085) for {'C': 10, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': False}\n",
      "0.791 (+/-0.087) for {'C': 10, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': True}\n",
      "0.791 (+/-0.087) for {'C': 10, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': False}\n",
      "0.794 (+/-0.085) for {'C': 10, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': True}\n",
      "0.794 (+/-0.085) for {'C': 10, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': False}\n",
      "0.795 (+/-0.076) for {'C': 10, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': True}\n",
      "0.795 (+/-0.076) for {'C': 10, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': False}\n",
      "0.794 (+/-0.085) for {'C': 10, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 1e-05, 'warm_start': True}\n",
      "0.794 (+/-0.085) for {'C': 10, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 1e-05, 'warm_start': False}\n",
      "0.794 (+/-0.085) for {'C': 10, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.0001, 'warm_start': True}\n",
      "0.794 (+/-0.085) for {'C': 10, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.0001, 'warm_start': False}\n",
      "0.794 (+/-0.085) for {'C': 10, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.001, 'warm_start': True}\n",
      "0.794 (+/-0.085) for {'C': 10, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.001, 'warm_start': False}\n",
      "0.794 (+/-0.085) for {'C': 10, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.01, 'warm_start': True}\n",
      "0.794 (+/-0.085) for {'C': 10, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.01, 'warm_start': False}\n",
      "0.794 (+/-0.085) for {'C': 10, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.1, 'warm_start': True}\n",
      "0.794 (+/-0.085) for {'C': 10, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.1, 'warm_start': False}\n",
      "0.794 (+/-0.085) for {'C': 10, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 1e-05, 'warm_start': True}\n",
      "0.794 (+/-0.085) for {'C': 10, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 1e-05, 'warm_start': False}\n",
      "0.794 (+/-0.085) for {'C': 10, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.0001, 'warm_start': True}\n",
      "0.794 (+/-0.085) for {'C': 10, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.0001, 'warm_start': False}\n",
      "0.794 (+/-0.085) for {'C': 10, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.001, 'warm_start': True}\n",
      "0.794 (+/-0.085) for {'C': 10, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.001, 'warm_start': False}\n",
      "0.794 (+/-0.085) for {'C': 10, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.01, 'warm_start': True}\n",
      "0.794 (+/-0.085) for {'C': 10, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.01, 'warm_start': False}\n",
      "0.791 (+/-0.087) for {'C': 10, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.1, 'warm_start': True}\n",
      "0.791 (+/-0.087) for {'C': 10, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.1, 'warm_start': False}\n",
      "0.794 (+/-0.085) for {'C': 10, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'sag', 'tol': 1e-05, 'warm_start': True}\n",
      "0.794 (+/-0.085) for {'C': 10, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'sag', 'tol': 1e-05, 'warm_start': False}\n",
      "0.794 (+/-0.085) for {'C': 10, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.0001, 'warm_start': True}\n",
      "0.794 (+/-0.085) for {'C': 10, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.0001, 'warm_start': False}\n",
      "0.794 (+/-0.085) for {'C': 10, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.001, 'warm_start': True}\n",
      "0.794 (+/-0.085) for {'C': 10, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.001, 'warm_start': False}\n",
      "0.794 (+/-0.077) for {'C': 10, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.01, 'warm_start': True}\n",
      "0.794 (+/-0.077) for {'C': 10, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.01, 'warm_start': False}\n",
      "0.782 (+/-0.081) for {'C': 10, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.1, 'warm_start': True}\n",
      "0.785 (+/-0.073) for {'C': 10, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.1, 'warm_start': False}\n",
      "0.794 (+/-0.085) for {'C': 10, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'saga', 'tol': 1e-05, 'warm_start': True}\n",
      "0.794 (+/-0.085) for {'C': 10, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'saga', 'tol': 1e-05, 'warm_start': False}\n",
      "0.794 (+/-0.085) for {'C': 10, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.0001, 'warm_start': True}\n",
      "0.794 (+/-0.085) for {'C': 10, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.0001, 'warm_start': False}\n",
      "0.796 (+/-0.080) for {'C': 10, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.001, 'warm_start': True}\n",
      "0.796 (+/-0.080) for {'C': 10, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.001, 'warm_start': False}\n",
      "0.795 (+/-0.070) for {'C': 10, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.01, 'warm_start': True}\n",
      "0.795 (+/-0.070) for {'C': 10, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.01, 'warm_start': False}\n",
      "0.780 (+/-0.079) for {'C': 10, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.1, 'warm_start': True}\n",
      "0.775 (+/-0.071) for {'C': 10, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.1, 'warm_start': False}\n",
      "0.794 (+/-0.085) for {'C': 10, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': True}\n",
      "0.794 (+/-0.085) for {'C': 10, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': False}\n",
      "0.794 (+/-0.085) for {'C': 10, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': True}\n",
      "0.794 (+/-0.085) for {'C': 10, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': False}\n",
      "0.791 (+/-0.087) for {'C': 10, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': True}\n",
      "0.791 (+/-0.087) for {'C': 10, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': False}\n",
      "0.794 (+/-0.085) for {'C': 10, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': True}\n",
      "0.794 (+/-0.085) for {'C': 10, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': False}\n",
      "0.795 (+/-0.076) for {'C': 10, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': True}\n",
      "0.795 (+/-0.076) for {'C': 10, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': False}\n",
      "0.794 (+/-0.085) for {'C': 10, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 1e-05, 'warm_start': True}\n",
      "0.794 (+/-0.085) for {'C': 10, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 1e-05, 'warm_start': False}\n",
      "0.794 (+/-0.085) for {'C': 10, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.0001, 'warm_start': True}\n",
      "0.794 (+/-0.085) for {'C': 10, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.0001, 'warm_start': False}\n",
      "0.794 (+/-0.085) for {'C': 10, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.001, 'warm_start': True}\n",
      "0.794 (+/-0.085) for {'C': 10, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.001, 'warm_start': False}\n",
      "0.794 (+/-0.085) for {'C': 10, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.01, 'warm_start': True}\n",
      "0.794 (+/-0.085) for {'C': 10, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.01, 'warm_start': False}\n",
      "0.794 (+/-0.085) for {'C': 10, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.1, 'warm_start': True}\n",
      "0.794 (+/-0.085) for {'C': 10, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.1, 'warm_start': False}\n",
      "0.794 (+/-0.085) for {'C': 10, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 1e-05, 'warm_start': True}\n",
      "0.794 (+/-0.085) for {'C': 10, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 1e-05, 'warm_start': False}\n",
      "0.794 (+/-0.085) for {'C': 10, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.0001, 'warm_start': True}\n",
      "0.794 (+/-0.085) for {'C': 10, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.0001, 'warm_start': False}\n",
      "0.794 (+/-0.085) for {'C': 10, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.001, 'warm_start': True}\n",
      "0.794 (+/-0.085) for {'C': 10, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.001, 'warm_start': False}\n",
      "0.794 (+/-0.085) for {'C': 10, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.01, 'warm_start': True}\n",
      "0.794 (+/-0.085) for {'C': 10, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.01, 'warm_start': False}\n",
      "0.791 (+/-0.087) for {'C': 10, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.1, 'warm_start': True}\n",
      "0.791 (+/-0.087) for {'C': 10, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.1, 'warm_start': False}\n",
      "0.794 (+/-0.085) for {'C': 10, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'sag', 'tol': 1e-05, 'warm_start': True}\n",
      "0.794 (+/-0.085) for {'C': 10, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'sag', 'tol': 1e-05, 'warm_start': False}\n",
      "0.794 (+/-0.085) for {'C': 10, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.0001, 'warm_start': True}\n",
      "0.794 (+/-0.085) for {'C': 10, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.0001, 'warm_start': False}\n",
      "0.794 (+/-0.085) for {'C': 10, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.001, 'warm_start': True}\n",
      "0.794 (+/-0.085) for {'C': 10, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.001, 'warm_start': False}\n",
      "0.795 (+/-0.076) for {'C': 10, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.01, 'warm_start': True}\n",
      "0.795 (+/-0.076) for {'C': 10, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.01, 'warm_start': False}\n",
      "0.785 (+/-0.094) for {'C': 10, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.1, 'warm_start': True}\n",
      "0.784 (+/-0.083) for {'C': 10, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.1, 'warm_start': False}\n",
      "0.794 (+/-0.085) for {'C': 10, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'saga', 'tol': 1e-05, 'warm_start': True}\n",
      "0.794 (+/-0.085) for {'C': 10, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'saga', 'tol': 1e-05, 'warm_start': False}\n",
      "0.794 (+/-0.085) for {'C': 10, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.0001, 'warm_start': True}\n",
      "0.794 (+/-0.085) for {'C': 10, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.0001, 'warm_start': False}\n",
      "0.796 (+/-0.080) for {'C': 10, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.001, 'warm_start': True}\n",
      "0.796 (+/-0.080) for {'C': 10, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.001, 'warm_start': False}\n",
      "0.795 (+/-0.070) for {'C': 10, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.01, 'warm_start': True}\n",
      "0.794 (+/-0.069) for {'C': 10, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.01, 'warm_start': False}\n",
      "0.771 (+/-0.080) for {'C': 10, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.1, 'warm_start': True}\n",
      "0.774 (+/-0.080) for {'C': 10, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.1, 'warm_start': False}\n",
      "0.794 (+/-0.085) for {'C': 10, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': True}\n",
      "0.794 (+/-0.085) for {'C': 10, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': False}\n",
      "0.794 (+/-0.085) for {'C': 10, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': True}\n",
      "0.794 (+/-0.085) for {'C': 10, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': False}\n",
      "0.791 (+/-0.087) for {'C': 10, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': True}\n",
      "0.791 (+/-0.087) for {'C': 10, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': False}\n",
      "0.794 (+/-0.085) for {'C': 10, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': True}\n",
      "0.794 (+/-0.085) for {'C': 10, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': False}\n",
      "0.795 (+/-0.076) for {'C': 10, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': True}\n",
      "0.795 (+/-0.076) for {'C': 10, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': False}\n",
      "0.794 (+/-0.085) for {'C': 10, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 1e-05, 'warm_start': True}\n",
      "0.794 (+/-0.085) for {'C': 10, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 1e-05, 'warm_start': False}\n",
      "0.794 (+/-0.085) for {'C': 10, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.0001, 'warm_start': True}\n",
      "0.794 (+/-0.085) for {'C': 10, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.0001, 'warm_start': False}\n",
      "0.794 (+/-0.085) for {'C': 10, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.001, 'warm_start': True}\n",
      "0.794 (+/-0.085) for {'C': 10, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.001, 'warm_start': False}\n",
      "0.794 (+/-0.085) for {'C': 10, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.01, 'warm_start': True}\n",
      "0.794 (+/-0.085) for {'C': 10, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.01, 'warm_start': False}\n",
      "0.794 (+/-0.085) for {'C': 10, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.1, 'warm_start': True}\n",
      "0.794 (+/-0.085) for {'C': 10, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.1, 'warm_start': False}\n",
      "0.794 (+/-0.085) for {'C': 10, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 1e-05, 'warm_start': True}\n",
      "0.794 (+/-0.085) for {'C': 10, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 1e-05, 'warm_start': False}\n",
      "0.794 (+/-0.085) for {'C': 10, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.0001, 'warm_start': True}\n",
      "0.794 (+/-0.085) for {'C': 10, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.0001, 'warm_start': False}\n",
      "0.794 (+/-0.085) for {'C': 10, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.001, 'warm_start': True}\n",
      "0.794 (+/-0.085) for {'C': 10, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.001, 'warm_start': False}\n",
      "0.794 (+/-0.085) for {'C': 10, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.01, 'warm_start': True}\n",
      "0.794 (+/-0.085) for {'C': 10, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.01, 'warm_start': False}\n",
      "0.791 (+/-0.087) for {'C': 10, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.1, 'warm_start': True}\n",
      "0.791 (+/-0.087) for {'C': 10, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.1, 'warm_start': False}\n",
      "0.794 (+/-0.085) for {'C': 10, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'sag', 'tol': 1e-05, 'warm_start': True}\n",
      "0.794 (+/-0.085) for {'C': 10, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'sag', 'tol': 1e-05, 'warm_start': False}\n",
      "0.794 (+/-0.085) for {'C': 10, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.0001, 'warm_start': True}\n",
      "0.794 (+/-0.085) for {'C': 10, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.0001, 'warm_start': False}\n",
      "0.794 (+/-0.085) for {'C': 10, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.001, 'warm_start': True}\n",
      "0.794 (+/-0.085) for {'C': 10, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.001, 'warm_start': False}\n",
      "0.794 (+/-0.077) for {'C': 10, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.01, 'warm_start': True}\n",
      "0.795 (+/-0.078) for {'C': 10, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.01, 'warm_start': False}\n",
      "0.784 (+/-0.072) for {'C': 10, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.1, 'warm_start': True}\n",
      "0.788 (+/-0.077) for {'C': 10, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.1, 'warm_start': False}\n",
      "0.794 (+/-0.085) for {'C': 10, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'saga', 'tol': 1e-05, 'warm_start': True}\n",
      "0.794 (+/-0.085) for {'C': 10, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'saga', 'tol': 1e-05, 'warm_start': False}\n",
      "0.794 (+/-0.085) for {'C': 10, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.0001, 'warm_start': True}\n",
      "0.794 (+/-0.085) for {'C': 10, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.0001, 'warm_start': False}\n",
      "0.796 (+/-0.080) for {'C': 10, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.001, 'warm_start': True}\n",
      "0.796 (+/-0.080) for {'C': 10, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.001, 'warm_start': False}\n",
      "0.795 (+/-0.070) for {'C': 10, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.01, 'warm_start': True}\n",
      "0.795 (+/-0.070) for {'C': 10, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.01, 'warm_start': False}\n",
      "0.778 (+/-0.084) for {'C': 10, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.1, 'warm_start': True}\n",
      "0.771 (+/-0.085) for {'C': 10, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.1, 'warm_start': False}\n",
      "0.764 (+/-0.073) for {'C': 10, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': True}\n",
      "0.764 (+/-0.073) for {'C': 10, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': False}\n",
      "0.764 (+/-0.073) for {'C': 10, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': True}\n",
      "0.764 (+/-0.073) for {'C': 10, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': False}\n",
      "0.764 (+/-0.073) for {'C': 10, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': True}\n",
      "0.764 (+/-0.073) for {'C': 10, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': False}\n",
      "0.764 (+/-0.073) for {'C': 10, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': True}\n",
      "0.764 (+/-0.073) for {'C': 10, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': False}\n",
      "0.763 (+/-0.063) for {'C': 10, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': True}\n",
      "0.763 (+/-0.063) for {'C': 10, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': False}\n",
      "0.764 (+/-0.073) for {'C': 10, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 1e-05, 'warm_start': True}\n",
      "0.764 (+/-0.073) for {'C': 10, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 1e-05, 'warm_start': False}\n",
      "0.764 (+/-0.073) for {'C': 10, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.0001, 'warm_start': True}\n",
      "0.764 (+/-0.073) for {'C': 10, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.0001, 'warm_start': False}\n",
      "0.764 (+/-0.073) for {'C': 10, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.001, 'warm_start': True}\n",
      "0.764 (+/-0.073) for {'C': 10, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.001, 'warm_start': False}\n",
      "0.764 (+/-0.073) for {'C': 10, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.01, 'warm_start': True}\n",
      "0.764 (+/-0.073) for {'C': 10, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.01, 'warm_start': False}\n",
      "0.764 (+/-0.073) for {'C': 10, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.1, 'warm_start': True}\n",
      "0.764 (+/-0.073) for {'C': 10, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.1, 'warm_start': False}\n",
      "0.764 (+/-0.073) for {'C': 10, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 1e-05, 'warm_start': True}\n",
      "0.764 (+/-0.073) for {'C': 10, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 1e-05, 'warm_start': False}\n",
      "0.764 (+/-0.073) for {'C': 10, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.0001, 'warm_start': True}\n",
      "0.764 (+/-0.073) for {'C': 10, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.0001, 'warm_start': False}\n",
      "0.764 (+/-0.073) for {'C': 10, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.001, 'warm_start': True}\n",
      "0.764 (+/-0.073) for {'C': 10, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.001, 'warm_start': False}\n",
      "0.764 (+/-0.073) for {'C': 10, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.01, 'warm_start': True}\n",
      "0.764 (+/-0.073) for {'C': 10, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.01, 'warm_start': False}\n",
      "0.764 (+/-0.073) for {'C': 10, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.1, 'warm_start': True}\n",
      "0.764 (+/-0.073) for {'C': 10, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.1, 'warm_start': False}\n",
      "0.764 (+/-0.070) for {'C': 10, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l2', 'solver': 'sag', 'tol': 1e-05, 'warm_start': True}\n",
      "0.764 (+/-0.070) for {'C': 10, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l2', 'solver': 'sag', 'tol': 1e-05, 'warm_start': False}\n",
      "0.764 (+/-0.070) for {'C': 10, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.0001, 'warm_start': True}\n",
      "0.764 (+/-0.070) for {'C': 10, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.0001, 'warm_start': False}\n",
      "0.764 (+/-0.070) for {'C': 10, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.001, 'warm_start': True}\n",
      "0.764 (+/-0.070) for {'C': 10, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.001, 'warm_start': False}\n",
      "0.765 (+/-0.065) for {'C': 10, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.01, 'warm_start': True}\n",
      "0.765 (+/-0.065) for {'C': 10, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.01, 'warm_start': False}\n",
      "0.763 (+/-0.064) for {'C': 10, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.1, 'warm_start': True}\n",
      "0.753 (+/-0.060) for {'C': 10, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.1, 'warm_start': False}\n",
      "0.763 (+/-0.064) for {'C': 10, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l2', 'solver': 'saga', 'tol': 1e-05, 'warm_start': True}\n",
      "0.763 (+/-0.064) for {'C': 10, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l2', 'solver': 'saga', 'tol': 1e-05, 'warm_start': False}\n",
      "0.763 (+/-0.064) for {'C': 10, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.0001, 'warm_start': True}\n",
      "0.763 (+/-0.064) for {'C': 10, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.0001, 'warm_start': False}\n",
      "0.763 (+/-0.064) for {'C': 10, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.001, 'warm_start': True}\n",
      "0.763 (+/-0.064) for {'C': 10, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.001, 'warm_start': False}\n",
      "0.763 (+/-0.069) for {'C': 10, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.01, 'warm_start': True}\n",
      "0.763 (+/-0.069) for {'C': 10, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.01, 'warm_start': False}\n",
      "0.767 (+/-0.071) for {'C': 10, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.1, 'warm_start': True}\n",
      "0.770 (+/-0.072) for {'C': 10, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.1, 'warm_start': False}\n",
      "0.764 (+/-0.073) for {'C': 10, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': True}\n",
      "0.764 (+/-0.073) for {'C': 10, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': False}\n",
      "0.764 (+/-0.073) for {'C': 10, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': True}\n",
      "0.764 (+/-0.073) for {'C': 10, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': False}\n",
      "0.764 (+/-0.073) for {'C': 10, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': True}\n",
      "0.764 (+/-0.073) for {'C': 10, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': False}\n",
      "0.764 (+/-0.073) for {'C': 10, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': True}\n",
      "0.764 (+/-0.073) for {'C': 10, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': False}\n",
      "0.763 (+/-0.063) for {'C': 10, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': True}\n",
      "0.763 (+/-0.063) for {'C': 10, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': False}\n",
      "0.764 (+/-0.073) for {'C': 10, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 1e-05, 'warm_start': True}\n",
      "0.764 (+/-0.073) for {'C': 10, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 1e-05, 'warm_start': False}\n",
      "0.764 (+/-0.073) for {'C': 10, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.0001, 'warm_start': True}\n",
      "0.764 (+/-0.073) for {'C': 10, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.0001, 'warm_start': False}\n",
      "0.764 (+/-0.073) for {'C': 10, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.001, 'warm_start': True}\n",
      "0.764 (+/-0.073) for {'C': 10, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.001, 'warm_start': False}\n",
      "0.764 (+/-0.073) for {'C': 10, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.01, 'warm_start': True}\n",
      "0.764 (+/-0.073) for {'C': 10, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.01, 'warm_start': False}\n",
      "0.764 (+/-0.073) for {'C': 10, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.1, 'warm_start': True}\n",
      "0.764 (+/-0.073) for {'C': 10, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.1, 'warm_start': False}\n",
      "0.764 (+/-0.073) for {'C': 10, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 1e-05, 'warm_start': True}\n",
      "0.764 (+/-0.073) for {'C': 10, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 1e-05, 'warm_start': False}\n",
      "0.764 (+/-0.073) for {'C': 10, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.0001, 'warm_start': True}\n",
      "0.764 (+/-0.073) for {'C': 10, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.0001, 'warm_start': False}\n",
      "0.764 (+/-0.073) for {'C': 10, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.001, 'warm_start': True}\n",
      "0.764 (+/-0.073) for {'C': 10, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.001, 'warm_start': False}\n",
      "0.764 (+/-0.073) for {'C': 10, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.01, 'warm_start': True}\n",
      "0.764 (+/-0.073) for {'C': 10, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.01, 'warm_start': False}\n",
      "0.764 (+/-0.073) for {'C': 10, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.1, 'warm_start': True}\n",
      "0.764 (+/-0.073) for {'C': 10, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.1, 'warm_start': False}\n",
      "0.764 (+/-0.073) for {'C': 10, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l2', 'solver': 'sag', 'tol': 1e-05, 'warm_start': True}\n",
      "0.764 (+/-0.073) for {'C': 10, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l2', 'solver': 'sag', 'tol': 1e-05, 'warm_start': False}\n",
      "0.764 (+/-0.073) for {'C': 10, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.0001, 'warm_start': True}\n",
      "0.764 (+/-0.073) for {'C': 10, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.0001, 'warm_start': False}\n",
      "0.765 (+/-0.074) for {'C': 10, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.001, 'warm_start': True}\n",
      "0.765 (+/-0.074) for {'C': 10, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.001, 'warm_start': False}\n",
      "0.765 (+/-0.065) for {'C': 10, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.01, 'warm_start': True}\n",
      "0.765 (+/-0.065) for {'C': 10, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.01, 'warm_start': False}\n",
      "0.765 (+/-0.057) for {'C': 10, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.1, 'warm_start': True}\n",
      "0.766 (+/-0.072) for {'C': 10, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.1, 'warm_start': False}\n",
      "0.765 (+/-0.074) for {'C': 10, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l2', 'solver': 'saga', 'tol': 1e-05, 'warm_start': True}\n",
      "0.765 (+/-0.074) for {'C': 10, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l2', 'solver': 'saga', 'tol': 1e-05, 'warm_start': False}\n",
      "0.765 (+/-0.074) for {'C': 10, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.0001, 'warm_start': True}\n",
      "0.765 (+/-0.074) for {'C': 10, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.0001, 'warm_start': False}\n",
      "0.764 (+/-0.069) for {'C': 10, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.001, 'warm_start': True}\n",
      "0.764 (+/-0.069) for {'C': 10, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.001, 'warm_start': False}\n",
      "0.763 (+/-0.069) for {'C': 10, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.01, 'warm_start': True}\n",
      "0.763 (+/-0.069) for {'C': 10, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.01, 'warm_start': False}\n",
      "0.768 (+/-0.062) for {'C': 10, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.1, 'warm_start': True}\n",
      "0.771 (+/-0.083) for {'C': 10, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.1, 'warm_start': False}\n",
      "0.764 (+/-0.073) for {'C': 10, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': True}\n",
      "0.764 (+/-0.073) for {'C': 10, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': False}\n",
      "0.764 (+/-0.073) for {'C': 10, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': True}\n",
      "0.764 (+/-0.073) for {'C': 10, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': False}\n",
      "0.764 (+/-0.073) for {'C': 10, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': True}\n",
      "0.764 (+/-0.073) for {'C': 10, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': False}\n",
      "0.764 (+/-0.073) for {'C': 10, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': True}\n",
      "0.764 (+/-0.073) for {'C': 10, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': False}\n",
      "0.763 (+/-0.063) for {'C': 10, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': True}\n",
      "0.763 (+/-0.063) for {'C': 10, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': False}\n",
      "0.764 (+/-0.073) for {'C': 10, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 1e-05, 'warm_start': True}\n",
      "0.764 (+/-0.073) for {'C': 10, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 1e-05, 'warm_start': False}\n",
      "0.764 (+/-0.073) for {'C': 10, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.0001, 'warm_start': True}\n",
      "0.764 (+/-0.073) for {'C': 10, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.0001, 'warm_start': False}\n",
      "0.764 (+/-0.073) for {'C': 10, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.001, 'warm_start': True}\n",
      "0.764 (+/-0.073) for {'C': 10, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.001, 'warm_start': False}\n",
      "0.764 (+/-0.073) for {'C': 10, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.01, 'warm_start': True}\n",
      "0.764 (+/-0.073) for {'C': 10, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.01, 'warm_start': False}\n",
      "0.764 (+/-0.073) for {'C': 10, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.1, 'warm_start': True}\n",
      "0.764 (+/-0.073) for {'C': 10, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.1, 'warm_start': False}\n",
      "0.764 (+/-0.073) for {'C': 10, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 1e-05, 'warm_start': True}\n",
      "0.764 (+/-0.073) for {'C': 10, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 1e-05, 'warm_start': False}\n",
      "0.764 (+/-0.073) for {'C': 10, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.0001, 'warm_start': True}\n",
      "0.764 (+/-0.073) for {'C': 10, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.0001, 'warm_start': False}\n",
      "0.764 (+/-0.073) for {'C': 10, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.001, 'warm_start': True}\n",
      "0.764 (+/-0.073) for {'C': 10, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.001, 'warm_start': False}\n",
      "0.764 (+/-0.073) for {'C': 10, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.01, 'warm_start': True}\n",
      "0.764 (+/-0.073) for {'C': 10, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.01, 'warm_start': False}\n",
      "0.764 (+/-0.073) for {'C': 10, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.1, 'warm_start': True}\n",
      "0.764 (+/-0.073) for {'C': 10, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.1, 'warm_start': False}\n",
      "0.764 (+/-0.073) for {'C': 10, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'sag', 'tol': 1e-05, 'warm_start': True}\n",
      "0.764 (+/-0.073) for {'C': 10, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'sag', 'tol': 1e-05, 'warm_start': False}\n",
      "0.764 (+/-0.073) for {'C': 10, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.0001, 'warm_start': True}\n",
      "0.764 (+/-0.073) for {'C': 10, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.0001, 'warm_start': False}\n",
      "0.765 (+/-0.074) for {'C': 10, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.001, 'warm_start': True}\n",
      "0.765 (+/-0.074) for {'C': 10, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.001, 'warm_start': False}\n",
      "0.765 (+/-0.065) for {'C': 10, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.01, 'warm_start': True}\n",
      "0.765 (+/-0.065) for {'C': 10, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.01, 'warm_start': False}\n",
      "0.764 (+/-0.073) for {'C': 10, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.1, 'warm_start': True}\n",
      "0.765 (+/-0.069) for {'C': 10, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.1, 'warm_start': False}\n",
      "0.764 (+/-0.073) for {'C': 10, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'saga', 'tol': 1e-05, 'warm_start': True}\n",
      "0.764 (+/-0.073) for {'C': 10, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'saga', 'tol': 1e-05, 'warm_start': False}\n",
      "0.764 (+/-0.073) for {'C': 10, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.0001, 'warm_start': True}\n",
      "0.764 (+/-0.073) for {'C': 10, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.0001, 'warm_start': False}\n",
      "0.764 (+/-0.069) for {'C': 10, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.001, 'warm_start': True}\n",
      "0.764 (+/-0.069) for {'C': 10, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.001, 'warm_start': False}\n",
      "0.763 (+/-0.069) for {'C': 10, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.01, 'warm_start': True}\n",
      "0.763 (+/-0.069) for {'C': 10, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.01, 'warm_start': False}\n",
      "0.770 (+/-0.087) for {'C': 10, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.1, 'warm_start': True}\n",
      "0.773 (+/-0.063) for {'C': 10, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.1, 'warm_start': False}\n",
      "0.764 (+/-0.073) for {'C': 10, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': True}\n",
      "0.764 (+/-0.073) for {'C': 10, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': False}\n",
      "0.764 (+/-0.073) for {'C': 10, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': True}\n",
      "0.764 (+/-0.073) for {'C': 10, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': False}\n",
      "0.764 (+/-0.073) for {'C': 10, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': True}\n",
      "0.764 (+/-0.073) for {'C': 10, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': False}\n",
      "0.764 (+/-0.073) for {'C': 10, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': True}\n",
      "0.764 (+/-0.073) for {'C': 10, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': False}\n",
      "0.763 (+/-0.063) for {'C': 10, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': True}\n",
      "0.763 (+/-0.063) for {'C': 10, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': False}\n",
      "0.764 (+/-0.073) for {'C': 10, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 1e-05, 'warm_start': True}\n",
      "0.764 (+/-0.073) for {'C': 10, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 1e-05, 'warm_start': False}\n",
      "0.764 (+/-0.073) for {'C': 10, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.0001, 'warm_start': True}\n",
      "0.764 (+/-0.073) for {'C': 10, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.0001, 'warm_start': False}\n",
      "0.764 (+/-0.073) for {'C': 10, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.001, 'warm_start': True}\n",
      "0.764 (+/-0.073) for {'C': 10, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.001, 'warm_start': False}\n",
      "0.764 (+/-0.073) for {'C': 10, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.01, 'warm_start': True}\n",
      "0.764 (+/-0.073) for {'C': 10, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.01, 'warm_start': False}\n",
      "0.764 (+/-0.073) for {'C': 10, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.1, 'warm_start': True}\n",
      "0.764 (+/-0.073) for {'C': 10, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.1, 'warm_start': False}\n",
      "0.764 (+/-0.073) for {'C': 10, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 1e-05, 'warm_start': True}\n",
      "0.764 (+/-0.073) for {'C': 10, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 1e-05, 'warm_start': False}\n",
      "0.764 (+/-0.073) for {'C': 10, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.0001, 'warm_start': True}\n",
      "0.764 (+/-0.073) for {'C': 10, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.0001, 'warm_start': False}\n",
      "0.764 (+/-0.073) for {'C': 10, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.001, 'warm_start': True}\n",
      "0.764 (+/-0.073) for {'C': 10, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.001, 'warm_start': False}\n",
      "0.764 (+/-0.073) for {'C': 10, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.01, 'warm_start': True}\n",
      "0.764 (+/-0.073) for {'C': 10, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.01, 'warm_start': False}\n",
      "0.764 (+/-0.073) for {'C': 10, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.1, 'warm_start': True}\n",
      "0.764 (+/-0.073) for {'C': 10, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.1, 'warm_start': False}\n",
      "0.764 (+/-0.073) for {'C': 10, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'sag', 'tol': 1e-05, 'warm_start': True}\n",
      "0.764 (+/-0.073) for {'C': 10, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'sag', 'tol': 1e-05, 'warm_start': False}\n",
      "0.764 (+/-0.073) for {'C': 10, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.0001, 'warm_start': True}\n",
      "0.764 (+/-0.073) for {'C': 10, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.0001, 'warm_start': False}\n",
      "0.765 (+/-0.074) for {'C': 10, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.001, 'warm_start': True}\n",
      "0.765 (+/-0.074) for {'C': 10, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.001, 'warm_start': False}\n",
      "0.765 (+/-0.065) for {'C': 10, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.01, 'warm_start': True}\n",
      "0.765 (+/-0.065) for {'C': 10, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.01, 'warm_start': False}\n",
      "0.763 (+/-0.065) for {'C': 10, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.1, 'warm_start': True}\n",
      "0.767 (+/-0.090) for {'C': 10, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.1, 'warm_start': False}\n",
      "0.764 (+/-0.073) for {'C': 10, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'saga', 'tol': 1e-05, 'warm_start': True}\n",
      "0.764 (+/-0.073) for {'C': 10, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'saga', 'tol': 1e-05, 'warm_start': False}\n",
      "0.764 (+/-0.073) for {'C': 10, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.0001, 'warm_start': True}\n",
      "0.764 (+/-0.073) for {'C': 10, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.0001, 'warm_start': False}\n",
      "0.764 (+/-0.069) for {'C': 10, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.001, 'warm_start': True}\n",
      "0.764 (+/-0.069) for {'C': 10, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.001, 'warm_start': False}\n",
      "0.763 (+/-0.069) for {'C': 10, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.01, 'warm_start': True}\n",
      "0.763 (+/-0.069) for {'C': 10, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.01, 'warm_start': False}\n",
      "0.764 (+/-0.051) for {'C': 10, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.1, 'warm_start': True}\n",
      "0.774 (+/-0.074) for {'C': 10, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.1, 'warm_start': False}\n",
      "0.764 (+/-0.073) for {'C': 10, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': True}\n",
      "0.764 (+/-0.073) for {'C': 10, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': False}\n",
      "0.764 (+/-0.073) for {'C': 10, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': True}\n",
      "0.764 (+/-0.073) for {'C': 10, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': False}\n",
      "0.764 (+/-0.073) for {'C': 10, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': True}\n",
      "0.764 (+/-0.073) for {'C': 10, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': False}\n",
      "0.764 (+/-0.073) for {'C': 10, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': True}\n",
      "0.764 (+/-0.073) for {'C': 10, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': False}\n",
      "0.763 (+/-0.063) for {'C': 10, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': True}\n",
      "0.763 (+/-0.063) for {'C': 10, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': False}\n",
      "0.764 (+/-0.073) for {'C': 10, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 1e-05, 'warm_start': True}\n",
      "0.764 (+/-0.073) for {'C': 10, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 1e-05, 'warm_start': False}\n",
      "0.764 (+/-0.073) for {'C': 10, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.0001, 'warm_start': True}\n",
      "0.764 (+/-0.073) for {'C': 10, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.0001, 'warm_start': False}\n",
      "0.764 (+/-0.073) for {'C': 10, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.001, 'warm_start': True}\n",
      "0.764 (+/-0.073) for {'C': 10, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.001, 'warm_start': False}\n",
      "0.764 (+/-0.073) for {'C': 10, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.01, 'warm_start': True}\n",
      "0.764 (+/-0.073) for {'C': 10, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.01, 'warm_start': False}\n",
      "0.764 (+/-0.073) for {'C': 10, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.1, 'warm_start': True}\n",
      "0.764 (+/-0.073) for {'C': 10, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.1, 'warm_start': False}\n",
      "0.764 (+/-0.073) for {'C': 10, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 1e-05, 'warm_start': True}\n",
      "0.764 (+/-0.073) for {'C': 10, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 1e-05, 'warm_start': False}\n",
      "0.764 (+/-0.073) for {'C': 10, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.0001, 'warm_start': True}\n",
      "0.764 (+/-0.073) for {'C': 10, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.0001, 'warm_start': False}\n",
      "0.764 (+/-0.073) for {'C': 10, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.001, 'warm_start': True}\n",
      "0.764 (+/-0.073) for {'C': 10, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.001, 'warm_start': False}\n",
      "0.764 (+/-0.073) for {'C': 10, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.01, 'warm_start': True}\n",
      "0.764 (+/-0.073) for {'C': 10, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.01, 'warm_start': False}\n",
      "0.764 (+/-0.073) for {'C': 10, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.1, 'warm_start': True}\n",
      "0.764 (+/-0.073) for {'C': 10, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.1, 'warm_start': False}\n",
      "0.764 (+/-0.073) for {'C': 10, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'sag', 'tol': 1e-05, 'warm_start': True}\n",
      "0.764 (+/-0.073) for {'C': 10, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'sag', 'tol': 1e-05, 'warm_start': False}\n",
      "0.764 (+/-0.073) for {'C': 10, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.0001, 'warm_start': True}\n",
      "0.764 (+/-0.073) for {'C': 10, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.0001, 'warm_start': False}\n",
      "0.765 (+/-0.074) for {'C': 10, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.001, 'warm_start': True}\n",
      "0.765 (+/-0.074) for {'C': 10, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.001, 'warm_start': False}\n",
      "0.765 (+/-0.065) for {'C': 10, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.01, 'warm_start': True}\n",
      "0.765 (+/-0.065) for {'C': 10, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.01, 'warm_start': False}\n",
      "0.765 (+/-0.069) for {'C': 10, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.1, 'warm_start': True}\n",
      "0.760 (+/-0.075) for {'C': 10, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.1, 'warm_start': False}\n",
      "0.764 (+/-0.073) for {'C': 10, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'saga', 'tol': 1e-05, 'warm_start': True}\n",
      "0.764 (+/-0.073) for {'C': 10, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'saga', 'tol': 1e-05, 'warm_start': False}\n",
      "0.764 (+/-0.073) for {'C': 10, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.0001, 'warm_start': True}\n",
      "0.764 (+/-0.073) for {'C': 10, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.0001, 'warm_start': False}\n",
      "0.764 (+/-0.069) for {'C': 10, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.001, 'warm_start': True}\n",
      "0.764 (+/-0.069) for {'C': 10, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.001, 'warm_start': False}\n",
      "0.763 (+/-0.069) for {'C': 10, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.01, 'warm_start': True}\n",
      "0.763 (+/-0.069) for {'C': 10, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.01, 'warm_start': False}\n",
      "0.771 (+/-0.056) for {'C': 10, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.1, 'warm_start': True}\n",
      "0.774 (+/-0.080) for {'C': 10, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.1, 'warm_start': False}\n",
      "0.784 (+/-0.090) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': True}\n",
      "0.784 (+/-0.090) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': False}\n",
      "0.784 (+/-0.090) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': True}\n",
      "0.784 (+/-0.090) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': False}\n",
      "0.784 (+/-0.090) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': True}\n",
      "0.784 (+/-0.090) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': False}\n",
      "0.784 (+/-0.090) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': True}\n",
      "0.784 (+/-0.090) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': False}\n",
      "0.784 (+/-0.090) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': True}\n",
      "0.784 (+/-0.090) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': False}\n",
      "0.784 (+/-0.090) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l1', 'solver': 'saga', 'tol': 1e-05, 'warm_start': True}\n",
      "0.784 (+/-0.090) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l1', 'solver': 'saga', 'tol': 1e-05, 'warm_start': False}\n",
      "0.784 (+/-0.090) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.0001, 'warm_start': True}\n",
      "0.784 (+/-0.090) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.0001, 'warm_start': False}\n",
      "0.784 (+/-0.090) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.001, 'warm_start': True}\n",
      "0.784 (+/-0.090) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.001, 'warm_start': False}\n",
      "0.784 (+/-0.090) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.01, 'warm_start': True}\n",
      "0.784 (+/-0.090) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.01, 'warm_start': False}\n",
      "0.784 (+/-0.090) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.1, 'warm_start': True}\n",
      "0.784 (+/-0.090) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.1, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 1e-05, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 1e-05, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.0001, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.0001, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.001, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.001, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.01, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.01, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.1, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.1, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'none', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'none', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': False}\n",
      "0.796 (+/-0.080) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'none', 'solver': 'saga', 'tol': 1e-05, 'warm_start': True}\n",
      "0.796 (+/-0.080) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'none', 'solver': 'saga', 'tol': 1e-05, 'warm_start': False}\n",
      "0.796 (+/-0.080) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'none', 'solver': 'saga', 'tol': 0.0001, 'warm_start': True}\n",
      "0.796 (+/-0.080) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'none', 'solver': 'saga', 'tol': 0.0001, 'warm_start': False}\n",
      "0.796 (+/-0.080) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'none', 'solver': 'saga', 'tol': 0.001, 'warm_start': True}\n",
      "0.796 (+/-0.080) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'none', 'solver': 'saga', 'tol': 0.001, 'warm_start': False}\n",
      "0.795 (+/-0.070) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'none', 'solver': 'saga', 'tol': 0.01, 'warm_start': True}\n",
      "0.795 (+/-0.070) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'none', 'solver': 'saga', 'tol': 0.01, 'warm_start': False}\n",
      "0.777 (+/-0.082) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'none', 'solver': 'saga', 'tol': 0.1, 'warm_start': True}\n",
      "0.778 (+/-0.075) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'none', 'solver': 'saga', 'tol': 0.1, 'warm_start': False}\n",
      "0.784 (+/-0.090) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': True}\n",
      "0.784 (+/-0.090) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': False}\n",
      "0.784 (+/-0.090) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': True}\n",
      "0.784 (+/-0.090) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': False}\n",
      "0.784 (+/-0.090) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': True}\n",
      "0.784 (+/-0.090) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': False}\n",
      "0.784 (+/-0.090) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': True}\n",
      "0.784 (+/-0.090) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': False}\n",
      "0.784 (+/-0.090) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': True}\n",
      "0.784 (+/-0.090) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': False}\n",
      "0.784 (+/-0.090) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l1', 'solver': 'saga', 'tol': 1e-05, 'warm_start': True}\n",
      "0.784 (+/-0.090) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l1', 'solver': 'saga', 'tol': 1e-05, 'warm_start': False}\n",
      "0.784 (+/-0.090) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.0001, 'warm_start': True}\n",
      "0.784 (+/-0.090) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.0001, 'warm_start': False}\n",
      "0.784 (+/-0.090) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.001, 'warm_start': True}\n",
      "0.784 (+/-0.090) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.001, 'warm_start': False}\n",
      "0.784 (+/-0.090) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.01, 'warm_start': True}\n",
      "0.784 (+/-0.090) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.01, 'warm_start': False}\n",
      "0.784 (+/-0.090) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.1, 'warm_start': True}\n",
      "0.784 (+/-0.090) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.1, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 1e-05, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 1e-05, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.0001, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.0001, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.001, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.001, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.01, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.01, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.1, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.1, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'none', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'none', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': False}\n",
      "0.792 (+/-0.089) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'none', 'solver': 'saga', 'tol': 1e-05, 'warm_start': True}\n",
      "0.792 (+/-0.089) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'none', 'solver': 'saga', 'tol': 1e-05, 'warm_start': False}\n",
      "0.792 (+/-0.089) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'none', 'solver': 'saga', 'tol': 0.0001, 'warm_start': True}\n",
      "0.792 (+/-0.089) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'none', 'solver': 'saga', 'tol': 0.0001, 'warm_start': False}\n",
      "0.794 (+/-0.085) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'none', 'solver': 'saga', 'tol': 0.001, 'warm_start': True}\n",
      "0.794 (+/-0.085) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'none', 'solver': 'saga', 'tol': 0.001, 'warm_start': False}\n",
      "0.795 (+/-0.070) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'none', 'solver': 'saga', 'tol': 0.01, 'warm_start': True}\n",
      "0.795 (+/-0.070) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'none', 'solver': 'saga', 'tol': 0.01, 'warm_start': False}\n",
      "0.781 (+/-0.082) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'none', 'solver': 'saga', 'tol': 0.1, 'warm_start': True}\n",
      "0.774 (+/-0.077) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'none', 'solver': 'saga', 'tol': 0.1, 'warm_start': False}\n",
      "0.784 (+/-0.090) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': True}\n",
      "0.784 (+/-0.090) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': False}\n",
      "0.784 (+/-0.090) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': True}\n",
      "0.784 (+/-0.090) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': False}\n",
      "0.784 (+/-0.090) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': True}\n",
      "0.784 (+/-0.090) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': False}\n",
      "0.784 (+/-0.090) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': True}\n",
      "0.784 (+/-0.090) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': False}\n",
      "0.784 (+/-0.090) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': True}\n",
      "0.784 (+/-0.090) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': False}\n",
      "0.784 (+/-0.090) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l1', 'solver': 'saga', 'tol': 1e-05, 'warm_start': True}\n",
      "0.784 (+/-0.090) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l1', 'solver': 'saga', 'tol': 1e-05, 'warm_start': False}\n",
      "0.784 (+/-0.090) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.0001, 'warm_start': True}\n",
      "0.784 (+/-0.090) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.0001, 'warm_start': False}\n",
      "0.784 (+/-0.090) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.001, 'warm_start': True}\n",
      "0.784 (+/-0.090) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.001, 'warm_start': False}\n",
      "0.784 (+/-0.090) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.01, 'warm_start': True}\n",
      "0.784 (+/-0.090) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.01, 'warm_start': False}\n",
      "0.784 (+/-0.090) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.1, 'warm_start': True}\n",
      "0.784 (+/-0.090) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.1, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 1e-05, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 1e-05, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.0001, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.0001, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.001, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.001, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.01, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.01, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.1, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.1, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'none', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'none', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': False}\n",
      "0.791 (+/-0.087) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'none', 'solver': 'saga', 'tol': 1e-05, 'warm_start': True}\n",
      "0.791 (+/-0.087) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'none', 'solver': 'saga', 'tol': 1e-05, 'warm_start': False}\n",
      "0.791 (+/-0.087) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'none', 'solver': 'saga', 'tol': 0.0001, 'warm_start': True}\n",
      "0.791 (+/-0.087) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'none', 'solver': 'saga', 'tol': 0.0001, 'warm_start': False}\n",
      "0.794 (+/-0.085) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'none', 'solver': 'saga', 'tol': 0.001, 'warm_start': True}\n",
      "0.794 (+/-0.085) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'none', 'solver': 'saga', 'tol': 0.001, 'warm_start': False}\n",
      "0.795 (+/-0.070) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'none', 'solver': 'saga', 'tol': 0.01, 'warm_start': True}\n",
      "0.794 (+/-0.069) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'none', 'solver': 'saga', 'tol': 0.01, 'warm_start': False}\n",
      "0.785 (+/-0.089) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'none', 'solver': 'saga', 'tol': 0.1, 'warm_start': True}\n",
      "0.775 (+/-0.077) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'none', 'solver': 'saga', 'tol': 0.1, 'warm_start': False}\n",
      "0.784 (+/-0.090) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': True}\n",
      "0.784 (+/-0.090) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': False}\n",
      "0.784 (+/-0.090) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': True}\n",
      "0.784 (+/-0.090) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': False}\n",
      "0.784 (+/-0.090) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': True}\n",
      "0.784 (+/-0.090) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': False}\n",
      "0.784 (+/-0.090) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': True}\n",
      "0.784 (+/-0.090) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': False}\n",
      "0.784 (+/-0.090) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': True}\n",
      "0.784 (+/-0.090) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': False}\n",
      "0.784 (+/-0.090) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l1', 'solver': 'saga', 'tol': 1e-05, 'warm_start': True}\n",
      "0.784 (+/-0.090) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l1', 'solver': 'saga', 'tol': 1e-05, 'warm_start': False}\n",
      "0.784 (+/-0.090) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.0001, 'warm_start': True}\n",
      "0.784 (+/-0.090) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.0001, 'warm_start': False}\n",
      "0.784 (+/-0.090) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.001, 'warm_start': True}\n",
      "0.784 (+/-0.090) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.001, 'warm_start': False}\n",
      "0.784 (+/-0.090) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.01, 'warm_start': True}\n",
      "0.784 (+/-0.090) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.01, 'warm_start': False}\n",
      "0.784 (+/-0.090) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.1, 'warm_start': True}\n",
      "0.784 (+/-0.090) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.1, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 1e-05, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 1e-05, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.0001, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.0001, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.001, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.001, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.01, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.01, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.1, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.1, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'none', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'none', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': False}\n",
      "0.791 (+/-0.087) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'none', 'solver': 'saga', 'tol': 1e-05, 'warm_start': True}\n",
      "0.791 (+/-0.087) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'none', 'solver': 'saga', 'tol': 1e-05, 'warm_start': False}\n",
      "0.791 (+/-0.087) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'none', 'solver': 'saga', 'tol': 0.0001, 'warm_start': True}\n",
      "0.791 (+/-0.087) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'none', 'solver': 'saga', 'tol': 0.0001, 'warm_start': False}\n",
      "0.794 (+/-0.085) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'none', 'solver': 'saga', 'tol': 0.001, 'warm_start': True}\n",
      "0.794 (+/-0.085) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'none', 'solver': 'saga', 'tol': 0.001, 'warm_start': False}\n",
      "0.795 (+/-0.070) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'none', 'solver': 'saga', 'tol': 0.01, 'warm_start': True}\n",
      "0.795 (+/-0.070) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'none', 'solver': 'saga', 'tol': 0.01, 'warm_start': False}\n",
      "0.778 (+/-0.077) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'none', 'solver': 'saga', 'tol': 0.1, 'warm_start': True}\n",
      "0.784 (+/-0.082) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'none', 'solver': 'saga', 'tol': 0.1, 'warm_start': False}\n",
      "0.784 (+/-0.090) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': True}\n",
      "0.784 (+/-0.090) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': False}\n",
      "0.784 (+/-0.090) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': True}\n",
      "0.784 (+/-0.090) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': False}\n",
      "0.784 (+/-0.090) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': True}\n",
      "0.784 (+/-0.090) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': False}\n",
      "0.784 (+/-0.090) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': True}\n",
      "0.784 (+/-0.090) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': False}\n",
      "0.784 (+/-0.090) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': True}\n",
      "0.784 (+/-0.090) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': False}\n",
      "0.784 (+/-0.090) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l1', 'solver': 'saga', 'tol': 1e-05, 'warm_start': True}\n",
      "0.784 (+/-0.090) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l1', 'solver': 'saga', 'tol': 1e-05, 'warm_start': False}\n",
      "0.784 (+/-0.090) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.0001, 'warm_start': True}\n",
      "0.784 (+/-0.090) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.0001, 'warm_start': False}\n",
      "0.784 (+/-0.090) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.001, 'warm_start': True}\n",
      "0.784 (+/-0.090) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.001, 'warm_start': False}\n",
      "0.784 (+/-0.090) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.01, 'warm_start': True}\n",
      "0.784 (+/-0.090) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.01, 'warm_start': False}\n",
      "0.784 (+/-0.090) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.1, 'warm_start': True}\n",
      "0.784 (+/-0.090) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.1, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 1e-05, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 1e-05, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.0001, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.0001, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.001, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.001, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.01, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.01, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.1, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.1, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'none', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'none', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': False}\n",
      "0.791 (+/-0.087) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'none', 'solver': 'saga', 'tol': 1e-05, 'warm_start': True}\n",
      "0.791 (+/-0.087) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'none', 'solver': 'saga', 'tol': 1e-05, 'warm_start': False}\n",
      "0.791 (+/-0.087) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'none', 'solver': 'saga', 'tol': 0.0001, 'warm_start': True}\n",
      "0.791 (+/-0.087) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'none', 'solver': 'saga', 'tol': 0.0001, 'warm_start': False}\n",
      "0.794 (+/-0.085) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'none', 'solver': 'saga', 'tol': 0.001, 'warm_start': True}\n",
      "0.794 (+/-0.085) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'none', 'solver': 'saga', 'tol': 0.001, 'warm_start': False}\n",
      "0.795 (+/-0.070) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'none', 'solver': 'saga', 'tol': 0.01, 'warm_start': True}\n",
      "0.795 (+/-0.070) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'none', 'solver': 'saga', 'tol': 0.01, 'warm_start': False}\n",
      "0.774 (+/-0.074) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'none', 'solver': 'saga', 'tol': 0.1, 'warm_start': True}\n",
      "0.774 (+/-0.079) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'none', 'solver': 'saga', 'tol': 0.1, 'warm_start': False}\n",
      "0.784 (+/-0.090) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': True}\n",
      "0.784 (+/-0.090) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': False}\n",
      "0.784 (+/-0.090) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': True}\n",
      "0.784 (+/-0.090) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': False}\n",
      "0.784 (+/-0.090) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': True}\n",
      "0.784 (+/-0.090) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': False}\n",
      "0.784 (+/-0.090) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': True}\n",
      "0.784 (+/-0.090) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': False}\n",
      "0.784 (+/-0.090) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': True}\n",
      "0.784 (+/-0.090) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': False}\n",
      "0.784 (+/-0.090) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l1', 'solver': 'saga', 'tol': 1e-05, 'warm_start': True}\n",
      "0.784 (+/-0.090) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l1', 'solver': 'saga', 'tol': 1e-05, 'warm_start': False}\n",
      "0.784 (+/-0.090) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.0001, 'warm_start': True}\n",
      "0.784 (+/-0.090) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.0001, 'warm_start': False}\n",
      "0.784 (+/-0.090) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.001, 'warm_start': True}\n",
      "0.784 (+/-0.090) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.001, 'warm_start': False}\n",
      "0.784 (+/-0.090) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.01, 'warm_start': True}\n",
      "0.784 (+/-0.090) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.01, 'warm_start': False}\n",
      "0.784 (+/-0.090) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.1, 'warm_start': True}\n",
      "0.784 (+/-0.090) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.1, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 1e-05, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 1e-05, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.0001, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.0001, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.001, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.001, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.01, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.01, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.1, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.1, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'none', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'none', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': False}\n",
      "0.764 (+/-0.070) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'none', 'solver': 'saga', 'tol': 1e-05, 'warm_start': True}\n",
      "0.764 (+/-0.070) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'none', 'solver': 'saga', 'tol': 1e-05, 'warm_start': False}\n",
      "0.763 (+/-0.064) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'none', 'solver': 'saga', 'tol': 0.0001, 'warm_start': True}\n",
      "0.764 (+/-0.070) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'none', 'solver': 'saga', 'tol': 0.0001, 'warm_start': False}\n",
      "0.763 (+/-0.064) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'none', 'solver': 'saga', 'tol': 0.001, 'warm_start': True}\n",
      "0.763 (+/-0.064) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'none', 'solver': 'saga', 'tol': 0.001, 'warm_start': False}\n",
      "0.763 (+/-0.069) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'none', 'solver': 'saga', 'tol': 0.01, 'warm_start': True}\n",
      "0.763 (+/-0.069) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'none', 'solver': 'saga', 'tol': 0.01, 'warm_start': False}\n",
      "0.767 (+/-0.050) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'none', 'solver': 'saga', 'tol': 0.1, 'warm_start': True}\n",
      "0.770 (+/-0.067) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'none', 'solver': 'saga', 'tol': 0.1, 'warm_start': False}\n",
      "0.784 (+/-0.090) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': True}\n",
      "0.784 (+/-0.090) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': False}\n",
      "0.784 (+/-0.090) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': True}\n",
      "0.784 (+/-0.090) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': False}\n",
      "0.784 (+/-0.090) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': True}\n",
      "0.784 (+/-0.090) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': False}\n",
      "0.784 (+/-0.090) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': True}\n",
      "0.784 (+/-0.090) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': False}\n",
      "0.784 (+/-0.090) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': True}\n",
      "0.784 (+/-0.090) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': False}\n",
      "0.784 (+/-0.090) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l1', 'solver': 'saga', 'tol': 1e-05, 'warm_start': True}\n",
      "0.784 (+/-0.090) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l1', 'solver': 'saga', 'tol': 1e-05, 'warm_start': False}\n",
      "0.784 (+/-0.090) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.0001, 'warm_start': True}\n",
      "0.784 (+/-0.090) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.0001, 'warm_start': False}\n",
      "0.784 (+/-0.090) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.001, 'warm_start': True}\n",
      "0.784 (+/-0.090) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.001, 'warm_start': False}\n",
      "0.784 (+/-0.090) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.01, 'warm_start': True}\n",
      "0.784 (+/-0.090) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.01, 'warm_start': False}\n",
      "0.784 (+/-0.090) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.1, 'warm_start': True}\n",
      "0.784 (+/-0.090) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.1, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 1e-05, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 1e-05, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.0001, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.0001, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.001, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.001, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.01, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.01, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.1, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.1, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'none', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'none', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': False}\n",
      "0.764 (+/-0.073) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'none', 'solver': 'saga', 'tol': 1e-05, 'warm_start': True}\n",
      "0.764 (+/-0.073) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'none', 'solver': 'saga', 'tol': 1e-05, 'warm_start': False}\n",
      "0.764 (+/-0.073) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'none', 'solver': 'saga', 'tol': 0.0001, 'warm_start': True}\n",
      "0.764 (+/-0.073) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'none', 'solver': 'saga', 'tol': 0.0001, 'warm_start': False}\n",
      "0.763 (+/-0.068) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'none', 'solver': 'saga', 'tol': 0.001, 'warm_start': True}\n",
      "0.763 (+/-0.068) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'none', 'solver': 'saga', 'tol': 0.001, 'warm_start': False}\n",
      "0.764 (+/-0.075) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'none', 'solver': 'saga', 'tol': 0.01, 'warm_start': True}\n",
      "0.764 (+/-0.075) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'none', 'solver': 'saga', 'tol': 0.01, 'warm_start': False}\n",
      "0.770 (+/-0.064) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'none', 'solver': 'saga', 'tol': 0.1, 'warm_start': True}\n",
      "0.774 (+/-0.069) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'none', 'solver': 'saga', 'tol': 0.1, 'warm_start': False}\n",
      "0.784 (+/-0.090) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': True}\n",
      "0.784 (+/-0.090) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': False}\n",
      "0.784 (+/-0.090) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': True}\n",
      "0.784 (+/-0.090) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': False}\n",
      "0.784 (+/-0.090) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': True}\n",
      "0.784 (+/-0.090) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': False}\n",
      "0.784 (+/-0.090) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': True}\n",
      "0.784 (+/-0.090) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': False}\n",
      "0.784 (+/-0.090) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': True}\n",
      "0.784 (+/-0.090) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': False}\n",
      "0.784 (+/-0.090) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l1', 'solver': 'saga', 'tol': 1e-05, 'warm_start': True}\n",
      "0.784 (+/-0.090) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l1', 'solver': 'saga', 'tol': 1e-05, 'warm_start': False}\n",
      "0.784 (+/-0.090) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.0001, 'warm_start': True}\n",
      "0.784 (+/-0.090) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.0001, 'warm_start': False}\n",
      "0.784 (+/-0.090) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.001, 'warm_start': True}\n",
      "0.784 (+/-0.090) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.001, 'warm_start': False}\n",
      "0.784 (+/-0.090) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.01, 'warm_start': True}\n",
      "0.784 (+/-0.090) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.01, 'warm_start': False}\n",
      "0.784 (+/-0.090) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.1, 'warm_start': True}\n",
      "0.784 (+/-0.090) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.1, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 1e-05, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 1e-05, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.0001, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.0001, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.001, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.001, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.01, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.01, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.1, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.1, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'none', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'none', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': False}\n",
      "0.761 (+/-0.072) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'none', 'solver': 'saga', 'tol': 1e-05, 'warm_start': True}\n",
      "0.761 (+/-0.072) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'none', 'solver': 'saga', 'tol': 1e-05, 'warm_start': False}\n",
      "0.761 (+/-0.072) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'none', 'solver': 'saga', 'tol': 0.0001, 'warm_start': True}\n",
      "0.761 (+/-0.072) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'none', 'solver': 'saga', 'tol': 0.0001, 'warm_start': False}\n",
      "0.763 (+/-0.068) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'none', 'solver': 'saga', 'tol': 0.001, 'warm_start': True}\n",
      "0.763 (+/-0.068) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'none', 'solver': 'saga', 'tol': 0.001, 'warm_start': False}\n",
      "0.763 (+/-0.069) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'none', 'solver': 'saga', 'tol': 0.01, 'warm_start': True}\n",
      "0.763 (+/-0.069) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'none', 'solver': 'saga', 'tol': 0.01, 'warm_start': False}\n",
      "0.774 (+/-0.073) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'none', 'solver': 'saga', 'tol': 0.1, 'warm_start': True}\n",
      "0.774 (+/-0.069) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'none', 'solver': 'saga', 'tol': 0.1, 'warm_start': False}\n",
      "0.784 (+/-0.090) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': True}\n",
      "0.784 (+/-0.090) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': False}\n",
      "0.784 (+/-0.090) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': True}\n",
      "0.784 (+/-0.090) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': False}\n",
      "0.784 (+/-0.090) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': True}\n",
      "0.784 (+/-0.090) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': False}\n",
      "0.784 (+/-0.090) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': True}\n",
      "0.784 (+/-0.090) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': False}\n",
      "0.784 (+/-0.090) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': True}\n",
      "0.784 (+/-0.090) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': False}\n",
      "0.784 (+/-0.090) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l1', 'solver': 'saga', 'tol': 1e-05, 'warm_start': True}\n",
      "0.784 (+/-0.090) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l1', 'solver': 'saga', 'tol': 1e-05, 'warm_start': False}\n",
      "0.784 (+/-0.090) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.0001, 'warm_start': True}\n",
      "0.784 (+/-0.090) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.0001, 'warm_start': False}\n",
      "0.784 (+/-0.090) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.001, 'warm_start': True}\n",
      "0.784 (+/-0.090) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.001, 'warm_start': False}\n",
      "0.784 (+/-0.090) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.01, 'warm_start': True}\n",
      "0.784 (+/-0.090) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.01, 'warm_start': False}\n",
      "0.784 (+/-0.090) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.1, 'warm_start': True}\n",
      "0.784 (+/-0.090) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.1, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 1e-05, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 1e-05, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.0001, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.0001, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.001, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.001, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.01, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.01, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.1, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.1, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'none', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'none', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': False}\n",
      "0.761 (+/-0.072) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'none', 'solver': 'saga', 'tol': 1e-05, 'warm_start': True}\n",
      "0.761 (+/-0.072) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'none', 'solver': 'saga', 'tol': 1e-05, 'warm_start': False}\n",
      "0.761 (+/-0.072) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'none', 'solver': 'saga', 'tol': 0.0001, 'warm_start': True}\n",
      "0.761 (+/-0.072) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'none', 'solver': 'saga', 'tol': 0.0001, 'warm_start': False}\n",
      "0.763 (+/-0.068) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'none', 'solver': 'saga', 'tol': 0.001, 'warm_start': True}\n",
      "0.763 (+/-0.068) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'none', 'solver': 'saga', 'tol': 0.001, 'warm_start': False}\n",
      "0.763 (+/-0.069) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'none', 'solver': 'saga', 'tol': 0.01, 'warm_start': True}\n",
      "0.763 (+/-0.069) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'none', 'solver': 'saga', 'tol': 0.01, 'warm_start': False}\n",
      "0.772 (+/-0.068) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'none', 'solver': 'saga', 'tol': 0.1, 'warm_start': True}\n",
      "0.771 (+/-0.072) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'none', 'solver': 'saga', 'tol': 0.1, 'warm_start': False}\n",
      "0.784 (+/-0.090) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': True}\n",
      "0.784 (+/-0.090) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': False}\n",
      "0.784 (+/-0.090) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': True}\n",
      "0.784 (+/-0.090) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': False}\n",
      "0.784 (+/-0.090) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': True}\n",
      "0.784 (+/-0.090) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': False}\n",
      "0.784 (+/-0.090) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': True}\n",
      "0.784 (+/-0.090) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': False}\n",
      "0.784 (+/-0.090) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': True}\n",
      "0.784 (+/-0.090) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': False}\n",
      "0.784 (+/-0.090) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l1', 'solver': 'saga', 'tol': 1e-05, 'warm_start': True}\n",
      "0.784 (+/-0.090) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l1', 'solver': 'saga', 'tol': 1e-05, 'warm_start': False}\n",
      "0.784 (+/-0.090) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.0001, 'warm_start': True}\n",
      "0.784 (+/-0.090) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.0001, 'warm_start': False}\n",
      "0.784 (+/-0.090) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.001, 'warm_start': True}\n",
      "0.784 (+/-0.090) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.001, 'warm_start': False}\n",
      "0.784 (+/-0.090) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.01, 'warm_start': True}\n",
      "0.784 (+/-0.090) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.01, 'warm_start': False}\n",
      "0.784 (+/-0.090) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.1, 'warm_start': True}\n",
      "0.784 (+/-0.090) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.1, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 1e-05, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 1e-05, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.0001, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.0001, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.001, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.001, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.01, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.01, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.1, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.1, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'none', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'none', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': False}\n",
      "0.761 (+/-0.072) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'none', 'solver': 'saga', 'tol': 1e-05, 'warm_start': True}\n",
      "0.761 (+/-0.072) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'none', 'solver': 'saga', 'tol': 1e-05, 'warm_start': False}\n",
      "0.761 (+/-0.072) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'none', 'solver': 'saga', 'tol': 0.0001, 'warm_start': True}\n",
      "0.761 (+/-0.072) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'none', 'solver': 'saga', 'tol': 0.0001, 'warm_start': False}\n",
      "0.763 (+/-0.068) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'none', 'solver': 'saga', 'tol': 0.001, 'warm_start': True}\n",
      "0.763 (+/-0.068) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'none', 'solver': 'saga', 'tol': 0.001, 'warm_start': False}\n",
      "0.763 (+/-0.069) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'none', 'solver': 'saga', 'tol': 0.01, 'warm_start': True}\n",
      "0.763 (+/-0.069) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'none', 'solver': 'saga', 'tol': 0.01, 'warm_start': False}\n",
      "0.770 (+/-0.064) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'none', 'solver': 'saga', 'tol': 0.1, 'warm_start': True}\n",
      "0.771 (+/-0.084) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'none', 'solver': 'saga', 'tol': 0.1, 'warm_start': False}\n",
      "0.775 (+/-0.088) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': True}\n",
      "0.775 (+/-0.088) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': False}\n",
      "0.775 (+/-0.088) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': True}\n",
      "0.775 (+/-0.088) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': False}\n",
      "0.775 (+/-0.088) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': True}\n",
      "0.775 (+/-0.088) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': False}\n",
      "0.775 (+/-0.088) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': True}\n",
      "0.777 (+/-0.088) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': False}\n",
      "0.771 (+/-0.089) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': True}\n",
      "0.778 (+/-0.083) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': False}\n",
      "0.784 (+/-0.088) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l1', 'solver': 'saga', 'tol': 1e-05, 'warm_start': True}\n",
      "0.784 (+/-0.088) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l1', 'solver': 'saga', 'tol': 1e-05, 'warm_start': False}\n",
      "0.784 (+/-0.088) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.0001, 'warm_start': True}\n",
      "0.784 (+/-0.088) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.0001, 'warm_start': False}\n",
      "0.784 (+/-0.088) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.001, 'warm_start': True}\n",
      "0.784 (+/-0.088) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.001, 'warm_start': False}\n",
      "0.784 (+/-0.088) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.01, 'warm_start': True}\n",
      "0.781 (+/-0.087) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.01, 'warm_start': False}\n",
      "0.768 (+/-0.097) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.1, 'warm_start': True}\n",
      "0.774 (+/-0.086) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.1, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 1e-05, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 1e-05, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.0001, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.0001, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.001, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.001, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.01, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.01, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.1, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.1, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'none', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'none', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': False}\n",
      "0.796 (+/-0.080) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'none', 'solver': 'saga', 'tol': 1e-05, 'warm_start': True}\n",
      "0.796 (+/-0.080) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'none', 'solver': 'saga', 'tol': 1e-05, 'warm_start': False}\n",
      "0.796 (+/-0.080) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'none', 'solver': 'saga', 'tol': 0.0001, 'warm_start': True}\n",
      "0.796 (+/-0.080) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'none', 'solver': 'saga', 'tol': 0.0001, 'warm_start': False}\n",
      "0.796 (+/-0.080) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'none', 'solver': 'saga', 'tol': 0.001, 'warm_start': True}\n",
      "0.796 (+/-0.080) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'none', 'solver': 'saga', 'tol': 0.001, 'warm_start': False}\n",
      "0.794 (+/-0.069) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'none', 'solver': 'saga', 'tol': 0.01, 'warm_start': True}\n",
      "0.795 (+/-0.070) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'none', 'solver': 'saga', 'tol': 0.01, 'warm_start': False}\n",
      "0.780 (+/-0.077) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'none', 'solver': 'saga', 'tol': 0.1, 'warm_start': True}\n",
      "0.775 (+/-0.079) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'none', 'solver': 'saga', 'tol': 0.1, 'warm_start': False}\n",
      "0.775 (+/-0.088) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': True}\n",
      "0.775 (+/-0.088) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': False}\n",
      "0.775 (+/-0.088) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': True}\n",
      "0.775 (+/-0.088) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': False}\n",
      "0.775 (+/-0.088) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': True}\n",
      "0.775 (+/-0.088) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': False}\n",
      "0.775 (+/-0.088) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': True}\n",
      "0.775 (+/-0.088) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': False}\n",
      "0.774 (+/-0.090) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': True}\n",
      "0.772 (+/-0.091) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': False}\n",
      "0.784 (+/-0.088) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l1', 'solver': 'saga', 'tol': 1e-05, 'warm_start': True}\n",
      "0.784 (+/-0.088) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l1', 'solver': 'saga', 'tol': 1e-05, 'warm_start': False}\n",
      "0.784 (+/-0.088) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.0001, 'warm_start': True}\n",
      "0.784 (+/-0.088) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.0001, 'warm_start': False}\n",
      "0.784 (+/-0.088) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.001, 'warm_start': True}\n",
      "0.784 (+/-0.088) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.001, 'warm_start': False}\n",
      "0.782 (+/-0.086) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.01, 'warm_start': True}\n",
      "0.782 (+/-0.092) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.01, 'warm_start': False}\n",
      "0.784 (+/-0.091) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.1, 'warm_start': True}\n",
      "0.777 (+/-0.092) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.1, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 1e-05, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 1e-05, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.0001, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.0001, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.001, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.001, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.01, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.01, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.1, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.1, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'none', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'none', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': False}\n",
      "0.792 (+/-0.089) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'none', 'solver': 'saga', 'tol': 1e-05, 'warm_start': True}\n",
      "0.792 (+/-0.089) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'none', 'solver': 'saga', 'tol': 1e-05, 'warm_start': False}\n",
      "0.792 (+/-0.089) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'none', 'solver': 'saga', 'tol': 0.0001, 'warm_start': True}\n",
      "0.792 (+/-0.089) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'none', 'solver': 'saga', 'tol': 0.0001, 'warm_start': False}\n",
      "0.794 (+/-0.085) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'none', 'solver': 'saga', 'tol': 0.001, 'warm_start': True}\n",
      "0.794 (+/-0.085) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'none', 'solver': 'saga', 'tol': 0.001, 'warm_start': False}\n",
      "0.795 (+/-0.070) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'none', 'solver': 'saga', 'tol': 0.01, 'warm_start': True}\n",
      "0.794 (+/-0.069) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'none', 'solver': 'saga', 'tol': 0.01, 'warm_start': False}\n",
      "0.775 (+/-0.074) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'none', 'solver': 'saga', 'tol': 0.1, 'warm_start': True}\n",
      "0.766 (+/-0.086) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'none', 'solver': 'saga', 'tol': 0.1, 'warm_start': False}\n",
      "0.775 (+/-0.088) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': True}\n",
      "0.775 (+/-0.088) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': False}\n",
      "0.775 (+/-0.088) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': True}\n",
      "0.775 (+/-0.088) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': False}\n",
      "0.775 (+/-0.088) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': True}\n",
      "0.775 (+/-0.088) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': False}\n",
      "0.774 (+/-0.089) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': True}\n",
      "0.777 (+/-0.088) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': False}\n",
      "0.774 (+/-0.090) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': True}\n",
      "0.770 (+/-0.081) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': False}\n",
      "0.784 (+/-0.088) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l1', 'solver': 'saga', 'tol': 1e-05, 'warm_start': True}\n",
      "0.784 (+/-0.088) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l1', 'solver': 'saga', 'tol': 1e-05, 'warm_start': False}\n",
      "0.784 (+/-0.088) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.0001, 'warm_start': True}\n",
      "0.784 (+/-0.088) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.0001, 'warm_start': False}\n",
      "0.784 (+/-0.088) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.001, 'warm_start': True}\n",
      "0.784 (+/-0.088) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.001, 'warm_start': False}\n",
      "0.782 (+/-0.090) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.01, 'warm_start': True}\n",
      "0.778 (+/-0.088) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.01, 'warm_start': False}\n",
      "0.775 (+/-0.082) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.1, 'warm_start': True}\n",
      "0.774 (+/-0.084) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.1, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 1e-05, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 1e-05, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.0001, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.0001, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.001, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.001, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.01, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.01, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.1, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.1, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'none', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'none', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': False}\n",
      "0.791 (+/-0.087) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'none', 'solver': 'saga', 'tol': 1e-05, 'warm_start': True}\n",
      "0.791 (+/-0.087) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'none', 'solver': 'saga', 'tol': 1e-05, 'warm_start': False}\n",
      "0.791 (+/-0.087) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'none', 'solver': 'saga', 'tol': 0.0001, 'warm_start': True}\n",
      "0.791 (+/-0.087) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'none', 'solver': 'saga', 'tol': 0.0001, 'warm_start': False}\n",
      "0.794 (+/-0.085) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'none', 'solver': 'saga', 'tol': 0.001, 'warm_start': True}\n",
      "0.794 (+/-0.085) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'none', 'solver': 'saga', 'tol': 0.001, 'warm_start': False}\n",
      "0.795 (+/-0.070) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'none', 'solver': 'saga', 'tol': 0.01, 'warm_start': True}\n",
      "0.795 (+/-0.070) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'none', 'solver': 'saga', 'tol': 0.01, 'warm_start': False}\n",
      "0.780 (+/-0.080) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'none', 'solver': 'saga', 'tol': 0.1, 'warm_start': True}\n",
      "0.778 (+/-0.082) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'none', 'solver': 'saga', 'tol': 0.1, 'warm_start': False}\n",
      "0.775 (+/-0.088) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': True}\n",
      "0.775 (+/-0.088) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': False}\n",
      "0.775 (+/-0.088) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': True}\n",
      "0.775 (+/-0.088) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': False}\n",
      "0.775 (+/-0.088) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': True}\n",
      "0.775 (+/-0.088) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': False}\n",
      "0.774 (+/-0.089) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': True}\n",
      "0.774 (+/-0.089) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': False}\n",
      "0.777 (+/-0.085) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': True}\n",
      "0.772 (+/-0.090) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': False}\n",
      "0.784 (+/-0.088) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l1', 'solver': 'saga', 'tol': 1e-05, 'warm_start': True}\n",
      "0.784 (+/-0.088) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l1', 'solver': 'saga', 'tol': 1e-05, 'warm_start': False}\n",
      "0.784 (+/-0.088) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.0001, 'warm_start': True}\n",
      "0.784 (+/-0.088) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.0001, 'warm_start': False}\n",
      "0.784 (+/-0.088) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.001, 'warm_start': True}\n",
      "0.784 (+/-0.088) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.001, 'warm_start': False}\n",
      "0.784 (+/-0.088) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.01, 'warm_start': True}\n",
      "0.781 (+/-0.087) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.01, 'warm_start': False}\n",
      "0.774 (+/-0.091) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.1, 'warm_start': True}\n",
      "0.778 (+/-0.084) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.1, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 1e-05, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 1e-05, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.0001, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.0001, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.001, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.001, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.01, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.01, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.1, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.1, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'none', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'none', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': False}\n",
      "0.791 (+/-0.087) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'none', 'solver': 'saga', 'tol': 1e-05, 'warm_start': True}\n",
      "0.791 (+/-0.087) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'none', 'solver': 'saga', 'tol': 1e-05, 'warm_start': False}\n",
      "0.791 (+/-0.087) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'none', 'solver': 'saga', 'tol': 0.0001, 'warm_start': True}\n",
      "0.791 (+/-0.087) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'none', 'solver': 'saga', 'tol': 0.0001, 'warm_start': False}\n",
      "0.794 (+/-0.085) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'none', 'solver': 'saga', 'tol': 0.001, 'warm_start': True}\n",
      "0.794 (+/-0.085) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'none', 'solver': 'saga', 'tol': 0.001, 'warm_start': False}\n",
      "0.795 (+/-0.070) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'none', 'solver': 'saga', 'tol': 0.01, 'warm_start': True}\n",
      "0.794 (+/-0.069) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'none', 'solver': 'saga', 'tol': 0.01, 'warm_start': False}\n",
      "0.780 (+/-0.078) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'none', 'solver': 'saga', 'tol': 0.1, 'warm_start': True}\n",
      "0.775 (+/-0.083) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'none', 'solver': 'saga', 'tol': 0.1, 'warm_start': False}\n",
      "0.775 (+/-0.088) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': True}\n",
      "0.775 (+/-0.088) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': False}\n",
      "0.775 (+/-0.088) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': True}\n",
      "0.775 (+/-0.088) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': False}\n",
      "0.775 (+/-0.088) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': True}\n",
      "0.775 (+/-0.088) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': False}\n",
      "0.777 (+/-0.088) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': True}\n",
      "0.777 (+/-0.088) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': False}\n",
      "0.770 (+/-0.089) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': True}\n",
      "0.774 (+/-0.089) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': False}\n",
      "0.784 (+/-0.088) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l1', 'solver': 'saga', 'tol': 1e-05, 'warm_start': True}\n",
      "0.784 (+/-0.088) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l1', 'solver': 'saga', 'tol': 1e-05, 'warm_start': False}\n",
      "0.784 (+/-0.088) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.0001, 'warm_start': True}\n",
      "0.784 (+/-0.088) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.0001, 'warm_start': False}\n",
      "0.784 (+/-0.088) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.001, 'warm_start': True}\n",
      "0.784 (+/-0.088) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.001, 'warm_start': False}\n",
      "0.782 (+/-0.090) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.01, 'warm_start': True}\n",
      "0.784 (+/-0.088) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.01, 'warm_start': False}\n",
      "0.774 (+/-0.088) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.1, 'warm_start': True}\n",
      "0.772 (+/-0.090) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.1, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 1e-05, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 1e-05, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.0001, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.0001, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.001, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.001, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.01, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.01, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.1, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.1, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'none', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'none', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': False}\n",
      "0.791 (+/-0.087) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'none', 'solver': 'saga', 'tol': 1e-05, 'warm_start': True}\n",
      "0.791 (+/-0.087) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'none', 'solver': 'saga', 'tol': 1e-05, 'warm_start': False}\n",
      "0.791 (+/-0.087) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'none', 'solver': 'saga', 'tol': 0.0001, 'warm_start': True}\n",
      "0.791 (+/-0.087) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'none', 'solver': 'saga', 'tol': 0.0001, 'warm_start': False}\n",
      "0.794 (+/-0.085) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'none', 'solver': 'saga', 'tol': 0.001, 'warm_start': True}\n",
      "0.794 (+/-0.085) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'none', 'solver': 'saga', 'tol': 0.001, 'warm_start': False}\n",
      "0.795 (+/-0.070) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'none', 'solver': 'saga', 'tol': 0.01, 'warm_start': True}\n",
      "0.795 (+/-0.070) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'none', 'solver': 'saga', 'tol': 0.01, 'warm_start': False}\n",
      "0.773 (+/-0.075) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'none', 'solver': 'saga', 'tol': 0.1, 'warm_start': True}\n",
      "0.780 (+/-0.092) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'none', 'solver': 'saga', 'tol': 0.1, 'warm_start': False}\n",
      "0.756 (+/-0.075) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': True}\n",
      "0.756 (+/-0.075) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': False}\n",
      "0.756 (+/-0.075) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': True}\n",
      "0.756 (+/-0.075) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': False}\n",
      "0.756 (+/-0.075) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': True}\n",
      "0.757 (+/-0.078) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': False}\n",
      "0.761 (+/-0.082) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': True}\n",
      "0.756 (+/-0.075) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': False}\n",
      "0.750 (+/-0.064) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': True}\n",
      "0.760 (+/-0.077) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': False}\n",
      "0.756 (+/-0.075) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l1', 'solver': 'saga', 'tol': 1e-05, 'warm_start': True}\n",
      "0.756 (+/-0.075) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l1', 'solver': 'saga', 'tol': 1e-05, 'warm_start': False}\n",
      "0.756 (+/-0.075) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.0001, 'warm_start': True}\n",
      "0.756 (+/-0.075) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.0001, 'warm_start': False}\n",
      "0.757 (+/-0.078) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.001, 'warm_start': True}\n",
      "0.760 (+/-0.084) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.001, 'warm_start': False}\n",
      "0.758 (+/-0.076) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.01, 'warm_start': True}\n",
      "0.756 (+/-0.079) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.01, 'warm_start': False}\n",
      "0.761 (+/-0.078) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.1, 'warm_start': True}\n",
      "0.761 (+/-0.080) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.1, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 1e-05, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 1e-05, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.0001, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.0001, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.001, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.001, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.01, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.01, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.1, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.1, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'none', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'none', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': False}\n",
      "0.763 (+/-0.064) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'none', 'solver': 'saga', 'tol': 1e-05, 'warm_start': True}\n",
      "0.763 (+/-0.064) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'none', 'solver': 'saga', 'tol': 1e-05, 'warm_start': False}\n",
      "0.763 (+/-0.064) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'none', 'solver': 'saga', 'tol': 0.0001, 'warm_start': True}\n",
      "0.764 (+/-0.070) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'none', 'solver': 'saga', 'tol': 0.0001, 'warm_start': False}\n",
      "0.763 (+/-0.064) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'none', 'solver': 'saga', 'tol': 0.001, 'warm_start': True}\n",
      "0.763 (+/-0.064) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'none', 'solver': 'saga', 'tol': 0.001, 'warm_start': False}\n",
      "0.763 (+/-0.069) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'none', 'solver': 'saga', 'tol': 0.01, 'warm_start': True}\n",
      "0.763 (+/-0.069) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'none', 'solver': 'saga', 'tol': 0.01, 'warm_start': False}\n",
      "0.771 (+/-0.084) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'none', 'solver': 'saga', 'tol': 0.1, 'warm_start': True}\n",
      "0.771 (+/-0.057) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'none', 'solver': 'saga', 'tol': 0.1, 'warm_start': False}\n",
      "0.756 (+/-0.075) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': True}\n",
      "0.756 (+/-0.075) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': False}\n",
      "0.756 (+/-0.075) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': True}\n",
      "0.756 (+/-0.075) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': False}\n",
      "0.756 (+/-0.075) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': True}\n",
      "0.756 (+/-0.075) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': False}\n",
      "0.758 (+/-0.082) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': True}\n",
      "0.757 (+/-0.078) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': False}\n",
      "0.756 (+/-0.077) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': True}\n",
      "0.754 (+/-0.072) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': False}\n",
      "0.756 (+/-0.075) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l1', 'solver': 'saga', 'tol': 1e-05, 'warm_start': True}\n",
      "0.756 (+/-0.075) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l1', 'solver': 'saga', 'tol': 1e-05, 'warm_start': False}\n",
      "0.756 (+/-0.075) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.0001, 'warm_start': True}\n",
      "0.756 (+/-0.075) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.0001, 'warm_start': False}\n",
      "0.760 (+/-0.084) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.001, 'warm_start': True}\n",
      "0.758 (+/-0.081) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.001, 'warm_start': False}\n",
      "0.760 (+/-0.082) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.01, 'warm_start': True}\n",
      "0.760 (+/-0.080) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.01, 'warm_start': False}\n",
      "0.756 (+/-0.065) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.1, 'warm_start': True}\n",
      "0.756 (+/-0.072) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.1, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 1e-05, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 1e-05, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.0001, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.0001, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.001, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.001, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.01, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.01, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.1, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.1, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'none', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'none', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': False}\n",
      "0.764 (+/-0.073) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'none', 'solver': 'saga', 'tol': 1e-05, 'warm_start': True}\n",
      "0.764 (+/-0.073) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'none', 'solver': 'saga', 'tol': 1e-05, 'warm_start': False}\n",
      "0.764 (+/-0.073) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'none', 'solver': 'saga', 'tol': 0.0001, 'warm_start': True}\n",
      "0.764 (+/-0.073) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'none', 'solver': 'saga', 'tol': 0.0001, 'warm_start': False}\n",
      "0.763 (+/-0.068) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'none', 'solver': 'saga', 'tol': 0.001, 'warm_start': True}\n",
      "0.763 (+/-0.068) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'none', 'solver': 'saga', 'tol': 0.001, 'warm_start': False}\n",
      "0.763 (+/-0.069) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'none', 'solver': 'saga', 'tol': 0.01, 'warm_start': True}\n",
      "0.763 (+/-0.069) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'none', 'solver': 'saga', 'tol': 0.01, 'warm_start': False}\n",
      "0.765 (+/-0.047) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'none', 'solver': 'saga', 'tol': 0.1, 'warm_start': True}\n",
      "0.771 (+/-0.073) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'none', 'solver': 'saga', 'tol': 0.1, 'warm_start': False}\n",
      "0.756 (+/-0.075) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': True}\n",
      "0.756 (+/-0.075) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': False}\n",
      "0.756 (+/-0.075) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': True}\n",
      "0.756 (+/-0.075) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': False}\n",
      "0.756 (+/-0.075) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': True}\n",
      "0.757 (+/-0.078) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': False}\n",
      "0.758 (+/-0.082) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': True}\n",
      "0.757 (+/-0.078) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': False}\n",
      "0.754 (+/-0.072) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': True}\n",
      "0.760 (+/-0.079) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': False}\n",
      "0.756 (+/-0.075) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l1', 'solver': 'saga', 'tol': 1e-05, 'warm_start': True}\n",
      "0.756 (+/-0.075) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l1', 'solver': 'saga', 'tol': 1e-05, 'warm_start': False}\n",
      "0.756 (+/-0.075) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.0001, 'warm_start': True}\n",
      "0.756 (+/-0.075) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.0001, 'warm_start': False}\n",
      "0.758 (+/-0.081) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.001, 'warm_start': True}\n",
      "0.760 (+/-0.084) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.001, 'warm_start': False}\n",
      "0.758 (+/-0.080) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.01, 'warm_start': True}\n",
      "0.761 (+/-0.082) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.01, 'warm_start': False}\n",
      "0.758 (+/-0.073) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.1, 'warm_start': True}\n",
      "0.761 (+/-0.061) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.1, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 1e-05, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 1e-05, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.0001, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.0001, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.001, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.001, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.01, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.01, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.1, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.1, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'none', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'none', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': False}\n",
      "0.761 (+/-0.072) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'none', 'solver': 'saga', 'tol': 1e-05, 'warm_start': True}\n",
      "0.761 (+/-0.072) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'none', 'solver': 'saga', 'tol': 1e-05, 'warm_start': False}\n",
      "0.761 (+/-0.072) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'none', 'solver': 'saga', 'tol': 0.0001, 'warm_start': True}\n",
      "0.761 (+/-0.072) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'none', 'solver': 'saga', 'tol': 0.0001, 'warm_start': False}\n",
      "0.763 (+/-0.068) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'none', 'solver': 'saga', 'tol': 0.001, 'warm_start': True}\n",
      "0.763 (+/-0.068) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'none', 'solver': 'saga', 'tol': 0.001, 'warm_start': False}\n",
      "0.763 (+/-0.069) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'none', 'solver': 'saga', 'tol': 0.01, 'warm_start': True}\n",
      "0.763 (+/-0.069) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'none', 'solver': 'saga', 'tol': 0.01, 'warm_start': False}\n",
      "0.768 (+/-0.076) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'none', 'solver': 'saga', 'tol': 0.1, 'warm_start': True}\n",
      "0.768 (+/-0.070) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'none', 'solver': 'saga', 'tol': 0.1, 'warm_start': False}\n",
      "0.756 (+/-0.075) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': True}\n",
      "0.756 (+/-0.075) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': False}\n",
      "0.756 (+/-0.075) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': True}\n",
      "0.756 (+/-0.075) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': False}\n",
      "0.756 (+/-0.075) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': True}\n",
      "0.756 (+/-0.075) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': False}\n",
      "0.757 (+/-0.078) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': True}\n",
      "0.760 (+/-0.084) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': False}\n",
      "0.760 (+/-0.072) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': True}\n",
      "0.756 (+/-0.074) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': False}\n",
      "0.756 (+/-0.075) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l1', 'solver': 'saga', 'tol': 1e-05, 'warm_start': True}\n",
      "0.756 (+/-0.075) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l1', 'solver': 'saga', 'tol': 1e-05, 'warm_start': False}\n",
      "0.756 (+/-0.075) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.0001, 'warm_start': True}\n",
      "0.756 (+/-0.075) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.0001, 'warm_start': False}\n",
      "0.758 (+/-0.081) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.001, 'warm_start': True}\n",
      "0.757 (+/-0.078) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.001, 'warm_start': False}\n",
      "0.756 (+/-0.075) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.01, 'warm_start': True}\n",
      "0.758 (+/-0.082) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.01, 'warm_start': False}\n",
      "0.763 (+/-0.070) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.1, 'warm_start': True}\n",
      "0.761 (+/-0.069) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.1, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 1e-05, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 1e-05, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.0001, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.0001, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.001, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.001, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.01, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.01, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.1, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.1, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'none', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'none', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': False}\n",
      "0.761 (+/-0.072) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'none', 'solver': 'saga', 'tol': 1e-05, 'warm_start': True}\n",
      "0.761 (+/-0.072) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'none', 'solver': 'saga', 'tol': 1e-05, 'warm_start': False}\n",
      "0.761 (+/-0.072) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'none', 'solver': 'saga', 'tol': 0.0001, 'warm_start': True}\n",
      "0.761 (+/-0.072) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'none', 'solver': 'saga', 'tol': 0.0001, 'warm_start': False}\n",
      "0.763 (+/-0.068) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'none', 'solver': 'saga', 'tol': 0.001, 'warm_start': True}\n",
      "0.763 (+/-0.068) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'none', 'solver': 'saga', 'tol': 0.001, 'warm_start': False}\n",
      "0.763 (+/-0.069) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'none', 'solver': 'saga', 'tol': 0.01, 'warm_start': True}\n",
      "0.763 (+/-0.069) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'none', 'solver': 'saga', 'tol': 0.01, 'warm_start': False}\n",
      "0.774 (+/-0.071) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'none', 'solver': 'saga', 'tol': 0.1, 'warm_start': True}\n",
      "0.768 (+/-0.087) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'none', 'solver': 'saga', 'tol': 0.1, 'warm_start': False}\n",
      "0.756 (+/-0.075) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': True}\n",
      "0.756 (+/-0.075) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': False}\n",
      "0.756 (+/-0.075) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': True}\n",
      "0.756 (+/-0.075) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': False}\n",
      "0.756 (+/-0.075) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': True}\n",
      "0.756 (+/-0.075) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': False}\n",
      "0.757 (+/-0.079) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': True}\n",
      "0.756 (+/-0.070) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': False}\n",
      "0.764 (+/-0.070) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': True}\n",
      "0.758 (+/-0.078) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': False}\n",
      "0.756 (+/-0.075) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l1', 'solver': 'saga', 'tol': 1e-05, 'warm_start': True}\n",
      "0.756 (+/-0.075) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l1', 'solver': 'saga', 'tol': 1e-05, 'warm_start': False}\n",
      "0.756 (+/-0.075) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.0001, 'warm_start': True}\n",
      "0.756 (+/-0.075) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.0001, 'warm_start': False}\n",
      "0.758 (+/-0.081) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.001, 'warm_start': True}\n",
      "0.757 (+/-0.078) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.001, 'warm_start': False}\n",
      "0.758 (+/-0.086) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.01, 'warm_start': True}\n",
      "0.758 (+/-0.079) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.01, 'warm_start': False}\n",
      "0.764 (+/-0.071) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.1, 'warm_start': True}\n",
      "0.758 (+/-0.076) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.1, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 1e-05, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 1e-05, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.0001, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.0001, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.001, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.001, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.01, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.01, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.1, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.1, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'none', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'none', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': False}\n",
      "0.761 (+/-0.072) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'none', 'solver': 'saga', 'tol': 1e-05, 'warm_start': True}\n",
      "0.761 (+/-0.072) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'none', 'solver': 'saga', 'tol': 1e-05, 'warm_start': False}\n",
      "0.761 (+/-0.072) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'none', 'solver': 'saga', 'tol': 0.0001, 'warm_start': True}\n",
      "0.761 (+/-0.072) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'none', 'solver': 'saga', 'tol': 0.0001, 'warm_start': False}\n",
      "0.763 (+/-0.068) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'none', 'solver': 'saga', 'tol': 0.001, 'warm_start': True}\n",
      "0.763 (+/-0.068) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'none', 'solver': 'saga', 'tol': 0.001, 'warm_start': False}\n",
      "0.763 (+/-0.069) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'none', 'solver': 'saga', 'tol': 0.01, 'warm_start': True}\n",
      "0.763 (+/-0.069) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'none', 'solver': 'saga', 'tol': 0.01, 'warm_start': False}\n",
      "0.775 (+/-0.080) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'none', 'solver': 'saga', 'tol': 0.1, 'warm_start': True}\n",
      "0.770 (+/-0.067) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'none', 'solver': 'saga', 'tol': 0.1, 'warm_start': False}\n",
      "0.796 (+/-0.092) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': True}\n",
      "0.796 (+/-0.092) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': False}\n",
      "0.796 (+/-0.092) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': True}\n",
      "0.796 (+/-0.092) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': False}\n",
      "0.796 (+/-0.092) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': True}\n",
      "0.796 (+/-0.092) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': False}\n",
      "0.796 (+/-0.092) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': True}\n",
      "0.796 (+/-0.092) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': False}\n",
      "0.791 (+/-0.072) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': True}\n",
      "0.796 (+/-0.073) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': False}\n",
      "0.796 (+/-0.092) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l1', 'solver': 'saga', 'tol': 1e-05, 'warm_start': True}\n",
      "0.796 (+/-0.092) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l1', 'solver': 'saga', 'tol': 1e-05, 'warm_start': False}\n",
      "0.796 (+/-0.092) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.0001, 'warm_start': True}\n",
      "0.796 (+/-0.092) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.0001, 'warm_start': False}\n",
      "0.796 (+/-0.092) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.001, 'warm_start': True}\n",
      "0.796 (+/-0.092) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.001, 'warm_start': False}\n",
      "0.795 (+/-0.076) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.01, 'warm_start': True}\n",
      "0.795 (+/-0.076) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.01, 'warm_start': False}\n",
      "0.767 (+/-0.076) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.1, 'warm_start': True}\n",
      "0.782 (+/-0.085) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.1, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 1e-05, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 1e-05, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.0001, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.0001, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.001, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.001, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.01, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.01, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.1, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.1, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'none', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'none', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': False}\n",
      "0.796 (+/-0.080) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'none', 'solver': 'saga', 'tol': 1e-05, 'warm_start': True}\n",
      "0.796 (+/-0.080) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'none', 'solver': 'saga', 'tol': 1e-05, 'warm_start': False}\n",
      "0.796 (+/-0.080) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'none', 'solver': 'saga', 'tol': 0.0001, 'warm_start': True}\n",
      "0.796 (+/-0.080) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'none', 'solver': 'saga', 'tol': 0.0001, 'warm_start': False}\n",
      "0.796 (+/-0.080) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'none', 'solver': 'saga', 'tol': 0.001, 'warm_start': True}\n",
      "0.796 (+/-0.080) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'none', 'solver': 'saga', 'tol': 0.001, 'warm_start': False}\n",
      "0.795 (+/-0.070) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'none', 'solver': 'saga', 'tol': 0.01, 'warm_start': True}\n",
      "0.795 (+/-0.070) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'none', 'solver': 'saga', 'tol': 0.01, 'warm_start': False}\n",
      "0.774 (+/-0.081) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'none', 'solver': 'saga', 'tol': 0.1, 'warm_start': True}\n",
      "0.774 (+/-0.079) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'none', 'solver': 'saga', 'tol': 0.1, 'warm_start': False}\n",
      "0.796 (+/-0.092) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': True}\n",
      "0.796 (+/-0.092) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': False}\n",
      "0.796 (+/-0.092) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': True}\n",
      "0.796 (+/-0.092) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': False}\n",
      "0.796 (+/-0.092) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': True}\n",
      "0.796 (+/-0.092) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': False}\n",
      "0.796 (+/-0.092) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': True}\n",
      "0.796 (+/-0.083) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': False}\n",
      "0.789 (+/-0.066) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': True}\n",
      "0.796 (+/-0.078) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': False}\n",
      "0.796 (+/-0.092) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l1', 'solver': 'saga', 'tol': 1e-05, 'warm_start': True}\n",
      "0.796 (+/-0.092) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l1', 'solver': 'saga', 'tol': 1e-05, 'warm_start': False}\n",
      "0.796 (+/-0.092) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.0001, 'warm_start': True}\n",
      "0.796 (+/-0.092) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.0001, 'warm_start': False}\n",
      "0.796 (+/-0.092) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.001, 'warm_start': True}\n",
      "0.796 (+/-0.092) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.001, 'warm_start': False}\n",
      "0.795 (+/-0.076) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.01, 'warm_start': True}\n",
      "0.795 (+/-0.076) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.01, 'warm_start': False}\n",
      "0.773 (+/-0.087) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.1, 'warm_start': True}\n",
      "0.777 (+/-0.078) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.1, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 1e-05, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 1e-05, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.0001, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.0001, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.001, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.001, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.01, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.01, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.1, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.1, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'none', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'none', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': False}\n",
      "0.792 (+/-0.089) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'none', 'solver': 'saga', 'tol': 1e-05, 'warm_start': True}\n",
      "0.792 (+/-0.089) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'none', 'solver': 'saga', 'tol': 1e-05, 'warm_start': False}\n",
      "0.792 (+/-0.089) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'none', 'solver': 'saga', 'tol': 0.0001, 'warm_start': True}\n",
      "0.792 (+/-0.089) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'none', 'solver': 'saga', 'tol': 0.0001, 'warm_start': False}\n",
      "0.794 (+/-0.085) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'none', 'solver': 'saga', 'tol': 0.001, 'warm_start': True}\n",
      "0.794 (+/-0.085) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'none', 'solver': 'saga', 'tol': 0.001, 'warm_start': False}\n",
      "0.795 (+/-0.070) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'none', 'solver': 'saga', 'tol': 0.01, 'warm_start': True}\n",
      "0.794 (+/-0.069) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'none', 'solver': 'saga', 'tol': 0.01, 'warm_start': False}\n",
      "0.774 (+/-0.078) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'none', 'solver': 'saga', 'tol': 0.1, 'warm_start': True}\n",
      "0.777 (+/-0.084) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'none', 'solver': 'saga', 'tol': 0.1, 'warm_start': False}\n",
      "0.796 (+/-0.092) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': True}\n",
      "0.796 (+/-0.092) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': False}\n",
      "0.796 (+/-0.092) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': True}\n",
      "0.796 (+/-0.092) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': False}\n",
      "0.796 (+/-0.092) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': True}\n",
      "0.796 (+/-0.092) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': False}\n",
      "0.794 (+/-0.078) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': True}\n",
      "0.795 (+/-0.085) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': False}\n",
      "0.795 (+/-0.069) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': True}\n",
      "0.792 (+/-0.077) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': False}\n",
      "0.796 (+/-0.092) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l1', 'solver': 'saga', 'tol': 1e-05, 'warm_start': True}\n",
      "0.796 (+/-0.092) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l1', 'solver': 'saga', 'tol': 1e-05, 'warm_start': False}\n",
      "0.796 (+/-0.092) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.0001, 'warm_start': True}\n",
      "0.796 (+/-0.092) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.0001, 'warm_start': False}\n",
      "0.796 (+/-0.092) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.001, 'warm_start': True}\n",
      "0.796 (+/-0.092) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.001, 'warm_start': False}\n",
      "0.795 (+/-0.076) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.01, 'warm_start': True}\n",
      "0.795 (+/-0.076) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.01, 'warm_start': False}\n",
      "0.781 (+/-0.079) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.1, 'warm_start': True}\n",
      "0.782 (+/-0.076) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.1, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 1e-05, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 1e-05, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.0001, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.0001, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.001, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.001, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.01, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.01, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.1, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.1, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'none', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'none', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': False}\n",
      "0.791 (+/-0.087) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'none', 'solver': 'saga', 'tol': 1e-05, 'warm_start': True}\n",
      "0.791 (+/-0.087) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'none', 'solver': 'saga', 'tol': 1e-05, 'warm_start': False}\n",
      "0.791 (+/-0.087) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'none', 'solver': 'saga', 'tol': 0.0001, 'warm_start': True}\n",
      "0.791 (+/-0.087) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'none', 'solver': 'saga', 'tol': 0.0001, 'warm_start': False}\n",
      "0.794 (+/-0.085) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'none', 'solver': 'saga', 'tol': 0.001, 'warm_start': True}\n",
      "0.794 (+/-0.085) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'none', 'solver': 'saga', 'tol': 0.001, 'warm_start': False}\n",
      "0.795 (+/-0.070) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'none', 'solver': 'saga', 'tol': 0.01, 'warm_start': True}\n",
      "0.794 (+/-0.069) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'none', 'solver': 'saga', 'tol': 0.01, 'warm_start': False}\n",
      "0.775 (+/-0.077) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'none', 'solver': 'saga', 'tol': 0.1, 'warm_start': True}\n",
      "0.780 (+/-0.087) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'none', 'solver': 'saga', 'tol': 0.1, 'warm_start': False}\n",
      "0.796 (+/-0.092) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': True}\n",
      "0.796 (+/-0.092) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': False}\n",
      "0.796 (+/-0.092) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': True}\n",
      "0.796 (+/-0.092) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': False}\n",
      "0.796 (+/-0.092) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': True}\n",
      "0.796 (+/-0.092) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': False}\n",
      "0.792 (+/-0.071) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': True}\n",
      "0.795 (+/-0.085) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': False}\n",
      "0.795 (+/-0.075) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': True}\n",
      "0.792 (+/-0.070) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': False}\n",
      "0.796 (+/-0.092) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l1', 'solver': 'saga', 'tol': 1e-05, 'warm_start': True}\n",
      "0.796 (+/-0.092) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l1', 'solver': 'saga', 'tol': 1e-05, 'warm_start': False}\n",
      "0.796 (+/-0.092) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.0001, 'warm_start': True}\n",
      "0.796 (+/-0.092) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.0001, 'warm_start': False}\n",
      "0.796 (+/-0.092) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.001, 'warm_start': True}\n",
      "0.796 (+/-0.092) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.001, 'warm_start': False}\n",
      "0.795 (+/-0.076) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.01, 'warm_start': True}\n",
      "0.795 (+/-0.076) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.01, 'warm_start': False}\n",
      "0.778 (+/-0.072) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.1, 'warm_start': True}\n",
      "0.771 (+/-0.080) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.1, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 1e-05, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 1e-05, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.0001, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.0001, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.001, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.001, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.01, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.01, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.1, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.1, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'none', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'none', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': False}\n",
      "0.791 (+/-0.087) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'none', 'solver': 'saga', 'tol': 1e-05, 'warm_start': True}\n",
      "0.791 (+/-0.087) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'none', 'solver': 'saga', 'tol': 1e-05, 'warm_start': False}\n",
      "0.791 (+/-0.087) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'none', 'solver': 'saga', 'tol': 0.0001, 'warm_start': True}\n",
      "0.791 (+/-0.087) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'none', 'solver': 'saga', 'tol': 0.0001, 'warm_start': False}\n",
      "0.794 (+/-0.085) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'none', 'solver': 'saga', 'tol': 0.001, 'warm_start': True}\n",
      "0.794 (+/-0.085) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'none', 'solver': 'saga', 'tol': 0.001, 'warm_start': False}\n",
      "0.795 (+/-0.070) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'none', 'solver': 'saga', 'tol': 0.01, 'warm_start': True}\n",
      "0.795 (+/-0.070) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'none', 'solver': 'saga', 'tol': 0.01, 'warm_start': False}\n",
      "0.782 (+/-0.086) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'none', 'solver': 'saga', 'tol': 0.1, 'warm_start': True}\n",
      "0.777 (+/-0.081) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'none', 'solver': 'saga', 'tol': 0.1, 'warm_start': False}\n",
      "0.796 (+/-0.092) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': True}\n",
      "0.796 (+/-0.092) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': False}\n",
      "0.796 (+/-0.092) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': True}\n",
      "0.796 (+/-0.092) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': False}\n",
      "0.796 (+/-0.092) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': True}\n",
      "0.796 (+/-0.092) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': False}\n",
      "0.795 (+/-0.085) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': True}\n",
      "0.794 (+/-0.084) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': False}\n",
      "0.791 (+/-0.081) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': True}\n",
      "0.795 (+/-0.076) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': False}\n",
      "0.796 (+/-0.092) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l1', 'solver': 'saga', 'tol': 1e-05, 'warm_start': True}\n",
      "0.796 (+/-0.092) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l1', 'solver': 'saga', 'tol': 1e-05, 'warm_start': False}\n",
      "0.796 (+/-0.092) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.0001, 'warm_start': True}\n",
      "0.796 (+/-0.092) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.0001, 'warm_start': False}\n",
      "0.796 (+/-0.092) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.001, 'warm_start': True}\n",
      "0.796 (+/-0.092) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.001, 'warm_start': False}\n",
      "0.795 (+/-0.076) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.01, 'warm_start': True}\n",
      "0.795 (+/-0.076) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.01, 'warm_start': False}\n",
      "0.775 (+/-0.069) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.1, 'warm_start': True}\n",
      "0.774 (+/-0.075) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.1, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 1e-05, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 1e-05, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.0001, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.0001, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.001, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.001, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.01, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.01, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.1, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.1, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'none', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'none', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': False}\n",
      "0.791 (+/-0.087) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'none', 'solver': 'saga', 'tol': 1e-05, 'warm_start': True}\n",
      "0.791 (+/-0.087) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'none', 'solver': 'saga', 'tol': 1e-05, 'warm_start': False}\n",
      "0.791 (+/-0.087) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'none', 'solver': 'saga', 'tol': 0.0001, 'warm_start': True}\n",
      "0.791 (+/-0.087) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'none', 'solver': 'saga', 'tol': 0.0001, 'warm_start': False}\n",
      "0.794 (+/-0.085) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'none', 'solver': 'saga', 'tol': 0.001, 'warm_start': True}\n",
      "0.794 (+/-0.085) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'none', 'solver': 'saga', 'tol': 0.001, 'warm_start': False}\n",
      "0.795 (+/-0.070) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'none', 'solver': 'saga', 'tol': 0.01, 'warm_start': True}\n",
      "0.795 (+/-0.070) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'none', 'solver': 'saga', 'tol': 0.01, 'warm_start': False}\n",
      "0.778 (+/-0.074) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'none', 'solver': 'saga', 'tol': 0.1, 'warm_start': True}\n",
      "0.775 (+/-0.068) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'none', 'solver': 'saga', 'tol': 0.1, 'warm_start': False}\n",
      "0.767 (+/-0.065) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': True}\n",
      "0.767 (+/-0.065) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': False}\n",
      "0.767 (+/-0.065) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': True}\n",
      "0.767 (+/-0.065) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': False}\n",
      "0.767 (+/-0.065) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': True}\n",
      "0.770 (+/-0.067) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': False}\n",
      "0.770 (+/-0.071) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': True}\n",
      "0.768 (+/-0.070) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': False}\n",
      "0.767 (+/-0.076) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': True}\n",
      "0.768 (+/-0.073) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': False}\n",
      "0.763 (+/-0.068) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l1', 'solver': 'saga', 'tol': 1e-05, 'warm_start': True}\n",
      "0.763 (+/-0.068) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l1', 'solver': 'saga', 'tol': 1e-05, 'warm_start': False}\n",
      "0.763 (+/-0.068) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.0001, 'warm_start': True}\n",
      "0.763 (+/-0.068) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.0001, 'warm_start': False}\n",
      "0.764 (+/-0.070) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.001, 'warm_start': True}\n",
      "0.763 (+/-0.068) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.001, 'warm_start': False}\n",
      "0.758 (+/-0.066) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.01, 'warm_start': True}\n",
      "0.758 (+/-0.066) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.01, 'warm_start': False}\n",
      "0.771 (+/-0.061) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.1, 'warm_start': True}\n",
      "0.771 (+/-0.062) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.1, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 1e-05, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 1e-05, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.0001, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.0001, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.001, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.001, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.01, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.01, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.1, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.1, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'none', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'none', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': False}\n",
      "0.764 (+/-0.070) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'none', 'solver': 'saga', 'tol': 1e-05, 'warm_start': True}\n",
      "0.764 (+/-0.070) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'none', 'solver': 'saga', 'tol': 1e-05, 'warm_start': False}\n",
      "0.763 (+/-0.064) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'none', 'solver': 'saga', 'tol': 0.0001, 'warm_start': True}\n",
      "0.764 (+/-0.070) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'none', 'solver': 'saga', 'tol': 0.0001, 'warm_start': False}\n",
      "0.763 (+/-0.064) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'none', 'solver': 'saga', 'tol': 0.001, 'warm_start': True}\n",
      "0.763 (+/-0.064) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'none', 'solver': 'saga', 'tol': 0.001, 'warm_start': False}\n",
      "0.763 (+/-0.069) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'none', 'solver': 'saga', 'tol': 0.01, 'warm_start': True}\n",
      "0.763 (+/-0.069) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'none', 'solver': 'saga', 'tol': 0.01, 'warm_start': False}\n",
      "0.768 (+/-0.052) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'none', 'solver': 'saga', 'tol': 0.1, 'warm_start': True}\n",
      "0.772 (+/-0.068) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'none', 'solver': 'saga', 'tol': 0.1, 'warm_start': False}\n",
      "0.767 (+/-0.065) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': True}\n",
      "0.767 (+/-0.065) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': False}\n",
      "0.767 (+/-0.065) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': True}\n",
      "0.767 (+/-0.065) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': False}\n",
      "0.767 (+/-0.065) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': True}\n",
      "0.767 (+/-0.065) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': False}\n",
      "0.767 (+/-0.070) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': True}\n",
      "0.767 (+/-0.065) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': False}\n",
      "0.770 (+/-0.063) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': True}\n",
      "0.765 (+/-0.061) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': False}\n",
      "0.765 (+/-0.064) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l1', 'solver': 'saga', 'tol': 1e-05, 'warm_start': True}\n",
      "0.765 (+/-0.064) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l1', 'solver': 'saga', 'tol': 1e-05, 'warm_start': False}\n",
      "0.765 (+/-0.064) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.0001, 'warm_start': True}\n",
      "0.765 (+/-0.064) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.0001, 'warm_start': False}\n",
      "0.767 (+/-0.065) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.001, 'warm_start': True}\n",
      "0.768 (+/-0.066) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.001, 'warm_start': False}\n",
      "0.758 (+/-0.066) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.01, 'warm_start': True}\n",
      "0.758 (+/-0.066) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.01, 'warm_start': False}\n",
      "0.772 (+/-0.071) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.1, 'warm_start': True}\n",
      "0.773 (+/-0.079) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.1, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 1e-05, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 1e-05, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.0001, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.0001, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.001, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.001, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.01, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.01, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.1, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.1, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'none', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'none', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': False}\n",
      "0.764 (+/-0.073) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'none', 'solver': 'saga', 'tol': 1e-05, 'warm_start': True}\n",
      "0.764 (+/-0.073) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'none', 'solver': 'saga', 'tol': 1e-05, 'warm_start': False}\n",
      "0.764 (+/-0.073) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'none', 'solver': 'saga', 'tol': 0.0001, 'warm_start': True}\n",
      "0.764 (+/-0.073) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'none', 'solver': 'saga', 'tol': 0.0001, 'warm_start': False}\n",
      "0.763 (+/-0.068) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'none', 'solver': 'saga', 'tol': 0.001, 'warm_start': True}\n",
      "0.763 (+/-0.068) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'none', 'solver': 'saga', 'tol': 0.001, 'warm_start': False}\n",
      "0.763 (+/-0.069) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'none', 'solver': 'saga', 'tol': 0.01, 'warm_start': True}\n",
      "0.763 (+/-0.069) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'none', 'solver': 'saga', 'tol': 0.01, 'warm_start': False}\n",
      "0.774 (+/-0.080) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'none', 'solver': 'saga', 'tol': 0.1, 'warm_start': True}\n",
      "0.768 (+/-0.062) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'none', 'solver': 'saga', 'tol': 0.1, 'warm_start': False}\n",
      "0.767 (+/-0.065) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': True}\n",
      "0.767 (+/-0.065) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': False}\n",
      "0.767 (+/-0.065) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': True}\n",
      "0.767 (+/-0.065) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': False}\n",
      "0.765 (+/-0.065) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': True}\n",
      "0.767 (+/-0.065) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': False}\n",
      "0.770 (+/-0.071) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': True}\n",
      "0.765 (+/-0.065) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': False}\n",
      "0.767 (+/-0.062) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': True}\n",
      "0.765 (+/-0.062) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': False}\n",
      "0.767 (+/-0.065) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l1', 'solver': 'saga', 'tol': 1e-05, 'warm_start': True}\n",
      "0.767 (+/-0.065) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l1', 'solver': 'saga', 'tol': 1e-05, 'warm_start': False}\n",
      "0.767 (+/-0.065) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.0001, 'warm_start': True}\n",
      "0.767 (+/-0.065) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.0001, 'warm_start': False}\n",
      "0.767 (+/-0.065) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.001, 'warm_start': True}\n",
      "0.768 (+/-0.066) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.001, 'warm_start': False}\n",
      "0.758 (+/-0.066) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.01, 'warm_start': True}\n",
      "0.758 (+/-0.066) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.01, 'warm_start': False}\n",
      "0.771 (+/-0.062) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.1, 'warm_start': True}\n",
      "0.773 (+/-0.071) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.1, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 1e-05, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 1e-05, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.0001, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.0001, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.001, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.001, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.01, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.01, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.1, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.1, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'none', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'none', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': False}\n",
      "0.761 (+/-0.072) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'none', 'solver': 'saga', 'tol': 1e-05, 'warm_start': True}\n",
      "0.761 (+/-0.072) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'none', 'solver': 'saga', 'tol': 1e-05, 'warm_start': False}\n",
      "0.761 (+/-0.072) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'none', 'solver': 'saga', 'tol': 0.0001, 'warm_start': True}\n",
      "0.761 (+/-0.072) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'none', 'solver': 'saga', 'tol': 0.0001, 'warm_start': False}\n",
      "0.763 (+/-0.068) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'none', 'solver': 'saga', 'tol': 0.001, 'warm_start': True}\n",
      "0.763 (+/-0.068) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'none', 'solver': 'saga', 'tol': 0.001, 'warm_start': False}\n",
      "0.763 (+/-0.069) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'none', 'solver': 'saga', 'tol': 0.01, 'warm_start': True}\n",
      "0.763 (+/-0.069) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'none', 'solver': 'saga', 'tol': 0.01, 'warm_start': False}\n",
      "0.766 (+/-0.061) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'none', 'solver': 'saga', 'tol': 0.1, 'warm_start': True}\n",
      "0.767 (+/-0.060) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'none', 'solver': 'saga', 'tol': 0.1, 'warm_start': False}\n",
      "0.767 (+/-0.065) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': True}\n",
      "0.767 (+/-0.065) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': False}\n",
      "0.767 (+/-0.065) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': True}\n",
      "0.767 (+/-0.065) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': False}\n",
      "0.767 (+/-0.065) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': True}\n",
      "0.767 (+/-0.065) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': False}\n",
      "0.765 (+/-0.065) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': True}\n",
      "0.767 (+/-0.069) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': False}\n",
      "0.764 (+/-0.070) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': True}\n",
      "0.761 (+/-0.060) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': False}\n",
      "0.767 (+/-0.065) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l1', 'solver': 'saga', 'tol': 1e-05, 'warm_start': True}\n",
      "0.767 (+/-0.065) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l1', 'solver': 'saga', 'tol': 1e-05, 'warm_start': False}\n",
      "0.767 (+/-0.065) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.0001, 'warm_start': True}\n",
      "0.767 (+/-0.065) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.0001, 'warm_start': False}\n",
      "0.767 (+/-0.065) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.001, 'warm_start': True}\n",
      "0.767 (+/-0.065) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.001, 'warm_start': False}\n",
      "0.758 (+/-0.066) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.01, 'warm_start': True}\n",
      "0.758 (+/-0.066) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.01, 'warm_start': False}\n",
      "0.770 (+/-0.080) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.1, 'warm_start': True}\n",
      "0.765 (+/-0.060) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.1, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 1e-05, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 1e-05, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.0001, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.0001, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.001, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.001, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.01, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.01, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.1, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.1, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'none', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'none', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': False}\n",
      "0.761 (+/-0.072) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'none', 'solver': 'saga', 'tol': 1e-05, 'warm_start': True}\n",
      "0.761 (+/-0.072) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'none', 'solver': 'saga', 'tol': 1e-05, 'warm_start': False}\n",
      "0.761 (+/-0.072) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'none', 'solver': 'saga', 'tol': 0.0001, 'warm_start': True}\n",
      "0.761 (+/-0.072) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'none', 'solver': 'saga', 'tol': 0.0001, 'warm_start': False}\n",
      "0.764 (+/-0.073) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'none', 'solver': 'saga', 'tol': 0.001, 'warm_start': True}\n",
      "0.763 (+/-0.068) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'none', 'solver': 'saga', 'tol': 0.001, 'warm_start': False}\n",
      "0.763 (+/-0.069) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'none', 'solver': 'saga', 'tol': 0.01, 'warm_start': True}\n",
      "0.763 (+/-0.069) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'none', 'solver': 'saga', 'tol': 0.01, 'warm_start': False}\n",
      "0.770 (+/-0.064) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'none', 'solver': 'saga', 'tol': 0.1, 'warm_start': True}\n",
      "0.764 (+/-0.077) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'none', 'solver': 'saga', 'tol': 0.1, 'warm_start': False}\n",
      "0.767 (+/-0.065) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': True}\n",
      "0.767 (+/-0.065) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': False}\n",
      "0.767 (+/-0.065) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': True}\n",
      "0.767 (+/-0.065) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': False}\n",
      "0.768 (+/-0.066) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': True}\n",
      "0.765 (+/-0.065) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': False}\n",
      "0.768 (+/-0.070) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': True}\n",
      "0.768 (+/-0.066) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': False}\n",
      "0.767 (+/-0.062) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': True}\n",
      "0.770 (+/-0.075) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': False}\n",
      "0.767 (+/-0.065) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l1', 'solver': 'saga', 'tol': 1e-05, 'warm_start': True}\n",
      "0.767 (+/-0.065) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l1', 'solver': 'saga', 'tol': 1e-05, 'warm_start': False}\n",
      "0.767 (+/-0.065) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.0001, 'warm_start': True}\n",
      "0.767 (+/-0.065) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.0001, 'warm_start': False}\n",
      "0.768 (+/-0.066) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.001, 'warm_start': True}\n",
      "0.767 (+/-0.065) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.001, 'warm_start': False}\n",
      "0.758 (+/-0.066) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.01, 'warm_start': True}\n",
      "0.758 (+/-0.066) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.01, 'warm_start': False}\n",
      "0.771 (+/-0.061) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.1, 'warm_start': True}\n",
      "0.770 (+/-0.062) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.1, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 1e-05, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 1e-05, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.0001, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.0001, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.001, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.001, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.01, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.01, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.1, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.1, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'none', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'none', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': False}\n",
      "0.761 (+/-0.072) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'none', 'solver': 'saga', 'tol': 1e-05, 'warm_start': True}\n",
      "0.761 (+/-0.072) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'none', 'solver': 'saga', 'tol': 1e-05, 'warm_start': False}\n",
      "0.761 (+/-0.072) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'none', 'solver': 'saga', 'tol': 0.0001, 'warm_start': True}\n",
      "0.761 (+/-0.072) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'none', 'solver': 'saga', 'tol': 0.0001, 'warm_start': False}\n",
      "0.763 (+/-0.068) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'none', 'solver': 'saga', 'tol': 0.001, 'warm_start': True}\n",
      "0.763 (+/-0.068) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'none', 'solver': 'saga', 'tol': 0.001, 'warm_start': False}\n",
      "0.763 (+/-0.069) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'none', 'solver': 'saga', 'tol': 0.01, 'warm_start': True}\n",
      "0.763 (+/-0.069) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'none', 'solver': 'saga', 'tol': 0.01, 'warm_start': False}\n",
      "0.772 (+/-0.072) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'none', 'solver': 'saga', 'tol': 0.1, 'warm_start': True}\n",
      "0.770 (+/-0.075) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'none', 'solver': 'saga', 'tol': 0.1, 'warm_start': False}\n",
      "0.792 (+/-0.089) for {'C': 10, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': True}\n",
      "0.792 (+/-0.089) for {'C': 10, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': False}\n",
      "0.792 (+/-0.089) for {'C': 10, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': True}\n",
      "0.792 (+/-0.089) for {'C': 10, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': False}\n",
      "0.792 (+/-0.089) for {'C': 10, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': True}\n",
      "0.792 (+/-0.089) for {'C': 10, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': False}\n",
      "0.791 (+/-0.087) for {'C': 10, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': True}\n",
      "0.794 (+/-0.081) for {'C': 10, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': False}\n",
      "0.794 (+/-0.079) for {'C': 10, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': True}\n",
      "0.791 (+/-0.081) for {'C': 10, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': False}\n",
      "0.796 (+/-0.080) for {'C': 10, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l1', 'solver': 'saga', 'tol': 1e-05, 'warm_start': True}\n",
      "0.796 (+/-0.080) for {'C': 10, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l1', 'solver': 'saga', 'tol': 1e-05, 'warm_start': False}\n",
      "0.796 (+/-0.080) for {'C': 10, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.0001, 'warm_start': True}\n",
      "0.796 (+/-0.080) for {'C': 10, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.0001, 'warm_start': False}\n",
      "0.796 (+/-0.080) for {'C': 10, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.001, 'warm_start': True}\n",
      "0.796 (+/-0.080) for {'C': 10, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.001, 'warm_start': False}\n",
      "0.795 (+/-0.070) for {'C': 10, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.01, 'warm_start': True}\n",
      "0.795 (+/-0.070) for {'C': 10, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.01, 'warm_start': False}\n",
      "0.771 (+/-0.079) for {'C': 10, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.1, 'warm_start': True}\n",
      "0.770 (+/-0.086) for {'C': 10, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.1, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 1e-05, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 1e-05, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.0001, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.0001, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.001, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.001, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.01, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.01, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.1, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.1, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'none', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'none', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': False}\n",
      "0.796 (+/-0.080) for {'C': 10, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'none', 'solver': 'saga', 'tol': 1e-05, 'warm_start': True}\n",
      "0.796 (+/-0.080) for {'C': 10, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'none', 'solver': 'saga', 'tol': 1e-05, 'warm_start': False}\n",
      "0.796 (+/-0.080) for {'C': 10, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'none', 'solver': 'saga', 'tol': 0.0001, 'warm_start': True}\n",
      "0.796 (+/-0.080) for {'C': 10, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'none', 'solver': 'saga', 'tol': 0.0001, 'warm_start': False}\n",
      "0.796 (+/-0.080) for {'C': 10, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'none', 'solver': 'saga', 'tol': 0.001, 'warm_start': True}\n",
      "0.796 (+/-0.080) for {'C': 10, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'none', 'solver': 'saga', 'tol': 0.001, 'warm_start': False}\n",
      "0.794 (+/-0.069) for {'C': 10, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'none', 'solver': 'saga', 'tol': 0.01, 'warm_start': True}\n",
      "0.795 (+/-0.070) for {'C': 10, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'none', 'solver': 'saga', 'tol': 0.01, 'warm_start': False}\n",
      "0.774 (+/-0.091) for {'C': 10, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'none', 'solver': 'saga', 'tol': 0.1, 'warm_start': True}\n",
      "0.777 (+/-0.081) for {'C': 10, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'none', 'solver': 'saga', 'tol': 0.1, 'warm_start': False}\n",
      "0.792 (+/-0.089) for {'C': 10, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': True}\n",
      "0.792 (+/-0.089) for {'C': 10, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': False}\n",
      "0.792 (+/-0.089) for {'C': 10, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': True}\n",
      "0.792 (+/-0.089) for {'C': 10, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': False}\n",
      "0.792 (+/-0.089) for {'C': 10, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': True}\n",
      "0.791 (+/-0.083) for {'C': 10, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': False}\n",
      "0.791 (+/-0.087) for {'C': 10, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': True}\n",
      "0.792 (+/-0.089) for {'C': 10, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': False}\n",
      "0.791 (+/-0.079) for {'C': 10, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': True}\n",
      "0.792 (+/-0.082) for {'C': 10, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': False}\n",
      "0.794 (+/-0.085) for {'C': 10, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l1', 'solver': 'saga', 'tol': 1e-05, 'warm_start': True}\n",
      "0.794 (+/-0.085) for {'C': 10, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l1', 'solver': 'saga', 'tol': 1e-05, 'warm_start': False}\n",
      "0.794 (+/-0.085) for {'C': 10, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.0001, 'warm_start': True}\n",
      "0.794 (+/-0.085) for {'C': 10, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.0001, 'warm_start': False}\n",
      "0.796 (+/-0.080) for {'C': 10, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.001, 'warm_start': True}\n",
      "0.796 (+/-0.080) for {'C': 10, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.001, 'warm_start': False}\n",
      "0.795 (+/-0.070) for {'C': 10, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.01, 'warm_start': True}\n",
      "0.795 (+/-0.070) for {'C': 10, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.01, 'warm_start': False}\n",
      "0.775 (+/-0.078) for {'C': 10, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.1, 'warm_start': True}\n",
      "0.771 (+/-0.082) for {'C': 10, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.1, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 1e-05, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 1e-05, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.0001, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.0001, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.001, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.001, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.01, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.01, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.1, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.1, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'none', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'none', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': False}\n",
      "0.792 (+/-0.089) for {'C': 10, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'none', 'solver': 'saga', 'tol': 1e-05, 'warm_start': True}\n",
      "0.792 (+/-0.089) for {'C': 10, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'none', 'solver': 'saga', 'tol': 1e-05, 'warm_start': False}\n",
      "0.792 (+/-0.089) for {'C': 10, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'none', 'solver': 'saga', 'tol': 0.0001, 'warm_start': True}\n",
      "0.792 (+/-0.089) for {'C': 10, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'none', 'solver': 'saga', 'tol': 0.0001, 'warm_start': False}\n",
      "0.794 (+/-0.085) for {'C': 10, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'none', 'solver': 'saga', 'tol': 0.001, 'warm_start': True}\n",
      "0.794 (+/-0.085) for {'C': 10, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'none', 'solver': 'saga', 'tol': 0.001, 'warm_start': False}\n",
      "0.795 (+/-0.070) for {'C': 10, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'none', 'solver': 'saga', 'tol': 0.01, 'warm_start': True}\n",
      "0.795 (+/-0.070) for {'C': 10, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'none', 'solver': 'saga', 'tol': 0.01, 'warm_start': False}\n",
      "0.778 (+/-0.074) for {'C': 10, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'none', 'solver': 'saga', 'tol': 0.1, 'warm_start': True}\n",
      "0.778 (+/-0.074) for {'C': 10, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'none', 'solver': 'saga', 'tol': 0.1, 'warm_start': False}\n",
      "0.792 (+/-0.089) for {'C': 10, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': True}\n",
      "0.792 (+/-0.089) for {'C': 10, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': False}\n",
      "0.792 (+/-0.089) for {'C': 10, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': True}\n",
      "0.792 (+/-0.089) for {'C': 10, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': False}\n",
      "0.792 (+/-0.089) for {'C': 10, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': True}\n",
      "0.792 (+/-0.089) for {'C': 10, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': False}\n",
      "0.792 (+/-0.089) for {'C': 10, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': True}\n",
      "0.789 (+/-0.086) for {'C': 10, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': False}\n",
      "0.787 (+/-0.073) for {'C': 10, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': True}\n",
      "0.791 (+/-0.079) for {'C': 10, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': False}\n",
      "0.794 (+/-0.085) for {'C': 10, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l1', 'solver': 'saga', 'tol': 1e-05, 'warm_start': True}\n",
      "0.794 (+/-0.085) for {'C': 10, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l1', 'solver': 'saga', 'tol': 1e-05, 'warm_start': False}\n",
      "0.794 (+/-0.085) for {'C': 10, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.0001, 'warm_start': True}\n",
      "0.794 (+/-0.085) for {'C': 10, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.0001, 'warm_start': False}\n",
      "0.796 (+/-0.080) for {'C': 10, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.001, 'warm_start': True}\n",
      "0.796 (+/-0.080) for {'C': 10, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.001, 'warm_start': False}\n",
      "0.795 (+/-0.070) for {'C': 10, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.01, 'warm_start': True}\n",
      "0.795 (+/-0.070) for {'C': 10, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.01, 'warm_start': False}\n",
      "0.782 (+/-0.074) for {'C': 10, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.1, 'warm_start': True}\n",
      "0.771 (+/-0.074) for {'C': 10, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.1, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 1e-05, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 1e-05, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.0001, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.0001, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.001, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.001, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.01, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.01, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.1, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.1, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'none', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'none', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': False}\n",
      "0.791 (+/-0.087) for {'C': 10, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'none', 'solver': 'saga', 'tol': 1e-05, 'warm_start': True}\n",
      "0.791 (+/-0.087) for {'C': 10, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'none', 'solver': 'saga', 'tol': 1e-05, 'warm_start': False}\n",
      "0.791 (+/-0.087) for {'C': 10, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'none', 'solver': 'saga', 'tol': 0.0001, 'warm_start': True}\n",
      "0.791 (+/-0.087) for {'C': 10, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'none', 'solver': 'saga', 'tol': 0.0001, 'warm_start': False}\n",
      "0.794 (+/-0.085) for {'C': 10, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'none', 'solver': 'saga', 'tol': 0.001, 'warm_start': True}\n",
      "0.794 (+/-0.085) for {'C': 10, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'none', 'solver': 'saga', 'tol': 0.001, 'warm_start': False}\n",
      "0.795 (+/-0.070) for {'C': 10, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'none', 'solver': 'saga', 'tol': 0.01, 'warm_start': True}\n",
      "0.795 (+/-0.070) for {'C': 10, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'none', 'solver': 'saga', 'tol': 0.01, 'warm_start': False}\n",
      "0.771 (+/-0.079) for {'C': 10, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'none', 'solver': 'saga', 'tol': 0.1, 'warm_start': True}\n",
      "0.773 (+/-0.074) for {'C': 10, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'none', 'solver': 'saga', 'tol': 0.1, 'warm_start': False}\n",
      "0.792 (+/-0.089) for {'C': 10, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': True}\n",
      "0.792 (+/-0.089) for {'C': 10, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': False}\n",
      "0.792 (+/-0.089) for {'C': 10, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': True}\n",
      "0.792 (+/-0.089) for {'C': 10, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': False}\n",
      "0.792 (+/-0.089) for {'C': 10, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': True}\n",
      "0.791 (+/-0.083) for {'C': 10, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': False}\n",
      "0.789 (+/-0.086) for {'C': 10, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': True}\n",
      "0.791 (+/-0.087) for {'C': 10, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': False}\n",
      "0.794 (+/-0.087) for {'C': 10, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': True}\n",
      "0.798 (+/-0.077) for {'C': 10, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': False}\n",
      "0.792 (+/-0.089) for {'C': 10, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l1', 'solver': 'saga', 'tol': 1e-05, 'warm_start': True}\n",
      "0.792 (+/-0.089) for {'C': 10, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l1', 'solver': 'saga', 'tol': 1e-05, 'warm_start': False}\n",
      "0.794 (+/-0.085) for {'C': 10, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.0001, 'warm_start': True}\n",
      "0.794 (+/-0.085) for {'C': 10, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.0001, 'warm_start': False}\n",
      "0.796 (+/-0.080) for {'C': 10, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.001, 'warm_start': True}\n",
      "0.796 (+/-0.080) for {'C': 10, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.001, 'warm_start': False}\n",
      "0.795 (+/-0.070) for {'C': 10, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.01, 'warm_start': True}\n",
      "0.795 (+/-0.070) for {'C': 10, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.01, 'warm_start': False}\n",
      "0.773 (+/-0.078) for {'C': 10, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.1, 'warm_start': True}\n",
      "0.775 (+/-0.075) for {'C': 10, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.1, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 1e-05, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 1e-05, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.0001, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.0001, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.001, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.001, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.01, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.01, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.1, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.1, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'none', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'none', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': False}\n",
      "0.791 (+/-0.087) for {'C': 10, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'none', 'solver': 'saga', 'tol': 1e-05, 'warm_start': True}\n",
      "0.791 (+/-0.087) for {'C': 10, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'none', 'solver': 'saga', 'tol': 1e-05, 'warm_start': False}\n",
      "0.791 (+/-0.087) for {'C': 10, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'none', 'solver': 'saga', 'tol': 0.0001, 'warm_start': True}\n",
      "0.791 (+/-0.087) for {'C': 10, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'none', 'solver': 'saga', 'tol': 0.0001, 'warm_start': False}\n",
      "0.794 (+/-0.085) for {'C': 10, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'none', 'solver': 'saga', 'tol': 0.001, 'warm_start': True}\n",
      "0.794 (+/-0.085) for {'C': 10, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'none', 'solver': 'saga', 'tol': 0.001, 'warm_start': False}\n",
      "0.795 (+/-0.070) for {'C': 10, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'none', 'solver': 'saga', 'tol': 0.01, 'warm_start': True}\n",
      "0.795 (+/-0.070) for {'C': 10, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'none', 'solver': 'saga', 'tol': 0.01, 'warm_start': False}\n",
      "0.775 (+/-0.073) for {'C': 10, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'none', 'solver': 'saga', 'tol': 0.1, 'warm_start': True}\n",
      "0.771 (+/-0.075) for {'C': 10, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'none', 'solver': 'saga', 'tol': 0.1, 'warm_start': False}\n",
      "0.792 (+/-0.089) for {'C': 10, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': True}\n",
      "0.792 (+/-0.089) for {'C': 10, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': False}\n",
      "0.792 (+/-0.089) for {'C': 10, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': True}\n",
      "0.792 (+/-0.089) for {'C': 10, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': False}\n",
      "0.791 (+/-0.083) for {'C': 10, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': True}\n",
      "0.792 (+/-0.089) for {'C': 10, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': False}\n",
      "0.792 (+/-0.084) for {'C': 10, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': True}\n",
      "0.792 (+/-0.089) for {'C': 10, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': False}\n",
      "0.795 (+/-0.072) for {'C': 10, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': True}\n",
      "0.791 (+/-0.085) for {'C': 10, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': False}\n",
      "0.792 (+/-0.089) for {'C': 10, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l1', 'solver': 'saga', 'tol': 1e-05, 'warm_start': True}\n",
      "0.792 (+/-0.089) for {'C': 10, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l1', 'solver': 'saga', 'tol': 1e-05, 'warm_start': False}\n",
      "0.794 (+/-0.085) for {'C': 10, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.0001, 'warm_start': True}\n",
      "0.794 (+/-0.085) for {'C': 10, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.0001, 'warm_start': False}\n",
      "0.796 (+/-0.080) for {'C': 10, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.001, 'warm_start': True}\n",
      "0.796 (+/-0.080) for {'C': 10, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.001, 'warm_start': False}\n",
      "0.795 (+/-0.070) for {'C': 10, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.01, 'warm_start': True}\n",
      "0.795 (+/-0.070) for {'C': 10, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.01, 'warm_start': False}\n",
      "0.775 (+/-0.079) for {'C': 10, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.1, 'warm_start': True}\n",
      "0.777 (+/-0.086) for {'C': 10, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.1, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 1e-05, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 1e-05, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.0001, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.0001, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.001, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.001, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.01, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.01, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.1, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.1, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'none', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'none', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': False}\n",
      "0.791 (+/-0.087) for {'C': 10, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'none', 'solver': 'saga', 'tol': 1e-05, 'warm_start': True}\n",
      "0.791 (+/-0.087) for {'C': 10, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'none', 'solver': 'saga', 'tol': 1e-05, 'warm_start': False}\n",
      "0.791 (+/-0.087) for {'C': 10, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'none', 'solver': 'saga', 'tol': 0.0001, 'warm_start': True}\n",
      "0.791 (+/-0.087) for {'C': 10, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'none', 'solver': 'saga', 'tol': 0.0001, 'warm_start': False}\n",
      "0.794 (+/-0.085) for {'C': 10, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'none', 'solver': 'saga', 'tol': 0.001, 'warm_start': True}\n",
      "0.794 (+/-0.085) for {'C': 10, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'none', 'solver': 'saga', 'tol': 0.001, 'warm_start': False}\n",
      "0.795 (+/-0.070) for {'C': 10, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'none', 'solver': 'saga', 'tol': 0.01, 'warm_start': True}\n",
      "0.795 (+/-0.070) for {'C': 10, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'none', 'solver': 'saga', 'tol': 0.01, 'warm_start': False}\n",
      "0.774 (+/-0.081) for {'C': 10, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'none', 'solver': 'saga', 'tol': 0.1, 'warm_start': True}\n",
      "0.777 (+/-0.084) for {'C': 10, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'none', 'solver': 'saga', 'tol': 0.1, 'warm_start': False}\n",
      "0.763 (+/-0.072) for {'C': 10, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': True}\n",
      "0.763 (+/-0.072) for {'C': 10, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': False}\n",
      "0.763 (+/-0.072) for {'C': 10, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': True}\n",
      "0.763 (+/-0.072) for {'C': 10, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': False}\n",
      "0.763 (+/-0.072) for {'C': 10, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': True}\n",
      "0.763 (+/-0.072) for {'C': 10, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': False}\n",
      "0.764 (+/-0.078) for {'C': 10, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': True}\n",
      "0.764 (+/-0.078) for {'C': 10, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': False}\n",
      "0.765 (+/-0.081) for {'C': 10, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': True}\n",
      "0.764 (+/-0.082) for {'C': 10, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': False}\n",
      "0.763 (+/-0.064) for {'C': 10, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l1', 'solver': 'saga', 'tol': 1e-05, 'warm_start': True}\n",
      "0.763 (+/-0.064) for {'C': 10, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l1', 'solver': 'saga', 'tol': 1e-05, 'warm_start': False}\n",
      "0.763 (+/-0.064) for {'C': 10, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.0001, 'warm_start': True}\n",
      "0.763 (+/-0.064) for {'C': 10, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.0001, 'warm_start': False}\n",
      "0.763 (+/-0.064) for {'C': 10, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.001, 'warm_start': True}\n",
      "0.763 (+/-0.064) for {'C': 10, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.001, 'warm_start': False}\n",
      "0.763 (+/-0.069) for {'C': 10, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.01, 'warm_start': True}\n",
      "0.763 (+/-0.069) for {'C': 10, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.01, 'warm_start': False}\n",
      "0.770 (+/-0.060) for {'C': 10, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.1, 'warm_start': True}\n",
      "0.772 (+/-0.071) for {'C': 10, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.1, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 1e-05, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 1e-05, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.0001, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.0001, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.001, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.001, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.01, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.01, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.1, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.1, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'none', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'none', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': False}\n",
      "0.764 (+/-0.070) for {'C': 10, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'none', 'solver': 'saga', 'tol': 1e-05, 'warm_start': True}\n",
      "0.763 (+/-0.064) for {'C': 10, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'none', 'solver': 'saga', 'tol': 1e-05, 'warm_start': False}\n",
      "0.764 (+/-0.070) for {'C': 10, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'none', 'solver': 'saga', 'tol': 0.0001, 'warm_start': True}\n",
      "0.763 (+/-0.064) for {'C': 10, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'none', 'solver': 'saga', 'tol': 0.0001, 'warm_start': False}\n",
      "0.763 (+/-0.064) for {'C': 10, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'none', 'solver': 'saga', 'tol': 0.001, 'warm_start': True}\n",
      "0.763 (+/-0.064) for {'C': 10, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'none', 'solver': 'saga', 'tol': 0.001, 'warm_start': False}\n",
      "0.763 (+/-0.069) for {'C': 10, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'none', 'solver': 'saga', 'tol': 0.01, 'warm_start': True}\n",
      "0.763 (+/-0.069) for {'C': 10, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'none', 'solver': 'saga', 'tol': 0.01, 'warm_start': False}\n",
      "0.773 (+/-0.076) for {'C': 10, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'none', 'solver': 'saga', 'tol': 0.1, 'warm_start': True}\n",
      "0.772 (+/-0.062) for {'C': 10, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'none', 'solver': 'saga', 'tol': 0.1, 'warm_start': False}\n",
      "0.763 (+/-0.072) for {'C': 10, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': True}\n",
      "0.763 (+/-0.072) for {'C': 10, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': False}\n",
      "0.763 (+/-0.072) for {'C': 10, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': True}\n",
      "0.763 (+/-0.072) for {'C': 10, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': False}\n",
      "0.763 (+/-0.072) for {'C': 10, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': True}\n",
      "0.763 (+/-0.072) for {'C': 10, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': False}\n",
      "0.764 (+/-0.078) for {'C': 10, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': True}\n",
      "0.764 (+/-0.078) for {'C': 10, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': False}\n",
      "0.767 (+/-0.069) for {'C': 10, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': True}\n",
      "0.768 (+/-0.068) for {'C': 10, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': False}\n",
      "0.764 (+/-0.073) for {'C': 10, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l1', 'solver': 'saga', 'tol': 1e-05, 'warm_start': True}\n",
      "0.764 (+/-0.073) for {'C': 10, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l1', 'solver': 'saga', 'tol': 1e-05, 'warm_start': False}\n",
      "0.764 (+/-0.073) for {'C': 10, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.0001, 'warm_start': True}\n",
      "0.764 (+/-0.073) for {'C': 10, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.0001, 'warm_start': False}\n",
      "0.763 (+/-0.068) for {'C': 10, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.001, 'warm_start': True}\n",
      "0.763 (+/-0.068) for {'C': 10, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.001, 'warm_start': False}\n",
      "0.763 (+/-0.069) for {'C': 10, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.01, 'warm_start': True}\n",
      "0.763 (+/-0.069) for {'C': 10, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.01, 'warm_start': False}\n",
      "0.774 (+/-0.064) for {'C': 10, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.1, 'warm_start': True}\n",
      "0.771 (+/-0.073) for {'C': 10, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.1, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 1e-05, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 1e-05, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.0001, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.0001, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.001, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.001, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.01, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.01, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.1, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.1, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'none', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'none', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': False}\n",
      "0.764 (+/-0.073) for {'C': 10, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'none', 'solver': 'saga', 'tol': 1e-05, 'warm_start': True}\n",
      "0.764 (+/-0.073) for {'C': 10, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'none', 'solver': 'saga', 'tol': 1e-05, 'warm_start': False}\n",
      "0.764 (+/-0.073) for {'C': 10, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'none', 'solver': 'saga', 'tol': 0.0001, 'warm_start': True}\n",
      "0.764 (+/-0.073) for {'C': 10, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'none', 'solver': 'saga', 'tol': 0.0001, 'warm_start': False}\n",
      "0.764 (+/-0.073) for {'C': 10, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'none', 'solver': 'saga', 'tol': 0.001, 'warm_start': True}\n",
      "0.764 (+/-0.073) for {'C': 10, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'none', 'solver': 'saga', 'tol': 0.001, 'warm_start': False}\n",
      "0.763 (+/-0.069) for {'C': 10, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'none', 'solver': 'saga', 'tol': 0.01, 'warm_start': True}\n",
      "0.763 (+/-0.069) for {'C': 10, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'none', 'solver': 'saga', 'tol': 0.01, 'warm_start': False}\n",
      "0.770 (+/-0.067) for {'C': 10, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'none', 'solver': 'saga', 'tol': 0.1, 'warm_start': True}\n",
      "0.770 (+/-0.060) for {'C': 10, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'none', 'solver': 'saga', 'tol': 0.1, 'warm_start': False}\n",
      "0.763 (+/-0.072) for {'C': 10, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': True}\n",
      "0.763 (+/-0.072) for {'C': 10, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': False}\n",
      "0.763 (+/-0.072) for {'C': 10, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': True}\n",
      "0.763 (+/-0.072) for {'C': 10, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': False}\n",
      "0.763 (+/-0.072) for {'C': 10, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': True}\n",
      "0.763 (+/-0.072) for {'C': 10, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': False}\n",
      "0.765 (+/-0.080) for {'C': 10, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': True}\n",
      "0.765 (+/-0.080) for {'C': 10, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': False}\n",
      "0.770 (+/-0.069) for {'C': 10, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': True}\n",
      "0.761 (+/-0.059) for {'C': 10, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': False}\n",
      "0.763 (+/-0.072) for {'C': 10, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l1', 'solver': 'saga', 'tol': 1e-05, 'warm_start': True}\n",
      "0.763 (+/-0.072) for {'C': 10, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l1', 'solver': 'saga', 'tol': 1e-05, 'warm_start': False}\n",
      "0.763 (+/-0.072) for {'C': 10, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.0001, 'warm_start': True}\n",
      "0.763 (+/-0.072) for {'C': 10, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.0001, 'warm_start': False}\n",
      "0.763 (+/-0.068) for {'C': 10, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.001, 'warm_start': True}\n",
      "0.763 (+/-0.068) for {'C': 10, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.001, 'warm_start': False}\n",
      "0.763 (+/-0.069) for {'C': 10, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.01, 'warm_start': True}\n",
      "0.763 (+/-0.069) for {'C': 10, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.01, 'warm_start': False}\n",
      "0.763 (+/-0.042) for {'C': 10, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.1, 'warm_start': True}\n",
      "0.775 (+/-0.074) for {'C': 10, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.1, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 1e-05, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 1e-05, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.0001, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.0001, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.001, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.001, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.01, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.01, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.1, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.1, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'none', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'none', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': False}\n",
      "0.761 (+/-0.072) for {'C': 10, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'none', 'solver': 'saga', 'tol': 1e-05, 'warm_start': True}\n",
      "0.761 (+/-0.072) for {'C': 10, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'none', 'solver': 'saga', 'tol': 1e-05, 'warm_start': False}\n",
      "0.761 (+/-0.072) for {'C': 10, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'none', 'solver': 'saga', 'tol': 0.0001, 'warm_start': True}\n",
      "0.761 (+/-0.072) for {'C': 10, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'none', 'solver': 'saga', 'tol': 0.0001, 'warm_start': False}\n",
      "0.763 (+/-0.068) for {'C': 10, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'none', 'solver': 'saga', 'tol': 0.001, 'warm_start': True}\n",
      "0.763 (+/-0.068) for {'C': 10, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'none', 'solver': 'saga', 'tol': 0.001, 'warm_start': False}\n",
      "0.763 (+/-0.069) for {'C': 10, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'none', 'solver': 'saga', 'tol': 0.01, 'warm_start': True}\n",
      "0.763 (+/-0.069) for {'C': 10, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'none', 'solver': 'saga', 'tol': 0.01, 'warm_start': False}\n",
      "0.761 (+/-0.058) for {'C': 10, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'none', 'solver': 'saga', 'tol': 0.1, 'warm_start': True}\n",
      "0.771 (+/-0.086) for {'C': 10, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'none', 'solver': 'saga', 'tol': 0.1, 'warm_start': False}\n",
      "0.763 (+/-0.072) for {'C': 10, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': True}\n",
      "0.763 (+/-0.072) for {'C': 10, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': False}\n",
      "0.763 (+/-0.072) for {'C': 10, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': True}\n",
      "0.763 (+/-0.072) for {'C': 10, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': False}\n",
      "0.763 (+/-0.072) for {'C': 10, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': True}\n",
      "0.763 (+/-0.072) for {'C': 10, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': False}\n",
      "0.764 (+/-0.078) for {'C': 10, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': True}\n",
      "0.761 (+/-0.072) for {'C': 10, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': False}\n",
      "0.764 (+/-0.078) for {'C': 10, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': True}\n",
      "0.767 (+/-0.070) for {'C': 10, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': False}\n",
      "0.763 (+/-0.072) for {'C': 10, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l1', 'solver': 'saga', 'tol': 1e-05, 'warm_start': True}\n",
      "0.763 (+/-0.072) for {'C': 10, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l1', 'solver': 'saga', 'tol': 1e-05, 'warm_start': False}\n",
      "0.763 (+/-0.072) for {'C': 10, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.0001, 'warm_start': True}\n",
      "0.763 (+/-0.072) for {'C': 10, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.0001, 'warm_start': False}\n",
      "0.763 (+/-0.068) for {'C': 10, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.001, 'warm_start': True}\n",
      "0.763 (+/-0.068) for {'C': 10, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.001, 'warm_start': False}\n",
      "0.763 (+/-0.069) for {'C': 10, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.01, 'warm_start': True}\n",
      "0.763 (+/-0.069) for {'C': 10, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.01, 'warm_start': False}\n",
      "0.770 (+/-0.057) for {'C': 10, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.1, 'warm_start': True}\n",
      "0.763 (+/-0.074) for {'C': 10, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.1, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 1e-05, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 1e-05, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.0001, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.0001, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.001, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.001, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.01, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.01, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.1, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.1, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'none', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'none', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': False}\n",
      "0.761 (+/-0.072) for {'C': 10, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'none', 'solver': 'saga', 'tol': 1e-05, 'warm_start': True}\n",
      "0.761 (+/-0.072) for {'C': 10, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'none', 'solver': 'saga', 'tol': 1e-05, 'warm_start': False}\n",
      "0.761 (+/-0.072) for {'C': 10, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'none', 'solver': 'saga', 'tol': 0.0001, 'warm_start': True}\n",
      "0.761 (+/-0.072) for {'C': 10, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'none', 'solver': 'saga', 'tol': 0.0001, 'warm_start': False}\n",
      "0.763 (+/-0.068) for {'C': 10, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'none', 'solver': 'saga', 'tol': 0.001, 'warm_start': True}\n",
      "0.763 (+/-0.068) for {'C': 10, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'none', 'solver': 'saga', 'tol': 0.001, 'warm_start': False}\n",
      "0.763 (+/-0.069) for {'C': 10, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'none', 'solver': 'saga', 'tol': 0.01, 'warm_start': True}\n",
      "0.763 (+/-0.069) for {'C': 10, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'none', 'solver': 'saga', 'tol': 0.01, 'warm_start': False}\n",
      "0.771 (+/-0.066) for {'C': 10, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'none', 'solver': 'saga', 'tol': 0.1, 'warm_start': True}\n",
      "0.771 (+/-0.057) for {'C': 10, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'none', 'solver': 'saga', 'tol': 0.1, 'warm_start': False}\n",
      "0.763 (+/-0.072) for {'C': 10, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': True}\n",
      "0.763 (+/-0.072) for {'C': 10, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': False}\n",
      "0.763 (+/-0.072) for {'C': 10, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': True}\n",
      "0.763 (+/-0.072) for {'C': 10, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': False}\n",
      "0.763 (+/-0.072) for {'C': 10, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': True}\n",
      "0.763 (+/-0.072) for {'C': 10, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': False}\n",
      "0.763 (+/-0.072) for {'C': 10, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': True}\n",
      "0.765 (+/-0.080) for {'C': 10, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': False}\n",
      "0.770 (+/-0.085) for {'C': 10, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': True}\n",
      "0.763 (+/-0.072) for {'C': 10, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': False}\n",
      "0.763 (+/-0.072) for {'C': 10, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l1', 'solver': 'saga', 'tol': 1e-05, 'warm_start': True}\n",
      "0.763 (+/-0.072) for {'C': 10, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l1', 'solver': 'saga', 'tol': 1e-05, 'warm_start': False}\n",
      "0.763 (+/-0.072) for {'C': 10, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.0001, 'warm_start': True}\n",
      "0.763 (+/-0.072) for {'C': 10, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.0001, 'warm_start': False}\n",
      "0.763 (+/-0.068) for {'C': 10, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.001, 'warm_start': True}\n",
      "0.763 (+/-0.068) for {'C': 10, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.001, 'warm_start': False}\n",
      "0.763 (+/-0.069) for {'C': 10, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.01, 'warm_start': True}\n",
      "0.763 (+/-0.069) for {'C': 10, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.01, 'warm_start': False}\n",
      "0.775 (+/-0.077) for {'C': 10, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.1, 'warm_start': True}\n",
      "0.772 (+/-0.074) for {'C': 10, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.1, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 1e-05, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 1e-05, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.0001, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.0001, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.001, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.001, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.01, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.01, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.1, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.1, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'none', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'none', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': False}\n",
      "0.761 (+/-0.072) for {'C': 10, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'none', 'solver': 'saga', 'tol': 1e-05, 'warm_start': True}\n",
      "0.761 (+/-0.072) for {'C': 10, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'none', 'solver': 'saga', 'tol': 1e-05, 'warm_start': False}\n",
      "0.761 (+/-0.072) for {'C': 10, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'none', 'solver': 'saga', 'tol': 0.0001, 'warm_start': True}\n",
      "0.761 (+/-0.072) for {'C': 10, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'none', 'solver': 'saga', 'tol': 0.0001, 'warm_start': False}\n",
      "0.763 (+/-0.068) for {'C': 10, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'none', 'solver': 'saga', 'tol': 0.001, 'warm_start': True}\n",
      "0.763 (+/-0.068) for {'C': 10, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'none', 'solver': 'saga', 'tol': 0.001, 'warm_start': False}\n",
      "0.763 (+/-0.069) for {'C': 10, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'none', 'solver': 'saga', 'tol': 0.01, 'warm_start': True}\n",
      "0.763 (+/-0.069) for {'C': 10, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'none', 'solver': 'saga', 'tol': 0.01, 'warm_start': False}\n",
      "0.771 (+/-0.077) for {'C': 10, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'none', 'solver': 'saga', 'tol': 0.1, 'warm_start': True}\n",
      "0.777 (+/-0.068) for {'C': 10, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'none', 'solver': 'saga', 'tol': 0.1, 'warm_start': False}\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.85      0.85      0.85       114\n",
      "         1.0       0.73      0.73      0.73        64\n",
      "\n",
      "    accuracy                           0.81       178\n",
      "   macro avg       0.79      0.79      0.79       178\n",
      "weighted avg       0.81      0.81      0.81       178\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "tuned_parameters = [\n",
    "                    {'penalty': ['l2'],\n",
    "                     'C': [0.01,0.1,1.0,10], 'fit_intercept':[True,False], 'solver':['liblinear','newton-cg', 'lbfgs', 'sag', 'saga'],\n",
    "                     'max_iter':[100,500,1000,1500,2000],'warm_start':[True, False],'fit_intercept':[True, False],\n",
    "                     'tol':[0.00001,0.0001,0.001,0.01,0.1]},\n",
    "                    {'penalty': ['l1', 'elasticnet', 'none'],\n",
    "                     'C': [0.01,0.1,1.0,10], 'fit_intercept':[True,False], 'solver':[ 'liblinear', 'saga'],\n",
    "                     'max_iter':[100,500,1000,1500,2000],'warm_start':[True, False],'fit_intercept':[True, False],\n",
    "                     'tol':[0.00001,0.0001,0.001,0.01,0.1]}\n",
    "                    ]\n",
    "\n",
    "\n",
    "print()\n",
    "\n",
    "clf = GridSearchCV(\n",
    "    LogisticRegression(), tuned_parameters, scoring='accuracy',cv=10\n",
    ")\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best parameters set found on development set:\")\n",
    "print()\n",
    "print(clf.best_params_)\n",
    "print()\n",
    "print(\"Grid scores on development set:\")\n",
    "print()\n",
    "means = clf.cv_results_['mean_test_score']\n",
    "stds = clf.cv_results_['std_test_score']\n",
    "for mean, std, params in zip(means, stds, clf.cv_results_['params']):\n",
    "    print(\"%0.3f (+/-%0.03f) for %r\"\n",
    "          % (mean, std * 2, params))\n",
    "print()\n",
    "\n",
    "print(\"Detailed classification report:\")\n",
    "print()\n",
    "print(\"The model is trained on the full development set.\")\n",
    "print(\"The scores are computed on the full evaluation set.\")\n",
    "print()\n",
    "y_true, y_pred = y_test, clf.predict(X_test)\n",
    "print(classification_report(y_true, y_pred))\n",
    "print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1TE7sEruQ7qi"
   },
   "source": [
    "###Cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "AsSHb_h0QzXx",
    "outputId": "7c141151-ea42-4aaa-9f55-73d7d526da4c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.796879\n"
     ]
    }
   ],
   "source": [
    "clf = LogisticRegression(C= 10, fit_intercept= True, max_iter= 1500, penalty= 'l1', solver= 'liblinear', tol= 0.1, warm_start= False)\n",
    "score=cross_validate(clf, X, y, cv=10, scoring=\"accuracy\")[\"test_score\"].mean()\n",
    "print(f\"{score:.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wB4fhopYMZcQ"
   },
   "source": [
    "### Generating Predicion Result for submission in .csv format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JGN24RYr7nJN"
   },
   "outputs": [],
   "source": [
    "df2 = pd.read_csv(url2)\n",
    "clf = LogisticRegression(C= 10, fit_intercept= True, max_iter= 1500, penalty= 'l1', solver= 'liblinear', tol= 0.1, warm_start= False)\n",
    "clf.fit(X, y)\n",
    "pred=clf.predict(X_test2)\n",
    "pd.DataFrame({\"PassengerId\": df2[\"PassengerId\"], \"Survived\": pred}).to_csv(\"log_reg_submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1ZFkJ7pp7oi_"
   },
   "source": [
    "The generated results csv file need to be copied and pasted to another csv file in order to make a successful submisison due to an unknown formatting issue."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hw-roPvL3ylU"
   },
   "source": [
    "###Kaggle Submisison Score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bKuZWFFM3GIJ"
   },
   "source": [
    "![alt text](https://raw.githubusercontent.com/zyzhang1130/CE9010/master/Titanic/logistic_regression.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uefZVRzR5iw0"
   },
   "source": [
    "## K-nearest Neighbors Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 520
    },
    "colab_type": "code",
    "id": "WfA5vNQI5hvl",
    "outputId": "5a56c159-2771-4739-d3a2-a75dd7af0830"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best parameters set found on development set:\n",
      "\n",
      "{'n_neighbors': 20, 'weights': 'uniform'}\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "0.709 (+/-0.149) for {'n_neighbors': 1, 'weights': 'uniform'}\n",
      "0.709 (+/-0.149) for {'n_neighbors': 1, 'weights': 'distance'}\n",
      "0.791 (+/-0.080) for {'n_neighbors': 10, 'weights': 'uniform'}\n",
      "0.758 (+/-0.098) for {'n_neighbors': 10, 'weights': 'distance'}\n",
      "0.799 (+/-0.106) for {'n_neighbors': 20, 'weights': 'uniform'}\n",
      "0.765 (+/-0.094) for {'n_neighbors': 20, 'weights': 'distance'}\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.85      0.88      0.86       114\n",
      "         1.0       0.77      0.72      0.74        64\n",
      "\n",
      "    accuracy                           0.82       178\n",
      "   macro avg       0.81      0.80      0.80       178\n",
      "weighted avg       0.82      0.82      0.82       178\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "tuned_parameters = [{'n_neighbors': [1, 10, 20],\n",
    "                     'weights': ['uniform', 'distance']}\n",
    "                    ]\n",
    "\n",
    "\n",
    "print()\n",
    "\n",
    "clf = GridSearchCV(\n",
    "    KNeighborsClassifier(), tuned_parameters, scoring='accuracy',cv=10\n",
    ")\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best parameters set found on development set:\")\n",
    "print()\n",
    "print(clf.best_params_)\n",
    "print()\n",
    "print(\"Grid scores on development set:\")\n",
    "print()\n",
    "means = clf.cv_results_['mean_test_score']\n",
    "stds = clf.cv_results_['std_test_score']\n",
    "for mean, std, params in zip(means, stds, clf.cv_results_['params']):\n",
    "    print(\"%0.3f (+/-%0.03f) for %r\"\n",
    "          % (mean, std * 2, params))\n",
    "print()\n",
    "\n",
    "print(\"Detailed classification report:\")\n",
    "print()\n",
    "print(\"The model is trained on the full development set.\")\n",
    "print(\"The scores are computed on the full evaluation set.\")\n",
    "print()\n",
    "y_true, y_pred = y_test, clf.predict(X_test)\n",
    "print(classification_report(y_true, y_pred))\n",
    "print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 589
    },
    "colab_type": "code",
    "id": "LCaz0cvb_4_3",
    "outputId": "1b9361f4-8852-41e0-d30c-4dc709ddb610"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best parameters set found on development set:\n",
      "\n",
      "{'n_neighbors': 12, 'weights': 'distance'}\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "0.759 (+/-0.098) for {'n_neighbors': 7, 'weights': 'distance'}\n",
      "0.763 (+/-0.104) for {'n_neighbors': 8, 'weights': 'distance'}\n",
      "0.767 (+/-0.104) for {'n_neighbors': 9, 'weights': 'distance'}\n",
      "0.758 (+/-0.098) for {'n_neighbors': 10, 'weights': 'distance'}\n",
      "0.764 (+/-0.103) for {'n_neighbors': 11, 'weights': 'distance'}\n",
      "0.767 (+/-0.101) for {'n_neighbors': 12, 'weights': 'distance'}\n",
      "0.761 (+/-0.089) for {'n_neighbors': 13, 'weights': 'distance'}\n",
      "0.763 (+/-0.101) for {'n_neighbors': 14, 'weights': 'distance'}\n",
      "0.764 (+/-0.097) for {'n_neighbors': 15, 'weights': 'distance'}\n",
      "0.764 (+/-0.093) for {'n_neighbors': 16, 'weights': 'distance'}\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.83      0.89      0.86       114\n",
      "         1.0       0.77      0.69      0.73        64\n",
      "\n",
      "    accuracy                           0.81       178\n",
      "   macro avg       0.80      0.79      0.79       178\n",
      "weighted avg       0.81      0.81      0.81       178\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "tuned_parameters = [{'n_neighbors': [7, 8, 9, 10, 11, 12, 13, 14, 15, 16],\n",
    "                     'weights': [ 'distance']}\n",
    "                    ]\n",
    "\n",
    "\n",
    "print()\n",
    "\n",
    "clf = GridSearchCV(\n",
    "    KNeighborsClassifier(), tuned_parameters, scoring='accuracy', cv=10\n",
    ")\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best parameters set found on development set:\")\n",
    "print()\n",
    "print(clf.best_params_)\n",
    "print()\n",
    "print(\"Grid scores on development set:\")\n",
    "print()\n",
    "means = clf.cv_results_['mean_test_score']\n",
    "stds = clf.cv_results_['std_test_score']\n",
    "for mean, std, params in zip(means, stds, clf.cv_results_['params']):\n",
    "    print(\"%0.3f (+/-%0.03f) for %r\"\n",
    "          % (mean, std * 2, params))\n",
    "print()\n",
    "\n",
    "print(\"Detailed classification report:\")\n",
    "print()\n",
    "print(\"The model is trained on the full development set.\")\n",
    "print(\"The scores are computed on the full evaluation set.\")\n",
    "print()\n",
    "y_true, y_pred = y_test, clf.predict(X_test)\n",
    "print(classification_report(y_true, y_pred))\n",
    "print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "S2Gy8Tnqfbd7"
   },
   "source": [
    "However, when we use this selected parameters, it did not produce a better result than when 'n_neighbors'=7. This is likely due to the fact that the training dataset size is rather limited and hence even cross-validation was applied, overfitting still occurred."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "a3KjeDsUTgVD"
   },
   "source": [
    "###Cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "sZFhpjKIRhHF",
    "outputId": "411d115d-01fd-4bc6-f34a-db8c7e5da56c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.774407\n"
     ]
    }
   ],
   "source": [
    "clf = KNeighborsClassifier(n_neighbors=7,weights='distance')\n",
    "score=cross_validate(clf, X, y, cv=10, scoring=\"accuracy\")[\"test_score\"].mean()\n",
    "print(f\"{score:.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xLlaxYE7McC6"
   },
   "source": [
    "### Generating Predicion Result for submission in .csv format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "niTqWzv8rEO3"
   },
   "outputs": [],
   "source": [
    "df2 = pd.read_csv(url2)\n",
    "clf = KNeighborsClassifier(n_neighbors=7,weights='distance')\n",
    "clf.fit(X, y)\n",
    "pred=clf.predict(X_test2)\n",
    "pd.DataFrame({\"PassengerId\": df2[\"PassengerId\"], \"Survived\": pred}).to_csv(\"knn_submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "taXxFO6w9IfZ"
   },
   "source": [
    "![alt text](https://raw.githubusercontent.com/zyzhang1130/CE9010/master/Titanic/knn.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Pol0BFqogOhr"
   },
   "source": [
    "## DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 641
    },
    "colab_type": "code",
    "id": "XdzlVQgEqXz2",
    "outputId": "31be2bd3-70b4-4957-e124-8aff273aefd1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best parameters set found on development set:\n",
      "\n",
      "{'max_depth': 7}\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "0.774 (+/-0.061) for {'max_depth': 4}\n",
      "0.803 (+/-0.087) for {'max_depth': 5}\n",
      "0.791 (+/-0.130) for {'max_depth': 6}\n",
      "0.805 (+/-0.114) for {'max_depth': 7}\n",
      "0.788 (+/-0.127) for {'max_depth': 8}\n",
      "0.791 (+/-0.111) for {'max_depth': 9}\n",
      "0.784 (+/-0.085) for {'max_depth': 10}\n",
      "0.795 (+/-0.103) for {'max_depth': 11}\n",
      "0.780 (+/-0.131) for {'max_depth': 12}\n",
      "0.782 (+/-0.121) for {'max_depth': 13}\n",
      "0.777 (+/-0.139) for {'max_depth': 14}\n",
      "0.773 (+/-0.112) for {'max_depth': 15}\n",
      "0.773 (+/-0.122) for {'max_depth': 16}\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.82      0.93      0.87       114\n",
      "         1.0       0.83      0.62      0.71        64\n",
      "\n",
      "    accuracy                           0.82       178\n",
      "   macro avg       0.82      0.78      0.79       178\n",
      "weighted avg       0.82      0.82      0.81       178\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "tuned_parameters = [{'max_depth': [4,5,6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16]}\n",
    "                    ]\n",
    "\n",
    "\n",
    "print()\n",
    "\n",
    "clf = GridSearchCV(\n",
    "    DecisionTreeClassifier(), tuned_parameters, scoring='accuracy', cv=10\n",
    ")\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best parameters set found on development set:\")\n",
    "print()\n",
    "print(clf.best_params_)\n",
    "print()\n",
    "print(\"Grid scores on development set:\")\n",
    "print()\n",
    "means = clf.cv_results_['mean_test_score']\n",
    "stds = clf.cv_results_['std_test_score']\n",
    "for mean, std, params in zip(means, stds, clf.cv_results_['params']):\n",
    "    print(\"%0.3f (+/-%0.03f) for %r\"\n",
    "          % (mean, std * 2, params))\n",
    "print()\n",
    "\n",
    "print(\"Detailed classification report:\")\n",
    "print()\n",
    "print(\"The model is trained on the full development set.\")\n",
    "print(\"The scores are computed on the full evaluation set.\")\n",
    "print()\n",
    "y_true, y_pred = y_test, clf.predict(X_test)\n",
    "print(classification_report(y_true, y_pred))\n",
    "print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "V8NSN6vITj05"
   },
   "source": [
    "###Cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "aVumKaLJRwMz",
    "outputId": "51292cfc-fbe8-4623-e8ea-cd1113b74105"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.794657\n"
     ]
    }
   ],
   "source": [
    "clf = DecisionTreeClassifier(max_depth=7)\n",
    "score=cross_validate(clf, X, y, cv=10, scoring=\"accuracy\")[\"test_score\"].mean()\n",
    "print(f\"{score:.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Uu-YBpJKMd-G"
   },
   "source": [
    "### Generating Predicion Result for submission in .csv format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "P7Nms3-NrRP_"
   },
   "outputs": [],
   "source": [
    "df2 = pd.read_csv(url2)\n",
    "clf = DecisionTreeClassifier(max_depth=7)\n",
    "clf.fit(X, y)\n",
    "pred=clf.predict(X_test2)\n",
    "pd.DataFrame({\"PassengerId\": df2[\"PassengerId\"], \"Survived\": pred}).to_csv(\"DecisionTree_submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wFUZiAwo4SSd"
   },
   "source": [
    "![alt text](https://raw.githubusercontent.com/zyzhang1130/CE9010/master/Titanic/DecisionTree.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SQbRksfjmHr1"
   },
   "source": [
    "## GaussianProcessClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 520
    },
    "colab_type": "code",
    "id": "Su4WWi9xmJPs",
    "outputId": "2699d75f-31d1-4db5-fdaf-e6c37b97406c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best parameters set found on development set:\n",
      "\n",
      "{'kernel': 1**2 * RBF(length_scale=0.8)}\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "0.794 (+/-0.078) for {'kernel': 1**2 * RBF(length_scale=0.8)}\n",
      "0.794 (+/-0.078) for {'kernel': 1**2 * RBF(length_scale=0.9)}\n",
      "0.794 (+/-0.078) for {'kernel': 1**2 * RBF(length_scale=1)}\n",
      "0.794 (+/-0.078) for {'kernel': 1**2 * RBF(length_scale=1.1)}\n",
      "0.794 (+/-0.078) for {'kernel': 1**2 * RBF(length_scale=1.2)}\n",
      "0.794 (+/-0.078) for {'kernel': 1**2 * RBF(length_scale=1.3)}\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.86      0.89      0.88       114\n",
      "         1.0       0.80      0.73      0.76        64\n",
      "\n",
      "    accuracy                           0.84       178\n",
      "   macro avg       0.83      0.81      0.82       178\n",
      "weighted avg       0.84      0.84      0.84       178\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "tuned_parameters = [{'kernel':[1.0 * RBF(0.8),1.0 * RBF(0.9),1.0 * RBF(1.0),1.0 * RBF(1.1),1.0 * RBF(1.2),1.0 * RBF(1.3)]}\n",
    "                    ]\n",
    "\n",
    "\n",
    "print()\n",
    "\n",
    "clf = GridSearchCV(\n",
    "    GaussianProcessClassifier(), tuned_parameters, scoring='accuracy', cv=10\n",
    ")\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best parameters set found on development set:\")\n",
    "print()\n",
    "print(clf.best_params_)\n",
    "print()\n",
    "print(\"Grid scores on development set:\")\n",
    "print()\n",
    "means = clf.cv_results_['mean_test_score']\n",
    "stds = clf.cv_results_['std_test_score']\n",
    "for mean, std, params in zip(means, stds, clf.cv_results_['params']):\n",
    "    print(\"%0.3f (+/-%0.03f) for %r\"\n",
    "          % (mean, std * 2, params))\n",
    "print()\n",
    "\n",
    "print(\"Detailed classification report:\")\n",
    "print()\n",
    "print(\"The model is trained on the full development set.\")\n",
    "print(\"The scores are computed on the full evaluation set.\")\n",
    "print()\n",
    "y_true, y_pred = y_test, clf.predict(X_test)\n",
    "print(classification_report(y_true, y_pred))\n",
    "print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BoScu4AUTlrt"
   },
   "source": [
    "###Cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "KdQJzZfzSDAY",
    "outputId": "4466d679-0b36-4a37-db52-550fcd3dff31"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.815943\n"
     ]
    }
   ],
   "source": [
    "clf = GaussianProcessClassifier(1**2 * RBF(length_scale=0.8))\n",
    "score=cross_validate(clf, X, y, cv=10, scoring=\"accuracy\")[\"test_score\"].mean()\n",
    "print(f\"{score:.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1Ga4dOPoMfsl"
   },
   "source": [
    "### Generating Predicion Result for submission in .csv format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "72RgBwcOrfS3"
   },
   "outputs": [],
   "source": [
    "df2 = pd.read_csv(url2)\n",
    "clf = GaussianProcessClassifier(1**2 * RBF(length_scale=0.8))\n",
    "clf.fit(X, y)\n",
    "pred=clf.predict(X_test2)\n",
    "pd.DataFrame({\"PassengerId\": df2[\"PassengerId\"], \"Survived\": pred}).to_csv(\"GaussianProcess_submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XYKCujeq-_MM"
   },
   "source": [
    "![alt text](https://raw.githubusercontent.com/zyzhang1130/CE9010/master/Titanic/GaussianProcess.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3vfJ-NUNtXHd"
   },
   "source": [
    "## BaggingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 971
    },
    "colab_type": "code",
    "id": "V2DMamqHnZa7",
    "outputId": "49b673a3-e3cb-4521-ee44-651b38bd19e4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best parameters set found on development set:\n",
      "\n",
      "{'bootstrap': True, 'bootstrap_features': True, 'n_estimators': 10, 'warm_start': False}\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "0.787 (+/-0.098) for {'bootstrap': True, 'bootstrap_features': True, 'n_estimators': 8, 'warm_start': False}\n",
      "0.778 (+/-0.114) for {'bootstrap': True, 'bootstrap_features': True, 'n_estimators': 9, 'warm_start': False}\n",
      "0.808 (+/-0.097) for {'bootstrap': True, 'bootstrap_features': True, 'n_estimators': 10, 'warm_start': False}\n",
      "0.788 (+/-0.130) for {'bootstrap': True, 'bootstrap_features': True, 'n_estimators': 11, 'warm_start': False}\n",
      "0.785 (+/-0.105) for {'bootstrap': True, 'bootstrap_features': True, 'n_estimators': 12, 'warm_start': False}\n",
      "0.785 (+/-0.101) for {'bootstrap': True, 'bootstrap_features': True, 'n_estimators': 13, 'warm_start': False}\n",
      "0.792 (+/-0.084) for {'bootstrap': True, 'bootstrap_features': True, 'n_estimators': 14, 'warm_start': False}\n",
      "0.795 (+/-0.119) for {'bootstrap': True, 'bootstrap_features': True, 'n_estimators': 15, 'warm_start': False}\n",
      "0.792 (+/-0.099) for {'bootstrap': True, 'bootstrap_features': False, 'n_estimators': 8, 'warm_start': False}\n",
      "0.781 (+/-0.125) for {'bootstrap': True, 'bootstrap_features': False, 'n_estimators': 9, 'warm_start': False}\n",
      "0.805 (+/-0.104) for {'bootstrap': True, 'bootstrap_features': False, 'n_estimators': 10, 'warm_start': False}\n",
      "0.784 (+/-0.119) for {'bootstrap': True, 'bootstrap_features': False, 'n_estimators': 11, 'warm_start': False}\n",
      "0.789 (+/-0.097) for {'bootstrap': True, 'bootstrap_features': False, 'n_estimators': 12, 'warm_start': False}\n",
      "0.795 (+/-0.105) for {'bootstrap': True, 'bootstrap_features': False, 'n_estimators': 13, 'warm_start': False}\n",
      "0.782 (+/-0.125) for {'bootstrap': True, 'bootstrap_features': False, 'n_estimators': 14, 'warm_start': False}\n",
      "0.791 (+/-0.125) for {'bootstrap': True, 'bootstrap_features': False, 'n_estimators': 15, 'warm_start': False}\n",
      "0.780 (+/-0.122) for {'bootstrap': False, 'bootstrap_features': True, 'n_estimators': 8, 'warm_start': False}\n",
      "0.771 (+/-0.112) for {'bootstrap': False, 'bootstrap_features': True, 'n_estimators': 9, 'warm_start': False}\n",
      "0.777 (+/-0.134) for {'bootstrap': False, 'bootstrap_features': True, 'n_estimators': 10, 'warm_start': False}\n",
      "0.788 (+/-0.128) for {'bootstrap': False, 'bootstrap_features': True, 'n_estimators': 11, 'warm_start': False}\n",
      "0.775 (+/-0.127) for {'bootstrap': False, 'bootstrap_features': True, 'n_estimators': 12, 'warm_start': False}\n",
      "0.772 (+/-0.139) for {'bootstrap': False, 'bootstrap_features': True, 'n_estimators': 13, 'warm_start': False}\n",
      "0.782 (+/-0.127) for {'bootstrap': False, 'bootstrap_features': True, 'n_estimators': 14, 'warm_start': False}\n",
      "0.796 (+/-0.114) for {'bootstrap': False, 'bootstrap_features': True, 'n_estimators': 15, 'warm_start': False}\n",
      "0.775 (+/-0.138) for {'bootstrap': False, 'bootstrap_features': False, 'n_estimators': 8, 'warm_start': False}\n",
      "0.765 (+/-0.131) for {'bootstrap': False, 'bootstrap_features': False, 'n_estimators': 9, 'warm_start': False}\n",
      "0.770 (+/-0.133) for {'bootstrap': False, 'bootstrap_features': False, 'n_estimators': 10, 'warm_start': False}\n",
      "0.775 (+/-0.130) for {'bootstrap': False, 'bootstrap_features': False, 'n_estimators': 11, 'warm_start': False}\n",
      "0.768 (+/-0.116) for {'bootstrap': False, 'bootstrap_features': False, 'n_estimators': 12, 'warm_start': False}\n",
      "0.768 (+/-0.127) for {'bootstrap': False, 'bootstrap_features': False, 'n_estimators': 13, 'warm_start': False}\n",
      "0.771 (+/-0.132) for {'bootstrap': False, 'bootstrap_features': False, 'n_estimators': 14, 'warm_start': False}\n",
      "0.765 (+/-0.129) for {'bootstrap': False, 'bootstrap_features': False, 'n_estimators': 15, 'warm_start': False}\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.76      0.93      0.84       114\n",
      "         1.0       0.79      0.48      0.60        64\n",
      "\n",
      "    accuracy                           0.77       178\n",
      "   macro avg       0.78      0.71      0.72       178\n",
      "weighted avg       0.77      0.77      0.75       178\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "tuned_parameters = [{ 'n_estimators':[8,9,10,11,12,13,14,15],'warm_start':[ False],'bootstrap':[True, False],'bootstrap_features':[True, False]}\n",
    "                    ]\n",
    "\n",
    "\n",
    "print()\n",
    "\n",
    "clf = GridSearchCV(\n",
    "    BaggingClassifier(), tuned_parameters, scoring='accuracy', cv=10\n",
    ")\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best parameters set found on development set:\")\n",
    "print()\n",
    "print(clf.best_params_)\n",
    "print()\n",
    "print(\"Grid scores on development set:\")\n",
    "print()\n",
    "means = clf.cv_results_['mean_test_score']\n",
    "stds = clf.cv_results_['std_test_score']\n",
    "for mean, std, params in zip(means, stds, clf.cv_results_['params']):\n",
    "    print(\"%0.3f (+/-%0.03f) for %r\"\n",
    "          % (mean, std * 2, params))\n",
    "print()\n",
    "\n",
    "print(\"Detailed classification report:\")\n",
    "print()\n",
    "print(\"The model is trained on the full development set.\")\n",
    "print(\"The scores are computed on the full evaluation set.\")\n",
    "print()\n",
    "y_true, y_pred = y_test, clf.predict(X_test)\n",
    "print(classification_report(y_true, y_pred))\n",
    "print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DSRD6nEsTpc4"
   },
   "source": [
    "###Cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "mfw7Na19STo4",
    "outputId": "1442ed15-c04e-4b7c-ed0b-e8c09c80164f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.792409\n"
     ]
    }
   ],
   "source": [
    "clf = BaggingClassifier(bootstrap= True, bootstrap_features= True, n_estimators= 10, warm_start= False)\n",
    "score=cross_validate(clf, X, y, cv=10, scoring=\"accuracy\")[\"test_score\"].mean()\n",
    "print(f\"{score:.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UAgozb_kMh0q"
   },
   "source": [
    "### Generating Predicion Result for submission in .csv format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZWkOTvYarzua"
   },
   "outputs": [],
   "source": [
    "df2 = pd.read_csv(url2)\n",
    "clf = BaggingClassifier(bootstrap= True, bootstrap_features= True, n_estimators= 10, warm_start= False)\n",
    "clf.fit(X, y)\n",
    "pred=clf.predict(X_test2)\n",
    "pd.DataFrame({\"PassengerId\": df2[\"PassengerId\"], \"Survived\": pred}).to_csv(\"Bagging_submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "c6ObMls2yae5"
   },
   "source": [
    "![alt text](https://raw.githubusercontent.com/zyzhang1130/CE9010/master/Titanic/bagging.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "aal4SmKxICmE"
   },
   "source": [
    "## MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "jtRR1NEswjXV",
    "outputId": "6d7a9b07-5389-4ddc-cff6-923f1d0948bb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best parameters set found on development set:\n",
      "\n",
      "{'alpha': 0.01, 'early_stopping': False, 'max_iter': 2000, 'solver': 'adam'}\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "0.791 (+/-0.091) for {'alpha': 0.0001, 'early_stopping': True, 'max_iter': 1000, 'solver': 'adam'}\n",
      "0.777 (+/-0.090) for {'alpha': 0.0001, 'early_stopping': True, 'max_iter': 1500, 'solver': 'adam'}\n",
      "0.767 (+/-0.089) for {'alpha': 0.0001, 'early_stopping': True, 'max_iter': 2000, 'solver': 'adam'}\n",
      "0.805 (+/-0.080) for {'alpha': 0.0001, 'early_stopping': False, 'max_iter': 1000, 'solver': 'adam'}\n",
      "0.796 (+/-0.090) for {'alpha': 0.0001, 'early_stopping': False, 'max_iter': 1500, 'solver': 'adam'}\n",
      "0.798 (+/-0.095) for {'alpha': 0.0001, 'early_stopping': False, 'max_iter': 2000, 'solver': 'adam'}\n",
      "0.774 (+/-0.089) for {'alpha': 0.001, 'early_stopping': True, 'max_iter': 1000, 'solver': 'adam'}\n",
      "0.770 (+/-0.087) for {'alpha': 0.001, 'early_stopping': True, 'max_iter': 1500, 'solver': 'adam'}\n",
      "0.787 (+/-0.115) for {'alpha': 0.001, 'early_stopping': True, 'max_iter': 2000, 'solver': 'adam'}\n",
      "0.808 (+/-0.091) for {'alpha': 0.001, 'early_stopping': False, 'max_iter': 1000, 'solver': 'adam'}\n",
      "0.802 (+/-0.089) for {'alpha': 0.001, 'early_stopping': False, 'max_iter': 1500, 'solver': 'adam'}\n",
      "0.796 (+/-0.082) for {'alpha': 0.001, 'early_stopping': False, 'max_iter': 2000, 'solver': 'adam'}\n",
      "0.759 (+/-0.115) for {'alpha': 0.01, 'early_stopping': True, 'max_iter': 1000, 'solver': 'adam'}\n",
      "0.778 (+/-0.113) for {'alpha': 0.01, 'early_stopping': True, 'max_iter': 1500, 'solver': 'adam'}\n",
      "0.774 (+/-0.100) for {'alpha': 0.01, 'early_stopping': True, 'max_iter': 2000, 'solver': 'adam'}\n",
      "0.802 (+/-0.078) for {'alpha': 0.01, 'early_stopping': False, 'max_iter': 1000, 'solver': 'adam'}\n",
      "0.802 (+/-0.092) for {'alpha': 0.01, 'early_stopping': False, 'max_iter': 1500, 'solver': 'adam'}\n",
      "0.812 (+/-0.083) for {'alpha': 0.01, 'early_stopping': False, 'max_iter': 2000, 'solver': 'adam'}\n",
      "0.765 (+/-0.099) for {'alpha': 0.1, 'early_stopping': True, 'max_iter': 1000, 'solver': 'adam'}\n",
      "0.782 (+/-0.083) for {'alpha': 0.1, 'early_stopping': True, 'max_iter': 1500, 'solver': 'adam'}\n",
      "0.763 (+/-0.075) for {'alpha': 0.1, 'early_stopping': True, 'max_iter': 2000, 'solver': 'adam'}\n",
      "0.810 (+/-0.085) for {'alpha': 0.1, 'early_stopping': False, 'max_iter': 1000, 'solver': 'adam'}\n",
      "0.803 (+/-0.083) for {'alpha': 0.1, 'early_stopping': False, 'max_iter': 1500, 'solver': 'adam'}\n",
      "0.803 (+/-0.092) for {'alpha': 0.1, 'early_stopping': False, 'max_iter': 2000, 'solver': 'adam'}\n",
      "0.777 (+/-0.122) for {'alpha': 1, 'early_stopping': True, 'max_iter': 1000, 'solver': 'adam'}\n",
      "0.756 (+/-0.093) for {'alpha': 1, 'early_stopping': True, 'max_iter': 1500, 'solver': 'adam'}\n",
      "0.778 (+/-0.066) for {'alpha': 1, 'early_stopping': True, 'max_iter': 2000, 'solver': 'adam'}\n",
      "0.798 (+/-0.075) for {'alpha': 1, 'early_stopping': False, 'max_iter': 1000, 'solver': 'adam'}\n",
      "0.795 (+/-0.074) for {'alpha': 1, 'early_stopping': False, 'max_iter': 1500, 'solver': 'adam'}\n",
      "0.796 (+/-0.080) for {'alpha': 1, 'early_stopping': False, 'max_iter': 2000, 'solver': 'adam'}\n",
      "0.600 (+/-0.133) for {'alpha': 0.0001, 'early_stopping': True, 'learning_rate': 'constant', 'max_iter': 1000, 'momentum': 0.1, 'solver': 'sgd'}\n",
      "0.524 (+/-0.269) for {'alpha': 0.0001, 'early_stopping': True, 'learning_rate': 'constant', 'max_iter': 1000, 'momentum': 0.3, 'solver': 'sgd'}\n",
      "0.585 (+/-0.221) for {'alpha': 0.0001, 'early_stopping': True, 'learning_rate': 'constant', 'max_iter': 1000, 'momentum': 0.5, 'solver': 'sgd'}\n",
      "0.673 (+/-0.086) for {'alpha': 0.0001, 'early_stopping': True, 'learning_rate': 'constant', 'max_iter': 1000, 'momentum': 0.7, 'solver': 'sgd'}\n",
      "0.735 (+/-0.078) for {'alpha': 0.0001, 'early_stopping': True, 'learning_rate': 'constant', 'max_iter': 1000, 'momentum': 0.9, 'solver': 'sgd'}\n",
      "0.547 (+/-0.256) for {'alpha': 0.0001, 'early_stopping': True, 'learning_rate': 'constant', 'max_iter': 1500, 'momentum': 0.1, 'solver': 'sgd'}\n",
      "0.580 (+/-0.188) for {'alpha': 0.0001, 'early_stopping': True, 'learning_rate': 'constant', 'max_iter': 1500, 'momentum': 0.3, 'solver': 'sgd'}\n",
      "0.573 (+/-0.226) for {'alpha': 0.0001, 'early_stopping': True, 'learning_rate': 'constant', 'max_iter': 1500, 'momentum': 0.5, 'solver': 'sgd'}\n",
      "0.590 (+/-0.241) for {'alpha': 0.0001, 'early_stopping': True, 'learning_rate': 'constant', 'max_iter': 1500, 'momentum': 0.7, 'solver': 'sgd'}\n",
      "0.694 (+/-0.217) for {'alpha': 0.0001, 'early_stopping': True, 'learning_rate': 'constant', 'max_iter': 1500, 'momentum': 0.9, 'solver': 'sgd'}\n",
      "0.535 (+/-0.307) for {'alpha': 0.0001, 'early_stopping': True, 'learning_rate': 'constant', 'max_iter': 2000, 'momentum': 0.1, 'solver': 'sgd'}\n",
      "0.593 (+/-0.212) for {'alpha': 0.0001, 'early_stopping': True, 'learning_rate': 'constant', 'max_iter': 2000, 'momentum': 0.3, 'solver': 'sgd'}\n",
      "0.497 (+/-0.216) for {'alpha': 0.0001, 'early_stopping': True, 'learning_rate': 'constant', 'max_iter': 2000, 'momentum': 0.5, 'solver': 'sgd'}\n",
      "0.606 (+/-0.237) for {'alpha': 0.0001, 'early_stopping': True, 'learning_rate': 'constant', 'max_iter': 2000, 'momentum': 0.7, 'solver': 'sgd'}\n",
      "0.701 (+/-0.126) for {'alpha': 0.0001, 'early_stopping': True, 'learning_rate': 'constant', 'max_iter': 2000, 'momentum': 0.9, 'solver': 'sgd'}\n",
      "0.469 (+/-0.197) for {'alpha': 0.0001, 'early_stopping': True, 'learning_rate': 'invscaling', 'max_iter': 1000, 'momentum': 0.1, 'solver': 'sgd'}\n",
      "0.463 (+/-0.160) for {'alpha': 0.0001, 'early_stopping': True, 'learning_rate': 'invscaling', 'max_iter': 1000, 'momentum': 0.3, 'solver': 'sgd'}\n",
      "0.486 (+/-0.223) for {'alpha': 0.0001, 'early_stopping': True, 'learning_rate': 'invscaling', 'max_iter': 1000, 'momentum': 0.5, 'solver': 'sgd'}\n",
      "0.573 (+/-0.218) for {'alpha': 0.0001, 'early_stopping': True, 'learning_rate': 'invscaling', 'max_iter': 1000, 'momentum': 0.7, 'solver': 'sgd'}\n",
      "0.483 (+/-0.200) for {'alpha': 0.0001, 'early_stopping': True, 'learning_rate': 'invscaling', 'max_iter': 1000, 'momentum': 0.9, 'solver': 'sgd'}\n",
      "0.525 (+/-0.256) for {'alpha': 0.0001, 'early_stopping': True, 'learning_rate': 'invscaling', 'max_iter': 1500, 'momentum': 0.1, 'solver': 'sgd'}\n",
      "0.497 (+/-0.297) for {'alpha': 0.0001, 'early_stopping': True, 'learning_rate': 'invscaling', 'max_iter': 1500, 'momentum': 0.3, 'solver': 'sgd'}\n",
      "0.531 (+/-0.285) for {'alpha': 0.0001, 'early_stopping': True, 'learning_rate': 'invscaling', 'max_iter': 1500, 'momentum': 0.5, 'solver': 'sgd'}\n",
      "0.476 (+/-0.225) for {'alpha': 0.0001, 'early_stopping': True, 'learning_rate': 'invscaling', 'max_iter': 1500, 'momentum': 0.7, 'solver': 'sgd'}\n",
      "0.546 (+/-0.255) for {'alpha': 0.0001, 'early_stopping': True, 'learning_rate': 'invscaling', 'max_iter': 1500, 'momentum': 0.9, 'solver': 'sgd'}\n",
      "0.506 (+/-0.260) for {'alpha': 0.0001, 'early_stopping': True, 'learning_rate': 'invscaling', 'max_iter': 2000, 'momentum': 0.1, 'solver': 'sgd'}\n",
      "0.497 (+/-0.296) for {'alpha': 0.0001, 'early_stopping': True, 'learning_rate': 'invscaling', 'max_iter': 2000, 'momentum': 0.3, 'solver': 'sgd'}\n",
      "0.516 (+/-0.225) for {'alpha': 0.0001, 'early_stopping': True, 'learning_rate': 'invscaling', 'max_iter': 2000, 'momentum': 0.5, 'solver': 'sgd'}\n",
      "0.489 (+/-0.179) for {'alpha': 0.0001, 'early_stopping': True, 'learning_rate': 'invscaling', 'max_iter': 2000, 'momentum': 0.7, 'solver': 'sgd'}\n",
      "0.518 (+/-0.217) for {'alpha': 0.0001, 'early_stopping': True, 'learning_rate': 'invscaling', 'max_iter': 2000, 'momentum': 0.9, 'solver': 'sgd'}\n",
      "0.598 (+/-0.187) for {'alpha': 0.0001, 'early_stopping': True, 'learning_rate': 'adaptive', 'max_iter': 1000, 'momentum': 0.1, 'solver': 'sgd'}\n",
      "0.548 (+/-0.273) for {'alpha': 0.0001, 'early_stopping': True, 'learning_rate': 'adaptive', 'max_iter': 1000, 'momentum': 0.3, 'solver': 'sgd'}\n",
      "0.605 (+/-0.147) for {'alpha': 0.0001, 'early_stopping': True, 'learning_rate': 'adaptive', 'max_iter': 1000, 'momentum': 0.5, 'solver': 'sgd'}\n",
      "0.565 (+/-0.231) for {'alpha': 0.0001, 'early_stopping': True, 'learning_rate': 'adaptive', 'max_iter': 1000, 'momentum': 0.7, 'solver': 'sgd'}\n",
      "0.716 (+/-0.138) for {'alpha': 0.0001, 'early_stopping': True, 'learning_rate': 'adaptive', 'max_iter': 1000, 'momentum': 0.9, 'solver': 'sgd'}\n",
      "0.521 (+/-0.261) for {'alpha': 0.0001, 'early_stopping': True, 'learning_rate': 'adaptive', 'max_iter': 1500, 'momentum': 0.1, 'solver': 'sgd'}\n",
      "0.524 (+/-0.316) for {'alpha': 0.0001, 'early_stopping': True, 'learning_rate': 'adaptive', 'max_iter': 1500, 'momentum': 0.3, 'solver': 'sgd'}\n",
      "0.599 (+/-0.255) for {'alpha': 0.0001, 'early_stopping': True, 'learning_rate': 'adaptive', 'max_iter': 1500, 'momentum': 0.5, 'solver': 'sgd'}\n",
      "0.566 (+/-0.258) for {'alpha': 0.0001, 'early_stopping': True, 'learning_rate': 'adaptive', 'max_iter': 1500, 'momentum': 0.7, 'solver': 'sgd'}\n",
      "0.739 (+/-0.089) for {'alpha': 0.0001, 'early_stopping': True, 'learning_rate': 'adaptive', 'max_iter': 1500, 'momentum': 0.9, 'solver': 'sgd'}\n",
      "0.573 (+/-0.283) for {'alpha': 0.0001, 'early_stopping': True, 'learning_rate': 'adaptive', 'max_iter': 2000, 'momentum': 0.1, 'solver': 'sgd'}\n",
      "0.532 (+/-0.130) for {'alpha': 0.0001, 'early_stopping': True, 'learning_rate': 'adaptive', 'max_iter': 2000, 'momentum': 0.3, 'solver': 'sgd'}\n",
      "0.607 (+/-0.228) for {'alpha': 0.0001, 'early_stopping': True, 'learning_rate': 'adaptive', 'max_iter': 2000, 'momentum': 0.5, 'solver': 'sgd'}\n",
      "0.606 (+/-0.198) for {'alpha': 0.0001, 'early_stopping': True, 'learning_rate': 'adaptive', 'max_iter': 2000, 'momentum': 0.7, 'solver': 'sgd'}\n",
      "0.723 (+/-0.164) for {'alpha': 0.0001, 'early_stopping': True, 'learning_rate': 'adaptive', 'max_iter': 2000, 'momentum': 0.9, 'solver': 'sgd'}\n",
      "0.791 (+/-0.074) for {'alpha': 0.0001, 'early_stopping': False, 'learning_rate': 'constant', 'max_iter': 1000, 'momentum': 0.1, 'solver': 'sgd'}\n",
      "0.777 (+/-0.074) for {'alpha': 0.0001, 'early_stopping': False, 'learning_rate': 'constant', 'max_iter': 1000, 'momentum': 0.3, 'solver': 'sgd'}\n",
      "0.781 (+/-0.076) for {'alpha': 0.0001, 'early_stopping': False, 'learning_rate': 'constant', 'max_iter': 1000, 'momentum': 0.5, 'solver': 'sgd'}\n",
      "0.789 (+/-0.084) for {'alpha': 0.0001, 'early_stopping': False, 'learning_rate': 'constant', 'max_iter': 1000, 'momentum': 0.7, 'solver': 'sgd'}\n",
      "0.787 (+/-0.083) for {'alpha': 0.0001, 'early_stopping': False, 'learning_rate': 'constant', 'max_iter': 1000, 'momentum': 0.9, 'solver': 'sgd'}\n",
      "0.778 (+/-0.077) for {'alpha': 0.0001, 'early_stopping': False, 'learning_rate': 'constant', 'max_iter': 1500, 'momentum': 0.1, 'solver': 'sgd'}\n",
      "0.778 (+/-0.093) for {'alpha': 0.0001, 'early_stopping': False, 'learning_rate': 'constant', 'max_iter': 1500, 'momentum': 0.3, 'solver': 'sgd'}\n",
      "0.778 (+/-0.084) for {'alpha': 0.0001, 'early_stopping': False, 'learning_rate': 'constant', 'max_iter': 1500, 'momentum': 0.5, 'solver': 'sgd'}\n",
      "0.787 (+/-0.088) for {'alpha': 0.0001, 'early_stopping': False, 'learning_rate': 'constant', 'max_iter': 1500, 'momentum': 0.7, 'solver': 'sgd'}\n",
      "0.791 (+/-0.077) for {'alpha': 0.0001, 'early_stopping': False, 'learning_rate': 'constant', 'max_iter': 1500, 'momentum': 0.9, 'solver': 'sgd'}\n",
      "0.780 (+/-0.088) for {'alpha': 0.0001, 'early_stopping': False, 'learning_rate': 'constant', 'max_iter': 2000, 'momentum': 0.1, 'solver': 'sgd'}\n",
      "0.781 (+/-0.092) for {'alpha': 0.0001, 'early_stopping': False, 'learning_rate': 'constant', 'max_iter': 2000, 'momentum': 0.3, 'solver': 'sgd'}\n",
      "0.777 (+/-0.071) for {'alpha': 0.0001, 'early_stopping': False, 'learning_rate': 'constant', 'max_iter': 2000, 'momentum': 0.5, 'solver': 'sgd'}\n",
      "0.785 (+/-0.074) for {'alpha': 0.0001, 'early_stopping': False, 'learning_rate': 'constant', 'max_iter': 2000, 'momentum': 0.7, 'solver': 'sgd'}\n",
      "0.788 (+/-0.084) for {'alpha': 0.0001, 'early_stopping': False, 'learning_rate': 'constant', 'max_iter': 2000, 'momentum': 0.9, 'solver': 'sgd'}\n",
      "0.548 (+/-0.275) for {'alpha': 0.0001, 'early_stopping': False, 'learning_rate': 'invscaling', 'max_iter': 1000, 'momentum': 0.1, 'solver': 'sgd'}\n",
      "0.427 (+/-0.232) for {'alpha': 0.0001, 'early_stopping': False, 'learning_rate': 'invscaling', 'max_iter': 1000, 'momentum': 0.3, 'solver': 'sgd'}\n",
      "0.510 (+/-0.213) for {'alpha': 0.0001, 'early_stopping': False, 'learning_rate': 'invscaling', 'max_iter': 1000, 'momentum': 0.5, 'solver': 'sgd'}\n",
      "0.584 (+/-0.195) for {'alpha': 0.0001, 'early_stopping': False, 'learning_rate': 'invscaling', 'max_iter': 1000, 'momentum': 0.7, 'solver': 'sgd'}\n",
      "0.475 (+/-0.253) for {'alpha': 0.0001, 'early_stopping': False, 'learning_rate': 'invscaling', 'max_iter': 1000, 'momentum': 0.9, 'solver': 'sgd'}\n",
      "0.569 (+/-0.270) for {'alpha': 0.0001, 'early_stopping': False, 'learning_rate': 'invscaling', 'max_iter': 1500, 'momentum': 0.1, 'solver': 'sgd'}\n",
      "0.431 (+/-0.213) for {'alpha': 0.0001, 'early_stopping': False, 'learning_rate': 'invscaling', 'max_iter': 1500, 'momentum': 0.3, 'solver': 'sgd'}\n",
      "0.489 (+/-0.241) for {'alpha': 0.0001, 'early_stopping': False, 'learning_rate': 'invscaling', 'max_iter': 1500, 'momentum': 0.5, 'solver': 'sgd'}\n",
      "0.520 (+/-0.248) for {'alpha': 0.0001, 'early_stopping': False, 'learning_rate': 'invscaling', 'max_iter': 1500, 'momentum': 0.7, 'solver': 'sgd'}\n",
      "0.523 (+/-0.272) for {'alpha': 0.0001, 'early_stopping': False, 'learning_rate': 'invscaling', 'max_iter': 1500, 'momentum': 0.9, 'solver': 'sgd'}\n",
      "0.457 (+/-0.224) for {'alpha': 0.0001, 'early_stopping': False, 'learning_rate': 'invscaling', 'max_iter': 2000, 'momentum': 0.1, 'solver': 'sgd'}\n",
      "0.460 (+/-0.296) for {'alpha': 0.0001, 'early_stopping': False, 'learning_rate': 'invscaling', 'max_iter': 2000, 'momentum': 0.3, 'solver': 'sgd'}\n",
      "0.503 (+/-0.277) for {'alpha': 0.0001, 'early_stopping': False, 'learning_rate': 'invscaling', 'max_iter': 2000, 'momentum': 0.5, 'solver': 'sgd'}\n",
      "0.601 (+/-0.187) for {'alpha': 0.0001, 'early_stopping': False, 'learning_rate': 'invscaling', 'max_iter': 2000, 'momentum': 0.7, 'solver': 'sgd'}\n",
      "0.534 (+/-0.249) for {'alpha': 0.0001, 'early_stopping': False, 'learning_rate': 'invscaling', 'max_iter': 2000, 'momentum': 0.9, 'solver': 'sgd'}\n",
      "0.785 (+/-0.106) for {'alpha': 0.0001, 'early_stopping': False, 'learning_rate': 'adaptive', 'max_iter': 1000, 'momentum': 0.1, 'solver': 'sgd'}\n",
      "0.781 (+/-0.066) for {'alpha': 0.0001, 'early_stopping': False, 'learning_rate': 'adaptive', 'max_iter': 1000, 'momentum': 0.3, 'solver': 'sgd'}\n",
      "0.791 (+/-0.083) for {'alpha': 0.0001, 'early_stopping': False, 'learning_rate': 'adaptive', 'max_iter': 1000, 'momentum': 0.5, 'solver': 'sgd'}\n",
      "0.781 (+/-0.070) for {'alpha': 0.0001, 'early_stopping': False, 'learning_rate': 'adaptive', 'max_iter': 1000, 'momentum': 0.7, 'solver': 'sgd'}\n",
      "0.789 (+/-0.079) for {'alpha': 0.0001, 'early_stopping': False, 'learning_rate': 'adaptive', 'max_iter': 1000, 'momentum': 0.9, 'solver': 'sgd'}\n",
      "0.782 (+/-0.081) for {'alpha': 0.0001, 'early_stopping': False, 'learning_rate': 'adaptive', 'max_iter': 1500, 'momentum': 0.1, 'solver': 'sgd'}\n",
      "0.774 (+/-0.076) for {'alpha': 0.0001, 'early_stopping': False, 'learning_rate': 'adaptive', 'max_iter': 1500, 'momentum': 0.3, 'solver': 'sgd'}\n",
      "0.794 (+/-0.084) for {'alpha': 0.0001, 'early_stopping': False, 'learning_rate': 'adaptive', 'max_iter': 1500, 'momentum': 0.5, 'solver': 'sgd'}\n",
      "0.782 (+/-0.090) for {'alpha': 0.0001, 'early_stopping': False, 'learning_rate': 'adaptive', 'max_iter': 1500, 'momentum': 0.7, 'solver': 'sgd'}\n",
      "0.792 (+/-0.075) for {'alpha': 0.0001, 'early_stopping': False, 'learning_rate': 'adaptive', 'max_iter': 1500, 'momentum': 0.9, 'solver': 'sgd'}\n",
      "0.785 (+/-0.099) for {'alpha': 0.0001, 'early_stopping': False, 'learning_rate': 'adaptive', 'max_iter': 2000, 'momentum': 0.1, 'solver': 'sgd'}\n",
      "0.780 (+/-0.080) for {'alpha': 0.0001, 'early_stopping': False, 'learning_rate': 'adaptive', 'max_iter': 2000, 'momentum': 0.3, 'solver': 'sgd'}\n",
      "0.775 (+/-0.067) for {'alpha': 0.0001, 'early_stopping': False, 'learning_rate': 'adaptive', 'max_iter': 2000, 'momentum': 0.5, 'solver': 'sgd'}\n",
      "0.781 (+/-0.070) for {'alpha': 0.0001, 'early_stopping': False, 'learning_rate': 'adaptive', 'max_iter': 2000, 'momentum': 0.7, 'solver': 'sgd'}\n",
      "0.784 (+/-0.080) for {'alpha': 0.0001, 'early_stopping': False, 'learning_rate': 'adaptive', 'max_iter': 2000, 'momentum': 0.9, 'solver': 'sgd'}\n",
      "0.525 (+/-0.239) for {'alpha': 0.001, 'early_stopping': True, 'learning_rate': 'constant', 'max_iter': 1000, 'momentum': 0.1, 'solver': 'sgd'}\n",
      "0.500 (+/-0.195) for {'alpha': 0.001, 'early_stopping': True, 'learning_rate': 'constant', 'max_iter': 1000, 'momentum': 0.3, 'solver': 'sgd'}\n",
      "0.521 (+/-0.318) for {'alpha': 0.001, 'early_stopping': True, 'learning_rate': 'constant', 'max_iter': 1000, 'momentum': 0.5, 'solver': 'sgd'}\n",
      "0.587 (+/-0.228) for {'alpha': 0.001, 'early_stopping': True, 'learning_rate': 'constant', 'max_iter': 1000, 'momentum': 0.7, 'solver': 'sgd'}\n",
      "0.646 (+/-0.297) for {'alpha': 0.001, 'early_stopping': True, 'learning_rate': 'constant', 'max_iter': 1000, 'momentum': 0.9, 'solver': 'sgd'}\n",
      "0.590 (+/-0.276) for {'alpha': 0.001, 'early_stopping': True, 'learning_rate': 'constant', 'max_iter': 1500, 'momentum': 0.1, 'solver': 'sgd'}\n",
      "0.546 (+/-0.254) for {'alpha': 0.001, 'early_stopping': True, 'learning_rate': 'constant', 'max_iter': 1500, 'momentum': 0.3, 'solver': 'sgd'}\n",
      "0.562 (+/-0.243) for {'alpha': 0.001, 'early_stopping': True, 'learning_rate': 'constant', 'max_iter': 1500, 'momentum': 0.5, 'solver': 'sgd'}\n",
      "0.566 (+/-0.244) for {'alpha': 0.001, 'early_stopping': True, 'learning_rate': 'constant', 'max_iter': 1500, 'momentum': 0.7, 'solver': 'sgd'}\n",
      "0.708 (+/-0.159) for {'alpha': 0.001, 'early_stopping': True, 'learning_rate': 'constant', 'max_iter': 1500, 'momentum': 0.9, 'solver': 'sgd'}\n",
      "0.496 (+/-0.232) for {'alpha': 0.001, 'early_stopping': True, 'learning_rate': 'constant', 'max_iter': 2000, 'momentum': 0.1, 'solver': 'sgd'}\n",
      "0.518 (+/-0.247) for {'alpha': 0.001, 'early_stopping': True, 'learning_rate': 'constant', 'max_iter': 2000, 'momentum': 0.3, 'solver': 'sgd'}\n",
      "0.537 (+/-0.248) for {'alpha': 0.001, 'early_stopping': True, 'learning_rate': 'constant', 'max_iter': 2000, 'momentum': 0.5, 'solver': 'sgd'}\n",
      "0.587 (+/-0.219) for {'alpha': 0.001, 'early_stopping': True, 'learning_rate': 'constant', 'max_iter': 2000, 'momentum': 0.7, 'solver': 'sgd'}\n",
      "0.654 (+/-0.075) for {'alpha': 0.001, 'early_stopping': True, 'learning_rate': 'constant', 'max_iter': 2000, 'momentum': 0.9, 'solver': 'sgd'}\n",
      "0.542 (+/-0.253) for {'alpha': 0.001, 'early_stopping': True, 'learning_rate': 'invscaling', 'max_iter': 1000, 'momentum': 0.1, 'solver': 'sgd'}\n",
      "0.486 (+/-0.221) for {'alpha': 0.001, 'early_stopping': True, 'learning_rate': 'invscaling', 'max_iter': 1000, 'momentum': 0.3, 'solver': 'sgd'}\n",
      "0.555 (+/-0.290) for {'alpha': 0.001, 'early_stopping': True, 'learning_rate': 'invscaling', 'max_iter': 1000, 'momentum': 0.5, 'solver': 'sgd'}\n",
      "0.499 (+/-0.281) for {'alpha': 0.001, 'early_stopping': True, 'learning_rate': 'invscaling', 'max_iter': 1000, 'momentum': 0.7, 'solver': 'sgd'}\n",
      "0.541 (+/-0.243) for {'alpha': 0.001, 'early_stopping': True, 'learning_rate': 'invscaling', 'max_iter': 1000, 'momentum': 0.9, 'solver': 'sgd'}\n",
      "0.470 (+/-0.232) for {'alpha': 0.001, 'early_stopping': True, 'learning_rate': 'invscaling', 'max_iter': 1500, 'momentum': 0.1, 'solver': 'sgd'}\n",
      "0.462 (+/-0.282) for {'alpha': 0.001, 'early_stopping': True, 'learning_rate': 'invscaling', 'max_iter': 1500, 'momentum': 0.3, 'solver': 'sgd'}\n",
      "0.531 (+/-0.329) for {'alpha': 0.001, 'early_stopping': True, 'learning_rate': 'invscaling', 'max_iter': 1500, 'momentum': 0.5, 'solver': 'sgd'}\n",
      "0.502 (+/-0.316) for {'alpha': 0.001, 'early_stopping': True, 'learning_rate': 'invscaling', 'max_iter': 1500, 'momentum': 0.7, 'solver': 'sgd'}\n",
      "0.417 (+/-0.258) for {'alpha': 0.001, 'early_stopping': True, 'learning_rate': 'invscaling', 'max_iter': 1500, 'momentum': 0.9, 'solver': 'sgd'}\n",
      "0.483 (+/-0.199) for {'alpha': 0.001, 'early_stopping': True, 'learning_rate': 'invscaling', 'max_iter': 2000, 'momentum': 0.1, 'solver': 'sgd'}\n",
      "0.555 (+/-0.306) for {'alpha': 0.001, 'early_stopping': True, 'learning_rate': 'invscaling', 'max_iter': 2000, 'momentum': 0.3, 'solver': 'sgd'}\n",
      "0.428 (+/-0.216) for {'alpha': 0.001, 'early_stopping': True, 'learning_rate': 'invscaling', 'max_iter': 2000, 'momentum': 0.5, 'solver': 'sgd'}\n",
      "0.509 (+/-0.235) for {'alpha': 0.001, 'early_stopping': True, 'learning_rate': 'invscaling', 'max_iter': 2000, 'momentum': 0.7, 'solver': 'sgd'}\n",
      "0.496 (+/-0.324) for {'alpha': 0.001, 'early_stopping': True, 'learning_rate': 'invscaling', 'max_iter': 2000, 'momentum': 0.9, 'solver': 'sgd'}\n",
      "0.521 (+/-0.268) for {'alpha': 0.001, 'early_stopping': True, 'learning_rate': 'adaptive', 'max_iter': 1000, 'momentum': 0.1, 'solver': 'sgd'}\n",
      "0.509 (+/-0.240) for {'alpha': 0.001, 'early_stopping': True, 'learning_rate': 'adaptive', 'max_iter': 1000, 'momentum': 0.3, 'solver': 'sgd'}\n",
      "0.601 (+/-0.120) for {'alpha': 0.001, 'early_stopping': True, 'learning_rate': 'adaptive', 'max_iter': 1000, 'momentum': 0.5, 'solver': 'sgd'}\n",
      "0.624 (+/-0.261) for {'alpha': 0.001, 'early_stopping': True, 'learning_rate': 'adaptive', 'max_iter': 1000, 'momentum': 0.7, 'solver': 'sgd'}\n",
      "0.707 (+/-0.177) for {'alpha': 0.001, 'early_stopping': True, 'learning_rate': 'adaptive', 'max_iter': 1000, 'momentum': 0.9, 'solver': 'sgd'}\n",
      "0.566 (+/-0.252) for {'alpha': 0.001, 'early_stopping': True, 'learning_rate': 'adaptive', 'max_iter': 1500, 'momentum': 0.1, 'solver': 'sgd'}\n",
      "0.579 (+/-0.197) for {'alpha': 0.001, 'early_stopping': True, 'learning_rate': 'adaptive', 'max_iter': 1500, 'momentum': 0.3, 'solver': 'sgd'}\n",
      "0.537 (+/-0.254) for {'alpha': 0.001, 'early_stopping': True, 'learning_rate': 'adaptive', 'max_iter': 1500, 'momentum': 0.5, 'solver': 'sgd'}\n",
      "0.601 (+/-0.186) for {'alpha': 0.001, 'early_stopping': True, 'learning_rate': 'adaptive', 'max_iter': 1500, 'momentum': 0.7, 'solver': 'sgd'}\n",
      "0.732 (+/-0.154) for {'alpha': 0.001, 'early_stopping': True, 'learning_rate': 'adaptive', 'max_iter': 1500, 'momentum': 0.9, 'solver': 'sgd'}\n",
      "0.480 (+/-0.215) for {'alpha': 0.001, 'early_stopping': True, 'learning_rate': 'adaptive', 'max_iter': 2000, 'momentum': 0.1, 'solver': 'sgd'}\n",
      "0.549 (+/-0.290) for {'alpha': 0.001, 'early_stopping': True, 'learning_rate': 'adaptive', 'max_iter': 2000, 'momentum': 0.3, 'solver': 'sgd'}\n",
      "0.557 (+/-0.240) for {'alpha': 0.001, 'early_stopping': True, 'learning_rate': 'adaptive', 'max_iter': 2000, 'momentum': 0.5, 'solver': 'sgd'}\n",
      "0.671 (+/-0.127) for {'alpha': 0.001, 'early_stopping': True, 'learning_rate': 'adaptive', 'max_iter': 2000, 'momentum': 0.7, 'solver': 'sgd'}\n",
      "0.681 (+/-0.118) for {'alpha': 0.001, 'early_stopping': True, 'learning_rate': 'adaptive', 'max_iter': 2000, 'momentum': 0.9, 'solver': 'sgd'}\n",
      "0.798 (+/-0.102) for {'alpha': 0.001, 'early_stopping': False, 'learning_rate': 'constant', 'max_iter': 1000, 'momentum': 0.1, 'solver': 'sgd'}\n",
      "0.781 (+/-0.082) for {'alpha': 0.001, 'early_stopping': False, 'learning_rate': 'constant', 'max_iter': 1000, 'momentum': 0.3, 'solver': 'sgd'}\n",
      "0.788 (+/-0.075) for {'alpha': 0.001, 'early_stopping': False, 'learning_rate': 'constant', 'max_iter': 1000, 'momentum': 0.5, 'solver': 'sgd'}\n",
      "0.782 (+/-0.068) for {'alpha': 0.001, 'early_stopping': False, 'learning_rate': 'constant', 'max_iter': 1000, 'momentum': 0.7, 'solver': 'sgd'}\n",
      "0.794 (+/-0.086) for {'alpha': 0.001, 'early_stopping': False, 'learning_rate': 'constant', 'max_iter': 1000, 'momentum': 0.9, 'solver': 'sgd'}\n",
      "0.784 (+/-0.078) for {'alpha': 0.001, 'early_stopping': False, 'learning_rate': 'constant', 'max_iter': 1500, 'momentum': 0.1, 'solver': 'sgd'}\n",
      "0.775 (+/-0.093) for {'alpha': 0.001, 'early_stopping': False, 'learning_rate': 'constant', 'max_iter': 1500, 'momentum': 0.3, 'solver': 'sgd'}\n",
      "0.773 (+/-0.064) for {'alpha': 0.001, 'early_stopping': False, 'learning_rate': 'constant', 'max_iter': 1500, 'momentum': 0.5, 'solver': 'sgd'}\n",
      "0.791 (+/-0.087) for {'alpha': 0.001, 'early_stopping': False, 'learning_rate': 'constant', 'max_iter': 1500, 'momentum': 0.7, 'solver': 'sgd'}\n",
      "0.789 (+/-0.081) for {'alpha': 0.001, 'early_stopping': False, 'learning_rate': 'constant', 'max_iter': 1500, 'momentum': 0.9, 'solver': 'sgd'}\n",
      "0.789 (+/-0.104) for {'alpha': 0.001, 'early_stopping': False, 'learning_rate': 'constant', 'max_iter': 2000, 'momentum': 0.1, 'solver': 'sgd'}\n",
      "0.774 (+/-0.088) for {'alpha': 0.001, 'early_stopping': False, 'learning_rate': 'constant', 'max_iter': 2000, 'momentum': 0.3, 'solver': 'sgd'}\n",
      "0.777 (+/-0.065) for {'alpha': 0.001, 'early_stopping': False, 'learning_rate': 'constant', 'max_iter': 2000, 'momentum': 0.5, 'solver': 'sgd'}\n",
      "0.789 (+/-0.060) for {'alpha': 0.001, 'early_stopping': False, 'learning_rate': 'constant', 'max_iter': 2000, 'momentum': 0.7, 'solver': 'sgd'}\n",
      "0.789 (+/-0.074) for {'alpha': 0.001, 'early_stopping': False, 'learning_rate': 'constant', 'max_iter': 2000, 'momentum': 0.9, 'solver': 'sgd'}\n",
      "0.431 (+/-0.217) for {'alpha': 0.001, 'early_stopping': False, 'learning_rate': 'invscaling', 'max_iter': 1000, 'momentum': 0.1, 'solver': 'sgd'}\n",
      "0.508 (+/-0.308) for {'alpha': 0.001, 'early_stopping': False, 'learning_rate': 'invscaling', 'max_iter': 1000, 'momentum': 0.3, 'solver': 'sgd'}\n",
      "0.543 (+/-0.376) for {'alpha': 0.001, 'early_stopping': False, 'learning_rate': 'invscaling', 'max_iter': 1000, 'momentum': 0.5, 'solver': 'sgd'}\n",
      "0.500 (+/-0.253) for {'alpha': 0.001, 'early_stopping': False, 'learning_rate': 'invscaling', 'max_iter': 1000, 'momentum': 0.7, 'solver': 'sgd'}\n",
      "0.521 (+/-0.291) for {'alpha': 0.001, 'early_stopping': False, 'learning_rate': 'invscaling', 'max_iter': 1000, 'momentum': 0.9, 'solver': 'sgd'}\n",
      "0.535 (+/-0.232) for {'alpha': 0.001, 'early_stopping': False, 'learning_rate': 'invscaling', 'max_iter': 1500, 'momentum': 0.1, 'solver': 'sgd'}\n",
      "0.397 (+/-0.259) for {'alpha': 0.001, 'early_stopping': False, 'learning_rate': 'invscaling', 'max_iter': 1500, 'momentum': 0.3, 'solver': 'sgd'}\n",
      "0.428 (+/-0.246) for {'alpha': 0.001, 'early_stopping': False, 'learning_rate': 'invscaling', 'max_iter': 1500, 'momentum': 0.5, 'solver': 'sgd'}\n",
      "0.490 (+/-0.286) for {'alpha': 0.001, 'early_stopping': False, 'learning_rate': 'invscaling', 'max_iter': 1500, 'momentum': 0.7, 'solver': 'sgd'}\n",
      "0.528 (+/-0.147) for {'alpha': 0.001, 'early_stopping': False, 'learning_rate': 'invscaling', 'max_iter': 1500, 'momentum': 0.9, 'solver': 'sgd'}\n",
      "0.484 (+/-0.280) for {'alpha': 0.001, 'early_stopping': False, 'learning_rate': 'invscaling', 'max_iter': 2000, 'momentum': 0.1, 'solver': 'sgd'}\n",
      "0.469 (+/-0.227) for {'alpha': 0.001, 'early_stopping': False, 'learning_rate': 'invscaling', 'max_iter': 2000, 'momentum': 0.3, 'solver': 'sgd'}\n",
      "0.525 (+/-0.204) for {'alpha': 0.001, 'early_stopping': False, 'learning_rate': 'invscaling', 'max_iter': 2000, 'momentum': 0.5, 'solver': 'sgd'}\n",
      "0.400 (+/-0.257) for {'alpha': 0.001, 'early_stopping': False, 'learning_rate': 'invscaling', 'max_iter': 2000, 'momentum': 0.7, 'solver': 'sgd'}\n",
      "0.494 (+/-0.251) for {'alpha': 0.001, 'early_stopping': False, 'learning_rate': 'invscaling', 'max_iter': 2000, 'momentum': 0.9, 'solver': 'sgd'}\n",
      "0.785 (+/-0.092) for {'alpha': 0.001, 'early_stopping': False, 'learning_rate': 'adaptive', 'max_iter': 1000, 'momentum': 0.1, 'solver': 'sgd'}\n",
      "0.781 (+/-0.096) for {'alpha': 0.001, 'early_stopping': False, 'learning_rate': 'adaptive', 'max_iter': 1000, 'momentum': 0.3, 'solver': 'sgd'}\n",
      "0.781 (+/-0.084) for {'alpha': 0.001, 'early_stopping': False, 'learning_rate': 'adaptive', 'max_iter': 1000, 'momentum': 0.5, 'solver': 'sgd'}\n",
      "0.787 (+/-0.081) for {'alpha': 0.001, 'early_stopping': False, 'learning_rate': 'adaptive', 'max_iter': 1000, 'momentum': 0.7, 'solver': 'sgd'}\n",
      "0.792 (+/-0.083) for {'alpha': 0.001, 'early_stopping': False, 'learning_rate': 'adaptive', 'max_iter': 1000, 'momentum': 0.9, 'solver': 'sgd'}\n",
      "0.782 (+/-0.093) for {'alpha': 0.001, 'early_stopping': False, 'learning_rate': 'adaptive', 'max_iter': 1500, 'momentum': 0.1, 'solver': 'sgd'}\n",
      "0.787 (+/-0.087) for {'alpha': 0.001, 'early_stopping': False, 'learning_rate': 'adaptive', 'max_iter': 1500, 'momentum': 0.3, 'solver': 'sgd'}\n",
      "0.788 (+/-0.090) for {'alpha': 0.001, 'early_stopping': False, 'learning_rate': 'adaptive', 'max_iter': 1500, 'momentum': 0.5, 'solver': 'sgd'}\n",
      "0.778 (+/-0.088) for {'alpha': 0.001, 'early_stopping': False, 'learning_rate': 'adaptive', 'max_iter': 1500, 'momentum': 0.7, 'solver': 'sgd'}\n",
      "0.792 (+/-0.081) for {'alpha': 0.001, 'early_stopping': False, 'learning_rate': 'adaptive', 'max_iter': 1500, 'momentum': 0.9, 'solver': 'sgd'}\n",
      "0.775 (+/-0.099) for {'alpha': 0.001, 'early_stopping': False, 'learning_rate': 'adaptive', 'max_iter': 2000, 'momentum': 0.1, 'solver': 'sgd'}\n",
      "0.785 (+/-0.098) for {'alpha': 0.001, 'early_stopping': False, 'learning_rate': 'adaptive', 'max_iter': 2000, 'momentum': 0.3, 'solver': 'sgd'}\n",
      "0.789 (+/-0.101) for {'alpha': 0.001, 'early_stopping': False, 'learning_rate': 'adaptive', 'max_iter': 2000, 'momentum': 0.5, 'solver': 'sgd'}\n",
      "0.784 (+/-0.073) for {'alpha': 0.001, 'early_stopping': False, 'learning_rate': 'adaptive', 'max_iter': 2000, 'momentum': 0.7, 'solver': 'sgd'}\n",
      "0.787 (+/-0.072) for {'alpha': 0.001, 'early_stopping': False, 'learning_rate': 'adaptive', 'max_iter': 2000, 'momentum': 0.9, 'solver': 'sgd'}\n",
      "0.563 (+/-0.255) for {'alpha': 0.01, 'early_stopping': True, 'learning_rate': 'constant', 'max_iter': 1000, 'momentum': 0.1, 'solver': 'sgd'}\n",
      "0.556 (+/-0.221) for {'alpha': 0.01, 'early_stopping': True, 'learning_rate': 'constant', 'max_iter': 1000, 'momentum': 0.3, 'solver': 'sgd'}\n",
      "0.554 (+/-0.230) for {'alpha': 0.01, 'early_stopping': True, 'learning_rate': 'constant', 'max_iter': 1000, 'momentum': 0.5, 'solver': 'sgd'}\n",
      "0.576 (+/-0.206) for {'alpha': 0.01, 'early_stopping': True, 'learning_rate': 'constant', 'max_iter': 1000, 'momentum': 0.7, 'solver': 'sgd'}\n",
      "0.661 (+/-0.265) for {'alpha': 0.01, 'early_stopping': True, 'learning_rate': 'constant', 'max_iter': 1000, 'momentum': 0.9, 'solver': 'sgd'}\n",
      "0.503 (+/-0.256) for {'alpha': 0.01, 'early_stopping': True, 'learning_rate': 'constant', 'max_iter': 1500, 'momentum': 0.1, 'solver': 'sgd'}\n",
      "0.534 (+/-0.324) for {'alpha': 0.01, 'early_stopping': True, 'learning_rate': 'constant', 'max_iter': 1500, 'momentum': 0.3, 'solver': 'sgd'}\n",
      "0.562 (+/-0.240) for {'alpha': 0.01, 'early_stopping': True, 'learning_rate': 'constant', 'max_iter': 1500, 'momentum': 0.5, 'solver': 'sgd'}\n",
      "0.611 (+/-0.313) for {'alpha': 0.01, 'early_stopping': True, 'learning_rate': 'constant', 'max_iter': 1500, 'momentum': 0.7, 'solver': 'sgd'}\n",
      "0.706 (+/-0.098) for {'alpha': 0.01, 'early_stopping': True, 'learning_rate': 'constant', 'max_iter': 1500, 'momentum': 0.9, 'solver': 'sgd'}\n",
      "0.541 (+/-0.247) for {'alpha': 0.01, 'early_stopping': True, 'learning_rate': 'constant', 'max_iter': 2000, 'momentum': 0.1, 'solver': 'sgd'}\n",
      "0.553 (+/-0.352) for {'alpha': 0.01, 'early_stopping': True, 'learning_rate': 'constant', 'max_iter': 2000, 'momentum': 0.3, 'solver': 'sgd'}\n",
      "0.534 (+/-0.335) for {'alpha': 0.01, 'early_stopping': True, 'learning_rate': 'constant', 'max_iter': 2000, 'momentum': 0.5, 'solver': 'sgd'}\n",
      "0.599 (+/-0.274) for {'alpha': 0.01, 'early_stopping': True, 'learning_rate': 'constant', 'max_iter': 2000, 'momentum': 0.7, 'solver': 'sgd'}\n",
      "0.675 (+/-0.189) for {'alpha': 0.01, 'early_stopping': True, 'learning_rate': 'constant', 'max_iter': 2000, 'momentum': 0.9, 'solver': 'sgd'}\n",
      "0.505 (+/-0.296) for {'alpha': 0.01, 'early_stopping': True, 'learning_rate': 'invscaling', 'max_iter': 1000, 'momentum': 0.1, 'solver': 'sgd'}\n",
      "0.534 (+/-0.185) for {'alpha': 0.01, 'early_stopping': True, 'learning_rate': 'invscaling', 'max_iter': 1000, 'momentum': 0.3, 'solver': 'sgd'}\n",
      "0.505 (+/-0.296) for {'alpha': 0.01, 'early_stopping': True, 'learning_rate': 'invscaling', 'max_iter': 1000, 'momentum': 0.5, 'solver': 'sgd'}\n",
      "0.440 (+/-0.237) for {'alpha': 0.01, 'early_stopping': True, 'learning_rate': 'invscaling', 'max_iter': 1000, 'momentum': 0.7, 'solver': 'sgd'}\n",
      "0.467 (+/-0.301) for {'alpha': 0.01, 'early_stopping': True, 'learning_rate': 'invscaling', 'max_iter': 1000, 'momentum': 0.9, 'solver': 'sgd'}\n",
      "0.521 (+/-0.253) for {'alpha': 0.01, 'early_stopping': True, 'learning_rate': 'invscaling', 'max_iter': 1500, 'momentum': 0.1, 'solver': 'sgd'}\n",
      "0.473 (+/-0.267) for {'alpha': 0.01, 'early_stopping': True, 'learning_rate': 'invscaling', 'max_iter': 1500, 'momentum': 0.3, 'solver': 'sgd'}\n",
      "0.522 (+/-0.265) for {'alpha': 0.01, 'early_stopping': True, 'learning_rate': 'invscaling', 'max_iter': 1500, 'momentum': 0.5, 'solver': 'sgd'}\n",
      "0.509 (+/-0.224) for {'alpha': 0.01, 'early_stopping': True, 'learning_rate': 'invscaling', 'max_iter': 1500, 'momentum': 0.7, 'solver': 'sgd'}\n",
      "0.474 (+/-0.192) for {'alpha': 0.01, 'early_stopping': True, 'learning_rate': 'invscaling', 'max_iter': 1500, 'momentum': 0.9, 'solver': 'sgd'}\n",
      "0.459 (+/-0.270) for {'alpha': 0.01, 'early_stopping': True, 'learning_rate': 'invscaling', 'max_iter': 2000, 'momentum': 0.1, 'solver': 'sgd'}\n",
      "0.460 (+/-0.200) for {'alpha': 0.01, 'early_stopping': True, 'learning_rate': 'invscaling', 'max_iter': 2000, 'momentum': 0.3, 'solver': 'sgd'}\n",
      "0.540 (+/-0.338) for {'alpha': 0.01, 'early_stopping': True, 'learning_rate': 'invscaling', 'max_iter': 2000, 'momentum': 0.5, 'solver': 'sgd'}\n",
      "0.475 (+/-0.294) for {'alpha': 0.01, 'early_stopping': True, 'learning_rate': 'invscaling', 'max_iter': 2000, 'momentum': 0.7, 'solver': 'sgd'}\n",
      "0.514 (+/-0.256) for {'alpha': 0.01, 'early_stopping': True, 'learning_rate': 'invscaling', 'max_iter': 2000, 'momentum': 0.9, 'solver': 'sgd'}\n",
      "0.546 (+/-0.232) for {'alpha': 0.01, 'early_stopping': True, 'learning_rate': 'adaptive', 'max_iter': 1000, 'momentum': 0.1, 'solver': 'sgd'}\n",
      "0.635 (+/-0.128) for {'alpha': 0.01, 'early_stopping': True, 'learning_rate': 'adaptive', 'max_iter': 1000, 'momentum': 0.3, 'solver': 'sgd'}\n",
      "0.558 (+/-0.230) for {'alpha': 0.01, 'early_stopping': True, 'learning_rate': 'adaptive', 'max_iter': 1000, 'momentum': 0.5, 'solver': 'sgd'}\n",
      "0.604 (+/-0.115) for {'alpha': 0.01, 'early_stopping': True, 'learning_rate': 'adaptive', 'max_iter': 1000, 'momentum': 0.7, 'solver': 'sgd'}\n",
      "0.719 (+/-0.083) for {'alpha': 0.01, 'early_stopping': True, 'learning_rate': 'adaptive', 'max_iter': 1000, 'momentum': 0.9, 'solver': 'sgd'}\n",
      "0.571 (+/-0.323) for {'alpha': 0.01, 'early_stopping': True, 'learning_rate': 'adaptive', 'max_iter': 1500, 'momentum': 0.1, 'solver': 'sgd'}\n",
      "0.534 (+/-0.184) for {'alpha': 0.01, 'early_stopping': True, 'learning_rate': 'adaptive', 'max_iter': 1500, 'momentum': 0.3, 'solver': 'sgd'}\n",
      "0.624 (+/-0.288) for {'alpha': 0.01, 'early_stopping': True, 'learning_rate': 'adaptive', 'max_iter': 1500, 'momentum': 0.5, 'solver': 'sgd'}\n",
      "0.563 (+/-0.275) for {'alpha': 0.01, 'early_stopping': True, 'learning_rate': 'adaptive', 'max_iter': 1500, 'momentum': 0.7, 'solver': 'sgd'}\n",
      "0.703 (+/-0.146) for {'alpha': 0.01, 'early_stopping': True, 'learning_rate': 'adaptive', 'max_iter': 1500, 'momentum': 0.9, 'solver': 'sgd'}\n",
      "0.528 (+/-0.214) for {'alpha': 0.01, 'early_stopping': True, 'learning_rate': 'adaptive', 'max_iter': 2000, 'momentum': 0.1, 'solver': 'sgd'}\n",
      "0.566 (+/-0.258) for {'alpha': 0.01, 'early_stopping': True, 'learning_rate': 'adaptive', 'max_iter': 2000, 'momentum': 0.3, 'solver': 'sgd'}\n",
      "0.549 (+/-0.230) for {'alpha': 0.01, 'early_stopping': True, 'learning_rate': 'adaptive', 'max_iter': 2000, 'momentum': 0.5, 'solver': 'sgd'}\n",
      "0.590 (+/-0.210) for {'alpha': 0.01, 'early_stopping': True, 'learning_rate': 'adaptive', 'max_iter': 2000, 'momentum': 0.7, 'solver': 'sgd'}\n",
      "0.743 (+/-0.116) for {'alpha': 0.01, 'early_stopping': True, 'learning_rate': 'adaptive', 'max_iter': 2000, 'momentum': 0.9, 'solver': 'sgd'}\n",
      "0.777 (+/-0.087) for {'alpha': 0.01, 'early_stopping': False, 'learning_rate': 'constant', 'max_iter': 1000, 'momentum': 0.1, 'solver': 'sgd'}\n",
      "0.785 (+/-0.075) for {'alpha': 0.01, 'early_stopping': False, 'learning_rate': 'constant', 'max_iter': 1000, 'momentum': 0.3, 'solver': 'sgd'}\n",
      "0.787 (+/-0.079) for {'alpha': 0.01, 'early_stopping': False, 'learning_rate': 'constant', 'max_iter': 1000, 'momentum': 0.5, 'solver': 'sgd'}\n",
      "0.794 (+/-0.074) for {'alpha': 0.01, 'early_stopping': False, 'learning_rate': 'constant', 'max_iter': 1000, 'momentum': 0.7, 'solver': 'sgd'}\n",
      "0.795 (+/-0.073) for {'alpha': 0.01, 'early_stopping': False, 'learning_rate': 'constant', 'max_iter': 1000, 'momentum': 0.9, 'solver': 'sgd'}\n",
      "0.774 (+/-0.083) for {'alpha': 0.01, 'early_stopping': False, 'learning_rate': 'constant', 'max_iter': 1500, 'momentum': 0.1, 'solver': 'sgd'}\n",
      "0.782 (+/-0.098) for {'alpha': 0.01, 'early_stopping': False, 'learning_rate': 'constant', 'max_iter': 1500, 'momentum': 0.3, 'solver': 'sgd'}\n",
      "0.788 (+/-0.068) for {'alpha': 0.01, 'early_stopping': False, 'learning_rate': 'constant', 'max_iter': 1500, 'momentum': 0.5, 'solver': 'sgd'}\n",
      "0.778 (+/-0.083) for {'alpha': 0.01, 'early_stopping': False, 'learning_rate': 'constant', 'max_iter': 1500, 'momentum': 0.7, 'solver': 'sgd'}\n",
      "0.787 (+/-0.084) for {'alpha': 0.01, 'early_stopping': False, 'learning_rate': 'constant', 'max_iter': 1500, 'momentum': 0.9, 'solver': 'sgd'}\n",
      "0.771 (+/-0.091) for {'alpha': 0.01, 'early_stopping': False, 'learning_rate': 'constant', 'max_iter': 2000, 'momentum': 0.1, 'solver': 'sgd'}\n",
      "0.782 (+/-0.086) for {'alpha': 0.01, 'early_stopping': False, 'learning_rate': 'constant', 'max_iter': 2000, 'momentum': 0.3, 'solver': 'sgd'}\n",
      "0.782 (+/-0.068) for {'alpha': 0.01, 'early_stopping': False, 'learning_rate': 'constant', 'max_iter': 2000, 'momentum': 0.5, 'solver': 'sgd'}\n",
      "0.784 (+/-0.085) for {'alpha': 0.01, 'early_stopping': False, 'learning_rate': 'constant', 'max_iter': 2000, 'momentum': 0.7, 'solver': 'sgd'}\n",
      "0.788 (+/-0.082) for {'alpha': 0.01, 'early_stopping': False, 'learning_rate': 'constant', 'max_iter': 2000, 'momentum': 0.9, 'solver': 'sgd'}\n",
      "0.530 (+/-0.317) for {'alpha': 0.01, 'early_stopping': False, 'learning_rate': 'invscaling', 'max_iter': 1000, 'momentum': 0.1, 'solver': 'sgd'}\n",
      "0.497 (+/-0.220) for {'alpha': 0.01, 'early_stopping': False, 'learning_rate': 'invscaling', 'max_iter': 1000, 'momentum': 0.3, 'solver': 'sgd'}\n",
      "0.490 (+/-0.359) for {'alpha': 0.01, 'early_stopping': False, 'learning_rate': 'invscaling', 'max_iter': 1000, 'momentum': 0.5, 'solver': 'sgd'}\n",
      "0.524 (+/-0.236) for {'alpha': 0.01, 'early_stopping': False, 'learning_rate': 'invscaling', 'max_iter': 1000, 'momentum': 0.7, 'solver': 'sgd'}\n",
      "0.476 (+/-0.236) for {'alpha': 0.01, 'early_stopping': False, 'learning_rate': 'invscaling', 'max_iter': 1000, 'momentum': 0.9, 'solver': 'sgd'}\n",
      "0.556 (+/-0.255) for {'alpha': 0.01, 'early_stopping': False, 'learning_rate': 'invscaling', 'max_iter': 1500, 'momentum': 0.1, 'solver': 'sgd'}\n",
      "0.521 (+/-0.223) for {'alpha': 0.01, 'early_stopping': False, 'learning_rate': 'invscaling', 'max_iter': 1500, 'momentum': 0.3, 'solver': 'sgd'}\n",
      "0.445 (+/-0.217) for {'alpha': 0.01, 'early_stopping': False, 'learning_rate': 'invscaling', 'max_iter': 1500, 'momentum': 0.5, 'solver': 'sgd'}\n",
      "0.510 (+/-0.213) for {'alpha': 0.01, 'early_stopping': False, 'learning_rate': 'invscaling', 'max_iter': 1500, 'momentum': 0.7, 'solver': 'sgd'}\n",
      "0.514 (+/-0.273) for {'alpha': 0.01, 'early_stopping': False, 'learning_rate': 'invscaling', 'max_iter': 1500, 'momentum': 0.9, 'solver': 'sgd'}\n",
      "0.476 (+/-0.238) for {'alpha': 0.01, 'early_stopping': False, 'learning_rate': 'invscaling', 'max_iter': 2000, 'momentum': 0.1, 'solver': 'sgd'}\n",
      "0.518 (+/-0.245) for {'alpha': 0.01, 'early_stopping': False, 'learning_rate': 'invscaling', 'max_iter': 2000, 'momentum': 0.3, 'solver': 'sgd'}\n",
      "0.491 (+/-0.254) for {'alpha': 0.01, 'early_stopping': False, 'learning_rate': 'invscaling', 'max_iter': 2000, 'momentum': 0.5, 'solver': 'sgd'}\n",
      "0.479 (+/-0.230) for {'alpha': 0.01, 'early_stopping': False, 'learning_rate': 'invscaling', 'max_iter': 2000, 'momentum': 0.7, 'solver': 'sgd'}\n",
      "0.547 (+/-0.252) for {'alpha': 0.01, 'early_stopping': False, 'learning_rate': 'invscaling', 'max_iter': 2000, 'momentum': 0.9, 'solver': 'sgd'}\n",
      "0.772 (+/-0.048) for {'alpha': 0.01, 'early_stopping': False, 'learning_rate': 'adaptive', 'max_iter': 1000, 'momentum': 0.1, 'solver': 'sgd'}\n",
      "0.789 (+/-0.105) for {'alpha': 0.01, 'early_stopping': False, 'learning_rate': 'adaptive', 'max_iter': 1000, 'momentum': 0.3, 'solver': 'sgd'}\n",
      "0.789 (+/-0.080) for {'alpha': 0.01, 'early_stopping': False, 'learning_rate': 'adaptive', 'max_iter': 1000, 'momentum': 0.5, 'solver': 'sgd'}\n",
      "0.787 (+/-0.065) for {'alpha': 0.01, 'early_stopping': False, 'learning_rate': 'adaptive', 'max_iter': 1000, 'momentum': 0.7, 'solver': 'sgd'}\n",
      "0.787 (+/-0.071) for {'alpha': 0.01, 'early_stopping': False, 'learning_rate': 'adaptive', 'max_iter': 1000, 'momentum': 0.9, 'solver': 'sgd'}\n",
      "0.779 (+/-0.073) for {'alpha': 0.01, 'early_stopping': False, 'learning_rate': 'adaptive', 'max_iter': 1500, 'momentum': 0.1, 'solver': 'sgd'}\n",
      "0.782 (+/-0.099) for {'alpha': 0.01, 'early_stopping': False, 'learning_rate': 'adaptive', 'max_iter': 1500, 'momentum': 0.3, 'solver': 'sgd'}\n",
      "0.775 (+/-0.081) for {'alpha': 0.01, 'early_stopping': False, 'learning_rate': 'adaptive', 'max_iter': 1500, 'momentum': 0.5, 'solver': 'sgd'}\n",
      "0.780 (+/-0.069) for {'alpha': 0.01, 'early_stopping': False, 'learning_rate': 'adaptive', 'max_iter': 1500, 'momentum': 0.7, 'solver': 'sgd'}\n",
      "0.789 (+/-0.084) for {'alpha': 0.01, 'early_stopping': False, 'learning_rate': 'adaptive', 'max_iter': 1500, 'momentum': 0.9, 'solver': 'sgd'}\n",
      "0.787 (+/-0.110) for {'alpha': 0.01, 'early_stopping': False, 'learning_rate': 'adaptive', 'max_iter': 2000, 'momentum': 0.1, 'solver': 'sgd'}\n",
      "0.789 (+/-0.105) for {'alpha': 0.01, 'early_stopping': False, 'learning_rate': 'adaptive', 'max_iter': 2000, 'momentum': 0.3, 'solver': 'sgd'}\n",
      "0.792 (+/-0.101) for {'alpha': 0.01, 'early_stopping': False, 'learning_rate': 'adaptive', 'max_iter': 2000, 'momentum': 0.5, 'solver': 'sgd'}\n",
      "0.794 (+/-0.078) for {'alpha': 0.01, 'early_stopping': False, 'learning_rate': 'adaptive', 'max_iter': 2000, 'momentum': 0.7, 'solver': 'sgd'}\n",
      "0.782 (+/-0.073) for {'alpha': 0.01, 'early_stopping': False, 'learning_rate': 'adaptive', 'max_iter': 2000, 'momentum': 0.9, 'solver': 'sgd'}\n",
      "0.524 (+/-0.278) for {'alpha': 0.1, 'early_stopping': True, 'learning_rate': 'constant', 'max_iter': 1000, 'momentum': 0.1, 'solver': 'sgd'}\n",
      "0.580 (+/-0.106) for {'alpha': 0.1, 'early_stopping': True, 'learning_rate': 'constant', 'max_iter': 1000, 'momentum': 0.3, 'solver': 'sgd'}\n",
      "0.527 (+/-0.285) for {'alpha': 0.1, 'early_stopping': True, 'learning_rate': 'constant', 'max_iter': 1000, 'momentum': 0.5, 'solver': 'sgd'}\n",
      "0.546 (+/-0.328) for {'alpha': 0.1, 'early_stopping': True, 'learning_rate': 'constant', 'max_iter': 1000, 'momentum': 0.7, 'solver': 'sgd'}\n",
      "0.678 (+/-0.214) for {'alpha': 0.1, 'early_stopping': True, 'learning_rate': 'constant', 'max_iter': 1000, 'momentum': 0.9, 'solver': 'sgd'}\n",
      "0.525 (+/-0.280) for {'alpha': 0.1, 'early_stopping': True, 'learning_rate': 'constant', 'max_iter': 1500, 'momentum': 0.1, 'solver': 'sgd'}\n",
      "0.525 (+/-0.307) for {'alpha': 0.1, 'early_stopping': True, 'learning_rate': 'constant', 'max_iter': 1500, 'momentum': 0.3, 'solver': 'sgd'}\n",
      "0.550 (+/-0.301) for {'alpha': 0.1, 'early_stopping': True, 'learning_rate': 'constant', 'max_iter': 1500, 'momentum': 0.5, 'solver': 'sgd'}\n",
      "0.605 (+/-0.315) for {'alpha': 0.1, 'early_stopping': True, 'learning_rate': 'constant', 'max_iter': 1500, 'momentum': 0.7, 'solver': 'sgd'}\n",
      "0.693 (+/-0.148) for {'alpha': 0.1, 'early_stopping': True, 'learning_rate': 'constant', 'max_iter': 1500, 'momentum': 0.9, 'solver': 'sgd'}\n",
      "0.485 (+/-0.227) for {'alpha': 0.1, 'early_stopping': True, 'learning_rate': 'constant', 'max_iter': 2000, 'momentum': 0.1, 'solver': 'sgd'}\n",
      "0.556 (+/-0.202) for {'alpha': 0.1, 'early_stopping': True, 'learning_rate': 'constant', 'max_iter': 2000, 'momentum': 0.3, 'solver': 'sgd'}\n",
      "0.449 (+/-0.166) for {'alpha': 0.1, 'early_stopping': True, 'learning_rate': 'constant', 'max_iter': 2000, 'momentum': 0.5, 'solver': 'sgd'}\n",
      "0.580 (+/-0.269) for {'alpha': 0.1, 'early_stopping': True, 'learning_rate': 'constant', 'max_iter': 2000, 'momentum': 0.7, 'solver': 'sgd'}\n",
      "0.670 (+/-0.103) for {'alpha': 0.1, 'early_stopping': True, 'learning_rate': 'constant', 'max_iter': 2000, 'momentum': 0.9, 'solver': 'sgd'}\n",
      "0.454 (+/-0.217) for {'alpha': 0.1, 'early_stopping': True, 'learning_rate': 'invscaling', 'max_iter': 1000, 'momentum': 0.1, 'solver': 'sgd'}\n",
      "0.557 (+/-0.247) for {'alpha': 0.1, 'early_stopping': True, 'learning_rate': 'invscaling', 'max_iter': 1000, 'momentum': 0.3, 'solver': 'sgd'}\n",
      "0.537 (+/-0.237) for {'alpha': 0.1, 'early_stopping': True, 'learning_rate': 'invscaling', 'max_iter': 1000, 'momentum': 0.5, 'solver': 'sgd'}\n",
      "0.481 (+/-0.244) for {'alpha': 0.1, 'early_stopping': True, 'learning_rate': 'invscaling', 'max_iter': 1000, 'momentum': 0.7, 'solver': 'sgd'}\n",
      "0.521 (+/-0.216) for {'alpha': 0.1, 'early_stopping': True, 'learning_rate': 'invscaling', 'max_iter': 1000, 'momentum': 0.9, 'solver': 'sgd'}\n",
      "0.408 (+/-0.282) for {'alpha': 0.1, 'early_stopping': True, 'learning_rate': 'invscaling', 'max_iter': 1500, 'momentum': 0.1, 'solver': 'sgd'}\n",
      "0.488 (+/-0.302) for {'alpha': 0.1, 'early_stopping': True, 'learning_rate': 'invscaling', 'max_iter': 1500, 'momentum': 0.3, 'solver': 'sgd'}\n",
      "0.563 (+/-0.344) for {'alpha': 0.1, 'early_stopping': True, 'learning_rate': 'invscaling', 'max_iter': 1500, 'momentum': 0.5, 'solver': 'sgd'}\n",
      "0.563 (+/-0.222) for {'alpha': 0.1, 'early_stopping': True, 'learning_rate': 'invscaling', 'max_iter': 1500, 'momentum': 0.7, 'solver': 'sgd'}\n",
      "0.506 (+/-0.328) for {'alpha': 0.1, 'early_stopping': True, 'learning_rate': 'invscaling', 'max_iter': 1500, 'momentum': 0.9, 'solver': 'sgd'}\n",
      "0.502 (+/-0.303) for {'alpha': 0.1, 'early_stopping': True, 'learning_rate': 'invscaling', 'max_iter': 2000, 'momentum': 0.1, 'solver': 'sgd'}\n",
      "0.452 (+/-0.136) for {'alpha': 0.1, 'early_stopping': True, 'learning_rate': 'invscaling', 'max_iter': 2000, 'momentum': 0.3, 'solver': 'sgd'}\n",
      "0.467 (+/-0.206) for {'alpha': 0.1, 'early_stopping': True, 'learning_rate': 'invscaling', 'max_iter': 2000, 'momentum': 0.5, 'solver': 'sgd'}\n",
      "0.537 (+/-0.263) for {'alpha': 0.1, 'early_stopping': True, 'learning_rate': 'invscaling', 'max_iter': 2000, 'momentum': 0.7, 'solver': 'sgd'}\n",
      "0.557 (+/-0.255) for {'alpha': 0.1, 'early_stopping': True, 'learning_rate': 'invscaling', 'max_iter': 2000, 'momentum': 0.9, 'solver': 'sgd'}\n",
      "0.472 (+/-0.223) for {'alpha': 0.1, 'early_stopping': True, 'learning_rate': 'adaptive', 'max_iter': 1000, 'momentum': 0.1, 'solver': 'sgd'}\n",
      "0.534 (+/-0.294) for {'alpha': 0.1, 'early_stopping': True, 'learning_rate': 'adaptive', 'max_iter': 1000, 'momentum': 0.3, 'solver': 'sgd'}\n",
      "0.508 (+/-0.254) for {'alpha': 0.1, 'early_stopping': True, 'learning_rate': 'adaptive', 'max_iter': 1000, 'momentum': 0.5, 'solver': 'sgd'}\n",
      "0.631 (+/-0.203) for {'alpha': 0.1, 'early_stopping': True, 'learning_rate': 'adaptive', 'max_iter': 1000, 'momentum': 0.7, 'solver': 'sgd'}\n",
      "0.666 (+/-0.135) for {'alpha': 0.1, 'early_stopping': True, 'learning_rate': 'adaptive', 'max_iter': 1000, 'momentum': 0.9, 'solver': 'sgd'}\n",
      "0.397 (+/-0.132) for {'alpha': 0.1, 'early_stopping': True, 'learning_rate': 'adaptive', 'max_iter': 1500, 'momentum': 0.1, 'solver': 'sgd'}\n",
      "0.507 (+/-0.229) for {'alpha': 0.1, 'early_stopping': True, 'learning_rate': 'adaptive', 'max_iter': 1500, 'momentum': 0.3, 'solver': 'sgd'}\n",
      "0.572 (+/-0.296) for {'alpha': 0.1, 'early_stopping': True, 'learning_rate': 'adaptive', 'max_iter': 1500, 'momentum': 0.5, 'solver': 'sgd'}\n",
      "0.657 (+/-0.279) for {'alpha': 0.1, 'early_stopping': True, 'learning_rate': 'adaptive', 'max_iter': 1500, 'momentum': 0.7, 'solver': 'sgd'}\n",
      "0.686 (+/-0.148) for {'alpha': 0.1, 'early_stopping': True, 'learning_rate': 'adaptive', 'max_iter': 1500, 'momentum': 0.9, 'solver': 'sgd'}\n",
      "0.522 (+/-0.272) for {'alpha': 0.1, 'early_stopping': True, 'learning_rate': 'adaptive', 'max_iter': 2000, 'momentum': 0.1, 'solver': 'sgd'}\n",
      "0.594 (+/-0.201) for {'alpha': 0.1, 'early_stopping': True, 'learning_rate': 'adaptive', 'max_iter': 2000, 'momentum': 0.3, 'solver': 'sgd'}\n",
      "0.602 (+/-0.195) for {'alpha': 0.1, 'early_stopping': True, 'learning_rate': 'adaptive', 'max_iter': 2000, 'momentum': 0.5, 'solver': 'sgd'}\n",
      "0.642 (+/-0.224) for {'alpha': 0.1, 'early_stopping': True, 'learning_rate': 'adaptive', 'max_iter': 2000, 'momentum': 0.7, 'solver': 'sgd'}\n",
      "0.726 (+/-0.105) for {'alpha': 0.1, 'early_stopping': True, 'learning_rate': 'adaptive', 'max_iter': 2000, 'momentum': 0.9, 'solver': 'sgd'}\n",
      "0.764 (+/-0.087) for {'alpha': 0.1, 'early_stopping': False, 'learning_rate': 'constant', 'max_iter': 1000, 'momentum': 0.1, 'solver': 'sgd'}\n",
      "0.782 (+/-0.080) for {'alpha': 0.1, 'early_stopping': False, 'learning_rate': 'constant', 'max_iter': 1000, 'momentum': 0.3, 'solver': 'sgd'}\n",
      "0.780 (+/-0.071) for {'alpha': 0.1, 'early_stopping': False, 'learning_rate': 'constant', 'max_iter': 1000, 'momentum': 0.5, 'solver': 'sgd'}\n",
      "0.787 (+/-0.082) for {'alpha': 0.1, 'early_stopping': False, 'learning_rate': 'constant', 'max_iter': 1000, 'momentum': 0.7, 'solver': 'sgd'}\n",
      "0.792 (+/-0.085) for {'alpha': 0.1, 'early_stopping': False, 'learning_rate': 'constant', 'max_iter': 1000, 'momentum': 0.9, 'solver': 'sgd'}\n",
      "0.757 (+/-0.105) for {'alpha': 0.1, 'early_stopping': False, 'learning_rate': 'constant', 'max_iter': 1500, 'momentum': 0.1, 'solver': 'sgd'}\n",
      "0.784 (+/-0.066) for {'alpha': 0.1, 'early_stopping': False, 'learning_rate': 'constant', 'max_iter': 1500, 'momentum': 0.3, 'solver': 'sgd'}\n",
      "0.792 (+/-0.082) for {'alpha': 0.1, 'early_stopping': False, 'learning_rate': 'constant', 'max_iter': 1500, 'momentum': 0.5, 'solver': 'sgd'}\n",
      "0.789 (+/-0.061) for {'alpha': 0.1, 'early_stopping': False, 'learning_rate': 'constant', 'max_iter': 1500, 'momentum': 0.7, 'solver': 'sgd'}\n",
      "0.789 (+/-0.074) for {'alpha': 0.1, 'early_stopping': False, 'learning_rate': 'constant', 'max_iter': 1500, 'momentum': 0.9, 'solver': 'sgd'}\n",
      "0.788 (+/-0.086) for {'alpha': 0.1, 'early_stopping': False, 'learning_rate': 'constant', 'max_iter': 2000, 'momentum': 0.1, 'solver': 'sgd'}\n",
      "0.784 (+/-0.100) for {'alpha': 0.1, 'early_stopping': False, 'learning_rate': 'constant', 'max_iter': 2000, 'momentum': 0.3, 'solver': 'sgd'}\n",
      "0.785 (+/-0.076) for {'alpha': 0.1, 'early_stopping': False, 'learning_rate': 'constant', 'max_iter': 2000, 'momentum': 0.5, 'solver': 'sgd'}\n",
      "0.792 (+/-0.078) for {'alpha': 0.1, 'early_stopping': False, 'learning_rate': 'constant', 'max_iter': 2000, 'momentum': 0.7, 'solver': 'sgd'}\n",
      "0.795 (+/-0.077) for {'alpha': 0.1, 'early_stopping': False, 'learning_rate': 'constant', 'max_iter': 2000, 'momentum': 0.9, 'solver': 'sgd'}\n",
      "0.548 (+/-0.225) for {'alpha': 0.1, 'early_stopping': False, 'learning_rate': 'invscaling', 'max_iter': 1000, 'momentum': 0.1, 'solver': 'sgd'}\n",
      "0.541 (+/-0.200) for {'alpha': 0.1, 'early_stopping': False, 'learning_rate': 'invscaling', 'max_iter': 1000, 'momentum': 0.3, 'solver': 'sgd'}\n",
      "0.545 (+/-0.295) for {'alpha': 0.1, 'early_stopping': False, 'learning_rate': 'invscaling', 'max_iter': 1000, 'momentum': 0.5, 'solver': 'sgd'}\n",
      "0.520 (+/-0.245) for {'alpha': 0.1, 'early_stopping': False, 'learning_rate': 'invscaling', 'max_iter': 1000, 'momentum': 0.7, 'solver': 'sgd'}\n",
      "0.569 (+/-0.289) for {'alpha': 0.1, 'early_stopping': False, 'learning_rate': 'invscaling', 'max_iter': 1000, 'momentum': 0.9, 'solver': 'sgd'}\n",
      "0.477 (+/-0.245) for {'alpha': 0.1, 'early_stopping': False, 'learning_rate': 'invscaling', 'max_iter': 1500, 'momentum': 0.1, 'solver': 'sgd'}\n",
      "0.433 (+/-0.211) for {'alpha': 0.1, 'early_stopping': False, 'learning_rate': 'invscaling', 'max_iter': 1500, 'momentum': 0.3, 'solver': 'sgd'}\n",
      "0.527 (+/-0.340) for {'alpha': 0.1, 'early_stopping': False, 'learning_rate': 'invscaling', 'max_iter': 1500, 'momentum': 0.5, 'solver': 'sgd'}\n",
      "0.463 (+/-0.233) for {'alpha': 0.1, 'early_stopping': False, 'learning_rate': 'invscaling', 'max_iter': 1500, 'momentum': 0.7, 'solver': 'sgd'}\n",
      "0.490 (+/-0.228) for {'alpha': 0.1, 'early_stopping': False, 'learning_rate': 'invscaling', 'max_iter': 1500, 'momentum': 0.9, 'solver': 'sgd'}\n",
      "0.531 (+/-0.234) for {'alpha': 0.1, 'early_stopping': False, 'learning_rate': 'invscaling', 'max_iter': 2000, 'momentum': 0.1, 'solver': 'sgd'}\n",
      "0.518 (+/-0.218) for {'alpha': 0.1, 'early_stopping': False, 'learning_rate': 'invscaling', 'max_iter': 2000, 'momentum': 0.3, 'solver': 'sgd'}\n",
      "0.528 (+/-0.244) for {'alpha': 0.1, 'early_stopping': False, 'learning_rate': 'invscaling', 'max_iter': 2000, 'momentum': 0.5, 'solver': 'sgd'}\n",
      "0.507 (+/-0.266) for {'alpha': 0.1, 'early_stopping': False, 'learning_rate': 'invscaling', 'max_iter': 2000, 'momentum': 0.7, 'solver': 'sgd'}\n",
      "0.490 (+/-0.233) for {'alpha': 0.1, 'early_stopping': False, 'learning_rate': 'invscaling', 'max_iter': 2000, 'momentum': 0.9, 'solver': 'sgd'}\n",
      "0.781 (+/-0.112) for {'alpha': 0.1, 'early_stopping': False, 'learning_rate': 'adaptive', 'max_iter': 1000, 'momentum': 0.1, 'solver': 'sgd'}\n",
      "0.772 (+/-0.093) for {'alpha': 0.1, 'early_stopping': False, 'learning_rate': 'adaptive', 'max_iter': 1000, 'momentum': 0.3, 'solver': 'sgd'}\n",
      "0.775 (+/-0.073) for {'alpha': 0.1, 'early_stopping': False, 'learning_rate': 'adaptive', 'max_iter': 1000, 'momentum': 0.5, 'solver': 'sgd'}\n",
      "0.784 (+/-0.078) for {'alpha': 0.1, 'early_stopping': False, 'learning_rate': 'adaptive', 'max_iter': 1000, 'momentum': 0.7, 'solver': 'sgd'}\n",
      "0.788 (+/-0.083) for {'alpha': 0.1, 'early_stopping': False, 'learning_rate': 'adaptive', 'max_iter': 1000, 'momentum': 0.9, 'solver': 'sgd'}\n",
      "0.770 (+/-0.106) for {'alpha': 0.1, 'early_stopping': False, 'learning_rate': 'adaptive', 'max_iter': 1500, 'momentum': 0.1, 'solver': 'sgd'}\n",
      "0.774 (+/-0.072) for {'alpha': 0.1, 'early_stopping': False, 'learning_rate': 'adaptive', 'max_iter': 1500, 'momentum': 0.3, 'solver': 'sgd'}\n",
      "0.789 (+/-0.082) for {'alpha': 0.1, 'early_stopping': False, 'learning_rate': 'adaptive', 'max_iter': 1500, 'momentum': 0.5, 'solver': 'sgd'}\n",
      "0.787 (+/-0.071) for {'alpha': 0.1, 'early_stopping': False, 'learning_rate': 'adaptive', 'max_iter': 1500, 'momentum': 0.7, 'solver': 'sgd'}\n",
      "0.784 (+/-0.084) for {'alpha': 0.1, 'early_stopping': False, 'learning_rate': 'adaptive', 'max_iter': 1500, 'momentum': 0.9, 'solver': 'sgd'}\n",
      "0.777 (+/-0.082) for {'alpha': 0.1, 'early_stopping': False, 'learning_rate': 'adaptive', 'max_iter': 2000, 'momentum': 0.1, 'solver': 'sgd'}\n",
      "0.801 (+/-0.102) for {'alpha': 0.1, 'early_stopping': False, 'learning_rate': 'adaptive', 'max_iter': 2000, 'momentum': 0.3, 'solver': 'sgd'}\n",
      "0.780 (+/-0.086) for {'alpha': 0.1, 'early_stopping': False, 'learning_rate': 'adaptive', 'max_iter': 2000, 'momentum': 0.5, 'solver': 'sgd'}\n",
      "0.792 (+/-0.072) for {'alpha': 0.1, 'early_stopping': False, 'learning_rate': 'adaptive', 'max_iter': 2000, 'momentum': 0.7, 'solver': 'sgd'}\n",
      "0.782 (+/-0.077) for {'alpha': 0.1, 'early_stopping': False, 'learning_rate': 'adaptive', 'max_iter': 2000, 'momentum': 0.9, 'solver': 'sgd'}\n",
      "0.524 (+/-0.240) for {'alpha': 1, 'early_stopping': True, 'learning_rate': 'constant', 'max_iter': 1000, 'momentum': 0.1, 'solver': 'sgd'}\n",
      "0.493 (+/-0.233) for {'alpha': 1, 'early_stopping': True, 'learning_rate': 'constant', 'max_iter': 1000, 'momentum': 0.3, 'solver': 'sgd'}\n",
      "0.486 (+/-0.278) for {'alpha': 1, 'early_stopping': True, 'learning_rate': 'constant', 'max_iter': 1000, 'momentum': 0.5, 'solver': 'sgd'}\n",
      "0.569 (+/-0.243) for {'alpha': 1, 'early_stopping': True, 'learning_rate': 'constant', 'max_iter': 1000, 'momentum': 0.7, 'solver': 'sgd'}\n",
      "0.711 (+/-0.091) for {'alpha': 1, 'early_stopping': True, 'learning_rate': 'constant', 'max_iter': 1000, 'momentum': 0.9, 'solver': 'sgd'}\n",
      "0.550 (+/-0.166) for {'alpha': 1, 'early_stopping': True, 'learning_rate': 'constant', 'max_iter': 1500, 'momentum': 0.1, 'solver': 'sgd'}\n",
      "0.529 (+/-0.312) for {'alpha': 1, 'early_stopping': True, 'learning_rate': 'constant', 'max_iter': 1500, 'momentum': 0.3, 'solver': 'sgd'}\n",
      "0.612 (+/-0.082) for {'alpha': 1, 'early_stopping': True, 'learning_rate': 'constant', 'max_iter': 1500, 'momentum': 0.5, 'solver': 'sgd'}\n",
      "0.633 (+/-0.121) for {'alpha': 1, 'early_stopping': True, 'learning_rate': 'constant', 'max_iter': 1500, 'momentum': 0.7, 'solver': 'sgd'}\n",
      "0.713 (+/-0.086) for {'alpha': 1, 'early_stopping': True, 'learning_rate': 'constant', 'max_iter': 1500, 'momentum': 0.9, 'solver': 'sgd'}\n",
      "0.504 (+/-0.225) for {'alpha': 1, 'early_stopping': True, 'learning_rate': 'constant', 'max_iter': 2000, 'momentum': 0.1, 'solver': 'sgd'}\n",
      "0.566 (+/-0.266) for {'alpha': 1, 'early_stopping': True, 'learning_rate': 'constant', 'max_iter': 2000, 'momentum': 0.3, 'solver': 'sgd'}\n",
      "0.560 (+/-0.246) for {'alpha': 1, 'early_stopping': True, 'learning_rate': 'constant', 'max_iter': 2000, 'momentum': 0.5, 'solver': 'sgd'}\n",
      "0.538 (+/-0.317) for {'alpha': 1, 'early_stopping': True, 'learning_rate': 'constant', 'max_iter': 2000, 'momentum': 0.7, 'solver': 'sgd'}\n",
      "0.701 (+/-0.139) for {'alpha': 1, 'early_stopping': True, 'learning_rate': 'constant', 'max_iter': 2000, 'momentum': 0.9, 'solver': 'sgd'}\n",
      "0.546 (+/-0.234) for {'alpha': 1, 'early_stopping': True, 'learning_rate': 'invscaling', 'max_iter': 1000, 'momentum': 0.1, 'solver': 'sgd'}\n",
      "0.510 (+/-0.211) for {'alpha': 1, 'early_stopping': True, 'learning_rate': 'invscaling', 'max_iter': 1000, 'momentum': 0.3, 'solver': 'sgd'}\n",
      "0.507 (+/-0.244) for {'alpha': 1, 'early_stopping': True, 'learning_rate': 'invscaling', 'max_iter': 1000, 'momentum': 0.5, 'solver': 'sgd'}\n",
      "0.525 (+/-0.217) for {'alpha': 1, 'early_stopping': True, 'learning_rate': 'invscaling', 'max_iter': 1000, 'momentum': 0.7, 'solver': 'sgd'}\n",
      "0.532 (+/-0.264) for {'alpha': 1, 'early_stopping': True, 'learning_rate': 'invscaling', 'max_iter': 1000, 'momentum': 0.9, 'solver': 'sgd'}\n",
      "0.531 (+/-0.255) for {'alpha': 1, 'early_stopping': True, 'learning_rate': 'invscaling', 'max_iter': 1500, 'momentum': 0.1, 'solver': 'sgd'}\n",
      "0.458 (+/-0.314) for {'alpha': 1, 'early_stopping': True, 'learning_rate': 'invscaling', 'max_iter': 1500, 'momentum': 0.3, 'solver': 'sgd'}\n",
      "0.479 (+/-0.249) for {'alpha': 1, 'early_stopping': True, 'learning_rate': 'invscaling', 'max_iter': 1500, 'momentum': 0.5, 'solver': 'sgd'}\n",
      "0.489 (+/-0.195) for {'alpha': 1, 'early_stopping': True, 'learning_rate': 'invscaling', 'max_iter': 1500, 'momentum': 0.7, 'solver': 'sgd'}\n",
      "0.525 (+/-0.276) for {'alpha': 1, 'early_stopping': True, 'learning_rate': 'invscaling', 'max_iter': 1500, 'momentum': 0.9, 'solver': 'sgd'}\n",
      "0.519 (+/-0.281) for {'alpha': 1, 'early_stopping': True, 'learning_rate': 'invscaling', 'max_iter': 2000, 'momentum': 0.1, 'solver': 'sgd'}\n",
      "0.594 (+/-0.198) for {'alpha': 1, 'early_stopping': True, 'learning_rate': 'invscaling', 'max_iter': 2000, 'momentum': 0.3, 'solver': 'sgd'}\n",
      "0.517 (+/-0.283) for {'alpha': 1, 'early_stopping': True, 'learning_rate': 'invscaling', 'max_iter': 2000, 'momentum': 0.5, 'solver': 'sgd'}\n",
      "0.489 (+/-0.201) for {'alpha': 1, 'early_stopping': True, 'learning_rate': 'invscaling', 'max_iter': 2000, 'momentum': 0.7, 'solver': 'sgd'}\n",
      "0.466 (+/-0.251) for {'alpha': 1, 'early_stopping': True, 'learning_rate': 'invscaling', 'max_iter': 2000, 'momentum': 0.9, 'solver': 'sgd'}\n",
      "0.575 (+/-0.285) for {'alpha': 1, 'early_stopping': True, 'learning_rate': 'adaptive', 'max_iter': 1000, 'momentum': 0.1, 'solver': 'sgd'}\n",
      "0.552 (+/-0.216) for {'alpha': 1, 'early_stopping': True, 'learning_rate': 'adaptive', 'max_iter': 1000, 'momentum': 0.3, 'solver': 'sgd'}\n",
      "0.521 (+/-0.306) for {'alpha': 1, 'early_stopping': True, 'learning_rate': 'adaptive', 'max_iter': 1000, 'momentum': 0.5, 'solver': 'sgd'}\n",
      "0.613 (+/-0.274) for {'alpha': 1, 'early_stopping': True, 'learning_rate': 'adaptive', 'max_iter': 1000, 'momentum': 0.7, 'solver': 'sgd'}\n",
      "0.678 (+/-0.237) for {'alpha': 1, 'early_stopping': True, 'learning_rate': 'adaptive', 'max_iter': 1000, 'momentum': 0.9, 'solver': 'sgd'}\n",
      "0.577 (+/-0.166) for {'alpha': 1, 'early_stopping': True, 'learning_rate': 'adaptive', 'max_iter': 1500, 'momentum': 0.1, 'solver': 'sgd'}\n",
      "0.534 (+/-0.246) for {'alpha': 1, 'early_stopping': True, 'learning_rate': 'adaptive', 'max_iter': 1500, 'momentum': 0.3, 'solver': 'sgd'}\n",
      "0.511 (+/-0.291) for {'alpha': 1, 'early_stopping': True, 'learning_rate': 'adaptive', 'max_iter': 1500, 'momentum': 0.5, 'solver': 'sgd'}\n",
      "0.651 (+/-0.138) for {'alpha': 1, 'early_stopping': True, 'learning_rate': 'adaptive', 'max_iter': 1500, 'momentum': 0.7, 'solver': 'sgd'}\n",
      "0.692 (+/-0.140) for {'alpha': 1, 'early_stopping': True, 'learning_rate': 'adaptive', 'max_iter': 1500, 'momentum': 0.9, 'solver': 'sgd'}\n",
      "0.569 (+/-0.266) for {'alpha': 1, 'early_stopping': True, 'learning_rate': 'adaptive', 'max_iter': 2000, 'momentum': 0.1, 'solver': 'sgd'}\n",
      "0.586 (+/-0.116) for {'alpha': 1, 'early_stopping': True, 'learning_rate': 'adaptive', 'max_iter': 2000, 'momentum': 0.3, 'solver': 'sgd'}\n",
      "0.632 (+/-0.189) for {'alpha': 1, 'early_stopping': True, 'learning_rate': 'adaptive', 'max_iter': 2000, 'momentum': 0.5, 'solver': 'sgd'}\n",
      "0.573 (+/-0.308) for {'alpha': 1, 'early_stopping': True, 'learning_rate': 'adaptive', 'max_iter': 2000, 'momentum': 0.7, 'solver': 'sgd'}\n",
      "0.676 (+/-0.152) for {'alpha': 1, 'early_stopping': True, 'learning_rate': 'adaptive', 'max_iter': 2000, 'momentum': 0.9, 'solver': 'sgd'}\n",
      "0.770 (+/-0.083) for {'alpha': 1, 'early_stopping': False, 'learning_rate': 'constant', 'max_iter': 1000, 'momentum': 0.1, 'solver': 'sgd'}\n",
      "0.789 (+/-0.104) for {'alpha': 1, 'early_stopping': False, 'learning_rate': 'constant', 'max_iter': 1000, 'momentum': 0.3, 'solver': 'sgd'}\n",
      "0.792 (+/-0.083) for {'alpha': 1, 'early_stopping': False, 'learning_rate': 'constant', 'max_iter': 1000, 'momentum': 0.5, 'solver': 'sgd'}\n",
      "0.788 (+/-0.076) for {'alpha': 1, 'early_stopping': False, 'learning_rate': 'constant', 'max_iter': 1000, 'momentum': 0.7, 'solver': 'sgd'}\n",
      "0.791 (+/-0.081) for {'alpha': 1, 'early_stopping': False, 'learning_rate': 'constant', 'max_iter': 1000, 'momentum': 0.9, 'solver': 'sgd'}\n",
      "0.782 (+/-0.110) for {'alpha': 1, 'early_stopping': False, 'learning_rate': 'constant', 'max_iter': 1500, 'momentum': 0.1, 'solver': 'sgd'}\n",
      "0.785 (+/-0.086) for {'alpha': 1, 'early_stopping': False, 'learning_rate': 'constant', 'max_iter': 1500, 'momentum': 0.3, 'solver': 'sgd'}\n",
      "0.787 (+/-0.085) for {'alpha': 1, 'early_stopping': False, 'learning_rate': 'constant', 'max_iter': 1500, 'momentum': 0.5, 'solver': 'sgd'}\n",
      "0.785 (+/-0.057) for {'alpha': 1, 'early_stopping': False, 'learning_rate': 'constant', 'max_iter': 1500, 'momentum': 0.7, 'solver': 'sgd'}\n",
      "0.791 (+/-0.072) for {'alpha': 1, 'early_stopping': False, 'learning_rate': 'constant', 'max_iter': 1500, 'momentum': 0.9, 'solver': 'sgd'}\n",
      "0.778 (+/-0.098) for {'alpha': 1, 'early_stopping': False, 'learning_rate': 'constant', 'max_iter': 2000, 'momentum': 0.1, 'solver': 'sgd'}\n",
      "0.801 (+/-0.093) for {'alpha': 1, 'early_stopping': False, 'learning_rate': 'constant', 'max_iter': 2000, 'momentum': 0.3, 'solver': 'sgd'}\n",
      "0.794 (+/-0.081) for {'alpha': 1, 'early_stopping': False, 'learning_rate': 'constant', 'max_iter': 2000, 'momentum': 0.5, 'solver': 'sgd'}\n",
      "0.789 (+/-0.083) for {'alpha': 1, 'early_stopping': False, 'learning_rate': 'constant', 'max_iter': 2000, 'momentum': 0.7, 'solver': 'sgd'}\n",
      "0.795 (+/-0.076) for {'alpha': 1, 'early_stopping': False, 'learning_rate': 'constant', 'max_iter': 2000, 'momentum': 0.9, 'solver': 'sgd'}\n",
      "0.482 (+/-0.247) for {'alpha': 1, 'early_stopping': False, 'learning_rate': 'invscaling', 'max_iter': 1000, 'momentum': 0.1, 'solver': 'sgd'}\n",
      "0.575 (+/-0.300) for {'alpha': 1, 'early_stopping': False, 'learning_rate': 'invscaling', 'max_iter': 1000, 'momentum': 0.3, 'solver': 'sgd'}\n",
      "0.503 (+/-0.253) for {'alpha': 1, 'early_stopping': False, 'learning_rate': 'invscaling', 'max_iter': 1000, 'momentum': 0.5, 'solver': 'sgd'}\n",
      "0.575 (+/-0.240) for {'alpha': 1, 'early_stopping': False, 'learning_rate': 'invscaling', 'max_iter': 1000, 'momentum': 0.7, 'solver': 'sgd'}\n",
      "0.563 (+/-0.220) for {'alpha': 1, 'early_stopping': False, 'learning_rate': 'invscaling', 'max_iter': 1000, 'momentum': 0.9, 'solver': 'sgd'}\n",
      "0.491 (+/-0.301) for {'alpha': 1, 'early_stopping': False, 'learning_rate': 'invscaling', 'max_iter': 1500, 'momentum': 0.1, 'solver': 'sgd'}\n",
      "0.483 (+/-0.246) for {'alpha': 1, 'early_stopping': False, 'learning_rate': 'invscaling', 'max_iter': 1500, 'momentum': 0.3, 'solver': 'sgd'}\n",
      "0.487 (+/-0.181) for {'alpha': 1, 'early_stopping': False, 'learning_rate': 'invscaling', 'max_iter': 1500, 'momentum': 0.5, 'solver': 'sgd'}\n",
      "0.524 (+/-0.276) for {'alpha': 1, 'early_stopping': False, 'learning_rate': 'invscaling', 'max_iter': 1500, 'momentum': 0.7, 'solver': 'sgd'}\n",
      "0.458 (+/-0.270) for {'alpha': 1, 'early_stopping': False, 'learning_rate': 'invscaling', 'max_iter': 1500, 'momentum': 0.9, 'solver': 'sgd'}\n",
      "0.479 (+/-0.200) for {'alpha': 1, 'early_stopping': False, 'learning_rate': 'invscaling', 'max_iter': 2000, 'momentum': 0.1, 'solver': 'sgd'}\n",
      "0.501 (+/-0.294) for {'alpha': 1, 'early_stopping': False, 'learning_rate': 'invscaling', 'max_iter': 2000, 'momentum': 0.3, 'solver': 'sgd'}\n",
      "0.516 (+/-0.203) for {'alpha': 1, 'early_stopping': False, 'learning_rate': 'invscaling', 'max_iter': 2000, 'momentum': 0.5, 'solver': 'sgd'}\n",
      "0.552 (+/-0.312) for {'alpha': 1, 'early_stopping': False, 'learning_rate': 'invscaling', 'max_iter': 2000, 'momentum': 0.7, 'solver': 'sgd'}\n",
      "0.548 (+/-0.310) for {'alpha': 1, 'early_stopping': False, 'learning_rate': 'invscaling', 'max_iter': 2000, 'momentum': 0.9, 'solver': 'sgd'}\n",
      "0.798 (+/-0.104) for {'alpha': 1, 'early_stopping': False, 'learning_rate': 'adaptive', 'max_iter': 1000, 'momentum': 0.1, 'solver': 'sgd'}\n",
      "0.792 (+/-0.091) for {'alpha': 1, 'early_stopping': False, 'learning_rate': 'adaptive', 'max_iter': 1000, 'momentum': 0.3, 'solver': 'sgd'}\n",
      "0.777 (+/-0.086) for {'alpha': 1, 'early_stopping': False, 'learning_rate': 'adaptive', 'max_iter': 1000, 'momentum': 0.5, 'solver': 'sgd'}\n",
      "0.788 (+/-0.088) for {'alpha': 1, 'early_stopping': False, 'learning_rate': 'adaptive', 'max_iter': 1000, 'momentum': 0.7, 'solver': 'sgd'}\n",
      "0.794 (+/-0.077) for {'alpha': 1, 'early_stopping': False, 'learning_rate': 'adaptive', 'max_iter': 1000, 'momentum': 0.9, 'solver': 'sgd'}\n",
      "0.786 (+/-0.072) for {'alpha': 1, 'early_stopping': False, 'learning_rate': 'adaptive', 'max_iter': 1500, 'momentum': 0.1, 'solver': 'sgd'}\n",
      "0.785 (+/-0.082) for {'alpha': 1, 'early_stopping': False, 'learning_rate': 'adaptive', 'max_iter': 1500, 'momentum': 0.3, 'solver': 'sgd'}\n",
      "0.789 (+/-0.098) for {'alpha': 1, 'early_stopping': False, 'learning_rate': 'adaptive', 'max_iter': 1500, 'momentum': 0.5, 'solver': 'sgd'}\n",
      "0.788 (+/-0.076) for {'alpha': 1, 'early_stopping': False, 'learning_rate': 'adaptive', 'max_iter': 1500, 'momentum': 0.7, 'solver': 'sgd'}\n",
      "0.789 (+/-0.074) for {'alpha': 1, 'early_stopping': False, 'learning_rate': 'adaptive', 'max_iter': 1500, 'momentum': 0.9, 'solver': 'sgd'}\n",
      "0.784 (+/-0.114) for {'alpha': 1, 'early_stopping': False, 'learning_rate': 'adaptive', 'max_iter': 2000, 'momentum': 0.1, 'solver': 'sgd'}\n",
      "0.784 (+/-0.069) for {'alpha': 1, 'early_stopping': False, 'learning_rate': 'adaptive', 'max_iter': 2000, 'momentum': 0.3, 'solver': 'sgd'}\n",
      "0.787 (+/-0.079) for {'alpha': 1, 'early_stopping': False, 'learning_rate': 'adaptive', 'max_iter': 2000, 'momentum': 0.5, 'solver': 'sgd'}\n",
      "0.782 (+/-0.099) for {'alpha': 1, 'early_stopping': False, 'learning_rate': 'adaptive', 'max_iter': 2000, 'momentum': 0.7, 'solver': 'sgd'}\n",
      "0.788 (+/-0.068) for {'alpha': 1, 'early_stopping': False, 'learning_rate': 'adaptive', 'max_iter': 2000, 'momentum': 0.9, 'solver': 'sgd'}\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.89      0.90      0.90       114\n",
      "         1.0       0.82      0.80      0.81        64\n",
      "\n",
      "    accuracy                           0.87       178\n",
      "   macro avg       0.86      0.85      0.85       178\n",
      "weighted avg       0.86      0.87      0.86       178\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "tuned_parameters = [{ 'alpha':[0.0001,0.001,0.01,0.1,1], 'max_iter':[1000,1500,2000],\n",
    "      'solver':['adam'], 'early_stopping':[True, False]},\n",
    "                    { 'alpha':[0.0001,0.001,0.01,0.1,1],\n",
    "'max_iter':[1000,1500,2000],'momentum':[0.1,0.3,0.5,0.7,0.9],\n",
    "                     'solver':['sgd'], 'early_stopping':[True, False],'learning_rate':['constant','invscaling','adaptive']},\n",
    "                    ]\n",
    "\n",
    "\n",
    "print()\n",
    "\n",
    "clf = GridSearchCV(\n",
    "    MLPClassifier(), tuned_parameters, scoring='accuracy', cv=10\n",
    ")\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best parameters set found on development set:\")\n",
    "print()\n",
    "print(clf.best_params_)\n",
    "print()\n",
    "print(\"Grid scores on development set:\")\n",
    "print()\n",
    "means = clf.cv_results_['mean_test_score']\n",
    "stds = clf.cv_results_['std_test_score']\n",
    "for mean, std, params in zip(means, stds, clf.cv_results_['params']):\n",
    "    print(\"%0.3f (+/-%0.03f) for %r\"\n",
    "          % (mean, std * 2, params))\n",
    "print()\n",
    "\n",
    "print(\"Detailed classification report:\")\n",
    "print()\n",
    "print(\"The model is trained on the full development set.\")\n",
    "print(\"The scores are computed on the full evaluation set.\")\n",
    "print()\n",
    "y_true, y_pred = y_test, clf.predict(X_test)\n",
    "print(classification_report(y_true, y_pred))\n",
    "print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XFGkbUewTrHN"
   },
   "source": [
    "###Cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "c4aD0u-YSbcp",
    "outputId": "f570647c-e9ff-4f62-9571-a62fba266d3e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.801348\n"
     ]
    }
   ],
   "source": [
    "clf = MLPClassifier(alpha= 0.01, early_stopping= False, max_iter= 2000, solver='adam')\n",
    "score=cross_validate(clf, X, y, cv=10, scoring=\"accuracy\")[\"test_score\"].mean()\n",
    "print(f\"{score:.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1oY7OpOMMjbA"
   },
   "source": [
    "### Generating Predicion Result for submission in .csv format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZjT-qeiMr91u"
   },
   "outputs": [],
   "source": [
    "df2 = pd.read_csv(url2)\n",
    "clf = MLPClassifier(alpha= 0.01, early_stopping= False, max_iter= 2000, solver='adam')\n",
    "clf.fit(X, y)\n",
    "pred=clf.predict(X_test2)\n",
    "pd.DataFrame({\"PassengerId\": df2[\"PassengerId\"], \"Survived\": pred}).to_csv(\"MLP_submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GZ-lxD2aAHX6"
   },
   "source": [
    "![alt text](https://raw.githubusercontent.com/zyzhang1130/CE9010/master/Titanic/mlp.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nZyDLaUo7BjQ"
   },
   "source": [
    "## Gradient Boosting Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "3WR9I_zx7Gx2",
    "outputId": "12a551e2-e05e-4c3b-a57e-d11a782699e1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best parameters set found on development set:\n",
      "\n",
      "{'learning_rate': 0.1, 'loss': 'exponential', 'max_depth': 4, 'warm_start': True}\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "0.610 (+/-0.011) for {'learning_rate': 0.001, 'loss': 'deviance', 'max_depth': 1, 'warm_start': True}\n",
      "0.610 (+/-0.011) for {'learning_rate': 0.001, 'loss': 'deviance', 'max_depth': 1, 'warm_start': False}\n",
      "0.610 (+/-0.011) for {'learning_rate': 0.001, 'loss': 'deviance', 'max_depth': 2, 'warm_start': True}\n",
      "0.610 (+/-0.011) for {'learning_rate': 0.001, 'loss': 'deviance', 'max_depth': 2, 'warm_start': False}\n",
      "0.610 (+/-0.011) for {'learning_rate': 0.001, 'loss': 'deviance', 'max_depth': 3, 'warm_start': True}\n",
      "0.610 (+/-0.011) for {'learning_rate': 0.001, 'loss': 'deviance', 'max_depth': 3, 'warm_start': False}\n",
      "0.610 (+/-0.011) for {'learning_rate': 0.001, 'loss': 'deviance', 'max_depth': 4, 'warm_start': True}\n",
      "0.610 (+/-0.011) for {'learning_rate': 0.001, 'loss': 'deviance', 'max_depth': 4, 'warm_start': False}\n",
      "0.610 (+/-0.011) for {'learning_rate': 0.001, 'loss': 'deviance', 'max_depth': 5, 'warm_start': True}\n",
      "0.610 (+/-0.011) for {'learning_rate': 0.001, 'loss': 'deviance', 'max_depth': 5, 'warm_start': False}\n",
      "0.610 (+/-0.011) for {'learning_rate': 0.001, 'loss': 'deviance', 'max_depth': 6, 'warm_start': True}\n",
      "0.610 (+/-0.011) for {'learning_rate': 0.001, 'loss': 'deviance', 'max_depth': 6, 'warm_start': False}\n",
      "0.610 (+/-0.011) for {'learning_rate': 0.001, 'loss': 'deviance', 'max_depth': 7, 'warm_start': True}\n",
      "0.610 (+/-0.011) for {'learning_rate': 0.001, 'loss': 'deviance', 'max_depth': 7, 'warm_start': False}\n",
      "0.610 (+/-0.011) for {'learning_rate': 0.001, 'loss': 'deviance', 'max_depth': 8, 'warm_start': True}\n",
      "0.610 (+/-0.011) for {'learning_rate': 0.001, 'loss': 'deviance', 'max_depth': 8, 'warm_start': False}\n",
      "0.610 (+/-0.011) for {'learning_rate': 0.001, 'loss': 'deviance', 'max_depth': 9, 'warm_start': True}\n",
      "0.610 (+/-0.011) for {'learning_rate': 0.001, 'loss': 'deviance', 'max_depth': 9, 'warm_start': False}\n",
      "0.610 (+/-0.011) for {'learning_rate': 0.001, 'loss': 'exponential', 'max_depth': 1, 'warm_start': True}\n",
      "0.610 (+/-0.011) for {'learning_rate': 0.001, 'loss': 'exponential', 'max_depth': 1, 'warm_start': False}\n",
      "0.610 (+/-0.011) for {'learning_rate': 0.001, 'loss': 'exponential', 'max_depth': 2, 'warm_start': True}\n",
      "0.610 (+/-0.011) for {'learning_rate': 0.001, 'loss': 'exponential', 'max_depth': 2, 'warm_start': False}\n",
      "0.610 (+/-0.011) for {'learning_rate': 0.001, 'loss': 'exponential', 'max_depth': 3, 'warm_start': True}\n",
      "0.610 (+/-0.011) for {'learning_rate': 0.001, 'loss': 'exponential', 'max_depth': 3, 'warm_start': False}\n",
      "0.610 (+/-0.011) for {'learning_rate': 0.001, 'loss': 'exponential', 'max_depth': 4, 'warm_start': True}\n",
      "0.610 (+/-0.011) for {'learning_rate': 0.001, 'loss': 'exponential', 'max_depth': 4, 'warm_start': False}\n",
      "0.610 (+/-0.011) for {'learning_rate': 0.001, 'loss': 'exponential', 'max_depth': 5, 'warm_start': True}\n",
      "0.610 (+/-0.011) for {'learning_rate': 0.001, 'loss': 'exponential', 'max_depth': 5, 'warm_start': False}\n",
      "0.610 (+/-0.011) for {'learning_rate': 0.001, 'loss': 'exponential', 'max_depth': 6, 'warm_start': True}\n",
      "0.610 (+/-0.011) for {'learning_rate': 0.001, 'loss': 'exponential', 'max_depth': 6, 'warm_start': False}\n",
      "0.610 (+/-0.011) for {'learning_rate': 0.001, 'loss': 'exponential', 'max_depth': 7, 'warm_start': True}\n",
      "0.610 (+/-0.011) for {'learning_rate': 0.001, 'loss': 'exponential', 'max_depth': 7, 'warm_start': False}\n",
      "0.610 (+/-0.011) for {'learning_rate': 0.001, 'loss': 'exponential', 'max_depth': 8, 'warm_start': True}\n",
      "0.610 (+/-0.011) for {'learning_rate': 0.001, 'loss': 'exponential', 'max_depth': 8, 'warm_start': False}\n",
      "0.610 (+/-0.011) for {'learning_rate': 0.001, 'loss': 'exponential', 'max_depth': 9, 'warm_start': True}\n",
      "0.610 (+/-0.011) for {'learning_rate': 0.001, 'loss': 'exponential', 'max_depth': 9, 'warm_start': False}\n",
      "0.784 (+/-0.090) for {'learning_rate': 0.01, 'loss': 'deviance', 'max_depth': 1, 'warm_start': True}\n",
      "0.784 (+/-0.090) for {'learning_rate': 0.01, 'loss': 'deviance', 'max_depth': 1, 'warm_start': False}\n",
      "0.780 (+/-0.082) for {'learning_rate': 0.01, 'loss': 'deviance', 'max_depth': 2, 'warm_start': True}\n",
      "0.780 (+/-0.082) for {'learning_rate': 0.01, 'loss': 'deviance', 'max_depth': 2, 'warm_start': False}\n",
      "0.802 (+/-0.094) for {'learning_rate': 0.01, 'loss': 'deviance', 'max_depth': 3, 'warm_start': True}\n",
      "0.802 (+/-0.094) for {'learning_rate': 0.01, 'loss': 'deviance', 'max_depth': 3, 'warm_start': False}\n",
      "0.812 (+/-0.091) for {'learning_rate': 0.01, 'loss': 'deviance', 'max_depth': 4, 'warm_start': True}\n",
      "0.812 (+/-0.091) for {'learning_rate': 0.01, 'loss': 'deviance', 'max_depth': 4, 'warm_start': False}\n",
      "0.816 (+/-0.089) for {'learning_rate': 0.01, 'loss': 'deviance', 'max_depth': 5, 'warm_start': True}\n",
      "0.815 (+/-0.092) for {'learning_rate': 0.01, 'loss': 'deviance', 'max_depth': 5, 'warm_start': False}\n",
      "0.816 (+/-0.084) for {'learning_rate': 0.01, 'loss': 'deviance', 'max_depth': 6, 'warm_start': True}\n",
      "0.815 (+/-0.086) for {'learning_rate': 0.01, 'loss': 'deviance', 'max_depth': 6, 'warm_start': False}\n",
      "0.813 (+/-0.083) for {'learning_rate': 0.01, 'loss': 'deviance', 'max_depth': 7, 'warm_start': True}\n",
      "0.812 (+/-0.086) for {'learning_rate': 0.01, 'loss': 'deviance', 'max_depth': 7, 'warm_start': False}\n",
      "0.816 (+/-0.099) for {'learning_rate': 0.01, 'loss': 'deviance', 'max_depth': 8, 'warm_start': True}\n",
      "0.816 (+/-0.102) for {'learning_rate': 0.01, 'loss': 'deviance', 'max_depth': 8, 'warm_start': False}\n",
      "0.799 (+/-0.119) for {'learning_rate': 0.01, 'loss': 'deviance', 'max_depth': 9, 'warm_start': True}\n",
      "0.798 (+/-0.111) for {'learning_rate': 0.01, 'loss': 'deviance', 'max_depth': 9, 'warm_start': False}\n",
      "0.784 (+/-0.090) for {'learning_rate': 0.01, 'loss': 'exponential', 'max_depth': 1, 'warm_start': True}\n",
      "0.784 (+/-0.090) for {'learning_rate': 0.01, 'loss': 'exponential', 'max_depth': 1, 'warm_start': False}\n",
      "0.780 (+/-0.082) for {'learning_rate': 0.01, 'loss': 'exponential', 'max_depth': 2, 'warm_start': True}\n",
      "0.780 (+/-0.082) for {'learning_rate': 0.01, 'loss': 'exponential', 'max_depth': 2, 'warm_start': False}\n",
      "0.801 (+/-0.096) for {'learning_rate': 0.01, 'loss': 'exponential', 'max_depth': 3, 'warm_start': True}\n",
      "0.801 (+/-0.096) for {'learning_rate': 0.01, 'loss': 'exponential', 'max_depth': 3, 'warm_start': False}\n",
      "0.809 (+/-0.095) for {'learning_rate': 0.01, 'loss': 'exponential', 'max_depth': 4, 'warm_start': True}\n",
      "0.809 (+/-0.095) for {'learning_rate': 0.01, 'loss': 'exponential', 'max_depth': 4, 'warm_start': False}\n",
      "0.811 (+/-0.089) for {'learning_rate': 0.01, 'loss': 'exponential', 'max_depth': 5, 'warm_start': True}\n",
      "0.811 (+/-0.089) for {'learning_rate': 0.01, 'loss': 'exponential', 'max_depth': 5, 'warm_start': False}\n",
      "0.815 (+/-0.092) for {'learning_rate': 0.01, 'loss': 'exponential', 'max_depth': 6, 'warm_start': True}\n",
      "0.817 (+/-0.087) for {'learning_rate': 0.01, 'loss': 'exponential', 'max_depth': 6, 'warm_start': False}\n",
      "0.813 (+/-0.084) for {'learning_rate': 0.01, 'loss': 'exponential', 'max_depth': 7, 'warm_start': True}\n",
      "0.815 (+/-0.083) for {'learning_rate': 0.01, 'loss': 'exponential', 'max_depth': 7, 'warm_start': False}\n",
      "0.815 (+/-0.092) for {'learning_rate': 0.01, 'loss': 'exponential', 'max_depth': 8, 'warm_start': True}\n",
      "0.816 (+/-0.093) for {'learning_rate': 0.01, 'loss': 'exponential', 'max_depth': 8, 'warm_start': False}\n",
      "0.801 (+/-0.106) for {'learning_rate': 0.01, 'loss': 'exponential', 'max_depth': 9, 'warm_start': True}\n",
      "0.802 (+/-0.107) for {'learning_rate': 0.01, 'loss': 'exponential', 'max_depth': 9, 'warm_start': False}\n",
      "0.802 (+/-0.097) for {'learning_rate': 0.1, 'loss': 'deviance', 'max_depth': 1, 'warm_start': True}\n",
      "0.802 (+/-0.097) for {'learning_rate': 0.1, 'loss': 'deviance', 'max_depth': 1, 'warm_start': False}\n",
      "0.819 (+/-0.094) for {'learning_rate': 0.1, 'loss': 'deviance', 'max_depth': 2, 'warm_start': True}\n",
      "0.819 (+/-0.094) for {'learning_rate': 0.1, 'loss': 'deviance', 'max_depth': 2, 'warm_start': False}\n",
      "0.827 (+/-0.082) for {'learning_rate': 0.1, 'loss': 'deviance', 'max_depth': 3, 'warm_start': True}\n",
      "0.827 (+/-0.082) for {'learning_rate': 0.1, 'loss': 'deviance', 'max_depth': 3, 'warm_start': False}\n",
      "0.827 (+/-0.085) for {'learning_rate': 0.1, 'loss': 'deviance', 'max_depth': 4, 'warm_start': True}\n",
      "0.829 (+/-0.083) for {'learning_rate': 0.1, 'loss': 'deviance', 'max_depth': 4, 'warm_start': False}\n",
      "0.816 (+/-0.072) for {'learning_rate': 0.1, 'loss': 'deviance', 'max_depth': 5, 'warm_start': True}\n",
      "0.817 (+/-0.070) for {'learning_rate': 0.1, 'loss': 'deviance', 'max_depth': 5, 'warm_start': False}\n",
      "0.801 (+/-0.100) for {'learning_rate': 0.1, 'loss': 'deviance', 'max_depth': 6, 'warm_start': True}\n",
      "0.803 (+/-0.092) for {'learning_rate': 0.1, 'loss': 'deviance', 'max_depth': 6, 'warm_start': False}\n",
      "0.794 (+/-0.096) for {'learning_rate': 0.1, 'loss': 'deviance', 'max_depth': 7, 'warm_start': True}\n",
      "0.801 (+/-0.095) for {'learning_rate': 0.1, 'loss': 'deviance', 'max_depth': 7, 'warm_start': False}\n",
      "0.801 (+/-0.116) for {'learning_rate': 0.1, 'loss': 'deviance', 'max_depth': 8, 'warm_start': True}\n",
      "0.796 (+/-0.119) for {'learning_rate': 0.1, 'loss': 'deviance', 'max_depth': 8, 'warm_start': False}\n",
      "0.798 (+/-0.129) for {'learning_rate': 0.1, 'loss': 'deviance', 'max_depth': 9, 'warm_start': True}\n",
      "0.795 (+/-0.124) for {'learning_rate': 0.1, 'loss': 'deviance', 'max_depth': 9, 'warm_start': False}\n",
      "0.791 (+/-0.091) for {'learning_rate': 0.1, 'loss': 'exponential', 'max_depth': 1, 'warm_start': True}\n",
      "0.791 (+/-0.091) for {'learning_rate': 0.1, 'loss': 'exponential', 'max_depth': 1, 'warm_start': False}\n",
      "0.809 (+/-0.112) for {'learning_rate': 0.1, 'loss': 'exponential', 'max_depth': 2, 'warm_start': True}\n",
      "0.809 (+/-0.112) for {'learning_rate': 0.1, 'loss': 'exponential', 'max_depth': 2, 'warm_start': False}\n",
      "0.829 (+/-0.082) for {'learning_rate': 0.1, 'loss': 'exponential', 'max_depth': 3, 'warm_start': True}\n",
      "0.829 (+/-0.082) for {'learning_rate': 0.1, 'loss': 'exponential', 'max_depth': 3, 'warm_start': False}\n",
      "0.830 (+/-0.090) for {'learning_rate': 0.1, 'loss': 'exponential', 'max_depth': 4, 'warm_start': True}\n",
      "0.830 (+/-0.090) for {'learning_rate': 0.1, 'loss': 'exponential', 'max_depth': 4, 'warm_start': False}\n",
      "0.812 (+/-0.086) for {'learning_rate': 0.1, 'loss': 'exponential', 'max_depth': 5, 'warm_start': True}\n",
      "0.813 (+/-0.084) for {'learning_rate': 0.1, 'loss': 'exponential', 'max_depth': 5, 'warm_start': False}\n",
      "0.806 (+/-0.087) for {'learning_rate': 0.1, 'loss': 'exponential', 'max_depth': 6, 'warm_start': True}\n",
      "0.799 (+/-0.098) for {'learning_rate': 0.1, 'loss': 'exponential', 'max_depth': 6, 'warm_start': False}\n",
      "0.798 (+/-0.092) for {'learning_rate': 0.1, 'loss': 'exponential', 'max_depth': 7, 'warm_start': True}\n",
      "0.803 (+/-0.111) for {'learning_rate': 0.1, 'loss': 'exponential', 'max_depth': 7, 'warm_start': False}\n",
      "0.794 (+/-0.103) for {'learning_rate': 0.1, 'loss': 'exponential', 'max_depth': 8, 'warm_start': True}\n",
      "0.791 (+/-0.094) for {'learning_rate': 0.1, 'loss': 'exponential', 'max_depth': 8, 'warm_start': False}\n",
      "0.784 (+/-0.120) for {'learning_rate': 0.1, 'loss': 'exponential', 'max_depth': 9, 'warm_start': True}\n",
      "0.805 (+/-0.114) for {'learning_rate': 0.1, 'loss': 'exponential', 'max_depth': 9, 'warm_start': False}\n",
      "0.810 (+/-0.094) for {'learning_rate': 1, 'loss': 'deviance', 'max_depth': 1, 'warm_start': True}\n",
      "0.810 (+/-0.094) for {'learning_rate': 1, 'loss': 'deviance', 'max_depth': 1, 'warm_start': False}\n",
      "0.799 (+/-0.102) for {'learning_rate': 1, 'loss': 'deviance', 'max_depth': 2, 'warm_start': True}\n",
      "0.799 (+/-0.102) for {'learning_rate': 1, 'loss': 'deviance', 'max_depth': 2, 'warm_start': False}\n",
      "0.786 (+/-0.114) for {'learning_rate': 1, 'loss': 'deviance', 'max_depth': 3, 'warm_start': True}\n",
      "0.791 (+/-0.113) for {'learning_rate': 1, 'loss': 'deviance', 'max_depth': 3, 'warm_start': False}\n",
      "0.775 (+/-0.137) for {'learning_rate': 1, 'loss': 'deviance', 'max_depth': 4, 'warm_start': True}\n",
      "0.778 (+/-0.134) for {'learning_rate': 1, 'loss': 'deviance', 'max_depth': 4, 'warm_start': False}\n",
      "0.784 (+/-0.133) for {'learning_rate': 1, 'loss': 'deviance', 'max_depth': 5, 'warm_start': True}\n",
      "0.785 (+/-0.130) for {'learning_rate': 1, 'loss': 'deviance', 'max_depth': 5, 'warm_start': False}\n",
      "0.784 (+/-0.113) for {'learning_rate': 1, 'loss': 'deviance', 'max_depth': 6, 'warm_start': True}\n",
      "0.792 (+/-0.132) for {'learning_rate': 1, 'loss': 'deviance', 'max_depth': 6, 'warm_start': False}\n",
      "0.796 (+/-0.095) for {'learning_rate': 1, 'loss': 'deviance', 'max_depth': 7, 'warm_start': True}\n",
      "0.801 (+/-0.104) for {'learning_rate': 1, 'loss': 'deviance', 'max_depth': 7, 'warm_start': False}\n",
      "0.793 (+/-0.112) for {'learning_rate': 1, 'loss': 'deviance', 'max_depth': 8, 'warm_start': True}\n",
      "0.789 (+/-0.109) for {'learning_rate': 1, 'loss': 'deviance', 'max_depth': 8, 'warm_start': False}\n",
      "0.791 (+/-0.107) for {'learning_rate': 1, 'loss': 'deviance', 'max_depth': 9, 'warm_start': True}\n",
      "0.784 (+/-0.114) for {'learning_rate': 1, 'loss': 'deviance', 'max_depth': 9, 'warm_start': False}\n",
      "0.813 (+/-0.104) for {'learning_rate': 1, 'loss': 'exponential', 'max_depth': 1, 'warm_start': True}\n",
      "0.813 (+/-0.104) for {'learning_rate': 1, 'loss': 'exponential', 'max_depth': 1, 'warm_start': False}\n",
      "0.799 (+/-0.110) for {'learning_rate': 1, 'loss': 'exponential', 'max_depth': 2, 'warm_start': True}\n",
      "0.799 (+/-0.110) for {'learning_rate': 1, 'loss': 'exponential', 'max_depth': 2, 'warm_start': False}\n",
      "0.784 (+/-0.138) for {'learning_rate': 1, 'loss': 'exponential', 'max_depth': 3, 'warm_start': True}\n",
      "0.785 (+/-0.137) for {'learning_rate': 1, 'loss': 'exponential', 'max_depth': 3, 'warm_start': False}\n",
      "0.782 (+/-0.123) for {'learning_rate': 1, 'loss': 'exponential', 'max_depth': 4, 'warm_start': True}\n",
      "0.785 (+/-0.131) for {'learning_rate': 1, 'loss': 'exponential', 'max_depth': 4, 'warm_start': False}\n",
      "0.794 (+/-0.113) for {'learning_rate': 1, 'loss': 'exponential', 'max_depth': 5, 'warm_start': True}\n",
      "0.789 (+/-0.093) for {'learning_rate': 1, 'loss': 'exponential', 'max_depth': 5, 'warm_start': False}\n",
      "0.791 (+/-0.132) for {'learning_rate': 1, 'loss': 'exponential', 'max_depth': 6, 'warm_start': True}\n",
      "0.787 (+/-0.135) for {'learning_rate': 1, 'loss': 'exponential', 'max_depth': 6, 'warm_start': False}\n",
      "0.792 (+/-0.123) for {'learning_rate': 1, 'loss': 'exponential', 'max_depth': 7, 'warm_start': True}\n",
      "0.793 (+/-0.135) for {'learning_rate': 1, 'loss': 'exponential', 'max_depth': 7, 'warm_start': False}\n",
      "0.796 (+/-0.145) for {'learning_rate': 1, 'loss': 'exponential', 'max_depth': 8, 'warm_start': True}\n",
      "0.795 (+/-0.135) for {'learning_rate': 1, 'loss': 'exponential', 'max_depth': 8, 'warm_start': False}\n",
      "0.792 (+/-0.128) for {'learning_rate': 1, 'loss': 'exponential', 'max_depth': 9, 'warm_start': True}\n",
      "0.785 (+/-0.124) for {'learning_rate': 1, 'loss': 'exponential', 'max_depth': 9, 'warm_start': False}\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.79      0.92      0.85       114\n",
      "         1.0       0.80      0.56      0.66        64\n",
      "\n",
      "    accuracy                           0.79       178\n",
      "   macro avg       0.79      0.74      0.76       178\n",
      "weighted avg       0.79      0.79      0.78       178\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "tuned_parameters = [{ 'loss':['deviance', 'exponential'], 'learning_rate':[0.001,0.01,0.1,1],\n",
    "      'warm_start':[True, False], 'max_depth':[1,2,3,4,5,6,7,8,9]}\n",
    "                    ]\n",
    "\n",
    "\n",
    "print()\n",
    "\n",
    "clf = GridSearchCV(\n",
    "    GradientBoostingClassifier(), tuned_parameters, scoring='accuracy', cv=10\n",
    ")\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best parameters set found on development set:\")\n",
    "print()\n",
    "print(clf.best_params_)\n",
    "print()\n",
    "print(\"Grid scores on development set:\")\n",
    "print()\n",
    "means = clf.cv_results_['mean_test_score']\n",
    "stds = clf.cv_results_['std_test_score']\n",
    "for mean, std, params in zip(means, stds, clf.cv_results_['params']):\n",
    "    print(\"%0.3f (+/-%0.03f) for %r\"\n",
    "          % (mean, std * 2, params))\n",
    "print()\n",
    "\n",
    "print(\"Detailed classification report:\")\n",
    "print()\n",
    "print(\"The model is trained on the full development set.\")\n",
    "print(\"The scores are computed on the full evaluation set.\")\n",
    "print()\n",
    "y_true, y_pred = y_test, clf.predict(X_test)\n",
    "print(classification_report(y_true, y_pred))\n",
    "print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Gvmd32XZTtLO"
   },
   "source": [
    "###Cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "FuoHmzHoSkd-",
    "outputId": "1d24d2ce-be96-482e-f293-8e0cf4416d99"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.819363\n"
     ]
    }
   ],
   "source": [
    "clf = GradientBoostingClassifier(learning_rate= 0.1, loss= 'exponential', max_depth= 4, warm_start= True)\n",
    "score=cross_validate(clf, X, y, cv=10, scoring=\"accuracy\")[\"test_score\"].mean()\n",
    "print(f\"{score:.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qmae7Z2yMlKP"
   },
   "source": [
    "### Generating Predicion Result for submission in .csv format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mmcGazd6sYDa"
   },
   "outputs": [],
   "source": [
    "df2 = pd.read_csv(url2)\n",
    "clf = GradientBoostingClassifier(learning_rate= 0.1, loss= 'exponential', max_depth= 4, warm_start= True)\n",
    "clf.fit(X, y)\n",
    "pred=clf.predict(X_test2)\n",
    "pd.DataFrame({\"PassengerId\": df2[\"PassengerId\"], \"Survived\": pred}).to_csv(\"GradientBoosting_submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "F3O08TBpA9FA"
   },
   "source": [
    "![alt text](https://raw.githubusercontent.com/zyzhang1130/CE9010/master/Titanic/GradientBoosting.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "u1qhZ7fOmbvB"
   },
   "source": [
    "## AdaBoost Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "E64nFMZ_moMm",
    "outputId": "c6497be2-2148-4fa9-b0e1-9caa32657f73"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best parameters set found on development set:\n",
      "\n",
      "{'algorithm': 'SAMME', 'base_estimator': DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
      "                       max_depth=7, max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                       random_state=None, splitter='best'), 'learning_rate': 0.2, 'n_estimators': 200}\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "0.778 (+/-0.108) for {'algorithm': 'SAMME.R', 'base_estimator': DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
      "                       max_depth=7, max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                       random_state=None, splitter='best'), 'learning_rate': 0.2, 'n_estimators': 50}\n",
      "0.794 (+/-0.118) for {'algorithm': 'SAMME.R', 'base_estimator': DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
      "                       max_depth=7, max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                       random_state=None, splitter='best'), 'learning_rate': 0.2, 'n_estimators': 60}\n",
      "0.787 (+/-0.099) for {'algorithm': 'SAMME.R', 'base_estimator': DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
      "                       max_depth=7, max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                       random_state=None, splitter='best'), 'learning_rate': 0.2, 'n_estimators': 70}\n",
      "0.781 (+/-0.121) for {'algorithm': 'SAMME.R', 'base_estimator': DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
      "                       max_depth=7, max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                       random_state=None, splitter='best'), 'learning_rate': 0.2, 'n_estimators': 80}\n",
      "0.791 (+/-0.120) for {'algorithm': 'SAMME.R', 'base_estimator': DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
      "                       max_depth=7, max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                       random_state=None, splitter='best'), 'learning_rate': 0.2, 'n_estimators': 90}\n",
      "0.789 (+/-0.128) for {'algorithm': 'SAMME.R', 'base_estimator': DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
      "                       max_depth=7, max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                       random_state=None, splitter='best'), 'learning_rate': 0.2, 'n_estimators': 100}\n",
      "0.789 (+/-0.101) for {'algorithm': 'SAMME.R', 'base_estimator': DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
      "                       max_depth=7, max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                       random_state=None, splitter='best'), 'learning_rate': 0.2, 'n_estimators': 120}\n",
      "0.791 (+/-0.126) for {'algorithm': 'SAMME.R', 'base_estimator': DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
      "                       max_depth=7, max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                       random_state=None, splitter='best'), 'learning_rate': 0.2, 'n_estimators': 140}\n",
      "0.792 (+/-0.111) for {'algorithm': 'SAMME.R', 'base_estimator': DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
      "                       max_depth=7, max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                       random_state=None, splitter='best'), 'learning_rate': 0.2, 'n_estimators': 160}\n",
      "0.791 (+/-0.093) for {'algorithm': 'SAMME.R', 'base_estimator': DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
      "                       max_depth=7, max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                       random_state=None, splitter='best'), 'learning_rate': 0.2, 'n_estimators': 180}\n",
      "0.789 (+/-0.111) for {'algorithm': 'SAMME.R', 'base_estimator': DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
      "                       max_depth=7, max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                       random_state=None, splitter='best'), 'learning_rate': 0.2, 'n_estimators': 200}\n",
      "0.781 (+/-0.117) for {'algorithm': 'SAMME.R', 'base_estimator': DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
      "                       max_depth=7, max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                       random_state=None, splitter='best'), 'learning_rate': 0.4, 'n_estimators': 50}\n",
      "0.785 (+/-0.118) for {'algorithm': 'SAMME.R', 'base_estimator': DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
      "                       max_depth=7, max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                       random_state=None, splitter='best'), 'learning_rate': 0.4, 'n_estimators': 60}\n",
      "0.784 (+/-0.129) for {'algorithm': 'SAMME.R', 'base_estimator': DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
      "                       max_depth=7, max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                       random_state=None, splitter='best'), 'learning_rate': 0.4, 'n_estimators': 70}\n",
      "0.791 (+/-0.141) for {'algorithm': 'SAMME.R', 'base_estimator': DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
      "                       max_depth=7, max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                       random_state=None, splitter='best'), 'learning_rate': 0.4, 'n_estimators': 80}\n",
      "0.791 (+/-0.102) for {'algorithm': 'SAMME.R', 'base_estimator': DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
      "                       max_depth=7, max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                       random_state=None, splitter='best'), 'learning_rate': 0.4, 'n_estimators': 90}\n",
      "0.780 (+/-0.122) for {'algorithm': 'SAMME.R', 'base_estimator': DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
      "                       max_depth=7, max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                       random_state=None, splitter='best'), 'learning_rate': 0.4, 'n_estimators': 100}\n",
      "0.779 (+/-0.121) for {'algorithm': 'SAMME.R', 'base_estimator': DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
      "                       max_depth=7, max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                       random_state=None, splitter='best'), 'learning_rate': 0.4, 'n_estimators': 120}\n",
      "0.788 (+/-0.113) for {'algorithm': 'SAMME.R', 'base_estimator': DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
      "                       max_depth=7, max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                       random_state=None, splitter='best'), 'learning_rate': 0.4, 'n_estimators': 140}\n",
      "0.774 (+/-0.123) for {'algorithm': 'SAMME.R', 'base_estimator': DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
      "                       max_depth=7, max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                       random_state=None, splitter='best'), 'learning_rate': 0.4, 'n_estimators': 160}\n",
      "0.789 (+/-0.108) for {'algorithm': 'SAMME.R', 'base_estimator': DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
      "                       max_depth=7, max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                       random_state=None, splitter='best'), 'learning_rate': 0.4, 'n_estimators': 180}\n",
      "0.785 (+/-0.128) for {'algorithm': 'SAMME.R', 'base_estimator': DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
      "                       max_depth=7, max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                       random_state=None, splitter='best'), 'learning_rate': 0.4, 'n_estimators': 200}\n",
      "0.777 (+/-0.106) for {'algorithm': 'SAMME.R', 'base_estimator': DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
      "                       max_depth=7, max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                       random_state=None, splitter='best'), 'learning_rate': 0.6, 'n_estimators': 50}\n",
      "0.782 (+/-0.099) for {'algorithm': 'SAMME.R', 'base_estimator': DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
      "                       max_depth=7, max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                       random_state=None, splitter='best'), 'learning_rate': 0.6, 'n_estimators': 60}\n",
      "0.792 (+/-0.114) for {'algorithm': 'SAMME.R', 'base_estimator': DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
      "                       max_depth=7, max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                       random_state=None, splitter='best'), 'learning_rate': 0.6, 'n_estimators': 70}\n",
      "0.788 (+/-0.120) for {'algorithm': 'SAMME.R', 'base_estimator': DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
      "                       max_depth=7, max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                       random_state=None, splitter='best'), 'learning_rate': 0.6, 'n_estimators': 80}\n",
      "0.791 (+/-0.121) for {'algorithm': 'SAMME.R', 'base_estimator': DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
      "                       max_depth=7, max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                       random_state=None, splitter='best'), 'learning_rate': 0.6, 'n_estimators': 90}\n",
      "0.801 (+/-0.113) for {'algorithm': 'SAMME.R', 'base_estimator': DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
      "                       max_depth=7, max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                       random_state=None, splitter='best'), 'learning_rate': 0.6, 'n_estimators': 100}\n",
      "0.792 (+/-0.097) for {'algorithm': 'SAMME.R', 'base_estimator': DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
      "                       max_depth=7, max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                       random_state=None, splitter='best'), 'learning_rate': 0.6, 'n_estimators': 120}\n",
      "0.782 (+/-0.111) for {'algorithm': 'SAMME.R', 'base_estimator': DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
      "                       max_depth=7, max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                       random_state=None, splitter='best'), 'learning_rate': 0.6, 'n_estimators': 140}\n",
      "0.803 (+/-0.104) for {'algorithm': 'SAMME.R', 'base_estimator': DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
      "                       max_depth=7, max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                       random_state=None, splitter='best'), 'learning_rate': 0.6, 'n_estimators': 160}\n",
      "0.791 (+/-0.099) for {'algorithm': 'SAMME.R', 'base_estimator': DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
      "                       max_depth=7, max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                       random_state=None, splitter='best'), 'learning_rate': 0.6, 'n_estimators': 180}\n",
      "0.784 (+/-0.103) for {'algorithm': 'SAMME.R', 'base_estimator': DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
      "                       max_depth=7, max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                       random_state=None, splitter='best'), 'learning_rate': 0.6, 'n_estimators': 200}\n",
      "0.785 (+/-0.106) for {'algorithm': 'SAMME.R', 'base_estimator': DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
      "                       max_depth=7, max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                       random_state=None, splitter='best'), 'learning_rate': 0.8, 'n_estimators': 50}\n",
      "0.793 (+/-0.110) for {'algorithm': 'SAMME.R', 'base_estimator': DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
      "                       max_depth=7, max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                       random_state=None, splitter='best'), 'learning_rate': 0.8, 'n_estimators': 60}\n",
      "0.778 (+/-0.122) for {'algorithm': 'SAMME.R', 'base_estimator': DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
      "                       max_depth=7, max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                       random_state=None, splitter='best'), 'learning_rate': 0.8, 'n_estimators': 70}\n",
      "0.784 (+/-0.101) for {'algorithm': 'SAMME.R', 'base_estimator': DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
      "                       max_depth=7, max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                       random_state=None, splitter='best'), 'learning_rate': 0.8, 'n_estimators': 80}\n",
      "0.778 (+/-0.141) for {'algorithm': 'SAMME.R', 'base_estimator': DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
      "                       max_depth=7, max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                       random_state=None, splitter='best'), 'learning_rate': 0.8, 'n_estimators': 90}\n",
      "0.788 (+/-0.130) for {'algorithm': 'SAMME.R', 'base_estimator': DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
      "                       max_depth=7, max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                       random_state=None, splitter='best'), 'learning_rate': 0.8, 'n_estimators': 100}\n",
      "0.794 (+/-0.119) for {'algorithm': 'SAMME.R', 'base_estimator': DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
      "                       max_depth=7, max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                       random_state=None, splitter='best'), 'learning_rate': 0.8, 'n_estimators': 120}\n",
      "0.792 (+/-0.098) for {'algorithm': 'SAMME.R', 'base_estimator': DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
      "                       max_depth=7, max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                       random_state=None, splitter='best'), 'learning_rate': 0.8, 'n_estimators': 140}\n",
      "0.805 (+/-0.118) for {'algorithm': 'SAMME.R', 'base_estimator': DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
      "                       max_depth=7, max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                       random_state=None, splitter='best'), 'learning_rate': 0.8, 'n_estimators': 160}\n",
      "0.792 (+/-0.107) for {'algorithm': 'SAMME.R', 'base_estimator': DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
      "                       max_depth=7, max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                       random_state=None, splitter='best'), 'learning_rate': 0.8, 'n_estimators': 180}\n",
      "0.785 (+/-0.117) for {'algorithm': 'SAMME.R', 'base_estimator': DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
      "                       max_depth=7, max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                       random_state=None, splitter='best'), 'learning_rate': 0.8, 'n_estimators': 200}\n",
      "0.782 (+/-0.121) for {'algorithm': 'SAMME.R', 'base_estimator': DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
      "                       max_depth=7, max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                       random_state=None, splitter='best'), 'learning_rate': 1.0, 'n_estimators': 50}\n",
      "0.777 (+/-0.115) for {'algorithm': 'SAMME.R', 'base_estimator': DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
      "                       max_depth=7, max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                       random_state=None, splitter='best'), 'learning_rate': 1.0, 'n_estimators': 60}\n",
      "0.802 (+/-0.107) for {'algorithm': 'SAMME.R', 'base_estimator': DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
      "                       max_depth=7, max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                       random_state=None, splitter='best'), 'learning_rate': 1.0, 'n_estimators': 70}\n",
      "0.795 (+/-0.106) for {'algorithm': 'SAMME.R', 'base_estimator': DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
      "                       max_depth=7, max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                       random_state=None, splitter='best'), 'learning_rate': 1.0, 'n_estimators': 80}\n",
      "0.787 (+/-0.106) for {'algorithm': 'SAMME.R', 'base_estimator': DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
      "                       max_depth=7, max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                       random_state=None, splitter='best'), 'learning_rate': 1.0, 'n_estimators': 90}\n",
      "0.786 (+/-0.094) for {'algorithm': 'SAMME.R', 'base_estimator': DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
      "                       max_depth=7, max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                       random_state=None, splitter='best'), 'learning_rate': 1.0, 'n_estimators': 100}\n",
      "0.792 (+/-0.134) for {'algorithm': 'SAMME.R', 'base_estimator': DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
      "                       max_depth=7, max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                       random_state=None, splitter='best'), 'learning_rate': 1.0, 'n_estimators': 120}\n",
      "0.795 (+/-0.129) for {'algorithm': 'SAMME.R', 'base_estimator': DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
      "                       max_depth=7, max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                       random_state=None, splitter='best'), 'learning_rate': 1.0, 'n_estimators': 140}\n",
      "0.788 (+/-0.110) for {'algorithm': 'SAMME.R', 'base_estimator': DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
      "                       max_depth=7, max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                       random_state=None, splitter='best'), 'learning_rate': 1.0, 'n_estimators': 160}\n",
      "0.788 (+/-0.136) for {'algorithm': 'SAMME.R', 'base_estimator': DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
      "                       max_depth=7, max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                       random_state=None, splitter='best'), 'learning_rate': 1.0, 'n_estimators': 180}\n",
      "0.798 (+/-0.112) for {'algorithm': 'SAMME.R', 'base_estimator': DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
      "                       max_depth=7, max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                       random_state=None, splitter='best'), 'learning_rate': 1.0, 'n_estimators': 200}\n",
      "0.771 (+/-0.139) for {'algorithm': 'SAMME.R', 'base_estimator': DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
      "                       max_depth=7, max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                       random_state=None, splitter='best'), 'learning_rate': 1.2, 'n_estimators': 50}\n",
      "0.778 (+/-0.110) for {'algorithm': 'SAMME.R', 'base_estimator': DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
      "                       max_depth=7, max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                       random_state=None, splitter='best'), 'learning_rate': 1.2, 'n_estimators': 60}\n",
      "0.771 (+/-0.095) for {'algorithm': 'SAMME.R', 'base_estimator': DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
      "                       max_depth=7, max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                       random_state=None, splitter='best'), 'learning_rate': 1.2, 'n_estimators': 70}\n",
      "0.777 (+/-0.126) for {'algorithm': 'SAMME.R', 'base_estimator': DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
      "                       max_depth=7, max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                       random_state=None, splitter='best'), 'learning_rate': 1.2, 'n_estimators': 80}\n",
      "0.789 (+/-0.124) for {'algorithm': 'SAMME.R', 'base_estimator': DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
      "                       max_depth=7, max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                       random_state=None, splitter='best'), 'learning_rate': 1.2, 'n_estimators': 90}\n",
      "0.789 (+/-0.128) for {'algorithm': 'SAMME.R', 'base_estimator': DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
      "                       max_depth=7, max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                       random_state=None, splitter='best'), 'learning_rate': 1.2, 'n_estimators': 100}\n",
      "0.799 (+/-0.111) for {'algorithm': 'SAMME.R', 'base_estimator': DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
      "                       max_depth=7, max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                       random_state=None, splitter='best'), 'learning_rate': 1.2, 'n_estimators': 120}\n",
      "0.798 (+/-0.101) for {'algorithm': 'SAMME.R', 'base_estimator': DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
      "                       max_depth=7, max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                       random_state=None, splitter='best'), 'learning_rate': 1.2, 'n_estimators': 140}\n",
      "0.785 (+/-0.099) for {'algorithm': 'SAMME.R', 'base_estimator': DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
      "                       max_depth=7, max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                       random_state=None, splitter='best'), 'learning_rate': 1.2, 'n_estimators': 160}\n",
      "0.794 (+/-0.112) for {'algorithm': 'SAMME.R', 'base_estimator': DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
      "                       max_depth=7, max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                       random_state=None, splitter='best'), 'learning_rate': 1.2, 'n_estimators': 180}\n",
      "0.788 (+/-0.103) for {'algorithm': 'SAMME.R', 'base_estimator': DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
      "                       max_depth=7, max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                       random_state=None, splitter='best'), 'learning_rate': 1.2, 'n_estimators': 200}\n",
      "0.779 (+/-0.124) for {'algorithm': 'SAMME.R', 'base_estimator': DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
      "                       max_depth=7, max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                       random_state=None, splitter='best'), 'learning_rate': 1.4, 'n_estimators': 50}\n",
      "0.789 (+/-0.104) for {'algorithm': 'SAMME.R', 'base_estimator': DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
      "                       max_depth=7, max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                       random_state=None, splitter='best'), 'learning_rate': 1.4, 'n_estimators': 60}\n",
      "0.782 (+/-0.123) for {'algorithm': 'SAMME.R', 'base_estimator': DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
      "                       max_depth=7, max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                       random_state=None, splitter='best'), 'learning_rate': 1.4, 'n_estimators': 70}\n",
      "0.785 (+/-0.089) for {'algorithm': 'SAMME.R', 'base_estimator': DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
      "                       max_depth=7, max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                       random_state=None, splitter='best'), 'learning_rate': 1.4, 'n_estimators': 80}\n",
      "0.781 (+/-0.121) for {'algorithm': 'SAMME.R', 'base_estimator': DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
      "                       max_depth=7, max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                       random_state=None, splitter='best'), 'learning_rate': 1.4, 'n_estimators': 90}\n",
      "0.788 (+/-0.131) for {'algorithm': 'SAMME.R', 'base_estimator': DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
      "                       max_depth=7, max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                       random_state=None, splitter='best'), 'learning_rate': 1.4, 'n_estimators': 100}\n",
      "0.777 (+/-0.139) for {'algorithm': 'SAMME.R', 'base_estimator': DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
      "                       max_depth=7, max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                       random_state=None, splitter='best'), 'learning_rate': 1.4, 'n_estimators': 120}\n",
      "0.789 (+/-0.113) for {'algorithm': 'SAMME.R', 'base_estimator': DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
      "                       max_depth=7, max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                       random_state=None, splitter='best'), 'learning_rate': 1.4, 'n_estimators': 140}\n",
      "0.789 (+/-0.115) for {'algorithm': 'SAMME.R', 'base_estimator': DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
      "                       max_depth=7, max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                       random_state=None, splitter='best'), 'learning_rate': 1.4, 'n_estimators': 160}\n",
      "0.774 (+/-0.119) for {'algorithm': 'SAMME.R', 'base_estimator': DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
      "                       max_depth=7, max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                       random_state=None, splitter='best'), 'learning_rate': 1.4, 'n_estimators': 180}\n",
      "0.785 (+/-0.129) for {'algorithm': 'SAMME.R', 'base_estimator': DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
      "                       max_depth=7, max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                       random_state=None, splitter='best'), 'learning_rate': 1.4, 'n_estimators': 200}\n",
      "0.808 (+/-0.088) for {'algorithm': 'SAMME', 'base_estimator': DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
      "                       max_depth=7, max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                       random_state=None, splitter='best'), 'learning_rate': 0.2, 'n_estimators': 50}\n",
      "0.815 (+/-0.089) for {'algorithm': 'SAMME', 'base_estimator': DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
      "                       max_depth=7, max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                       random_state=None, splitter='best'), 'learning_rate': 0.2, 'n_estimators': 60}\n",
      "0.815 (+/-0.085) for {'algorithm': 'SAMME', 'base_estimator': DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
      "                       max_depth=7, max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                       random_state=None, splitter='best'), 'learning_rate': 0.2, 'n_estimators': 70}\n",
      "0.816 (+/-0.076) for {'algorithm': 'SAMME', 'base_estimator': DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
      "                       max_depth=7, max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                       random_state=None, splitter='best'), 'learning_rate': 0.2, 'n_estimators': 80}\n",
      "0.813 (+/-0.083) for {'algorithm': 'SAMME', 'base_estimator': DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
      "                       max_depth=7, max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                       random_state=None, splitter='best'), 'learning_rate': 0.2, 'n_estimators': 90}\n",
      "0.812 (+/-0.106) for {'algorithm': 'SAMME', 'base_estimator': DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
      "                       max_depth=7, max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                       random_state=None, splitter='best'), 'learning_rate': 0.2, 'n_estimators': 100}\n",
      "0.806 (+/-0.090) for {'algorithm': 'SAMME', 'base_estimator': DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
      "                       max_depth=7, max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                       random_state=None, splitter='best'), 'learning_rate': 0.2, 'n_estimators': 120}\n",
      "0.815 (+/-0.090) for {'algorithm': 'SAMME', 'base_estimator': DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
      "                       max_depth=7, max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                       random_state=None, splitter='best'), 'learning_rate': 0.2, 'n_estimators': 140}\n",
      "0.812 (+/-0.105) for {'algorithm': 'SAMME', 'base_estimator': DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
      "                       max_depth=7, max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                       random_state=None, splitter='best'), 'learning_rate': 0.2, 'n_estimators': 160}\n",
      "0.805 (+/-0.097) for {'algorithm': 'SAMME', 'base_estimator': DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
      "                       max_depth=7, max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                       random_state=None, splitter='best'), 'learning_rate': 0.2, 'n_estimators': 180}\n",
      "0.816 (+/-0.084) for {'algorithm': 'SAMME', 'base_estimator': DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
      "                       max_depth=7, max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                       random_state=None, splitter='best'), 'learning_rate': 0.2, 'n_estimators': 200}\n",
      "0.811 (+/-0.088) for {'algorithm': 'SAMME', 'base_estimator': DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
      "                       max_depth=7, max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                       random_state=None, splitter='best'), 'learning_rate': 0.4, 'n_estimators': 50}\n",
      "0.810 (+/-0.082) for {'algorithm': 'SAMME', 'base_estimator': DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
      "                       max_depth=7, max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                       random_state=None, splitter='best'), 'learning_rate': 0.4, 'n_estimators': 60}\n",
      "0.809 (+/-0.097) for {'algorithm': 'SAMME', 'base_estimator': DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
      "                       max_depth=7, max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                       random_state=None, splitter='best'), 'learning_rate': 0.4, 'n_estimators': 70}\n",
      "0.812 (+/-0.083) for {'algorithm': 'SAMME', 'base_estimator': DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
      "                       max_depth=7, max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                       random_state=None, splitter='best'), 'learning_rate': 0.4, 'n_estimators': 80}\n",
      "0.801 (+/-0.118) for {'algorithm': 'SAMME', 'base_estimator': DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
      "                       max_depth=7, max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                       random_state=None, splitter='best'), 'learning_rate': 0.4, 'n_estimators': 90}\n",
      "0.808 (+/-0.096) for {'algorithm': 'SAMME', 'base_estimator': DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
      "                       max_depth=7, max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                       random_state=None, splitter='best'), 'learning_rate': 0.4, 'n_estimators': 100}\n",
      "0.795 (+/-0.109) for {'algorithm': 'SAMME', 'base_estimator': DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
      "                       max_depth=7, max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                       random_state=None, splitter='best'), 'learning_rate': 0.4, 'n_estimators': 120}\n",
      "0.798 (+/-0.102) for {'algorithm': 'SAMME', 'base_estimator': DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
      "                       max_depth=7, max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                       random_state=None, splitter='best'), 'learning_rate': 0.4, 'n_estimators': 140}\n",
      "0.803 (+/-0.102) for {'algorithm': 'SAMME', 'base_estimator': DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
      "                       max_depth=7, max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                       random_state=None, splitter='best'), 'learning_rate': 0.4, 'n_estimators': 160}\n",
      "0.803 (+/-0.112) for {'algorithm': 'SAMME', 'base_estimator': DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
      "                       max_depth=7, max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                       random_state=None, splitter='best'), 'learning_rate': 0.4, 'n_estimators': 180}\n",
      "0.799 (+/-0.119) for {'algorithm': 'SAMME', 'base_estimator': DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
      "                       max_depth=7, max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                       random_state=None, splitter='best'), 'learning_rate': 0.4, 'n_estimators': 200}\n",
      "0.795 (+/-0.102) for {'algorithm': 'SAMME', 'base_estimator': DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
      "                       max_depth=7, max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                       random_state=None, splitter='best'), 'learning_rate': 0.6, 'n_estimators': 50}\n",
      "0.799 (+/-0.094) for {'algorithm': 'SAMME', 'base_estimator': DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
      "                       max_depth=7, max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                       random_state=None, splitter='best'), 'learning_rate': 0.6, 'n_estimators': 60}\n",
      "0.796 (+/-0.120) for {'algorithm': 'SAMME', 'base_estimator': DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
      "                       max_depth=7, max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                       random_state=None, splitter='best'), 'learning_rate': 0.6, 'n_estimators': 70}\n",
      "0.799 (+/-0.105) for {'algorithm': 'SAMME', 'base_estimator': DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
      "                       max_depth=7, max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                       random_state=None, splitter='best'), 'learning_rate': 0.6, 'n_estimators': 80}\n",
      "0.796 (+/-0.093) for {'algorithm': 'SAMME', 'base_estimator': DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
      "                       max_depth=7, max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                       random_state=None, splitter='best'), 'learning_rate': 0.6, 'n_estimators': 90}\n",
      "0.791 (+/-0.105) for {'algorithm': 'SAMME', 'base_estimator': DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
      "                       max_depth=7, max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                       random_state=None, splitter='best'), 'learning_rate': 0.6, 'n_estimators': 100}\n",
      "0.795 (+/-0.110) for {'algorithm': 'SAMME', 'base_estimator': DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
      "                       max_depth=7, max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                       random_state=None, splitter='best'), 'learning_rate': 0.6, 'n_estimators': 120}\n",
      "0.802 (+/-0.130) for {'algorithm': 'SAMME', 'base_estimator': DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
      "                       max_depth=7, max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                       random_state=None, splitter='best'), 'learning_rate': 0.6, 'n_estimators': 140}\n",
      "0.796 (+/-0.100) for {'algorithm': 'SAMME', 'base_estimator': DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
      "                       max_depth=7, max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                       random_state=None, splitter='best'), 'learning_rate': 0.6, 'n_estimators': 160}\n",
      "0.791 (+/-0.087) for {'algorithm': 'SAMME', 'base_estimator': DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
      "                       max_depth=7, max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                       random_state=None, splitter='best'), 'learning_rate': 0.6, 'n_estimators': 180}\n",
      "0.787 (+/-0.115) for {'algorithm': 'SAMME', 'base_estimator': DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
      "                       max_depth=7, max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                       random_state=None, splitter='best'), 'learning_rate': 0.6, 'n_estimators': 200}\n",
      "0.794 (+/-0.112) for {'algorithm': 'SAMME', 'base_estimator': DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
      "                       max_depth=7, max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                       random_state=None, splitter='best'), 'learning_rate': 0.8, 'n_estimators': 50}\n",
      "0.796 (+/-0.112) for {'algorithm': 'SAMME', 'base_estimator': DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
      "                       max_depth=7, max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                       random_state=None, splitter='best'), 'learning_rate': 0.8, 'n_estimators': 60}\n",
      "0.808 (+/-0.106) for {'algorithm': 'SAMME', 'base_estimator': DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
      "                       max_depth=7, max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                       random_state=None, splitter='best'), 'learning_rate': 0.8, 'n_estimators': 70}\n",
      "0.803 (+/-0.110) for {'algorithm': 'SAMME', 'base_estimator': DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
      "                       max_depth=7, max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                       random_state=None, splitter='best'), 'learning_rate': 0.8, 'n_estimators': 80}\n",
      "0.803 (+/-0.108) for {'algorithm': 'SAMME', 'base_estimator': DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
      "                       max_depth=7, max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                       random_state=None, splitter='best'), 'learning_rate': 0.8, 'n_estimators': 90}\n",
      "0.788 (+/-0.119) for {'algorithm': 'SAMME', 'base_estimator': DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
      "                       max_depth=7, max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                       random_state=None, splitter='best'), 'learning_rate': 0.8, 'n_estimators': 100}\n",
      "0.789 (+/-0.112) for {'algorithm': 'SAMME', 'base_estimator': DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
      "                       max_depth=7, max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                       random_state=None, splitter='best'), 'learning_rate': 0.8, 'n_estimators': 120}\n",
      "0.794 (+/-0.116) for {'algorithm': 'SAMME', 'base_estimator': DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
      "                       max_depth=7, max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                       random_state=None, splitter='best'), 'learning_rate': 0.8, 'n_estimators': 140}\n",
      "0.794 (+/-0.116) for {'algorithm': 'SAMME', 'base_estimator': DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
      "                       max_depth=7, max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                       random_state=None, splitter='best'), 'learning_rate': 0.8, 'n_estimators': 160}\n",
      "0.794 (+/-0.108) for {'algorithm': 'SAMME', 'base_estimator': DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
      "                       max_depth=7, max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                       random_state=None, splitter='best'), 'learning_rate': 0.8, 'n_estimators': 180}\n",
      "0.785 (+/-0.114) for {'algorithm': 'SAMME', 'base_estimator': DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
      "                       max_depth=7, max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                       random_state=None, splitter='best'), 'learning_rate': 0.8, 'n_estimators': 200}\n",
      "0.785 (+/-0.124) for {'algorithm': 'SAMME', 'base_estimator': DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
      "                       max_depth=7, max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                       random_state=None, splitter='best'), 'learning_rate': 1.0, 'n_estimators': 50}\n",
      "0.794 (+/-0.130) for {'algorithm': 'SAMME', 'base_estimator': DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
      "                       max_depth=7, max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                       random_state=None, splitter='best'), 'learning_rate': 1.0, 'n_estimators': 60}\n",
      "0.795 (+/-0.132) for {'algorithm': 'SAMME', 'base_estimator': DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
      "                       max_depth=7, max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                       random_state=None, splitter='best'), 'learning_rate': 1.0, 'n_estimators': 70}\n",
      "0.789 (+/-0.120) for {'algorithm': 'SAMME', 'base_estimator': DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
      "                       max_depth=7, max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                       random_state=None, splitter='best'), 'learning_rate': 1.0, 'n_estimators': 80}\n",
      "0.788 (+/-0.124) for {'algorithm': 'SAMME', 'base_estimator': DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
      "                       max_depth=7, max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                       random_state=None, splitter='best'), 'learning_rate': 1.0, 'n_estimators': 90}\n",
      "0.782 (+/-0.100) for {'algorithm': 'SAMME', 'base_estimator': DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
      "                       max_depth=7, max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                       random_state=None, splitter='best'), 'learning_rate': 1.0, 'n_estimators': 100}\n",
      "0.795 (+/-0.125) for {'algorithm': 'SAMME', 'base_estimator': DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
      "                       max_depth=7, max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                       random_state=None, splitter='best'), 'learning_rate': 1.0, 'n_estimators': 120}\n",
      "0.796 (+/-0.110) for {'algorithm': 'SAMME', 'base_estimator': DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
      "                       max_depth=7, max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                       random_state=None, splitter='best'), 'learning_rate': 1.0, 'n_estimators': 140}\n",
      "0.799 (+/-0.126) for {'algorithm': 'SAMME', 'base_estimator': DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
      "                       max_depth=7, max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                       random_state=None, splitter='best'), 'learning_rate': 1.0, 'n_estimators': 160}\n",
      "0.799 (+/-0.121) for {'algorithm': 'SAMME', 'base_estimator': DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
      "                       max_depth=7, max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                       random_state=None, splitter='best'), 'learning_rate': 1.0, 'n_estimators': 180}\n",
      "0.794 (+/-0.117) for {'algorithm': 'SAMME', 'base_estimator': DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
      "                       max_depth=7, max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                       random_state=None, splitter='best'), 'learning_rate': 1.0, 'n_estimators': 200}\n",
      "0.775 (+/-0.112) for {'algorithm': 'SAMME', 'base_estimator': DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
      "                       max_depth=7, max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                       random_state=None, splitter='best'), 'learning_rate': 1.2, 'n_estimators': 50}\n",
      "0.778 (+/-0.138) for {'algorithm': 'SAMME', 'base_estimator': DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
      "                       max_depth=7, max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                       random_state=None, splitter='best'), 'learning_rate': 1.2, 'n_estimators': 60}\n",
      "0.789 (+/-0.132) for {'algorithm': 'SAMME', 'base_estimator': DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
      "                       max_depth=7, max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                       random_state=None, splitter='best'), 'learning_rate': 1.2, 'n_estimators': 70}\n",
      "0.789 (+/-0.128) for {'algorithm': 'SAMME', 'base_estimator': DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
      "                       max_depth=7, max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                       random_state=None, splitter='best'), 'learning_rate': 1.2, 'n_estimators': 80}\n",
      "0.789 (+/-0.140) for {'algorithm': 'SAMME', 'base_estimator': DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
      "                       max_depth=7, max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                       random_state=None, splitter='best'), 'learning_rate': 1.2, 'n_estimators': 90}\n",
      "0.788 (+/-0.127) for {'algorithm': 'SAMME', 'base_estimator': DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
      "                       max_depth=7, max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                       random_state=None, splitter='best'), 'learning_rate': 1.2, 'n_estimators': 100}\n",
      "0.787 (+/-0.134) for {'algorithm': 'SAMME', 'base_estimator': DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
      "                       max_depth=7, max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                       random_state=None, splitter='best'), 'learning_rate': 1.2, 'n_estimators': 120}\n",
      "0.787 (+/-0.115) for {'algorithm': 'SAMME', 'base_estimator': DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
      "                       max_depth=7, max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                       random_state=None, splitter='best'), 'learning_rate': 1.2, 'n_estimators': 140}\n",
      "0.795 (+/-0.114) for {'algorithm': 'SAMME', 'base_estimator': DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
      "                       max_depth=7, max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                       random_state=None, splitter='best'), 'learning_rate': 1.2, 'n_estimators': 160}\n",
      "0.787 (+/-0.141) for {'algorithm': 'SAMME', 'base_estimator': DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
      "                       max_depth=7, max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                       random_state=None, splitter='best'), 'learning_rate': 1.2, 'n_estimators': 180}\n",
      "0.801 (+/-0.127) for {'algorithm': 'SAMME', 'base_estimator': DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
      "                       max_depth=7, max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                       random_state=None, splitter='best'), 'learning_rate': 1.2, 'n_estimators': 200}\n",
      "0.784 (+/-0.173) for {'algorithm': 'SAMME', 'base_estimator': DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
      "                       max_depth=7, max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                       random_state=None, splitter='best'), 'learning_rate': 1.4, 'n_estimators': 50}\n",
      "0.777 (+/-0.160) for {'algorithm': 'SAMME', 'base_estimator': DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
      "                       max_depth=7, max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                       random_state=None, splitter='best'), 'learning_rate': 1.4, 'n_estimators': 60}\n",
      "0.787 (+/-0.130) for {'algorithm': 'SAMME', 'base_estimator': DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
      "                       max_depth=7, max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                       random_state=None, splitter='best'), 'learning_rate': 1.4, 'n_estimators': 70}\n",
      "0.784 (+/-0.134) for {'algorithm': 'SAMME', 'base_estimator': DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
      "                       max_depth=7, max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                       random_state=None, splitter='best'), 'learning_rate': 1.4, 'n_estimators': 80}\n",
      "0.789 (+/-0.132) for {'algorithm': 'SAMME', 'base_estimator': DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
      "                       max_depth=7, max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                       random_state=None, splitter='best'), 'learning_rate': 1.4, 'n_estimators': 90}\n",
      "0.791 (+/-0.135) for {'algorithm': 'SAMME', 'base_estimator': DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
      "                       max_depth=7, max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                       random_state=None, splitter='best'), 'learning_rate': 1.4, 'n_estimators': 100}\n",
      "0.788 (+/-0.153) for {'algorithm': 'SAMME', 'base_estimator': DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
      "                       max_depth=7, max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                       random_state=None, splitter='best'), 'learning_rate': 1.4, 'n_estimators': 120}\n",
      "0.777 (+/-0.154) for {'algorithm': 'SAMME', 'base_estimator': DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
      "                       max_depth=7, max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                       random_state=None, splitter='best'), 'learning_rate': 1.4, 'n_estimators': 140}\n",
      "0.788 (+/-0.132) for {'algorithm': 'SAMME', 'base_estimator': DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
      "                       max_depth=7, max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                       random_state=None, splitter='best'), 'learning_rate': 1.4, 'n_estimators': 160}\n",
      "0.789 (+/-0.126) for {'algorithm': 'SAMME', 'base_estimator': DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
      "                       max_depth=7, max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                       random_state=None, splitter='best'), 'learning_rate': 1.4, 'n_estimators': 180}\n",
      "0.784 (+/-0.140) for {'algorithm': 'SAMME', 'base_estimator': DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
      "                       max_depth=7, max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                       random_state=None, splitter='best'), 'learning_rate': 1.4, 'n_estimators': 200}\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.77      0.84      0.80       114\n",
      "         1.0       0.66      0.55      0.60        64\n",
      "\n",
      "    accuracy                           0.74       178\n",
      "   macro avg       0.71      0.69      0.70       178\n",
      "weighted avg       0.73      0.74      0.73       178\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "tuned_parameters = [{'base_estimator':[DecisionTreeClassifier(max_depth=7)], 'n_estimators':[50,60,70,80,90,100,120,140,160,180,200], 'algorithm':['SAMME.R', 'SAMME'],\n",
    "  'learning_rate':[0.2,0.4,0.6,0.8,1.0,1.2,1.4]}\n",
    "                    ]\n",
    "\n",
    "\n",
    "print()\n",
    "\n",
    "clf = GridSearchCV(\n",
    "    AdaBoostClassifier(), tuned_parameters, scoring='accuracy', cv=10\n",
    ")\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best parameters set found on development set:\")\n",
    "print()\n",
    "print(clf.best_params_)\n",
    "print()\n",
    "print(\"Grid scores on development set:\")\n",
    "print()\n",
    "means = clf.cv_results_['mean_test_score']\n",
    "stds = clf.cv_results_['std_test_score']\n",
    "for mean, std, params in zip(means, stds, clf.cv_results_['params']):\n",
    "    print(\"%0.3f (+/-%0.03f) for %r\"\n",
    "          % (mean, std * 2, params))\n",
    "print()\n",
    "\n",
    "print(\"Detailed classification report:\")\n",
    "print()\n",
    "print(\"The model is trained on the full development set.\")\n",
    "print(\"The scores are computed on the full evaluation set.\")\n",
    "print()\n",
    "y_true, y_pred = y_test, clf.predict(X_test)\n",
    "print(classification_report(y_true, y_pred))\n",
    "print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lCjoq8YYTusT"
   },
   "source": [
    "###Cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "Ijz_7UUrSrCG",
    "outputId": "deb0e386-fe04-48f5-db18-3d93e4549537"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.818215\n"
     ]
    }
   ],
   "source": [
    "clf = AdaBoostClassifier(algorithm= 'SAMME', base_estimator= DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
    "                       max_depth=7, max_features=None, max_leaf_nodes=None,\n",
    "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "                       min_samples_leaf=1, min_samples_split=2,\n",
    "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
    "                       random_state=None, splitter='best'), learning_rate= 0.2, n_estimators= 200)\n",
    "score=cross_validate(clf, X, y, cv=10, scoring=\"accuracy\")[\"test_score\"].mean()\n",
    "print(f\"{score:.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "S8lrQloLMnIc"
   },
   "source": [
    "### Generating Predicion Result for submission in .csv format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_9pVnNQtsu1Q"
   },
   "outputs": [],
   "source": [
    "df2 = pd.read_csv(url2)\n",
    "clf = AdaBoostClassifier(algorithm= 'SAMME', base_estimator= DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
    "                       max_depth=7, max_features=None, max_leaf_nodes=None,\n",
    "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "                       min_samples_leaf=1, min_samples_split=2,\n",
    "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
    "                       random_state=None, splitter='best'), learning_rate= 0.2, n_estimators= 200)\n",
    "clf.fit(X, y)\n",
    "pred=clf.predict(X_test2)\n",
    "pd.DataFrame({\"PassengerId\": df2[\"PassengerId\"], \"Survived\": pred}).to_csv(\"AdaBoost_submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TwVI2KfcuV2d"
   },
   "source": [
    "![alt text](https://raw.githubusercontent.com/zyzhang1130/CE9010/master/Titanic/ada.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Fj6LyIK_DpUh"
   },
   "source": [
    "## RandomForest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "QPOkzPgqDoSa",
    "outputId": "6d19972f-a069-40cb-9ad8-7ba0c06159d7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best parameters set found on development set:\n",
      "\n",
      "{'bootstrap': True, 'criterion': 'gini', 'min_samples_split': 8, 'n_estimators': 180, 'warm_start': False}\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "0.796 (+/-0.124) for {'bootstrap': True, 'criterion': 'gini', 'min_samples_split': 2, 'n_estimators': 60, 'warm_start': True}\n",
      "0.787 (+/-0.104) for {'bootstrap': True, 'criterion': 'gini', 'min_samples_split': 2, 'n_estimators': 60, 'warm_start': False}\n",
      "0.796 (+/-0.124) for {'bootstrap': True, 'criterion': 'gini', 'min_samples_split': 2, 'n_estimators': 70, 'warm_start': True}\n",
      "0.799 (+/-0.116) for {'bootstrap': True, 'criterion': 'gini', 'min_samples_split': 2, 'n_estimators': 70, 'warm_start': False}\n",
      "0.799 (+/-0.113) for {'bootstrap': True, 'criterion': 'gini', 'min_samples_split': 2, 'n_estimators': 80, 'warm_start': True}\n",
      "0.789 (+/-0.125) for {'bootstrap': True, 'criterion': 'gini', 'min_samples_split': 2, 'n_estimators': 80, 'warm_start': False}\n",
      "0.787 (+/-0.117) for {'bootstrap': True, 'criterion': 'gini', 'min_samples_split': 2, 'n_estimators': 90, 'warm_start': True}\n",
      "0.791 (+/-0.111) for {'bootstrap': True, 'criterion': 'gini', 'min_samples_split': 2, 'n_estimators': 90, 'warm_start': False}\n",
      "0.794 (+/-0.127) for {'bootstrap': True, 'criterion': 'gini', 'min_samples_split': 2, 'n_estimators': 100, 'warm_start': True}\n",
      "0.799 (+/-0.122) for {'bootstrap': True, 'criterion': 'gini', 'min_samples_split': 2, 'n_estimators': 100, 'warm_start': False}\n",
      "0.799 (+/-0.125) for {'bootstrap': True, 'criterion': 'gini', 'min_samples_split': 2, 'n_estimators': 120, 'warm_start': True}\n",
      "0.792 (+/-0.112) for {'bootstrap': True, 'criterion': 'gini', 'min_samples_split': 2, 'n_estimators': 120, 'warm_start': False}\n",
      "0.789 (+/-0.120) for {'bootstrap': True, 'criterion': 'gini', 'min_samples_split': 2, 'n_estimators': 140, 'warm_start': True}\n",
      "0.798 (+/-0.117) for {'bootstrap': True, 'criterion': 'gini', 'min_samples_split': 2, 'n_estimators': 140, 'warm_start': False}\n",
      "0.792 (+/-0.117) for {'bootstrap': True, 'criterion': 'gini', 'min_samples_split': 2, 'n_estimators': 160, 'warm_start': True}\n",
      "0.794 (+/-0.126) for {'bootstrap': True, 'criterion': 'gini', 'min_samples_split': 2, 'n_estimators': 160, 'warm_start': False}\n",
      "0.795 (+/-0.130) for {'bootstrap': True, 'criterion': 'gini', 'min_samples_split': 2, 'n_estimators': 180, 'warm_start': True}\n",
      "0.794 (+/-0.121) for {'bootstrap': True, 'criterion': 'gini', 'min_samples_split': 2, 'n_estimators': 180, 'warm_start': False}\n",
      "0.792 (+/-0.119) for {'bootstrap': True, 'criterion': 'gini', 'min_samples_split': 2, 'n_estimators': 200, 'warm_start': True}\n",
      "0.798 (+/-0.119) for {'bootstrap': True, 'criterion': 'gini', 'min_samples_split': 2, 'n_estimators': 200, 'warm_start': False}\n",
      "0.808 (+/-0.099) for {'bootstrap': True, 'criterion': 'gini', 'min_samples_split': 3, 'n_estimators': 60, 'warm_start': True}\n",
      "0.806 (+/-0.105) for {'bootstrap': True, 'criterion': 'gini', 'min_samples_split': 3, 'n_estimators': 60, 'warm_start': False}\n",
      "0.805 (+/-0.105) for {'bootstrap': True, 'criterion': 'gini', 'min_samples_split': 3, 'n_estimators': 70, 'warm_start': True}\n",
      "0.808 (+/-0.096) for {'bootstrap': True, 'criterion': 'gini', 'min_samples_split': 3, 'n_estimators': 70, 'warm_start': False}\n",
      "0.802 (+/-0.111) for {'bootstrap': True, 'criterion': 'gini', 'min_samples_split': 3, 'n_estimators': 80, 'warm_start': True}\n",
      "0.809 (+/-0.109) for {'bootstrap': True, 'criterion': 'gini', 'min_samples_split': 3, 'n_estimators': 80, 'warm_start': False}\n",
      "0.810 (+/-0.094) for {'bootstrap': True, 'criterion': 'gini', 'min_samples_split': 3, 'n_estimators': 90, 'warm_start': True}\n",
      "0.803 (+/-0.104) for {'bootstrap': True, 'criterion': 'gini', 'min_samples_split': 3, 'n_estimators': 90, 'warm_start': False}\n",
      "0.808 (+/-0.103) for {'bootstrap': True, 'criterion': 'gini', 'min_samples_split': 3, 'n_estimators': 100, 'warm_start': True}\n",
      "0.812 (+/-0.090) for {'bootstrap': True, 'criterion': 'gini', 'min_samples_split': 3, 'n_estimators': 100, 'warm_start': False}\n",
      "0.806 (+/-0.102) for {'bootstrap': True, 'criterion': 'gini', 'min_samples_split': 3, 'n_estimators': 120, 'warm_start': True}\n",
      "0.803 (+/-0.112) for {'bootstrap': True, 'criterion': 'gini', 'min_samples_split': 3, 'n_estimators': 120, 'warm_start': False}\n",
      "0.808 (+/-0.107) for {'bootstrap': True, 'criterion': 'gini', 'min_samples_split': 3, 'n_estimators': 140, 'warm_start': True}\n",
      "0.811 (+/-0.105) for {'bootstrap': True, 'criterion': 'gini', 'min_samples_split': 3, 'n_estimators': 140, 'warm_start': False}\n",
      "0.808 (+/-0.116) for {'bootstrap': True, 'criterion': 'gini', 'min_samples_split': 3, 'n_estimators': 160, 'warm_start': True}\n",
      "0.808 (+/-0.099) for {'bootstrap': True, 'criterion': 'gini', 'min_samples_split': 3, 'n_estimators': 160, 'warm_start': False}\n",
      "0.803 (+/-0.117) for {'bootstrap': True, 'criterion': 'gini', 'min_samples_split': 3, 'n_estimators': 180, 'warm_start': True}\n",
      "0.809 (+/-0.102) for {'bootstrap': True, 'criterion': 'gini', 'min_samples_split': 3, 'n_estimators': 180, 'warm_start': False}\n",
      "0.815 (+/-0.095) for {'bootstrap': True, 'criterion': 'gini', 'min_samples_split': 3, 'n_estimators': 200, 'warm_start': True}\n",
      "0.808 (+/-0.095) for {'bootstrap': True, 'criterion': 'gini', 'min_samples_split': 3, 'n_estimators': 200, 'warm_start': False}\n",
      "0.806 (+/-0.101) for {'bootstrap': True, 'criterion': 'gini', 'min_samples_split': 4, 'n_estimators': 60, 'warm_start': True}\n",
      "0.812 (+/-0.100) for {'bootstrap': True, 'criterion': 'gini', 'min_samples_split': 4, 'n_estimators': 60, 'warm_start': False}\n",
      "0.819 (+/-0.096) for {'bootstrap': True, 'criterion': 'gini', 'min_samples_split': 4, 'n_estimators': 70, 'warm_start': True}\n",
      "0.816 (+/-0.104) for {'bootstrap': True, 'criterion': 'gini', 'min_samples_split': 4, 'n_estimators': 70, 'warm_start': False}\n",
      "0.815 (+/-0.097) for {'bootstrap': True, 'criterion': 'gini', 'min_samples_split': 4, 'n_estimators': 80, 'warm_start': True}\n",
      "0.813 (+/-0.096) for {'bootstrap': True, 'criterion': 'gini', 'min_samples_split': 4, 'n_estimators': 80, 'warm_start': False}\n",
      "0.823 (+/-0.086) for {'bootstrap': True, 'criterion': 'gini', 'min_samples_split': 4, 'n_estimators': 90, 'warm_start': True}\n",
      "0.823 (+/-0.103) for {'bootstrap': True, 'criterion': 'gini', 'min_samples_split': 4, 'n_estimators': 90, 'warm_start': False}\n",
      "0.820 (+/-0.095) for {'bootstrap': True, 'criterion': 'gini', 'min_samples_split': 4, 'n_estimators': 100, 'warm_start': True}\n",
      "0.820 (+/-0.100) for {'bootstrap': True, 'criterion': 'gini', 'min_samples_split': 4, 'n_estimators': 100, 'warm_start': False}\n",
      "0.817 (+/-0.092) for {'bootstrap': True, 'criterion': 'gini', 'min_samples_split': 4, 'n_estimators': 120, 'warm_start': True}\n",
      "0.823 (+/-0.104) for {'bootstrap': True, 'criterion': 'gini', 'min_samples_split': 4, 'n_estimators': 120, 'warm_start': False}\n",
      "0.823 (+/-0.108) for {'bootstrap': True, 'criterion': 'gini', 'min_samples_split': 4, 'n_estimators': 140, 'warm_start': True}\n",
      "0.822 (+/-0.109) for {'bootstrap': True, 'criterion': 'gini', 'min_samples_split': 4, 'n_estimators': 140, 'warm_start': False}\n",
      "0.820 (+/-0.094) for {'bootstrap': True, 'criterion': 'gini', 'min_samples_split': 4, 'n_estimators': 160, 'warm_start': True}\n",
      "0.823 (+/-0.093) for {'bootstrap': True, 'criterion': 'gini', 'min_samples_split': 4, 'n_estimators': 160, 'warm_start': False}\n",
      "0.823 (+/-0.105) for {'bootstrap': True, 'criterion': 'gini', 'min_samples_split': 4, 'n_estimators': 180, 'warm_start': True}\n",
      "0.812 (+/-0.092) for {'bootstrap': True, 'criterion': 'gini', 'min_samples_split': 4, 'n_estimators': 180, 'warm_start': False}\n",
      "0.818 (+/-0.105) for {'bootstrap': True, 'criterion': 'gini', 'min_samples_split': 4, 'n_estimators': 200, 'warm_start': True}\n",
      "0.816 (+/-0.105) for {'bootstrap': True, 'criterion': 'gini', 'min_samples_split': 4, 'n_estimators': 200, 'warm_start': False}\n",
      "0.823 (+/-0.099) for {'bootstrap': True, 'criterion': 'gini', 'min_samples_split': 5, 'n_estimators': 60, 'warm_start': True}\n",
      "0.819 (+/-0.093) for {'bootstrap': True, 'criterion': 'gini', 'min_samples_split': 5, 'n_estimators': 60, 'warm_start': False}\n",
      "0.822 (+/-0.094) for {'bootstrap': True, 'criterion': 'gini', 'min_samples_split': 5, 'n_estimators': 70, 'warm_start': True}\n",
      "0.818 (+/-0.098) for {'bootstrap': True, 'criterion': 'gini', 'min_samples_split': 5, 'n_estimators': 70, 'warm_start': False}\n",
      "0.815 (+/-0.095) for {'bootstrap': True, 'criterion': 'gini', 'min_samples_split': 5, 'n_estimators': 80, 'warm_start': True}\n",
      "0.820 (+/-0.088) for {'bootstrap': True, 'criterion': 'gini', 'min_samples_split': 5, 'n_estimators': 80, 'warm_start': False}\n",
      "0.827 (+/-0.096) for {'bootstrap': True, 'criterion': 'gini', 'min_samples_split': 5, 'n_estimators': 90, 'warm_start': True}\n",
      "0.823 (+/-0.101) for {'bootstrap': True, 'criterion': 'gini', 'min_samples_split': 5, 'n_estimators': 90, 'warm_start': False}\n",
      "0.823 (+/-0.104) for {'bootstrap': True, 'criterion': 'gini', 'min_samples_split': 5, 'n_estimators': 100, 'warm_start': True}\n",
      "0.823 (+/-0.091) for {'bootstrap': True, 'criterion': 'gini', 'min_samples_split': 5, 'n_estimators': 100, 'warm_start': False}\n",
      "0.823 (+/-0.091) for {'bootstrap': True, 'criterion': 'gini', 'min_samples_split': 5, 'n_estimators': 120, 'warm_start': True}\n",
      "0.822 (+/-0.093) for {'bootstrap': True, 'criterion': 'gini', 'min_samples_split': 5, 'n_estimators': 120, 'warm_start': False}\n",
      "0.823 (+/-0.099) for {'bootstrap': True, 'criterion': 'gini', 'min_samples_split': 5, 'n_estimators': 140, 'warm_start': True}\n",
      "0.827 (+/-0.102) for {'bootstrap': True, 'criterion': 'gini', 'min_samples_split': 5, 'n_estimators': 140, 'warm_start': False}\n",
      "0.823 (+/-0.102) for {'bootstrap': True, 'criterion': 'gini', 'min_samples_split': 5, 'n_estimators': 160, 'warm_start': True}\n",
      "0.826 (+/-0.102) for {'bootstrap': True, 'criterion': 'gini', 'min_samples_split': 5, 'n_estimators': 160, 'warm_start': False}\n",
      "0.827 (+/-0.097) for {'bootstrap': True, 'criterion': 'gini', 'min_samples_split': 5, 'n_estimators': 180, 'warm_start': True}\n",
      "0.823 (+/-0.099) for {'bootstrap': True, 'criterion': 'gini', 'min_samples_split': 5, 'n_estimators': 180, 'warm_start': False}\n",
      "0.822 (+/-0.102) for {'bootstrap': True, 'criterion': 'gini', 'min_samples_split': 5, 'n_estimators': 200, 'warm_start': True}\n",
      "0.826 (+/-0.092) for {'bootstrap': True, 'criterion': 'gini', 'min_samples_split': 5, 'n_estimators': 200, 'warm_start': False}\n",
      "0.823 (+/-0.093) for {'bootstrap': True, 'criterion': 'gini', 'min_samples_split': 6, 'n_estimators': 60, 'warm_start': True}\n",
      "0.813 (+/-0.091) for {'bootstrap': True, 'criterion': 'gini', 'min_samples_split': 6, 'n_estimators': 60, 'warm_start': False}\n",
      "0.816 (+/-0.112) for {'bootstrap': True, 'criterion': 'gini', 'min_samples_split': 6, 'n_estimators': 70, 'warm_start': True}\n",
      "0.822 (+/-0.105) for {'bootstrap': True, 'criterion': 'gini', 'min_samples_split': 6, 'n_estimators': 70, 'warm_start': False}\n",
      "0.825 (+/-0.095) for {'bootstrap': True, 'criterion': 'gini', 'min_samples_split': 6, 'n_estimators': 80, 'warm_start': True}\n",
      "0.822 (+/-0.098) for {'bootstrap': True, 'criterion': 'gini', 'min_samples_split': 6, 'n_estimators': 80, 'warm_start': False}\n",
      "0.820 (+/-0.092) for {'bootstrap': True, 'criterion': 'gini', 'min_samples_split': 6, 'n_estimators': 90, 'warm_start': True}\n",
      "0.822 (+/-0.093) for {'bootstrap': True, 'criterion': 'gini', 'min_samples_split': 6, 'n_estimators': 90, 'warm_start': False}\n",
      "0.823 (+/-0.094) for {'bootstrap': True, 'criterion': 'gini', 'min_samples_split': 6, 'n_estimators': 100, 'warm_start': True}\n",
      "0.822 (+/-0.103) for {'bootstrap': True, 'criterion': 'gini', 'min_samples_split': 6, 'n_estimators': 100, 'warm_start': False}\n",
      "0.830 (+/-0.099) for {'bootstrap': True, 'criterion': 'gini', 'min_samples_split': 6, 'n_estimators': 120, 'warm_start': True}\n",
      "0.822 (+/-0.084) for {'bootstrap': True, 'criterion': 'gini', 'min_samples_split': 6, 'n_estimators': 120, 'warm_start': False}\n",
      "0.824 (+/-0.102) for {'bootstrap': True, 'criterion': 'gini', 'min_samples_split': 6, 'n_estimators': 140, 'warm_start': True}\n",
      "0.824 (+/-0.097) for {'bootstrap': True, 'criterion': 'gini', 'min_samples_split': 6, 'n_estimators': 140, 'warm_start': False}\n",
      "0.832 (+/-0.098) for {'bootstrap': True, 'criterion': 'gini', 'min_samples_split': 6, 'n_estimators': 160, 'warm_start': True}\n",
      "0.829 (+/-0.100) for {'bootstrap': True, 'criterion': 'gini', 'min_samples_split': 6, 'n_estimators': 160, 'warm_start': False}\n",
      "0.824 (+/-0.094) for {'bootstrap': True, 'criterion': 'gini', 'min_samples_split': 6, 'n_estimators': 180, 'warm_start': True}\n",
      "0.824 (+/-0.087) for {'bootstrap': True, 'criterion': 'gini', 'min_samples_split': 6, 'n_estimators': 180, 'warm_start': False}\n",
      "0.823 (+/-0.095) for {'bootstrap': True, 'criterion': 'gini', 'min_samples_split': 6, 'n_estimators': 200, 'warm_start': True}\n",
      "0.827 (+/-0.104) for {'bootstrap': True, 'criterion': 'gini', 'min_samples_split': 6, 'n_estimators': 200, 'warm_start': False}\n",
      "0.820 (+/-0.092) for {'bootstrap': True, 'criterion': 'gini', 'min_samples_split': 7, 'n_estimators': 60, 'warm_start': True}\n",
      "0.822 (+/-0.085) for {'bootstrap': True, 'criterion': 'gini', 'min_samples_split': 7, 'n_estimators': 60, 'warm_start': False}\n",
      "0.820 (+/-0.095) for {'bootstrap': True, 'criterion': 'gini', 'min_samples_split': 7, 'n_estimators': 70, 'warm_start': True}\n",
      "0.825 (+/-0.091) for {'bootstrap': True, 'criterion': 'gini', 'min_samples_split': 7, 'n_estimators': 70, 'warm_start': False}\n",
      "0.823 (+/-0.099) for {'bootstrap': True, 'criterion': 'gini', 'min_samples_split': 7, 'n_estimators': 80, 'warm_start': True}\n",
      "0.823 (+/-0.086) for {'bootstrap': True, 'criterion': 'gini', 'min_samples_split': 7, 'n_estimators': 80, 'warm_start': False}\n",
      "0.826 (+/-0.090) for {'bootstrap': True, 'criterion': 'gini', 'min_samples_split': 7, 'n_estimators': 90, 'warm_start': True}\n",
      "0.823 (+/-0.089) for {'bootstrap': True, 'criterion': 'gini', 'min_samples_split': 7, 'n_estimators': 90, 'warm_start': False}\n",
      "0.827 (+/-0.090) for {'bootstrap': True, 'criterion': 'gini', 'min_samples_split': 7, 'n_estimators': 100, 'warm_start': True}\n",
      "0.827 (+/-0.090) for {'bootstrap': True, 'criterion': 'gini', 'min_samples_split': 7, 'n_estimators': 100, 'warm_start': False}\n",
      "0.829 (+/-0.094) for {'bootstrap': True, 'criterion': 'gini', 'min_samples_split': 7, 'n_estimators': 120, 'warm_start': True}\n",
      "0.827 (+/-0.093) for {'bootstrap': True, 'criterion': 'gini', 'min_samples_split': 7, 'n_estimators': 120, 'warm_start': False}\n",
      "0.826 (+/-0.078) for {'bootstrap': True, 'criterion': 'gini', 'min_samples_split': 7, 'n_estimators': 140, 'warm_start': True}\n",
      "0.825 (+/-0.094) for {'bootstrap': True, 'criterion': 'gini', 'min_samples_split': 7, 'n_estimators': 140, 'warm_start': False}\n",
      "0.830 (+/-0.093) for {'bootstrap': True, 'criterion': 'gini', 'min_samples_split': 7, 'n_estimators': 160, 'warm_start': True}\n",
      "0.820 (+/-0.101) for {'bootstrap': True, 'criterion': 'gini', 'min_samples_split': 7, 'n_estimators': 160, 'warm_start': False}\n",
      "0.832 (+/-0.092) for {'bootstrap': True, 'criterion': 'gini', 'min_samples_split': 7, 'n_estimators': 180, 'warm_start': True}\n",
      "0.824 (+/-0.094) for {'bootstrap': True, 'criterion': 'gini', 'min_samples_split': 7, 'n_estimators': 180, 'warm_start': False}\n",
      "0.825 (+/-0.097) for {'bootstrap': True, 'criterion': 'gini', 'min_samples_split': 7, 'n_estimators': 200, 'warm_start': True}\n",
      "0.825 (+/-0.096) for {'bootstrap': True, 'criterion': 'gini', 'min_samples_split': 7, 'n_estimators': 200, 'warm_start': False}\n",
      "0.822 (+/-0.083) for {'bootstrap': True, 'criterion': 'gini', 'min_samples_split': 8, 'n_estimators': 60, 'warm_start': True}\n",
      "0.815 (+/-0.094) for {'bootstrap': True, 'criterion': 'gini', 'min_samples_split': 8, 'n_estimators': 60, 'warm_start': False}\n",
      "0.827 (+/-0.095) for {'bootstrap': True, 'criterion': 'gini', 'min_samples_split': 8, 'n_estimators': 70, 'warm_start': True}\n",
      "0.826 (+/-0.104) for {'bootstrap': True, 'criterion': 'gini', 'min_samples_split': 8, 'n_estimators': 70, 'warm_start': False}\n",
      "0.820 (+/-0.092) for {'bootstrap': True, 'criterion': 'gini', 'min_samples_split': 8, 'n_estimators': 80, 'warm_start': True}\n",
      "0.822 (+/-0.095) for {'bootstrap': True, 'criterion': 'gini', 'min_samples_split': 8, 'n_estimators': 80, 'warm_start': False}\n",
      "0.820 (+/-0.094) for {'bootstrap': True, 'criterion': 'gini', 'min_samples_split': 8, 'n_estimators': 90, 'warm_start': True}\n",
      "0.816 (+/-0.086) for {'bootstrap': True, 'criterion': 'gini', 'min_samples_split': 8, 'n_estimators': 90, 'warm_start': False}\n",
      "0.817 (+/-0.081) for {'bootstrap': True, 'criterion': 'gini', 'min_samples_split': 8, 'n_estimators': 100, 'warm_start': True}\n",
      "0.827 (+/-0.092) for {'bootstrap': True, 'criterion': 'gini', 'min_samples_split': 8, 'n_estimators': 100, 'warm_start': False}\n",
      "0.826 (+/-0.100) for {'bootstrap': True, 'criterion': 'gini', 'min_samples_split': 8, 'n_estimators': 120, 'warm_start': True}\n",
      "0.823 (+/-0.089) for {'bootstrap': True, 'criterion': 'gini', 'min_samples_split': 8, 'n_estimators': 120, 'warm_start': False}\n",
      "0.826 (+/-0.098) for {'bootstrap': True, 'criterion': 'gini', 'min_samples_split': 8, 'n_estimators': 140, 'warm_start': True}\n",
      "0.827 (+/-0.100) for {'bootstrap': True, 'criterion': 'gini', 'min_samples_split': 8, 'n_estimators': 140, 'warm_start': False}\n",
      "0.826 (+/-0.093) for {'bootstrap': True, 'criterion': 'gini', 'min_samples_split': 8, 'n_estimators': 160, 'warm_start': True}\n",
      "0.825 (+/-0.088) for {'bootstrap': True, 'criterion': 'gini', 'min_samples_split': 8, 'n_estimators': 160, 'warm_start': False}\n",
      "0.826 (+/-0.095) for {'bootstrap': True, 'criterion': 'gini', 'min_samples_split': 8, 'n_estimators': 180, 'warm_start': True}\n",
      "0.836 (+/-0.080) for {'bootstrap': True, 'criterion': 'gini', 'min_samples_split': 8, 'n_estimators': 180, 'warm_start': False}\n",
      "0.825 (+/-0.089) for {'bootstrap': True, 'criterion': 'gini', 'min_samples_split': 8, 'n_estimators': 200, 'warm_start': True}\n",
      "0.829 (+/-0.085) for {'bootstrap': True, 'criterion': 'gini', 'min_samples_split': 8, 'n_estimators': 200, 'warm_start': False}\n",
      "0.819 (+/-0.095) for {'bootstrap': True, 'criterion': 'gini', 'min_samples_split': 9, 'n_estimators': 60, 'warm_start': True}\n",
      "0.819 (+/-0.097) for {'bootstrap': True, 'criterion': 'gini', 'min_samples_split': 9, 'n_estimators': 60, 'warm_start': False}\n",
      "0.816 (+/-0.090) for {'bootstrap': True, 'criterion': 'gini', 'min_samples_split': 9, 'n_estimators': 70, 'warm_start': True}\n",
      "0.815 (+/-0.101) for {'bootstrap': True, 'criterion': 'gini', 'min_samples_split': 9, 'n_estimators': 70, 'warm_start': False}\n",
      "0.815 (+/-0.097) for {'bootstrap': True, 'criterion': 'gini', 'min_samples_split': 9, 'n_estimators': 80, 'warm_start': True}\n",
      "0.830 (+/-0.084) for {'bootstrap': True, 'criterion': 'gini', 'min_samples_split': 9, 'n_estimators': 80, 'warm_start': False}\n",
      "0.822 (+/-0.083) for {'bootstrap': True, 'criterion': 'gini', 'min_samples_split': 9, 'n_estimators': 90, 'warm_start': True}\n",
      "0.823 (+/-0.092) for {'bootstrap': True, 'criterion': 'gini', 'min_samples_split': 9, 'n_estimators': 90, 'warm_start': False}\n",
      "0.817 (+/-0.105) for {'bootstrap': True, 'criterion': 'gini', 'min_samples_split': 9, 'n_estimators': 100, 'warm_start': True}\n",
      "0.829 (+/-0.092) for {'bootstrap': True, 'criterion': 'gini', 'min_samples_split': 9, 'n_estimators': 100, 'warm_start': False}\n",
      "0.820 (+/-0.100) for {'bootstrap': True, 'criterion': 'gini', 'min_samples_split': 9, 'n_estimators': 120, 'warm_start': True}\n",
      "0.826 (+/-0.083) for {'bootstrap': True, 'criterion': 'gini', 'min_samples_split': 9, 'n_estimators': 120, 'warm_start': False}\n",
      "0.819 (+/-0.078) for {'bootstrap': True, 'criterion': 'gini', 'min_samples_split': 9, 'n_estimators': 140, 'warm_start': True}\n",
      "0.820 (+/-0.091) for {'bootstrap': True, 'criterion': 'gini', 'min_samples_split': 9, 'n_estimators': 140, 'warm_start': False}\n",
      "0.822 (+/-0.092) for {'bootstrap': True, 'criterion': 'gini', 'min_samples_split': 9, 'n_estimators': 160, 'warm_start': True}\n",
      "0.823 (+/-0.087) for {'bootstrap': True, 'criterion': 'gini', 'min_samples_split': 9, 'n_estimators': 160, 'warm_start': False}\n",
      "0.830 (+/-0.090) for {'bootstrap': True, 'criterion': 'gini', 'min_samples_split': 9, 'n_estimators': 180, 'warm_start': True}\n",
      "0.822 (+/-0.097) for {'bootstrap': True, 'criterion': 'gini', 'min_samples_split': 9, 'n_estimators': 180, 'warm_start': False}\n",
      "0.825 (+/-0.098) for {'bootstrap': True, 'criterion': 'gini', 'min_samples_split': 9, 'n_estimators': 200, 'warm_start': True}\n",
      "0.822 (+/-0.098) for {'bootstrap': True, 'criterion': 'gini', 'min_samples_split': 9, 'n_estimators': 200, 'warm_start': False}\n",
      "0.794 (+/-0.118) for {'bootstrap': True, 'criterion': 'entropy', 'min_samples_split': 2, 'n_estimators': 60, 'warm_start': True}\n",
      "0.788 (+/-0.130) for {'bootstrap': True, 'criterion': 'entropy', 'min_samples_split': 2, 'n_estimators': 60, 'warm_start': False}\n",
      "0.794 (+/-0.121) for {'bootstrap': True, 'criterion': 'entropy', 'min_samples_split': 2, 'n_estimators': 70, 'warm_start': True}\n",
      "0.794 (+/-0.131) for {'bootstrap': True, 'criterion': 'entropy', 'min_samples_split': 2, 'n_estimators': 70, 'warm_start': False}\n",
      "0.789 (+/-0.118) for {'bootstrap': True, 'criterion': 'entropy', 'min_samples_split': 2, 'n_estimators': 80, 'warm_start': True}\n",
      "0.787 (+/-0.112) for {'bootstrap': True, 'criterion': 'entropy', 'min_samples_split': 2, 'n_estimators': 80, 'warm_start': False}\n",
      "0.794 (+/-0.116) for {'bootstrap': True, 'criterion': 'entropy', 'min_samples_split': 2, 'n_estimators': 90, 'warm_start': True}\n",
      "0.798 (+/-0.118) for {'bootstrap': True, 'criterion': 'entropy', 'min_samples_split': 2, 'n_estimators': 90, 'warm_start': False}\n",
      "0.795 (+/-0.111) for {'bootstrap': True, 'criterion': 'entropy', 'min_samples_split': 2, 'n_estimators': 100, 'warm_start': True}\n",
      "0.798 (+/-0.107) for {'bootstrap': True, 'criterion': 'entropy', 'min_samples_split': 2, 'n_estimators': 100, 'warm_start': False}\n",
      "0.791 (+/-0.117) for {'bootstrap': True, 'criterion': 'entropy', 'min_samples_split': 2, 'n_estimators': 120, 'warm_start': True}\n",
      "0.792 (+/-0.114) for {'bootstrap': True, 'criterion': 'entropy', 'min_samples_split': 2, 'n_estimators': 120, 'warm_start': False}\n",
      "0.794 (+/-0.130) for {'bootstrap': True, 'criterion': 'entropy', 'min_samples_split': 2, 'n_estimators': 140, 'warm_start': True}\n",
      "0.794 (+/-0.114) for {'bootstrap': True, 'criterion': 'entropy', 'min_samples_split': 2, 'n_estimators': 140, 'warm_start': False}\n",
      "0.789 (+/-0.121) for {'bootstrap': True, 'criterion': 'entropy', 'min_samples_split': 2, 'n_estimators': 160, 'warm_start': True}\n",
      "0.792 (+/-0.121) for {'bootstrap': True, 'criterion': 'entropy', 'min_samples_split': 2, 'n_estimators': 160, 'warm_start': False}\n",
      "0.792 (+/-0.133) for {'bootstrap': True, 'criterion': 'entropy', 'min_samples_split': 2, 'n_estimators': 180, 'warm_start': True}\n",
      "0.791 (+/-0.115) for {'bootstrap': True, 'criterion': 'entropy', 'min_samples_split': 2, 'n_estimators': 180, 'warm_start': False}\n",
      "0.792 (+/-0.129) for {'bootstrap': True, 'criterion': 'entropy', 'min_samples_split': 2, 'n_estimators': 200, 'warm_start': True}\n",
      "0.796 (+/-0.119) for {'bootstrap': True, 'criterion': 'entropy', 'min_samples_split': 2, 'n_estimators': 200, 'warm_start': False}\n",
      "0.809 (+/-0.102) for {'bootstrap': True, 'criterion': 'entropy', 'min_samples_split': 3, 'n_estimators': 60, 'warm_start': True}\n",
      "0.808 (+/-0.111) for {'bootstrap': True, 'criterion': 'entropy', 'min_samples_split': 3, 'n_estimators': 60, 'warm_start': False}\n",
      "0.809 (+/-0.098) for {'bootstrap': True, 'criterion': 'entropy', 'min_samples_split': 3, 'n_estimators': 70, 'warm_start': True}\n",
      "0.809 (+/-0.100) for {'bootstrap': True, 'criterion': 'entropy', 'min_samples_split': 3, 'n_estimators': 70, 'warm_start': False}\n",
      "0.803 (+/-0.112) for {'bootstrap': True, 'criterion': 'entropy', 'min_samples_split': 3, 'n_estimators': 80, 'warm_start': True}\n",
      "0.813 (+/-0.095) for {'bootstrap': True, 'criterion': 'entropy', 'min_samples_split': 3, 'n_estimators': 80, 'warm_start': False}\n",
      "0.798 (+/-0.116) for {'bootstrap': True, 'criterion': 'entropy', 'min_samples_split': 3, 'n_estimators': 90, 'warm_start': True}\n",
      "0.802 (+/-0.099) for {'bootstrap': True, 'criterion': 'entropy', 'min_samples_split': 3, 'n_estimators': 90, 'warm_start': False}\n",
      "0.820 (+/-0.104) for {'bootstrap': True, 'criterion': 'entropy', 'min_samples_split': 3, 'n_estimators': 100, 'warm_start': True}\n",
      "0.809 (+/-0.107) for {'bootstrap': True, 'criterion': 'entropy', 'min_samples_split': 3, 'n_estimators': 100, 'warm_start': False}\n",
      "0.808 (+/-0.106) for {'bootstrap': True, 'criterion': 'entropy', 'min_samples_split': 3, 'n_estimators': 120, 'warm_start': True}\n",
      "0.798 (+/-0.106) for {'bootstrap': True, 'criterion': 'entropy', 'min_samples_split': 3, 'n_estimators': 120, 'warm_start': False}\n",
      "0.801 (+/-0.117) for {'bootstrap': True, 'criterion': 'entropy', 'min_samples_split': 3, 'n_estimators': 140, 'warm_start': True}\n",
      "0.806 (+/-0.103) for {'bootstrap': True, 'criterion': 'entropy', 'min_samples_split': 3, 'n_estimators': 140, 'warm_start': False}\n",
      "0.806 (+/-0.096) for {'bootstrap': True, 'criterion': 'entropy', 'min_samples_split': 3, 'n_estimators': 160, 'warm_start': True}\n",
      "0.803 (+/-0.108) for {'bootstrap': True, 'criterion': 'entropy', 'min_samples_split': 3, 'n_estimators': 160, 'warm_start': False}\n",
      "0.810 (+/-0.107) for {'bootstrap': True, 'criterion': 'entropy', 'min_samples_split': 3, 'n_estimators': 180, 'warm_start': True}\n",
      "0.810 (+/-0.095) for {'bootstrap': True, 'criterion': 'entropy', 'min_samples_split': 3, 'n_estimators': 180, 'warm_start': False}\n",
      "0.810 (+/-0.101) for {'bootstrap': True, 'criterion': 'entropy', 'min_samples_split': 3, 'n_estimators': 200, 'warm_start': True}\n",
      "0.802 (+/-0.110) for {'bootstrap': True, 'criterion': 'entropy', 'min_samples_split': 3, 'n_estimators': 200, 'warm_start': False}\n",
      "0.822 (+/-0.086) for {'bootstrap': True, 'criterion': 'entropy', 'min_samples_split': 4, 'n_estimators': 60, 'warm_start': True}\n",
      "0.809 (+/-0.100) for {'bootstrap': True, 'criterion': 'entropy', 'min_samples_split': 4, 'n_estimators': 60, 'warm_start': False}\n",
      "0.822 (+/-0.076) for {'bootstrap': True, 'criterion': 'entropy', 'min_samples_split': 4, 'n_estimators': 70, 'warm_start': True}\n",
      "0.818 (+/-0.112) for {'bootstrap': True, 'criterion': 'entropy', 'min_samples_split': 4, 'n_estimators': 70, 'warm_start': False}\n",
      "0.813 (+/-0.097) for {'bootstrap': True, 'criterion': 'entropy', 'min_samples_split': 4, 'n_estimators': 80, 'warm_start': True}\n",
      "0.820 (+/-0.093) for {'bootstrap': True, 'criterion': 'entropy', 'min_samples_split': 4, 'n_estimators': 80, 'warm_start': False}\n",
      "0.820 (+/-0.105) for {'bootstrap': True, 'criterion': 'entropy', 'min_samples_split': 4, 'n_estimators': 90, 'warm_start': True}\n",
      "0.823 (+/-0.083) for {'bootstrap': True, 'criterion': 'entropy', 'min_samples_split': 4, 'n_estimators': 90, 'warm_start': False}\n",
      "0.816 (+/-0.095) for {'bootstrap': True, 'criterion': 'entropy', 'min_samples_split': 4, 'n_estimators': 100, 'warm_start': True}\n",
      "0.822 (+/-0.102) for {'bootstrap': True, 'criterion': 'entropy', 'min_samples_split': 4, 'n_estimators': 100, 'warm_start': False}\n",
      "0.816 (+/-0.098) for {'bootstrap': True, 'criterion': 'entropy', 'min_samples_split': 4, 'n_estimators': 120, 'warm_start': True}\n",
      "0.815 (+/-0.095) for {'bootstrap': True, 'criterion': 'entropy', 'min_samples_split': 4, 'n_estimators': 120, 'warm_start': False}\n",
      "0.822 (+/-0.099) for {'bootstrap': True, 'criterion': 'entropy', 'min_samples_split': 4, 'n_estimators': 140, 'warm_start': True}\n",
      "0.817 (+/-0.094) for {'bootstrap': True, 'criterion': 'entropy', 'min_samples_split': 4, 'n_estimators': 140, 'warm_start': False}\n",
      "0.823 (+/-0.098) for {'bootstrap': True, 'criterion': 'entropy', 'min_samples_split': 4, 'n_estimators': 160, 'warm_start': True}\n",
      "0.819 (+/-0.093) for {'bootstrap': True, 'criterion': 'entropy', 'min_samples_split': 4, 'n_estimators': 160, 'warm_start': False}\n",
      "0.823 (+/-0.089) for {'bootstrap': True, 'criterion': 'entropy', 'min_samples_split': 4, 'n_estimators': 180, 'warm_start': True}\n",
      "0.820 (+/-0.102) for {'bootstrap': True, 'criterion': 'entropy', 'min_samples_split': 4, 'n_estimators': 180, 'warm_start': False}\n",
      "0.823 (+/-0.099) for {'bootstrap': True, 'criterion': 'entropy', 'min_samples_split': 4, 'n_estimators': 200, 'warm_start': True}\n",
      "0.816 (+/-0.100) for {'bootstrap': True, 'criterion': 'entropy', 'min_samples_split': 4, 'n_estimators': 200, 'warm_start': False}\n",
      "0.819 (+/-0.103) for {'bootstrap': True, 'criterion': 'entropy', 'min_samples_split': 5, 'n_estimators': 60, 'warm_start': True}\n",
      "0.824 (+/-0.107) for {'bootstrap': True, 'criterion': 'entropy', 'min_samples_split': 5, 'n_estimators': 60, 'warm_start': False}\n",
      "0.824 (+/-0.110) for {'bootstrap': True, 'criterion': 'entropy', 'min_samples_split': 5, 'n_estimators': 70, 'warm_start': True}\n",
      "0.819 (+/-0.104) for {'bootstrap': True, 'criterion': 'entropy', 'min_samples_split': 5, 'n_estimators': 70, 'warm_start': False}\n",
      "0.816 (+/-0.094) for {'bootstrap': True, 'criterion': 'entropy', 'min_samples_split': 5, 'n_estimators': 80, 'warm_start': True}\n",
      "0.825 (+/-0.103) for {'bootstrap': True, 'criterion': 'entropy', 'min_samples_split': 5, 'n_estimators': 80, 'warm_start': False}\n",
      "0.826 (+/-0.099) for {'bootstrap': True, 'criterion': 'entropy', 'min_samples_split': 5, 'n_estimators': 90, 'warm_start': True}\n",
      "0.827 (+/-0.102) for {'bootstrap': True, 'criterion': 'entropy', 'min_samples_split': 5, 'n_estimators': 90, 'warm_start': False}\n",
      "0.820 (+/-0.092) for {'bootstrap': True, 'criterion': 'entropy', 'min_samples_split': 5, 'n_estimators': 100, 'warm_start': True}\n",
      "0.822 (+/-0.081) for {'bootstrap': True, 'criterion': 'entropy', 'min_samples_split': 5, 'n_estimators': 100, 'warm_start': False}\n",
      "0.816 (+/-0.105) for {'bootstrap': True, 'criterion': 'entropy', 'min_samples_split': 5, 'n_estimators': 120, 'warm_start': True}\n",
      "0.823 (+/-0.100) for {'bootstrap': True, 'criterion': 'entropy', 'min_samples_split': 5, 'n_estimators': 120, 'warm_start': False}\n",
      "0.819 (+/-0.105) for {'bootstrap': True, 'criterion': 'entropy', 'min_samples_split': 5, 'n_estimators': 140, 'warm_start': True}\n",
      "0.826 (+/-0.106) for {'bootstrap': True, 'criterion': 'entropy', 'min_samples_split': 5, 'n_estimators': 140, 'warm_start': False}\n",
      "0.826 (+/-0.090) for {'bootstrap': True, 'criterion': 'entropy', 'min_samples_split': 5, 'n_estimators': 160, 'warm_start': True}\n",
      "0.826 (+/-0.104) for {'bootstrap': True, 'criterion': 'entropy', 'min_samples_split': 5, 'n_estimators': 160, 'warm_start': False}\n",
      "0.827 (+/-0.102) for {'bootstrap': True, 'criterion': 'entropy', 'min_samples_split': 5, 'n_estimators': 180, 'warm_start': True}\n",
      "0.825 (+/-0.098) for {'bootstrap': True, 'criterion': 'entropy', 'min_samples_split': 5, 'n_estimators': 180, 'warm_start': False}\n",
      "0.824 (+/-0.086) for {'bootstrap': True, 'criterion': 'entropy', 'min_samples_split': 5, 'n_estimators': 200, 'warm_start': True}\n",
      "0.820 (+/-0.103) for {'bootstrap': True, 'criterion': 'entropy', 'min_samples_split': 5, 'n_estimators': 200, 'warm_start': False}\n",
      "0.824 (+/-0.091) for {'bootstrap': True, 'criterion': 'entropy', 'min_samples_split': 6, 'n_estimators': 60, 'warm_start': True}\n",
      "0.819 (+/-0.080) for {'bootstrap': True, 'criterion': 'entropy', 'min_samples_split': 6, 'n_estimators': 60, 'warm_start': False}\n",
      "0.829 (+/-0.100) for {'bootstrap': True, 'criterion': 'entropy', 'min_samples_split': 6, 'n_estimators': 70, 'warm_start': True}\n",
      "0.832 (+/-0.071) for {'bootstrap': True, 'criterion': 'entropy', 'min_samples_split': 6, 'n_estimators': 70, 'warm_start': False}\n",
      "0.817 (+/-0.101) for {'bootstrap': True, 'criterion': 'entropy', 'min_samples_split': 6, 'n_estimators': 80, 'warm_start': True}\n",
      "0.822 (+/-0.098) for {'bootstrap': True, 'criterion': 'entropy', 'min_samples_split': 6, 'n_estimators': 80, 'warm_start': False}\n",
      "0.834 (+/-0.110) for {'bootstrap': True, 'criterion': 'entropy', 'min_samples_split': 6, 'n_estimators': 90, 'warm_start': True}\n",
      "0.823 (+/-0.094) for {'bootstrap': True, 'criterion': 'entropy', 'min_samples_split': 6, 'n_estimators': 90, 'warm_start': False}\n",
      "0.829 (+/-0.101) for {'bootstrap': True, 'criterion': 'entropy', 'min_samples_split': 6, 'n_estimators': 100, 'warm_start': True}\n",
      "0.826 (+/-0.096) for {'bootstrap': True, 'criterion': 'entropy', 'min_samples_split': 6, 'n_estimators': 100, 'warm_start': False}\n",
      "0.826 (+/-0.094) for {'bootstrap': True, 'criterion': 'entropy', 'min_samples_split': 6, 'n_estimators': 120, 'warm_start': True}\n",
      "0.819 (+/-0.110) for {'bootstrap': True, 'criterion': 'entropy', 'min_samples_split': 6, 'n_estimators': 120, 'warm_start': False}\n",
      "0.819 (+/-0.098) for {'bootstrap': True, 'criterion': 'entropy', 'min_samples_split': 6, 'n_estimators': 140, 'warm_start': True}\n",
      "0.832 (+/-0.090) for {'bootstrap': True, 'criterion': 'entropy', 'min_samples_split': 6, 'n_estimators': 140, 'warm_start': False}\n",
      "0.830 (+/-0.091) for {'bootstrap': True, 'criterion': 'entropy', 'min_samples_split': 6, 'n_estimators': 160, 'warm_start': True}\n",
      "0.826 (+/-0.084) for {'bootstrap': True, 'criterion': 'entropy', 'min_samples_split': 6, 'n_estimators': 160, 'warm_start': False}\n",
      "0.826 (+/-0.089) for {'bootstrap': True, 'criterion': 'entropy', 'min_samples_split': 6, 'n_estimators': 180, 'warm_start': True}\n",
      "0.827 (+/-0.089) for {'bootstrap': True, 'criterion': 'entropy', 'min_samples_split': 6, 'n_estimators': 180, 'warm_start': False}\n",
      "0.827 (+/-0.092) for {'bootstrap': True, 'criterion': 'entropy', 'min_samples_split': 6, 'n_estimators': 200, 'warm_start': True}\n",
      "0.825 (+/-0.103) for {'bootstrap': True, 'criterion': 'entropy', 'min_samples_split': 6, 'n_estimators': 200, 'warm_start': False}\n",
      "0.825 (+/-0.088) for {'bootstrap': True, 'criterion': 'entropy', 'min_samples_split': 7, 'n_estimators': 60, 'warm_start': True}\n",
      "0.822 (+/-0.095) for {'bootstrap': True, 'criterion': 'entropy', 'min_samples_split': 7, 'n_estimators': 60, 'warm_start': False}\n",
      "0.829 (+/-0.098) for {'bootstrap': True, 'criterion': 'entropy', 'min_samples_split': 7, 'n_estimators': 70, 'warm_start': True}\n",
      "0.820 (+/-0.087) for {'bootstrap': True, 'criterion': 'entropy', 'min_samples_split': 7, 'n_estimators': 70, 'warm_start': False}\n",
      "0.833 (+/-0.084) for {'bootstrap': True, 'criterion': 'entropy', 'min_samples_split': 7, 'n_estimators': 80, 'warm_start': True}\n",
      "0.822 (+/-0.087) for {'bootstrap': True, 'criterion': 'entropy', 'min_samples_split': 7, 'n_estimators': 80, 'warm_start': False}\n",
      "0.822 (+/-0.072) for {'bootstrap': True, 'criterion': 'entropy', 'min_samples_split': 7, 'n_estimators': 90, 'warm_start': True}\n",
      "0.823 (+/-0.103) for {'bootstrap': True, 'criterion': 'entropy', 'min_samples_split': 7, 'n_estimators': 90, 'warm_start': False}\n",
      "0.819 (+/-0.097) for {'bootstrap': True, 'criterion': 'entropy', 'min_samples_split': 7, 'n_estimators': 100, 'warm_start': True}\n",
      "0.830 (+/-0.089) for {'bootstrap': True, 'criterion': 'entropy', 'min_samples_split': 7, 'n_estimators': 100, 'warm_start': False}\n",
      "0.829 (+/-0.094) for {'bootstrap': True, 'criterion': 'entropy', 'min_samples_split': 7, 'n_estimators': 120, 'warm_start': True}\n",
      "0.830 (+/-0.079) for {'bootstrap': True, 'criterion': 'entropy', 'min_samples_split': 7, 'n_estimators': 120, 'warm_start': False}\n",
      "0.826 (+/-0.096) for {'bootstrap': True, 'criterion': 'entropy', 'min_samples_split': 7, 'n_estimators': 140, 'warm_start': True}\n",
      "0.830 (+/-0.082) for {'bootstrap': True, 'criterion': 'entropy', 'min_samples_split': 7, 'n_estimators': 140, 'warm_start': False}\n",
      "0.829 (+/-0.091) for {'bootstrap': True, 'criterion': 'entropy', 'min_samples_split': 7, 'n_estimators': 160, 'warm_start': True}\n",
      "0.826 (+/-0.098) for {'bootstrap': True, 'criterion': 'entropy', 'min_samples_split': 7, 'n_estimators': 160, 'warm_start': False}\n",
      "0.830 (+/-0.105) for {'bootstrap': True, 'criterion': 'entropy', 'min_samples_split': 7, 'n_estimators': 180, 'warm_start': True}\n",
      "0.827 (+/-0.096) for {'bootstrap': True, 'criterion': 'entropy', 'min_samples_split': 7, 'n_estimators': 180, 'warm_start': False}\n",
      "0.823 (+/-0.104) for {'bootstrap': True, 'criterion': 'entropy', 'min_samples_split': 7, 'n_estimators': 200, 'warm_start': True}\n",
      "0.829 (+/-0.088) for {'bootstrap': True, 'criterion': 'entropy', 'min_samples_split': 7, 'n_estimators': 200, 'warm_start': False}\n",
      "0.812 (+/-0.093) for {'bootstrap': True, 'criterion': 'entropy', 'min_samples_split': 8, 'n_estimators': 60, 'warm_start': True}\n",
      "0.818 (+/-0.078) for {'bootstrap': True, 'criterion': 'entropy', 'min_samples_split': 8, 'n_estimators': 60, 'warm_start': False}\n",
      "0.827 (+/-0.086) for {'bootstrap': True, 'criterion': 'entropy', 'min_samples_split': 8, 'n_estimators': 70, 'warm_start': True}\n",
      "0.818 (+/-0.100) for {'bootstrap': True, 'criterion': 'entropy', 'min_samples_split': 8, 'n_estimators': 70, 'warm_start': False}\n",
      "0.822 (+/-0.097) for {'bootstrap': True, 'criterion': 'entropy', 'min_samples_split': 8, 'n_estimators': 80, 'warm_start': True}\n",
      "0.826 (+/-0.089) for {'bootstrap': True, 'criterion': 'entropy', 'min_samples_split': 8, 'n_estimators': 80, 'warm_start': False}\n",
      "0.819 (+/-0.088) for {'bootstrap': True, 'criterion': 'entropy', 'min_samples_split': 8, 'n_estimators': 90, 'warm_start': True}\n",
      "0.820 (+/-0.090) for {'bootstrap': True, 'criterion': 'entropy', 'min_samples_split': 8, 'n_estimators': 90, 'warm_start': False}\n",
      "0.827 (+/-0.078) for {'bootstrap': True, 'criterion': 'entropy', 'min_samples_split': 8, 'n_estimators': 100, 'warm_start': True}\n",
      "0.822 (+/-0.097) for {'bootstrap': True, 'criterion': 'entropy', 'min_samples_split': 8, 'n_estimators': 100, 'warm_start': False}\n",
      "0.829 (+/-0.082) for {'bootstrap': True, 'criterion': 'entropy', 'min_samples_split': 8, 'n_estimators': 120, 'warm_start': True}\n",
      "0.824 (+/-0.097) for {'bootstrap': True, 'criterion': 'entropy', 'min_samples_split': 8, 'n_estimators': 120, 'warm_start': False}\n",
      "0.825 (+/-0.082) for {'bootstrap': True, 'criterion': 'entropy', 'min_samples_split': 8, 'n_estimators': 140, 'warm_start': True}\n",
      "0.825 (+/-0.089) for {'bootstrap': True, 'criterion': 'entropy', 'min_samples_split': 8, 'n_estimators': 140, 'warm_start': False}\n",
      "0.825 (+/-0.089) for {'bootstrap': True, 'criterion': 'entropy', 'min_samples_split': 8, 'n_estimators': 160, 'warm_start': True}\n",
      "0.826 (+/-0.102) for {'bootstrap': True, 'criterion': 'entropy', 'min_samples_split': 8, 'n_estimators': 160, 'warm_start': False}\n",
      "0.830 (+/-0.088) for {'bootstrap': True, 'criterion': 'entropy', 'min_samples_split': 8, 'n_estimators': 180, 'warm_start': True}\n",
      "0.827 (+/-0.085) for {'bootstrap': True, 'criterion': 'entropy', 'min_samples_split': 8, 'n_estimators': 180, 'warm_start': False}\n",
      "0.825 (+/-0.089) for {'bootstrap': True, 'criterion': 'entropy', 'min_samples_split': 8, 'n_estimators': 200, 'warm_start': True}\n",
      "0.826 (+/-0.090) for {'bootstrap': True, 'criterion': 'entropy', 'min_samples_split': 8, 'n_estimators': 200, 'warm_start': False}\n",
      "0.820 (+/-0.096) for {'bootstrap': True, 'criterion': 'entropy', 'min_samples_split': 9, 'n_estimators': 60, 'warm_start': True}\n",
      "0.827 (+/-0.102) for {'bootstrap': True, 'criterion': 'entropy', 'min_samples_split': 9, 'n_estimators': 60, 'warm_start': False}\n",
      "0.832 (+/-0.081) for {'bootstrap': True, 'criterion': 'entropy', 'min_samples_split': 9, 'n_estimators': 70, 'warm_start': True}\n",
      "0.826 (+/-0.100) for {'bootstrap': True, 'criterion': 'entropy', 'min_samples_split': 9, 'n_estimators': 70, 'warm_start': False}\n",
      "0.825 (+/-0.076) for {'bootstrap': True, 'criterion': 'entropy', 'min_samples_split': 9, 'n_estimators': 80, 'warm_start': True}\n",
      "0.830 (+/-0.097) for {'bootstrap': True, 'criterion': 'entropy', 'min_samples_split': 9, 'n_estimators': 80, 'warm_start': False}\n",
      "0.820 (+/-0.086) for {'bootstrap': True, 'criterion': 'entropy', 'min_samples_split': 9, 'n_estimators': 90, 'warm_start': True}\n",
      "0.817 (+/-0.106) for {'bootstrap': True, 'criterion': 'entropy', 'min_samples_split': 9, 'n_estimators': 90, 'warm_start': False}\n",
      "0.819 (+/-0.077) for {'bootstrap': True, 'criterion': 'entropy', 'min_samples_split': 9, 'n_estimators': 100, 'warm_start': True}\n",
      "0.822 (+/-0.083) for {'bootstrap': True, 'criterion': 'entropy', 'min_samples_split': 9, 'n_estimators': 100, 'warm_start': False}\n",
      "0.832 (+/-0.092) for {'bootstrap': True, 'criterion': 'entropy', 'min_samples_split': 9, 'n_estimators': 120, 'warm_start': True}\n",
      "0.830 (+/-0.082) for {'bootstrap': True, 'criterion': 'entropy', 'min_samples_split': 9, 'n_estimators': 120, 'warm_start': False}\n",
      "0.825 (+/-0.096) for {'bootstrap': True, 'criterion': 'entropy', 'min_samples_split': 9, 'n_estimators': 140, 'warm_start': True}\n",
      "0.833 (+/-0.087) for {'bootstrap': True, 'criterion': 'entropy', 'min_samples_split': 9, 'n_estimators': 140, 'warm_start': False}\n",
      "0.830 (+/-0.091) for {'bootstrap': True, 'criterion': 'entropy', 'min_samples_split': 9, 'n_estimators': 160, 'warm_start': True}\n",
      "0.820 (+/-0.105) for {'bootstrap': True, 'criterion': 'entropy', 'min_samples_split': 9, 'n_estimators': 160, 'warm_start': False}\n",
      "0.822 (+/-0.089) for {'bootstrap': True, 'criterion': 'entropy', 'min_samples_split': 9, 'n_estimators': 180, 'warm_start': True}\n",
      "0.825 (+/-0.096) for {'bootstrap': True, 'criterion': 'entropy', 'min_samples_split': 9, 'n_estimators': 180, 'warm_start': False}\n",
      "0.826 (+/-0.090) for {'bootstrap': True, 'criterion': 'entropy', 'min_samples_split': 9, 'n_estimators': 200, 'warm_start': True}\n",
      "0.827 (+/-0.092) for {'bootstrap': True, 'criterion': 'entropy', 'min_samples_split': 9, 'n_estimators': 200, 'warm_start': False}\n",
      "0.778 (+/-0.140) for {'bootstrap': False, 'criterion': 'gini', 'min_samples_split': 2, 'n_estimators': 60, 'warm_start': True}\n",
      "0.777 (+/-0.138) for {'bootstrap': False, 'criterion': 'gini', 'min_samples_split': 2, 'n_estimators': 60, 'warm_start': False}\n",
      "0.777 (+/-0.130) for {'bootstrap': False, 'criterion': 'gini', 'min_samples_split': 2, 'n_estimators': 70, 'warm_start': True}\n",
      "0.775 (+/-0.145) for {'bootstrap': False, 'criterion': 'gini', 'min_samples_split': 2, 'n_estimators': 70, 'warm_start': False}\n",
      "0.778 (+/-0.125) for {'bootstrap': False, 'criterion': 'gini', 'min_samples_split': 2, 'n_estimators': 80, 'warm_start': True}\n",
      "0.775 (+/-0.152) for {'bootstrap': False, 'criterion': 'gini', 'min_samples_split': 2, 'n_estimators': 80, 'warm_start': False}\n",
      "0.775 (+/-0.127) for {'bootstrap': False, 'criterion': 'gini', 'min_samples_split': 2, 'n_estimators': 90, 'warm_start': True}\n",
      "0.780 (+/-0.122) for {'bootstrap': False, 'criterion': 'gini', 'min_samples_split': 2, 'n_estimators': 90, 'warm_start': False}\n",
      "0.778 (+/-0.122) for {'bootstrap': False, 'criterion': 'gini', 'min_samples_split': 2, 'n_estimators': 100, 'warm_start': True}\n",
      "0.784 (+/-0.129) for {'bootstrap': False, 'criterion': 'gini', 'min_samples_split': 2, 'n_estimators': 100, 'warm_start': False}\n",
      "0.777 (+/-0.135) for {'bootstrap': False, 'criterion': 'gini', 'min_samples_split': 2, 'n_estimators': 120, 'warm_start': True}\n",
      "0.778 (+/-0.131) for {'bootstrap': False, 'criterion': 'gini', 'min_samples_split': 2, 'n_estimators': 120, 'warm_start': False}\n",
      "0.768 (+/-0.144) for {'bootstrap': False, 'criterion': 'gini', 'min_samples_split': 2, 'n_estimators': 140, 'warm_start': True}\n",
      "0.775 (+/-0.117) for {'bootstrap': False, 'criterion': 'gini', 'min_samples_split': 2, 'n_estimators': 140, 'warm_start': False}\n",
      "0.782 (+/-0.125) for {'bootstrap': False, 'criterion': 'gini', 'min_samples_split': 2, 'n_estimators': 160, 'warm_start': True}\n",
      "0.778 (+/-0.126) for {'bootstrap': False, 'criterion': 'gini', 'min_samples_split': 2, 'n_estimators': 160, 'warm_start': False}\n",
      "0.768 (+/-0.138) for {'bootstrap': False, 'criterion': 'gini', 'min_samples_split': 2, 'n_estimators': 180, 'warm_start': True}\n",
      "0.777 (+/-0.124) for {'bootstrap': False, 'criterion': 'gini', 'min_samples_split': 2, 'n_estimators': 180, 'warm_start': False}\n",
      "0.775 (+/-0.133) for {'bootstrap': False, 'criterion': 'gini', 'min_samples_split': 2, 'n_estimators': 200, 'warm_start': True}\n",
      "0.778 (+/-0.109) for {'bootstrap': False, 'criterion': 'gini', 'min_samples_split': 2, 'n_estimators': 200, 'warm_start': False}\n",
      "0.794 (+/-0.108) for {'bootstrap': False, 'criterion': 'gini', 'min_samples_split': 3, 'n_estimators': 60, 'warm_start': True}\n",
      "0.788 (+/-0.130) for {'bootstrap': False, 'criterion': 'gini', 'min_samples_split': 3, 'n_estimators': 60, 'warm_start': False}\n",
      "0.787 (+/-0.118) for {'bootstrap': False, 'criterion': 'gini', 'min_samples_split': 3, 'n_estimators': 70, 'warm_start': True}\n",
      "0.782 (+/-0.115) for {'bootstrap': False, 'criterion': 'gini', 'min_samples_split': 3, 'n_estimators': 70, 'warm_start': False}\n",
      "0.787 (+/-0.118) for {'bootstrap': False, 'criterion': 'gini', 'min_samples_split': 3, 'n_estimators': 80, 'warm_start': True}\n",
      "0.784 (+/-0.129) for {'bootstrap': False, 'criterion': 'gini', 'min_samples_split': 3, 'n_estimators': 80, 'warm_start': False}\n",
      "0.794 (+/-0.114) for {'bootstrap': False, 'criterion': 'gini', 'min_samples_split': 3, 'n_estimators': 90, 'warm_start': True}\n",
      "0.787 (+/-0.122) for {'bootstrap': False, 'criterion': 'gini', 'min_samples_split': 3, 'n_estimators': 90, 'warm_start': False}\n",
      "0.791 (+/-0.119) for {'bootstrap': False, 'criterion': 'gini', 'min_samples_split': 3, 'n_estimators': 100, 'warm_start': True}\n",
      "0.785 (+/-0.112) for {'bootstrap': False, 'criterion': 'gini', 'min_samples_split': 3, 'n_estimators': 100, 'warm_start': False}\n",
      "0.787 (+/-0.121) for {'bootstrap': False, 'criterion': 'gini', 'min_samples_split': 3, 'n_estimators': 120, 'warm_start': True}\n",
      "0.787 (+/-0.112) for {'bootstrap': False, 'criterion': 'gini', 'min_samples_split': 3, 'n_estimators': 120, 'warm_start': False}\n",
      "0.781 (+/-0.125) for {'bootstrap': False, 'criterion': 'gini', 'min_samples_split': 3, 'n_estimators': 140, 'warm_start': True}\n",
      "0.791 (+/-0.114) for {'bootstrap': False, 'criterion': 'gini', 'min_samples_split': 3, 'n_estimators': 140, 'warm_start': False}\n",
      "0.791 (+/-0.120) for {'bootstrap': False, 'criterion': 'gini', 'min_samples_split': 3, 'n_estimators': 160, 'warm_start': True}\n",
      "0.792 (+/-0.110) for {'bootstrap': False, 'criterion': 'gini', 'min_samples_split': 3, 'n_estimators': 160, 'warm_start': False}\n",
      "0.788 (+/-0.130) for {'bootstrap': False, 'criterion': 'gini', 'min_samples_split': 3, 'n_estimators': 180, 'warm_start': True}\n",
      "0.791 (+/-0.109) for {'bootstrap': False, 'criterion': 'gini', 'min_samples_split': 3, 'n_estimators': 180, 'warm_start': False}\n",
      "0.791 (+/-0.121) for {'bootstrap': False, 'criterion': 'gini', 'min_samples_split': 3, 'n_estimators': 200, 'warm_start': True}\n",
      "0.785 (+/-0.125) for {'bootstrap': False, 'criterion': 'gini', 'min_samples_split': 3, 'n_estimators': 200, 'warm_start': False}\n",
      "0.789 (+/-0.101) for {'bootstrap': False, 'criterion': 'gini', 'min_samples_split': 4, 'n_estimators': 60, 'warm_start': True}\n",
      "0.791 (+/-0.112) for {'bootstrap': False, 'criterion': 'gini', 'min_samples_split': 4, 'n_estimators': 60, 'warm_start': False}\n",
      "0.796 (+/-0.115) for {'bootstrap': False, 'criterion': 'gini', 'min_samples_split': 4, 'n_estimators': 70, 'warm_start': True}\n",
      "0.795 (+/-0.109) for {'bootstrap': False, 'criterion': 'gini', 'min_samples_split': 4, 'n_estimators': 70, 'warm_start': False}\n",
      "0.789 (+/-0.112) for {'bootstrap': False, 'criterion': 'gini', 'min_samples_split': 4, 'n_estimators': 80, 'warm_start': True}\n",
      "0.799 (+/-0.109) for {'bootstrap': False, 'criterion': 'gini', 'min_samples_split': 4, 'n_estimators': 80, 'warm_start': False}\n",
      "0.794 (+/-0.104) for {'bootstrap': False, 'criterion': 'gini', 'min_samples_split': 4, 'n_estimators': 90, 'warm_start': True}\n",
      "0.787 (+/-0.122) for {'bootstrap': False, 'criterion': 'gini', 'min_samples_split': 4, 'n_estimators': 90, 'warm_start': False}\n",
      "0.792 (+/-0.121) for {'bootstrap': False, 'criterion': 'gini', 'min_samples_split': 4, 'n_estimators': 100, 'warm_start': True}\n",
      "0.796 (+/-0.098) for {'bootstrap': False, 'criterion': 'gini', 'min_samples_split': 4, 'n_estimators': 100, 'warm_start': False}\n",
      "0.801 (+/-0.108) for {'bootstrap': False, 'criterion': 'gini', 'min_samples_split': 4, 'n_estimators': 120, 'warm_start': True}\n",
      "0.791 (+/-0.119) for {'bootstrap': False, 'criterion': 'gini', 'min_samples_split': 4, 'n_estimators': 120, 'warm_start': False}\n",
      "0.801 (+/-0.103) for {'bootstrap': False, 'criterion': 'gini', 'min_samples_split': 4, 'n_estimators': 140, 'warm_start': True}\n",
      "0.796 (+/-0.106) for {'bootstrap': False, 'criterion': 'gini', 'min_samples_split': 4, 'n_estimators': 140, 'warm_start': False}\n",
      "0.796 (+/-0.113) for {'bootstrap': False, 'criterion': 'gini', 'min_samples_split': 4, 'n_estimators': 160, 'warm_start': True}\n",
      "0.794 (+/-0.119) for {'bootstrap': False, 'criterion': 'gini', 'min_samples_split': 4, 'n_estimators': 160, 'warm_start': False}\n",
      "0.791 (+/-0.117) for {'bootstrap': False, 'criterion': 'gini', 'min_samples_split': 4, 'n_estimators': 180, 'warm_start': True}\n",
      "0.796 (+/-0.106) for {'bootstrap': False, 'criterion': 'gini', 'min_samples_split': 4, 'n_estimators': 180, 'warm_start': False}\n",
      "0.789 (+/-0.121) for {'bootstrap': False, 'criterion': 'gini', 'min_samples_split': 4, 'n_estimators': 200, 'warm_start': True}\n",
      "0.792 (+/-0.110) for {'bootstrap': False, 'criterion': 'gini', 'min_samples_split': 4, 'n_estimators': 200, 'warm_start': False}\n",
      "0.805 (+/-0.087) for {'bootstrap': False, 'criterion': 'gini', 'min_samples_split': 5, 'n_estimators': 60, 'warm_start': True}\n",
      "0.806 (+/-0.098) for {'bootstrap': False, 'criterion': 'gini', 'min_samples_split': 5, 'n_estimators': 60, 'warm_start': False}\n",
      "0.809 (+/-0.096) for {'bootstrap': False, 'criterion': 'gini', 'min_samples_split': 5, 'n_estimators': 70, 'warm_start': True}\n",
      "0.809 (+/-0.085) for {'bootstrap': False, 'criterion': 'gini', 'min_samples_split': 5, 'n_estimators': 70, 'warm_start': False}\n",
      "0.813 (+/-0.092) for {'bootstrap': False, 'criterion': 'gini', 'min_samples_split': 5, 'n_estimators': 80, 'warm_start': True}\n",
      "0.805 (+/-0.110) for {'bootstrap': False, 'criterion': 'gini', 'min_samples_split': 5, 'n_estimators': 80, 'warm_start': False}\n",
      "0.812 (+/-0.088) for {'bootstrap': False, 'criterion': 'gini', 'min_samples_split': 5, 'n_estimators': 90, 'warm_start': True}\n",
      "0.812 (+/-0.097) for {'bootstrap': False, 'criterion': 'gini', 'min_samples_split': 5, 'n_estimators': 90, 'warm_start': False}\n",
      "0.806 (+/-0.094) for {'bootstrap': False, 'criterion': 'gini', 'min_samples_split': 5, 'n_estimators': 100, 'warm_start': True}\n",
      "0.812 (+/-0.100) for {'bootstrap': False, 'criterion': 'gini', 'min_samples_split': 5, 'n_estimators': 100, 'warm_start': False}\n",
      "0.816 (+/-0.102) for {'bootstrap': False, 'criterion': 'gini', 'min_samples_split': 5, 'n_estimators': 120, 'warm_start': True}\n",
      "0.808 (+/-0.105) for {'bootstrap': False, 'criterion': 'gini', 'min_samples_split': 5, 'n_estimators': 120, 'warm_start': False}\n",
      "0.806 (+/-0.103) for {'bootstrap': False, 'criterion': 'gini', 'min_samples_split': 5, 'n_estimators': 140, 'warm_start': True}\n",
      "0.810 (+/-0.082) for {'bootstrap': False, 'criterion': 'gini', 'min_samples_split': 5, 'n_estimators': 140, 'warm_start': False}\n",
      "0.809 (+/-0.097) for {'bootstrap': False, 'criterion': 'gini', 'min_samples_split': 5, 'n_estimators': 160, 'warm_start': True}\n",
      "0.811 (+/-0.098) for {'bootstrap': False, 'criterion': 'gini', 'min_samples_split': 5, 'n_estimators': 160, 'warm_start': False}\n",
      "0.809 (+/-0.085) for {'bootstrap': False, 'criterion': 'gini', 'min_samples_split': 5, 'n_estimators': 180, 'warm_start': True}\n",
      "0.812 (+/-0.083) for {'bootstrap': False, 'criterion': 'gini', 'min_samples_split': 5, 'n_estimators': 180, 'warm_start': False}\n",
      "0.809 (+/-0.096) for {'bootstrap': False, 'criterion': 'gini', 'min_samples_split': 5, 'n_estimators': 200, 'warm_start': True}\n",
      "0.810 (+/-0.093) for {'bootstrap': False, 'criterion': 'gini', 'min_samples_split': 5, 'n_estimators': 200, 'warm_start': False}\n",
      "0.813 (+/-0.088) for {'bootstrap': False, 'criterion': 'gini', 'min_samples_split': 6, 'n_estimators': 60, 'warm_start': True}\n",
      "0.812 (+/-0.085) for {'bootstrap': False, 'criterion': 'gini', 'min_samples_split': 6, 'n_estimators': 60, 'warm_start': False}\n",
      "0.812 (+/-0.100) for {'bootstrap': False, 'criterion': 'gini', 'min_samples_split': 6, 'n_estimators': 70, 'warm_start': True}\n",
      "0.816 (+/-0.085) for {'bootstrap': False, 'criterion': 'gini', 'min_samples_split': 6, 'n_estimators': 70, 'warm_start': False}\n",
      "0.812 (+/-0.090) for {'bootstrap': False, 'criterion': 'gini', 'min_samples_split': 6, 'n_estimators': 80, 'warm_start': True}\n",
      "0.818 (+/-0.095) for {'bootstrap': False, 'criterion': 'gini', 'min_samples_split': 6, 'n_estimators': 80, 'warm_start': False}\n",
      "0.812 (+/-0.089) for {'bootstrap': False, 'criterion': 'gini', 'min_samples_split': 6, 'n_estimators': 90, 'warm_start': True}\n",
      "0.817 (+/-0.086) for {'bootstrap': False, 'criterion': 'gini', 'min_samples_split': 6, 'n_estimators': 90, 'warm_start': False}\n",
      "0.815 (+/-0.089) for {'bootstrap': False, 'criterion': 'gini', 'min_samples_split': 6, 'n_estimators': 100, 'warm_start': True}\n",
      "0.813 (+/-0.102) for {'bootstrap': False, 'criterion': 'gini', 'min_samples_split': 6, 'n_estimators': 100, 'warm_start': False}\n",
      "0.815 (+/-0.082) for {'bootstrap': False, 'criterion': 'gini', 'min_samples_split': 6, 'n_estimators': 120, 'warm_start': True}\n",
      "0.819 (+/-0.079) for {'bootstrap': False, 'criterion': 'gini', 'min_samples_split': 6, 'n_estimators': 120, 'warm_start': False}\n",
      "0.813 (+/-0.086) for {'bootstrap': False, 'criterion': 'gini', 'min_samples_split': 6, 'n_estimators': 140, 'warm_start': True}\n",
      "0.815 (+/-0.094) for {'bootstrap': False, 'criterion': 'gini', 'min_samples_split': 6, 'n_estimators': 140, 'warm_start': False}\n",
      "0.815 (+/-0.090) for {'bootstrap': False, 'criterion': 'gini', 'min_samples_split': 6, 'n_estimators': 160, 'warm_start': True}\n",
      "0.815 (+/-0.093) for {'bootstrap': False, 'criterion': 'gini', 'min_samples_split': 6, 'n_estimators': 160, 'warm_start': False}\n",
      "0.813 (+/-0.109) for {'bootstrap': False, 'criterion': 'gini', 'min_samples_split': 6, 'n_estimators': 180, 'warm_start': True}\n",
      "0.823 (+/-0.090) for {'bootstrap': False, 'criterion': 'gini', 'min_samples_split': 6, 'n_estimators': 180, 'warm_start': False}\n",
      "0.816 (+/-0.091) for {'bootstrap': False, 'criterion': 'gini', 'min_samples_split': 6, 'n_estimators': 200, 'warm_start': True}\n",
      "0.822 (+/-0.084) for {'bootstrap': False, 'criterion': 'gini', 'min_samples_split': 6, 'n_estimators': 200, 'warm_start': False}\n",
      "0.815 (+/-0.089) for {'bootstrap': False, 'criterion': 'gini', 'min_samples_split': 7, 'n_estimators': 60, 'warm_start': True}\n",
      "0.813 (+/-0.095) for {'bootstrap': False, 'criterion': 'gini', 'min_samples_split': 7, 'n_estimators': 60, 'warm_start': False}\n",
      "0.812 (+/-0.099) for {'bootstrap': False, 'criterion': 'gini', 'min_samples_split': 7, 'n_estimators': 70, 'warm_start': True}\n",
      "0.816 (+/-0.085) for {'bootstrap': False, 'criterion': 'gini', 'min_samples_split': 7, 'n_estimators': 70, 'warm_start': False}\n",
      "0.823 (+/-0.076) for {'bootstrap': False, 'criterion': 'gini', 'min_samples_split': 7, 'n_estimators': 80, 'warm_start': True}\n",
      "0.815 (+/-0.097) for {'bootstrap': False, 'criterion': 'gini', 'min_samples_split': 7, 'n_estimators': 80, 'warm_start': False}\n",
      "0.823 (+/-0.079) for {'bootstrap': False, 'criterion': 'gini', 'min_samples_split': 7, 'n_estimators': 90, 'warm_start': True}\n",
      "0.816 (+/-0.099) for {'bootstrap': False, 'criterion': 'gini', 'min_samples_split': 7, 'n_estimators': 90, 'warm_start': False}\n",
      "0.819 (+/-0.088) for {'bootstrap': False, 'criterion': 'gini', 'min_samples_split': 7, 'n_estimators': 100, 'warm_start': True}\n",
      "0.820 (+/-0.101) for {'bootstrap': False, 'criterion': 'gini', 'min_samples_split': 7, 'n_estimators': 100, 'warm_start': False}\n",
      "0.819 (+/-0.097) for {'bootstrap': False, 'criterion': 'gini', 'min_samples_split': 7, 'n_estimators': 120, 'warm_start': True}\n",
      "0.819 (+/-0.084) for {'bootstrap': False, 'criterion': 'gini', 'min_samples_split': 7, 'n_estimators': 120, 'warm_start': False}\n",
      "0.822 (+/-0.094) for {'bootstrap': False, 'criterion': 'gini', 'min_samples_split': 7, 'n_estimators': 140, 'warm_start': True}\n",
      "0.819 (+/-0.098) for {'bootstrap': False, 'criterion': 'gini', 'min_samples_split': 7, 'n_estimators': 140, 'warm_start': False}\n",
      "0.816 (+/-0.104) for {'bootstrap': False, 'criterion': 'gini', 'min_samples_split': 7, 'n_estimators': 160, 'warm_start': True}\n",
      "0.815 (+/-0.097) for {'bootstrap': False, 'criterion': 'gini', 'min_samples_split': 7, 'n_estimators': 160, 'warm_start': False}\n",
      "0.819 (+/-0.093) for {'bootstrap': False, 'criterion': 'gini', 'min_samples_split': 7, 'n_estimators': 180, 'warm_start': True}\n",
      "0.820 (+/-0.084) for {'bootstrap': False, 'criterion': 'gini', 'min_samples_split': 7, 'n_estimators': 180, 'warm_start': False}\n",
      "0.822 (+/-0.094) for {'bootstrap': False, 'criterion': 'gini', 'min_samples_split': 7, 'n_estimators': 200, 'warm_start': True}\n",
      "0.820 (+/-0.088) for {'bootstrap': False, 'criterion': 'gini', 'min_samples_split': 7, 'n_estimators': 200, 'warm_start': False}\n",
      "0.825 (+/-0.085) for {'bootstrap': False, 'criterion': 'gini', 'min_samples_split': 8, 'n_estimators': 60, 'warm_start': True}\n",
      "0.820 (+/-0.098) for {'bootstrap': False, 'criterion': 'gini', 'min_samples_split': 8, 'n_estimators': 60, 'warm_start': False}\n",
      "0.820 (+/-0.091) for {'bootstrap': False, 'criterion': 'gini', 'min_samples_split': 8, 'n_estimators': 70, 'warm_start': True}\n",
      "0.824 (+/-0.083) for {'bootstrap': False, 'criterion': 'gini', 'min_samples_split': 8, 'n_estimators': 70, 'warm_start': False}\n",
      "0.822 (+/-0.086) for {'bootstrap': False, 'criterion': 'gini', 'min_samples_split': 8, 'n_estimators': 80, 'warm_start': True}\n",
      "0.810 (+/-0.077) for {'bootstrap': False, 'criterion': 'gini', 'min_samples_split': 8, 'n_estimators': 80, 'warm_start': False}\n",
      "0.820 (+/-0.089) for {'bootstrap': False, 'criterion': 'gini', 'min_samples_split': 8, 'n_estimators': 90, 'warm_start': True}\n",
      "0.825 (+/-0.087) for {'bootstrap': False, 'criterion': 'gini', 'min_samples_split': 8, 'n_estimators': 90, 'warm_start': False}\n",
      "0.813 (+/-0.097) for {'bootstrap': False, 'criterion': 'gini', 'min_samples_split': 8, 'n_estimators': 100, 'warm_start': True}\n",
      "0.813 (+/-0.092) for {'bootstrap': False, 'criterion': 'gini', 'min_samples_split': 8, 'n_estimators': 100, 'warm_start': False}\n",
      "0.822 (+/-0.093) for {'bootstrap': False, 'criterion': 'gini', 'min_samples_split': 8, 'n_estimators': 120, 'warm_start': True}\n",
      "0.816 (+/-0.086) for {'bootstrap': False, 'criterion': 'gini', 'min_samples_split': 8, 'n_estimators': 120, 'warm_start': False}\n",
      "0.818 (+/-0.093) for {'bootstrap': False, 'criterion': 'gini', 'min_samples_split': 8, 'n_estimators': 140, 'warm_start': True}\n",
      "0.822 (+/-0.097) for {'bootstrap': False, 'criterion': 'gini', 'min_samples_split': 8, 'n_estimators': 140, 'warm_start': False}\n",
      "0.823 (+/-0.083) for {'bootstrap': False, 'criterion': 'gini', 'min_samples_split': 8, 'n_estimators': 160, 'warm_start': True}\n",
      "0.822 (+/-0.088) for {'bootstrap': False, 'criterion': 'gini', 'min_samples_split': 8, 'n_estimators': 160, 'warm_start': False}\n",
      "0.826 (+/-0.080) for {'bootstrap': False, 'criterion': 'gini', 'min_samples_split': 8, 'n_estimators': 180, 'warm_start': True}\n",
      "0.823 (+/-0.085) for {'bootstrap': False, 'criterion': 'gini', 'min_samples_split': 8, 'n_estimators': 180, 'warm_start': False}\n",
      "0.819 (+/-0.086) for {'bootstrap': False, 'criterion': 'gini', 'min_samples_split': 8, 'n_estimators': 200, 'warm_start': True}\n",
      "0.820 (+/-0.085) for {'bootstrap': False, 'criterion': 'gini', 'min_samples_split': 8, 'n_estimators': 200, 'warm_start': False}\n",
      "0.819 (+/-0.092) for {'bootstrap': False, 'criterion': 'gini', 'min_samples_split': 9, 'n_estimators': 60, 'warm_start': True}\n",
      "0.819 (+/-0.090) for {'bootstrap': False, 'criterion': 'gini', 'min_samples_split': 9, 'n_estimators': 60, 'warm_start': False}\n",
      "0.825 (+/-0.102) for {'bootstrap': False, 'criterion': 'gini', 'min_samples_split': 9, 'n_estimators': 70, 'warm_start': True}\n",
      "0.826 (+/-0.085) for {'bootstrap': False, 'criterion': 'gini', 'min_samples_split': 9, 'n_estimators': 70, 'warm_start': False}\n",
      "0.819 (+/-0.085) for {'bootstrap': False, 'criterion': 'gini', 'min_samples_split': 9, 'n_estimators': 80, 'warm_start': True}\n",
      "0.825 (+/-0.087) for {'bootstrap': False, 'criterion': 'gini', 'min_samples_split': 9, 'n_estimators': 80, 'warm_start': False}\n",
      "0.826 (+/-0.081) for {'bootstrap': False, 'criterion': 'gini', 'min_samples_split': 9, 'n_estimators': 90, 'warm_start': True}\n",
      "0.818 (+/-0.089) for {'bootstrap': False, 'criterion': 'gini', 'min_samples_split': 9, 'n_estimators': 90, 'warm_start': False}\n",
      "0.819 (+/-0.089) for {'bootstrap': False, 'criterion': 'gini', 'min_samples_split': 9, 'n_estimators': 100, 'warm_start': True}\n",
      "0.822 (+/-0.086) for {'bootstrap': False, 'criterion': 'gini', 'min_samples_split': 9, 'n_estimators': 100, 'warm_start': False}\n",
      "0.819 (+/-0.086) for {'bootstrap': False, 'criterion': 'gini', 'min_samples_split': 9, 'n_estimators': 120, 'warm_start': True}\n",
      "0.819 (+/-0.095) for {'bootstrap': False, 'criterion': 'gini', 'min_samples_split': 9, 'n_estimators': 120, 'warm_start': False}\n",
      "0.818 (+/-0.092) for {'bootstrap': False, 'criterion': 'gini', 'min_samples_split': 9, 'n_estimators': 140, 'warm_start': True}\n",
      "0.820 (+/-0.084) for {'bootstrap': False, 'criterion': 'gini', 'min_samples_split': 9, 'n_estimators': 140, 'warm_start': False}\n",
      "0.819 (+/-0.091) for {'bootstrap': False, 'criterion': 'gini', 'min_samples_split': 9, 'n_estimators': 160, 'warm_start': True}\n",
      "0.823 (+/-0.083) for {'bootstrap': False, 'criterion': 'gini', 'min_samples_split': 9, 'n_estimators': 160, 'warm_start': False}\n",
      "0.825 (+/-0.082) for {'bootstrap': False, 'criterion': 'gini', 'min_samples_split': 9, 'n_estimators': 180, 'warm_start': True}\n",
      "0.823 (+/-0.086) for {'bootstrap': False, 'criterion': 'gini', 'min_samples_split': 9, 'n_estimators': 180, 'warm_start': False}\n",
      "0.826 (+/-0.083) for {'bootstrap': False, 'criterion': 'gini', 'min_samples_split': 9, 'n_estimators': 200, 'warm_start': True}\n",
      "0.825 (+/-0.084) for {'bootstrap': False, 'criterion': 'gini', 'min_samples_split': 9, 'n_estimators': 200, 'warm_start': False}\n",
      "0.781 (+/-0.111) for {'bootstrap': False, 'criterion': 'entropy', 'min_samples_split': 2, 'n_estimators': 60, 'warm_start': True}\n",
      "0.785 (+/-0.134) for {'bootstrap': False, 'criterion': 'entropy', 'min_samples_split': 2, 'n_estimators': 60, 'warm_start': False}\n",
      "0.787 (+/-0.120) for {'bootstrap': False, 'criterion': 'entropy', 'min_samples_split': 2, 'n_estimators': 70, 'warm_start': True}\n",
      "0.781 (+/-0.119) for {'bootstrap': False, 'criterion': 'entropy', 'min_samples_split': 2, 'n_estimators': 70, 'warm_start': False}\n",
      "0.777 (+/-0.132) for {'bootstrap': False, 'criterion': 'entropy', 'min_samples_split': 2, 'n_estimators': 80, 'warm_start': True}\n",
      "0.775 (+/-0.120) for {'bootstrap': False, 'criterion': 'entropy', 'min_samples_split': 2, 'n_estimators': 80, 'warm_start': False}\n",
      "0.785 (+/-0.114) for {'bootstrap': False, 'criterion': 'entropy', 'min_samples_split': 2, 'n_estimators': 90, 'warm_start': True}\n",
      "0.787 (+/-0.110) for {'bootstrap': False, 'criterion': 'entropy', 'min_samples_split': 2, 'n_estimators': 90, 'warm_start': False}\n",
      "0.782 (+/-0.121) for {'bootstrap': False, 'criterion': 'entropy', 'min_samples_split': 2, 'n_estimators': 100, 'warm_start': True}\n",
      "0.782 (+/-0.120) for {'bootstrap': False, 'criterion': 'entropy', 'min_samples_split': 2, 'n_estimators': 100, 'warm_start': False}\n",
      "0.771 (+/-0.144) for {'bootstrap': False, 'criterion': 'entropy', 'min_samples_split': 2, 'n_estimators': 120, 'warm_start': True}\n",
      "0.773 (+/-0.140) for {'bootstrap': False, 'criterion': 'entropy', 'min_samples_split': 2, 'n_estimators': 120, 'warm_start': False}\n",
      "0.782 (+/-0.114) for {'bootstrap': False, 'criterion': 'entropy', 'min_samples_split': 2, 'n_estimators': 140, 'warm_start': True}\n",
      "0.784 (+/-0.120) for {'bootstrap': False, 'criterion': 'entropy', 'min_samples_split': 2, 'n_estimators': 140, 'warm_start': False}\n",
      "0.782 (+/-0.130) for {'bootstrap': False, 'criterion': 'entropy', 'min_samples_split': 2, 'n_estimators': 160, 'warm_start': True}\n",
      "0.778 (+/-0.127) for {'bootstrap': False, 'criterion': 'entropy', 'min_samples_split': 2, 'n_estimators': 160, 'warm_start': False}\n",
      "0.782 (+/-0.129) for {'bootstrap': False, 'criterion': 'entropy', 'min_samples_split': 2, 'n_estimators': 180, 'warm_start': True}\n",
      "0.785 (+/-0.123) for {'bootstrap': False, 'criterion': 'entropy', 'min_samples_split': 2, 'n_estimators': 180, 'warm_start': False}\n",
      "0.781 (+/-0.132) for {'bootstrap': False, 'criterion': 'entropy', 'min_samples_split': 2, 'n_estimators': 200, 'warm_start': True}\n",
      "0.781 (+/-0.125) for {'bootstrap': False, 'criterion': 'entropy', 'min_samples_split': 2, 'n_estimators': 200, 'warm_start': False}\n",
      "0.791 (+/-0.108) for {'bootstrap': False, 'criterion': 'entropy', 'min_samples_split': 3, 'n_estimators': 60, 'warm_start': True}\n",
      "0.789 (+/-0.122) for {'bootstrap': False, 'criterion': 'entropy', 'min_samples_split': 3, 'n_estimators': 60, 'warm_start': False}\n",
      "0.789 (+/-0.111) for {'bootstrap': False, 'criterion': 'entropy', 'min_samples_split': 3, 'n_estimators': 70, 'warm_start': True}\n",
      "0.794 (+/-0.103) for {'bootstrap': False, 'criterion': 'entropy', 'min_samples_split': 3, 'n_estimators': 70, 'warm_start': False}\n",
      "0.794 (+/-0.107) for {'bootstrap': False, 'criterion': 'entropy', 'min_samples_split': 3, 'n_estimators': 80, 'warm_start': True}\n",
      "0.789 (+/-0.108) for {'bootstrap': False, 'criterion': 'entropy', 'min_samples_split': 3, 'n_estimators': 80, 'warm_start': False}\n",
      "0.794 (+/-0.108) for {'bootstrap': False, 'criterion': 'entropy', 'min_samples_split': 3, 'n_estimators': 90, 'warm_start': True}\n",
      "0.788 (+/-0.116) for {'bootstrap': False, 'criterion': 'entropy', 'min_samples_split': 3, 'n_estimators': 90, 'warm_start': False}\n",
      "0.792 (+/-0.121) for {'bootstrap': False, 'criterion': 'entropy', 'min_samples_split': 3, 'n_estimators': 100, 'warm_start': True}\n",
      "0.792 (+/-0.098) for {'bootstrap': False, 'criterion': 'entropy', 'min_samples_split': 3, 'n_estimators': 100, 'warm_start': False}\n",
      "0.791 (+/-0.115) for {'bootstrap': False, 'criterion': 'entropy', 'min_samples_split': 3, 'n_estimators': 120, 'warm_start': True}\n",
      "0.782 (+/-0.131) for {'bootstrap': False, 'criterion': 'entropy', 'min_samples_split': 3, 'n_estimators': 120, 'warm_start': False}\n",
      "0.787 (+/-0.121) for {'bootstrap': False, 'criterion': 'entropy', 'min_samples_split': 3, 'n_estimators': 140, 'warm_start': True}\n",
      "0.794 (+/-0.111) for {'bootstrap': False, 'criterion': 'entropy', 'min_samples_split': 3, 'n_estimators': 140, 'warm_start': False}\n",
      "0.788 (+/-0.121) for {'bootstrap': False, 'criterion': 'entropy', 'min_samples_split': 3, 'n_estimators': 160, 'warm_start': True}\n",
      "0.788 (+/-0.129) for {'bootstrap': False, 'criterion': 'entropy', 'min_samples_split': 3, 'n_estimators': 160, 'warm_start': False}\n",
      "0.792 (+/-0.107) for {'bootstrap': False, 'criterion': 'entropy', 'min_samples_split': 3, 'n_estimators': 180, 'warm_start': True}\n",
      "0.792 (+/-0.115) for {'bootstrap': False, 'criterion': 'entropy', 'min_samples_split': 3, 'n_estimators': 180, 'warm_start': False}\n",
      "0.788 (+/-0.117) for {'bootstrap': False, 'criterion': 'entropy', 'min_samples_split': 3, 'n_estimators': 200, 'warm_start': True}\n",
      "0.788 (+/-0.125) for {'bootstrap': False, 'criterion': 'entropy', 'min_samples_split': 3, 'n_estimators': 200, 'warm_start': False}\n",
      "0.785 (+/-0.119) for {'bootstrap': False, 'criterion': 'entropy', 'min_samples_split': 4, 'n_estimators': 60, 'warm_start': True}\n",
      "0.798 (+/-0.118) for {'bootstrap': False, 'criterion': 'entropy', 'min_samples_split': 4, 'n_estimators': 60, 'warm_start': False}\n",
      "0.791 (+/-0.112) for {'bootstrap': False, 'criterion': 'entropy', 'min_samples_split': 4, 'n_estimators': 70, 'warm_start': True}\n",
      "0.802 (+/-0.106) for {'bootstrap': False, 'criterion': 'entropy', 'min_samples_split': 4, 'n_estimators': 70, 'warm_start': False}\n",
      "0.792 (+/-0.121) for {'bootstrap': False, 'criterion': 'entropy', 'min_samples_split': 4, 'n_estimators': 80, 'warm_start': True}\n",
      "0.792 (+/-0.099) for {'bootstrap': False, 'criterion': 'entropy', 'min_samples_split': 4, 'n_estimators': 80, 'warm_start': False}\n",
      "0.789 (+/-0.112) for {'bootstrap': False, 'criterion': 'entropy', 'min_samples_split': 4, 'n_estimators': 90, 'warm_start': True}\n",
      "0.801 (+/-0.108) for {'bootstrap': False, 'criterion': 'entropy', 'min_samples_split': 4, 'n_estimators': 90, 'warm_start': False}\n",
      "0.798 (+/-0.107) for {'bootstrap': False, 'criterion': 'entropy', 'min_samples_split': 4, 'n_estimators': 100, 'warm_start': True}\n",
      "0.798 (+/-0.109) for {'bootstrap': False, 'criterion': 'entropy', 'min_samples_split': 4, 'n_estimators': 100, 'warm_start': False}\n",
      "0.791 (+/-0.125) for {'bootstrap': False, 'criterion': 'entropy', 'min_samples_split': 4, 'n_estimators': 120, 'warm_start': True}\n",
      "0.791 (+/-0.103) for {'bootstrap': False, 'criterion': 'entropy', 'min_samples_split': 4, 'n_estimators': 120, 'warm_start': False}\n",
      "0.796 (+/-0.100) for {'bootstrap': False, 'criterion': 'entropy', 'min_samples_split': 4, 'n_estimators': 140, 'warm_start': True}\n",
      "0.799 (+/-0.115) for {'bootstrap': False, 'criterion': 'entropy', 'min_samples_split': 4, 'n_estimators': 140, 'warm_start': False}\n",
      "0.801 (+/-0.102) for {'bootstrap': False, 'criterion': 'entropy', 'min_samples_split': 4, 'n_estimators': 160, 'warm_start': True}\n",
      "0.795 (+/-0.123) for {'bootstrap': False, 'criterion': 'entropy', 'min_samples_split': 4, 'n_estimators': 160, 'warm_start': False}\n",
      "0.802 (+/-0.105) for {'bootstrap': False, 'criterion': 'entropy', 'min_samples_split': 4, 'n_estimators': 180, 'warm_start': True}\n",
      "0.789 (+/-0.127) for {'bootstrap': False, 'criterion': 'entropy', 'min_samples_split': 4, 'n_estimators': 180, 'warm_start': False}\n",
      "0.801 (+/-0.113) for {'bootstrap': False, 'criterion': 'entropy', 'min_samples_split': 4, 'n_estimators': 200, 'warm_start': True}\n",
      "0.795 (+/-0.104) for {'bootstrap': False, 'criterion': 'entropy', 'min_samples_split': 4, 'n_estimators': 200, 'warm_start': False}\n",
      "0.808 (+/-0.104) for {'bootstrap': False, 'criterion': 'entropy', 'min_samples_split': 5, 'n_estimators': 60, 'warm_start': True}\n",
      "0.808 (+/-0.090) for {'bootstrap': False, 'criterion': 'entropy', 'min_samples_split': 5, 'n_estimators': 60, 'warm_start': False}\n",
      "0.802 (+/-0.105) for {'bootstrap': False, 'criterion': 'entropy', 'min_samples_split': 5, 'n_estimators': 70, 'warm_start': True}\n",
      "0.809 (+/-0.093) for {'bootstrap': False, 'criterion': 'entropy', 'min_samples_split': 5, 'n_estimators': 70, 'warm_start': False}\n",
      "0.813 (+/-0.093) for {'bootstrap': False, 'criterion': 'entropy', 'min_samples_split': 5, 'n_estimators': 80, 'warm_start': True}\n",
      "0.809 (+/-0.108) for {'bootstrap': False, 'criterion': 'entropy', 'min_samples_split': 5, 'n_estimators': 80, 'warm_start': False}\n",
      "0.808 (+/-0.091) for {'bootstrap': False, 'criterion': 'entropy', 'min_samples_split': 5, 'n_estimators': 90, 'warm_start': True}\n",
      "0.808 (+/-0.098) for {'bootstrap': False, 'criterion': 'entropy', 'min_samples_split': 5, 'n_estimators': 90, 'warm_start': False}\n",
      "0.812 (+/-0.097) for {'bootstrap': False, 'criterion': 'entropy', 'min_samples_split': 5, 'n_estimators': 100, 'warm_start': True}\n",
      "0.809 (+/-0.111) for {'bootstrap': False, 'criterion': 'entropy', 'min_samples_split': 5, 'n_estimators': 100, 'warm_start': False}\n",
      "0.812 (+/-0.098) for {'bootstrap': False, 'criterion': 'entropy', 'min_samples_split': 5, 'n_estimators': 120, 'warm_start': True}\n",
      "0.810 (+/-0.101) for {'bootstrap': False, 'criterion': 'entropy', 'min_samples_split': 5, 'n_estimators': 120, 'warm_start': False}\n",
      "0.812 (+/-0.097) for {'bootstrap': False, 'criterion': 'entropy', 'min_samples_split': 5, 'n_estimators': 140, 'warm_start': True}\n",
      "0.810 (+/-0.094) for {'bootstrap': False, 'criterion': 'entropy', 'min_samples_split': 5, 'n_estimators': 140, 'warm_start': False}\n",
      "0.811 (+/-0.112) for {'bootstrap': False, 'criterion': 'entropy', 'min_samples_split': 5, 'n_estimators': 160, 'warm_start': True}\n",
      "0.809 (+/-0.092) for {'bootstrap': False, 'criterion': 'entropy', 'min_samples_split': 5, 'n_estimators': 160, 'warm_start': False}\n",
      "0.809 (+/-0.106) for {'bootstrap': False, 'criterion': 'entropy', 'min_samples_split': 5, 'n_estimators': 180, 'warm_start': True}\n",
      "0.809 (+/-0.106) for {'bootstrap': False, 'criterion': 'entropy', 'min_samples_split': 5, 'n_estimators': 180, 'warm_start': False}\n",
      "0.806 (+/-0.101) for {'bootstrap': False, 'criterion': 'entropy', 'min_samples_split': 5, 'n_estimators': 200, 'warm_start': True}\n",
      "0.815 (+/-0.089) for {'bootstrap': False, 'criterion': 'entropy', 'min_samples_split': 5, 'n_estimators': 200, 'warm_start': False}\n",
      "0.812 (+/-0.108) for {'bootstrap': False, 'criterion': 'entropy', 'min_samples_split': 6, 'n_estimators': 60, 'warm_start': True}\n",
      "0.812 (+/-0.096) for {'bootstrap': False, 'criterion': 'entropy', 'min_samples_split': 6, 'n_estimators': 60, 'warm_start': False}\n",
      "0.812 (+/-0.097) for {'bootstrap': False, 'criterion': 'entropy', 'min_samples_split': 6, 'n_estimators': 70, 'warm_start': True}\n",
      "0.822 (+/-0.092) for {'bootstrap': False, 'criterion': 'entropy', 'min_samples_split': 6, 'n_estimators': 70, 'warm_start': False}\n",
      "0.815 (+/-0.089) for {'bootstrap': False, 'criterion': 'entropy', 'min_samples_split': 6, 'n_estimators': 80, 'warm_start': True}\n",
      "0.820 (+/-0.101) for {'bootstrap': False, 'criterion': 'entropy', 'min_samples_split': 6, 'n_estimators': 80, 'warm_start': False}\n",
      "0.813 (+/-0.091) for {'bootstrap': False, 'criterion': 'entropy', 'min_samples_split': 6, 'n_estimators': 90, 'warm_start': True}\n",
      "0.813 (+/-0.094) for {'bootstrap': False, 'criterion': 'entropy', 'min_samples_split': 6, 'n_estimators': 90, 'warm_start': False}\n",
      "0.823 (+/-0.088) for {'bootstrap': False, 'criterion': 'entropy', 'min_samples_split': 6, 'n_estimators': 100, 'warm_start': True}\n",
      "0.820 (+/-0.090) for {'bootstrap': False, 'criterion': 'entropy', 'min_samples_split': 6, 'n_estimators': 100, 'warm_start': False}\n",
      "0.812 (+/-0.084) for {'bootstrap': False, 'criterion': 'entropy', 'min_samples_split': 6, 'n_estimators': 120, 'warm_start': True}\n",
      "0.815 (+/-0.096) for {'bootstrap': False, 'criterion': 'entropy', 'min_samples_split': 6, 'n_estimators': 120, 'warm_start': False}\n",
      "0.813 (+/-0.099) for {'bootstrap': False, 'criterion': 'entropy', 'min_samples_split': 6, 'n_estimators': 140, 'warm_start': True}\n",
      "0.815 (+/-0.098) for {'bootstrap': False, 'criterion': 'entropy', 'min_samples_split': 6, 'n_estimators': 140, 'warm_start': False}\n",
      "0.816 (+/-0.091) for {'bootstrap': False, 'criterion': 'entropy', 'min_samples_split': 6, 'n_estimators': 160, 'warm_start': True}\n",
      "0.810 (+/-0.110) for {'bootstrap': False, 'criterion': 'entropy', 'min_samples_split': 6, 'n_estimators': 160, 'warm_start': False}\n",
      "0.815 (+/-0.095) for {'bootstrap': False, 'criterion': 'entropy', 'min_samples_split': 6, 'n_estimators': 180, 'warm_start': True}\n",
      "0.813 (+/-0.087) for {'bootstrap': False, 'criterion': 'entropy', 'min_samples_split': 6, 'n_estimators': 180, 'warm_start': False}\n",
      "0.806 (+/-0.105) for {'bootstrap': False, 'criterion': 'entropy', 'min_samples_split': 6, 'n_estimators': 200, 'warm_start': True}\n",
      "0.812 (+/-0.095) for {'bootstrap': False, 'criterion': 'entropy', 'min_samples_split': 6, 'n_estimators': 200, 'warm_start': False}\n",
      "0.815 (+/-0.096) for {'bootstrap': False, 'criterion': 'entropy', 'min_samples_split': 7, 'n_estimators': 60, 'warm_start': True}\n",
      "0.823 (+/-0.091) for {'bootstrap': False, 'criterion': 'entropy', 'min_samples_split': 7, 'n_estimators': 60, 'warm_start': False}\n",
      "0.812 (+/-0.104) for {'bootstrap': False, 'criterion': 'entropy', 'min_samples_split': 7, 'n_estimators': 70, 'warm_start': True}\n",
      "0.813 (+/-0.107) for {'bootstrap': False, 'criterion': 'entropy', 'min_samples_split': 7, 'n_estimators': 70, 'warm_start': False}\n",
      "0.820 (+/-0.093) for {'bootstrap': False, 'criterion': 'entropy', 'min_samples_split': 7, 'n_estimators': 80, 'warm_start': True}\n",
      "0.813 (+/-0.097) for {'bootstrap': False, 'criterion': 'entropy', 'min_samples_split': 7, 'n_estimators': 80, 'warm_start': False}\n",
      "0.822 (+/-0.092) for {'bootstrap': False, 'criterion': 'entropy', 'min_samples_split': 7, 'n_estimators': 90, 'warm_start': True}\n",
      "0.818 (+/-0.094) for {'bootstrap': False, 'criterion': 'entropy', 'min_samples_split': 7, 'n_estimators': 90, 'warm_start': False}\n",
      "0.815 (+/-0.099) for {'bootstrap': False, 'criterion': 'entropy', 'min_samples_split': 7, 'n_estimators': 100, 'warm_start': True}\n",
      "0.818 (+/-0.096) for {'bootstrap': False, 'criterion': 'entropy', 'min_samples_split': 7, 'n_estimators': 100, 'warm_start': False}\n",
      "0.823 (+/-0.095) for {'bootstrap': False, 'criterion': 'entropy', 'min_samples_split': 7, 'n_estimators': 120, 'warm_start': True}\n",
      "0.820 (+/-0.088) for {'bootstrap': False, 'criterion': 'entropy', 'min_samples_split': 7, 'n_estimators': 120, 'warm_start': False}\n",
      "0.815 (+/-0.098) for {'bootstrap': False, 'criterion': 'entropy', 'min_samples_split': 7, 'n_estimators': 140, 'warm_start': True}\n",
      "0.817 (+/-0.093) for {'bootstrap': False, 'criterion': 'entropy', 'min_samples_split': 7, 'n_estimators': 140, 'warm_start': False}\n",
      "0.816 (+/-0.096) for {'bootstrap': False, 'criterion': 'entropy', 'min_samples_split': 7, 'n_estimators': 160, 'warm_start': True}\n",
      "0.820 (+/-0.092) for {'bootstrap': False, 'criterion': 'entropy', 'min_samples_split': 7, 'n_estimators': 160, 'warm_start': False}\n",
      "0.820 (+/-0.096) for {'bootstrap': False, 'criterion': 'entropy', 'min_samples_split': 7, 'n_estimators': 180, 'warm_start': True}\n",
      "0.819 (+/-0.086) for {'bootstrap': False, 'criterion': 'entropy', 'min_samples_split': 7, 'n_estimators': 180, 'warm_start': False}\n",
      "0.815 (+/-0.089) for {'bootstrap': False, 'criterion': 'entropy', 'min_samples_split': 7, 'n_estimators': 200, 'warm_start': True}\n",
      "0.819 (+/-0.102) for {'bootstrap': False, 'criterion': 'entropy', 'min_samples_split': 7, 'n_estimators': 200, 'warm_start': False}\n",
      "0.822 (+/-0.092) for {'bootstrap': False, 'criterion': 'entropy', 'min_samples_split': 8, 'n_estimators': 60, 'warm_start': True}\n",
      "0.817 (+/-0.090) for {'bootstrap': False, 'criterion': 'entropy', 'min_samples_split': 8, 'n_estimators': 60, 'warm_start': False}\n",
      "0.818 (+/-0.096) for {'bootstrap': False, 'criterion': 'entropy', 'min_samples_split': 8, 'n_estimators': 70, 'warm_start': True}\n",
      "0.820 (+/-0.097) for {'bootstrap': False, 'criterion': 'entropy', 'min_samples_split': 8, 'n_estimators': 70, 'warm_start': False}\n",
      "0.816 (+/-0.093) for {'bootstrap': False, 'criterion': 'entropy', 'min_samples_split': 8, 'n_estimators': 80, 'warm_start': True}\n",
      "0.823 (+/-0.081) for {'bootstrap': False, 'criterion': 'entropy', 'min_samples_split': 8, 'n_estimators': 80, 'warm_start': False}\n",
      "0.826 (+/-0.086) for {'bootstrap': False, 'criterion': 'entropy', 'min_samples_split': 8, 'n_estimators': 90, 'warm_start': True}\n",
      "0.818 (+/-0.093) for {'bootstrap': False, 'criterion': 'entropy', 'min_samples_split': 8, 'n_estimators': 90, 'warm_start': False}\n",
      "0.819 (+/-0.086) for {'bootstrap': False, 'criterion': 'entropy', 'min_samples_split': 8, 'n_estimators': 100, 'warm_start': True}\n",
      "0.825 (+/-0.088) for {'bootstrap': False, 'criterion': 'entropy', 'min_samples_split': 8, 'n_estimators': 100, 'warm_start': False}\n",
      "0.819 (+/-0.090) for {'bootstrap': False, 'criterion': 'entropy', 'min_samples_split': 8, 'n_estimators': 120, 'warm_start': True}\n",
      "0.829 (+/-0.067) for {'bootstrap': False, 'criterion': 'entropy', 'min_samples_split': 8, 'n_estimators': 120, 'warm_start': False}\n",
      "0.823 (+/-0.088) for {'bootstrap': False, 'criterion': 'entropy', 'min_samples_split': 8, 'n_estimators': 140, 'warm_start': True}\n",
      "0.826 (+/-0.078) for {'bootstrap': False, 'criterion': 'entropy', 'min_samples_split': 8, 'n_estimators': 140, 'warm_start': False}\n",
      "0.817 (+/-0.087) for {'bootstrap': False, 'criterion': 'entropy', 'min_samples_split': 8, 'n_estimators': 160, 'warm_start': True}\n",
      "0.822 (+/-0.083) for {'bootstrap': False, 'criterion': 'entropy', 'min_samples_split': 8, 'n_estimators': 160, 'warm_start': False}\n",
      "0.818 (+/-0.101) for {'bootstrap': False, 'criterion': 'entropy', 'min_samples_split': 8, 'n_estimators': 180, 'warm_start': True}\n",
      "0.823 (+/-0.088) for {'bootstrap': False, 'criterion': 'entropy', 'min_samples_split': 8, 'n_estimators': 180, 'warm_start': False}\n",
      "0.823 (+/-0.086) for {'bootstrap': False, 'criterion': 'entropy', 'min_samples_split': 8, 'n_estimators': 200, 'warm_start': True}\n",
      "0.820 (+/-0.089) for {'bootstrap': False, 'criterion': 'entropy', 'min_samples_split': 8, 'n_estimators': 200, 'warm_start': False}\n",
      "0.825 (+/-0.086) for {'bootstrap': False, 'criterion': 'entropy', 'min_samples_split': 9, 'n_estimators': 60, 'warm_start': True}\n",
      "0.816 (+/-0.075) for {'bootstrap': False, 'criterion': 'entropy', 'min_samples_split': 9, 'n_estimators': 60, 'warm_start': False}\n",
      "0.819 (+/-0.085) for {'bootstrap': False, 'criterion': 'entropy', 'min_samples_split': 9, 'n_estimators': 70, 'warm_start': True}\n",
      "0.826 (+/-0.081) for {'bootstrap': False, 'criterion': 'entropy', 'min_samples_split': 9, 'n_estimators': 70, 'warm_start': False}\n",
      "0.824 (+/-0.078) for {'bootstrap': False, 'criterion': 'entropy', 'min_samples_split': 9, 'n_estimators': 80, 'warm_start': True}\n",
      "0.825 (+/-0.080) for {'bootstrap': False, 'criterion': 'entropy', 'min_samples_split': 9, 'n_estimators': 80, 'warm_start': False}\n",
      "0.825 (+/-0.083) for {'bootstrap': False, 'criterion': 'entropy', 'min_samples_split': 9, 'n_estimators': 90, 'warm_start': True}\n",
      "0.820 (+/-0.089) for {'bootstrap': False, 'criterion': 'entropy', 'min_samples_split': 9, 'n_estimators': 90, 'warm_start': False}\n",
      "0.822 (+/-0.086) for {'bootstrap': False, 'criterion': 'entropy', 'min_samples_split': 9, 'n_estimators': 100, 'warm_start': True}\n",
      "0.820 (+/-0.088) for {'bootstrap': False, 'criterion': 'entropy', 'min_samples_split': 9, 'n_estimators': 100, 'warm_start': False}\n",
      "0.817 (+/-0.093) for {'bootstrap': False, 'criterion': 'entropy', 'min_samples_split': 9, 'n_estimators': 120, 'warm_start': True}\n",
      "0.820 (+/-0.091) for {'bootstrap': False, 'criterion': 'entropy', 'min_samples_split': 9, 'n_estimators': 120, 'warm_start': False}\n",
      "0.822 (+/-0.087) for {'bootstrap': False, 'criterion': 'entropy', 'min_samples_split': 9, 'n_estimators': 140, 'warm_start': True}\n",
      "0.825 (+/-0.084) for {'bootstrap': False, 'criterion': 'entropy', 'min_samples_split': 9, 'n_estimators': 140, 'warm_start': False}\n",
      "0.825 (+/-0.084) for {'bootstrap': False, 'criterion': 'entropy', 'min_samples_split': 9, 'n_estimators': 160, 'warm_start': True}\n",
      "0.829 (+/-0.089) for {'bootstrap': False, 'criterion': 'entropy', 'min_samples_split': 9, 'n_estimators': 160, 'warm_start': False}\n",
      "0.822 (+/-0.090) for {'bootstrap': False, 'criterion': 'entropy', 'min_samples_split': 9, 'n_estimators': 180, 'warm_start': True}\n",
      "0.823 (+/-0.090) for {'bootstrap': False, 'criterion': 'entropy', 'min_samples_split': 9, 'n_estimators': 180, 'warm_start': False}\n",
      "0.825 (+/-0.083) for {'bootstrap': False, 'criterion': 'entropy', 'min_samples_split': 9, 'n_estimators': 200, 'warm_start': True}\n",
      "0.822 (+/-0.086) for {'bootstrap': False, 'criterion': 'entropy', 'min_samples_split': 9, 'n_estimators': 200, 'warm_start': False}\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.88      0.90      0.89       114\n",
      "         1.0       0.82      0.78      0.80        64\n",
      "\n",
      "    accuracy                           0.86       178\n",
      "   macro avg       0.85      0.84      0.85       178\n",
      "weighted avg       0.86      0.86      0.86       178\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "tuned_parameters = [{ 'n_estimators':[60,70,80,90,100,120,140,160,180,200], 'criterion':['gini','entropy'],\n",
    "      'warm_start':[True, False], 'bootstrap':[True, False],'min_samples_split':[2,3,4,5,6,7,8,9]}\n",
    "                    ]\n",
    "\n",
    "\n",
    "print()\n",
    "\n",
    "clf = GridSearchCV(\n",
    "    RandomForestClassifier(), tuned_parameters, scoring='accuracy', cv=10\n",
    ")\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best parameters set found on development set:\")\n",
    "print()\n",
    "print(clf.best_params_)\n",
    "print()\n",
    "print(\"Grid scores on development set:\")\n",
    "print()\n",
    "means = clf.cv_results_['mean_test_score']\n",
    "stds = clf.cv_results_['std_test_score']\n",
    "for mean, std, params in zip(means, stds, clf.cv_results_['params']):\n",
    "    print(\"%0.3f (+/-%0.03f) for %r\"\n",
    "          % (mean, std * 2, params))\n",
    "print()\n",
    "\n",
    "print(\"Detailed classification report:\")\n",
    "print()\n",
    "print(\"The model is trained on the full development set.\")\n",
    "print(\"The scores are computed on the full evaluation set.\")\n",
    "print()\n",
    "y_true, y_pred = y_test, clf.predict(X_test)\n",
    "print(classification_report(y_true, y_pred))\n",
    "print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8wNpUvSRTwVl"
   },
   "source": [
    "###Cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "wW3nAhoYS0Yg",
    "outputId": "b1faf670-9c67-407a-cfb9-97228ff84da6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.835069\n"
     ]
    }
   ],
   "source": [
    "clf = RandomForestClassifier(bootstrap= True, criterion= 'gini', min_samples_split= 8, n_estimators= 180, warm_start= False)\n",
    "score=cross_validate(clf, X, y, cv=10, scoring=\"accuracy\")[\"test_score\"].mean()\n",
    "print(f\"{score:.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "p6z2PsaYMo4v"
   },
   "source": [
    "### Generating Predicion Result for submission in .csv format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VxWUIGMIvY7k"
   },
   "outputs": [],
   "source": [
    "df2 = pd.read_csv(url2)\n",
    "clf = RandomForestClassifier(bootstrap= True, criterion= 'gini', min_samples_split= 8, n_estimators= 180, warm_start= False)\n",
    "clf.fit(X, y)\n",
    "pred=clf.predict(X_test2)\n",
    "pd.DataFrame({\"PassengerId\": df2[\"PassengerId\"], \"Survived\": pred}).to_csv(\"RandomForestClassifier_submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FOJEYnfyCM0L"
   },
   "source": [
    "![alt text](https://raw.githubusercontent.com/zyzhang1130/CE9010/master/Titanic/RandomForest.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "csM_ArJuXjLr"
   },
   "source": [
    "## XGBoost Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "n39Lrvs8Xyu4"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 679
    },
    "colab_type": "code",
    "id": "TVyKTASLX5i-",
    "outputId": "8b1b1006-6f1d-4eed-e069-5258e108ad98"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_search.py:823: FutureWarning:\n",
      "\n",
      "The parameter 'iid' is deprecated in 0.22 and will be removed in 0.24.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "coss validation results {'mean_fit_time': array([0.41868615, 0.42174573, 0.4636878 , 0.70192904, 0.67201667,\n",
      "       0.61961665, 0.93390512, 0.80480742, 0.70481453, 1.08129082,\n",
      "       0.86310353, 0.63918233]), 'std_fit_time': array([0.02233087, 0.01785338, 0.01080505, 0.02454552, 0.02674497,\n",
      "       0.0341387 , 0.15101574, 0.07040121, 0.15885518, 0.12221958,\n",
      "       0.05393578, 0.07546581]), 'mean_score_time': array([0.02239423, 0.00688744, 0.00698676, 0.01178517, 0.01662512,\n",
      "       0.00748129, 0.00846801, 0.00689321, 0.00783014, 0.00812707,\n",
      "       0.01432238, 0.0042695 ]), 'std_score_time': array([0.0074922 , 0.00096934, 0.00283873, 0.00715047, 0.0030997 ,\n",
      "       0.00223604, 0.00185373, 0.00198884, 0.00223366, 0.00219941,\n",
      "       0.00523321, 0.00135888]), 'param_max_depth': masked_array(data=[3, 3, 3, 5, 5, 5, 7, 7, 7, 9, 9, 9],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'param_min_child_weight': masked_array(data=[1, 3, 5, 1, 3, 5, 1, 3, 5, 1, 3, 5],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'params': [{'max_depth': 3, 'min_child_weight': 1}, {'max_depth': 3, 'min_child_weight': 3}, {'max_depth': 3, 'min_child_weight': 5}, {'max_depth': 5, 'min_child_weight': 1}, {'max_depth': 5, 'min_child_weight': 3}, {'max_depth': 5, 'min_child_weight': 5}, {'max_depth': 7, 'min_child_weight': 1}, {'max_depth': 7, 'min_child_weight': 3}, {'max_depth': 7, 'min_child_weight': 5}, {'max_depth': 9, 'min_child_weight': 1}, {'max_depth': 9, 'min_child_weight': 3}, {'max_depth': 9, 'min_child_weight': 5}], 'split0_test_score': array([0.82953612, 0.82697044, 0.82122332, 0.84020936, 0.82614943,\n",
      "       0.83025452, 0.84000411, 0.84195402, 0.83210181, 0.84554598,\n",
      "       0.8452381 , 0.82984401]), 'split1_test_score': array([0.79505337, 0.80593186, 0.8102422 , 0.7944376 , 0.80131363,\n",
      "       0.80613711, 0.78807471, 0.79618227, 0.80654762, 0.78602217,\n",
      "       0.79833744, 0.80839491]), 'split2_test_score': array([0.91191223, 0.90992685, 0.90532915, 0.91410658, 0.90950888,\n",
      "       0.90365726, 0.90950888, 0.91473354, 0.90888192, 0.90595611,\n",
      "       0.91347962, 0.90741902]), 'split3_test_score': array([0.85057471, 0.86081505, 0.86792059, 0.84597701, 0.8539185 ,\n",
      "       0.86886102, 0.85141066, 0.85579937, 0.86091954, 0.84806688,\n",
      "       0.86060606, 0.86363636]), 'split4_test_score': array([0.85496262, 0.8674211 , 0.87406561, 0.85454734, 0.87385797,\n",
      "       0.87531146, 0.85371678, 0.87655731, 0.8744809 , 0.84644934,\n",
      "       0.87697259, 0.87323505]), 'mean_test_score': array([0.84840781, 0.85421306, 0.85575617, 0.84985558, 0.85294968,\n",
      "       0.85684427, 0.84854303, 0.8570453 , 0.85658636, 0.84640809,\n",
      "       0.85892676, 0.85650587]), 'std_test_score': array([0.03816624, 0.03576395, 0.03522706, 0.03828694, 0.03747419,\n",
      "       0.03451124, 0.03868115, 0.03909542, 0.03514879, 0.03793659,\n",
      "       0.03784952, 0.03449167]), 'rank_test_score': array([11,  7,  6,  9,  8,  3, 10,  2,  4, 12,  1,  5], dtype=int32)}\n",
      "best parameters {'max_depth': 9, 'min_child_weight': 3}\n",
      "best score 0.8589267618908758\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "model = XGBClassifier(learning_rate =0.1,\n",
    " n_estimators=1000,\n",
    " max_depth=10,\n",
    " min_child_weight=3,\n",
    " gamma=0,\n",
    " subsample=0.8,\n",
    " colsample_bytree=0.8,\n",
    " objective= 'binary:logistic',\n",
    " nthread=4,\n",
    " scale_pos_weight=1,\n",
    " seed=27)\n",
    "\n",
    "param_test1 = {\n",
    " 'max_depth':range(3,10,2),\n",
    " 'min_child_weight':range(1,6,2)\n",
    "}\n",
    "gsearch1 = GridSearchCV(estimator = XGBClassifier( learning_rate =0.1, n_estimators=140, max_depth=5,\n",
    " min_child_weight=1, gamma=0, subsample=0.8, colsample_bytree=0.8,\n",
    " objective= 'binary:logistic', nthread=4, scale_pos_weight=1, seed=27), \n",
    " param_grid = param_test1, scoring='roc_auc',n_jobs=4,iid=False, cv=5)\n",
    "gsearch1.fit(X_train,y_train)\n",
    "print('coss validation results',gsearch1.cv_results_ )\n",
    "print()\n",
    "print('best parameters',gsearch1.best_params_)\n",
    "print()\n",
    "print('best score',gsearch1.best_score_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 523
    },
    "colab_type": "code",
    "id": "Tjp3OVed6mjg",
    "outputId": "1cefd4af-dbd1-48cd-d6df-2b507d234e4d"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_search.py:823: FutureWarning:\n",
      "\n",
      "The parameter 'iid' is deprecated in 0.22 and will be removed in 0.24.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "coss validation results {'mean_fit_time': array([0.92014089, 0.87254848, 0.77533321, 0.97191906, 0.86867752,\n",
      "       0.76766458, 1.01229377, 0.85765433, 0.64589429]), 'std_fit_time': array([0.04079175, 0.03909655, 0.03449356, 0.0732732 , 0.02433322,\n",
      "       0.1217465 , 0.04318948, 0.01926955, 0.10747002]), 'mean_score_time': array([0.01254563, 0.01127682, 0.01024442, 0.00755224, 0.01465964,\n",
      "       0.00669146, 0.00992737, 0.01069221, 0.00542397]), 'std_score_time': array([0.00605097, 0.00665723, 0.00527317, 0.00276047, 0.0068149 ,\n",
      "       0.00181474, 0.00281513, 0.00507771, 0.00243942]), 'param_max_depth': masked_array(data=[8, 8, 8, 9, 9, 9, 10, 10, 10],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'param_min_child_weight': masked_array(data=[2, 3, 4, 2, 3, 4, 2, 3, 4],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'params': [{'max_depth': 8, 'min_child_weight': 2}, {'max_depth': 8, 'min_child_weight': 3}, {'max_depth': 8, 'min_child_weight': 4}, {'max_depth': 9, 'min_child_weight': 2}, {'max_depth': 9, 'min_child_weight': 3}, {'max_depth': 9, 'min_child_weight': 4}, {'max_depth': 10, 'min_child_weight': 2}, {'max_depth': 10, 'min_child_weight': 3}, {'max_depth': 10, 'min_child_weight': 4}], 'split0_test_score': array([0.83682266, 0.84585386, 0.82758621, 0.83682266, 0.8452381 ,\n",
      "       0.8316913 , 0.84154351, 0.83990148, 0.8316913 ]), 'split1_test_score': array([0.80100575, 0.79269294, 0.8034688 , 0.80038998, 0.79833744,\n",
      "       0.80470033, 0.80141626, 0.79772167, 0.79874795]), 'split2_test_score': array([0.907628  , 0.91347962, 0.9092999 , 0.91264368, 0.91347962,\n",
      "       0.90658307, 0.91577847, 0.90804598, 0.90658307]), 'split3_test_score': array([0.85329154, 0.86018809, 0.85705329, 0.85809822, 0.86060606,\n",
      "       0.85663532, 0.85412748, 0.86123302, 0.85788924]), 'split4_test_score': array([0.8674211 , 0.87967193, 0.87219684, 0.86077658, 0.87697259,\n",
      "       0.87468854, 0.86783638, 0.87967193, 0.87406561]), 'mean_test_score': array([0.85323381, 0.85837729, 0.85392101, 0.85374622, 0.85892676,\n",
      "       0.85485971, 0.85614042, 0.85731482, 0.85379543]), 'std_test_score': array([0.03509161, 0.0399106 , 0.03646803, 0.03652553, 0.03784952,\n",
      "       0.03499823, 0.03716275, 0.03726502, 0.03669603]), 'rank_test_score': array([9, 2, 6, 8, 1, 5, 4, 3, 7], dtype=int32)}\n",
      "\n",
      "best parameters {'max_depth': 9, 'min_child_weight': 3}\n",
      "\n",
      "best score 0.8589267618908758\n"
     ]
    }
   ],
   "source": [
    "param_test2 = {\n",
    " 'max_depth':[8,9,10],\n",
    " 'min_child_weight':[2,3,4]\n",
    "}\n",
    "gsearch2 = GridSearchCV(estimator = XGBClassifier( learning_rate=0.1, n_estimators=140, max_depth=5,\n",
    " min_child_weight=2, gamma=0, subsample=0.8, colsample_bytree=0.8,\n",
    " objective= 'binary:logistic', nthread=4, scale_pos_weight=1,seed=27), \n",
    " param_grid = param_test2, scoring='roc_auc',n_jobs=4,iid=False, cv=5)\n",
    "gsearch2.fit(X_train,y_train)\n",
    "print('coss validation results',gsearch2.cv_results_ )\n",
    "print()\n",
    "print('best parameters',gsearch2.best_params_)\n",
    "print()\n",
    "print('best score',gsearch2.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "11T0GWcxT0kc"
   },
   "source": [
    "###Cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "FSBu6ghHTCcD",
    "outputId": "6274cf88-4b43-4aee-c321-8cfa8a229ff1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.804732\n"
     ]
    }
   ],
   "source": [
    "clf = XGBClassifier(learning_rate =0.1,\n",
    " n_estimators=1000,\n",
    " max_depth=9,\n",
    " min_child_weight=3,\n",
    " gamma=0,\n",
    " subsample=0.8,\n",
    " colsample_bytree=0.8,\n",
    " objective= 'binary:logistic',\n",
    " nthread=4,\n",
    " scale_pos_weight=1,\n",
    " seed=27)\n",
    "score=cross_validate(clf, X, y, cv=10, scoring=\"accuracy\")[\"test_score\"].mean()\n",
    "print(f\"{score:.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RDspTPIzMrRn"
   },
   "source": [
    "### Generating Predicion Result for submission in .csv format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5aP8M_tlwBik"
   },
   "outputs": [],
   "source": [
    "df2 = pd.read_csv(url2)\n",
    "clf = XGBClassifier(learning_rate =0.1,\n",
    " n_estimators=1000,\n",
    " max_depth=9,\n",
    " min_child_weight=3,\n",
    " gamma=0,\n",
    " subsample=0.8,\n",
    " colsample_bytree=0.8,\n",
    " objective= 'binary:logistic',\n",
    " nthread=4,\n",
    " scale_pos_weight=1,\n",
    " seed=27)\n",
    "clf.fit(X, y)\n",
    "pred=clf.predict(X_test2)\n",
    "pd.DataFrame({\"PassengerId\": df2[\"PassengerId\"], \"Survived\": pred}).to_csv(\"XGBoost_submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "H9RkWmmhXIZ4"
   },
   "source": [
    "#Ensembel Learning Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "a-VWXbApXY5C"
   },
   "source": [
    "We use selected models with selected parameters to form ensemble classifiers. The ensemble classifiers are cross validated with 10-fold cross validation and with the all the data which have labels. After some trial and errors we realized that the optimal hyperparameters selected from grid search may not correspond to the best submission score. Our guess is that the 'optimal hyper-parameters' could be actually overfitting to the training data. Therefore, there are some changes in the hyper-parameter settings.The result from grid search can be used for reference instead of the absolute standard."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2NofEOJiD9L2"
   },
   "source": [
    "On a side notes, since thr API of AdaBoost classifier and random forest classifier are directly given in the scikit-learn library, despite the fact the technically these two are ensemble learning models as well, we already evaluated them in the previous secion."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "81avrvc6YatF"
   },
   "source": [
    "##Bagging Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pHTQVQP24YYR"
   },
   "source": [
    "For this bagging classifer we use self-defined base classifier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "2DcGjBrmhrYx",
    "outputId": "5c4cfe3b-47d9-47b5-da04-e26020cfbc5a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.797990\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "\n",
    "bclf= BaggingClassifier(LogisticRegression(C=0.123456789, solver=\"lbfgs\", max_iter=5000), random_state=0, warm_start=False,bootstrap=True, bootstrap_features=True, n_estimators= 500)\n",
    "\n",
    "\n",
    "score=cross_validate(bclf, X, y, cv=10, scoring=\"accuracy\")[\"test_score\"].mean()\n",
    "print(f\"{score:.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0-ihWAjC_BQW"
   },
   "source": [
    "### Generating Predicion Result for submission in .csv format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oUVSfth5_MPP"
   },
   "outputs": [],
   "source": [
    "df2 = pd.read_csv(url2)\n",
    "bclf.fit(X, y)\n",
    "pred=bclf.predict(X_test2)\n",
    "pd.DataFrame({\"PassengerId\": df2[\"PassengerId\"], \"Survived\": pred}).to_csv(\"Bagging2_submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wczf3YXdz5ry"
   },
   "source": [
    "![alt text](https://raw.githubusercontent.com/zyzhang1130/CE9010/master/Titanic/bagging2.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "unBxlpyqW3es"
   },
   "source": [
    "##Stacking Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jAN2uGTXW_pD"
   },
   "source": [
    "We use 3-fold cross valisation to evaluate the accuacy of the stacking classifier. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "ae4rijLqH4Tb",
    "outputId": "abb392ba-363a-4f15-da3a-c398d2a6e1fe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.819338\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import StackingClassifier\n",
    "from sklearn.model_selection import cross_validate\n",
    "base_learners  = [('1_1',SVC(gamma=2, C=1,probability=True)),     \n",
    "                  ('1_2',DecisionTreeClassifier(max_depth=8)),     \n",
    "                  ('1_3',MLPClassifier(alpha=1, max_iter=1000)),     \n",
    "                  ('1_4', KNeighborsClassifier(n_neighbors=7,weights='distance')),     \n",
    "                  ('1_5', BaggingClassifier(DecisionTreeClassifier(max_depth=5), n_estimators=10, random_state=0, warm_start=True)),     \n",
    "                  ('1_6',GaussianProcessClassifier(0.949**2 * RBF(length_scale=1))),     \n",
    "                  ('1_7',GradientBoostingClassifier(n_estimators=100, learning_rate=1.0,max_depth=1, random_state=0))]     \n",
    "stack_clf = StackingClassifier(estimators=base_learners,\n",
    "                          final_estimator=LogisticRegression(C=0.123456789, solver=\"lbfgs\", max_iter=5000),  \n",
    "                          cv=10)\n",
    "\n",
    "\n",
    "score=cross_validate(stack_clf, X, y, cv=10, scoring=\"accuracy\")[\"test_score\"].mean()\n",
    "print(f\"{score:.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "thIy_zY6_vRH"
   },
   "source": [
    "### Generating Predicion Result for submission in .csv format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Mnps3ioZ_2DS"
   },
   "outputs": [],
   "source": [
    "df2 = pd.read_csv(url2)\n",
    "stack_clf.fit(X, y)\n",
    "pred=stack_clf.predict(X_test2)\n",
    "pd.DataFrame({\"PassengerId\": df2[\"PassengerId\"], \"Survived\": pred}).to_csv(\"stacking_submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PKGYulZQ44Ht"
   },
   "source": [
    "###Kaggle Submission Score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GTlYMpuV3_VS"
   },
   "source": [
    "![alt text](https://raw.githubusercontent.com/zyzhang1130/CE9010/master/Titanic/stacking.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "28ZgEy7JaSEi"
   },
   "source": [
    "We observed from trail and error that it is not necessary that the based classifiers that individually perform better will give better score when stacked together. We think of the following possible causes: \n",
    "1. Stacking classifier requires the its base classifiers to be at non-correlate as possible. We assume this condition is fulfilled by that fact that these machine learning models are developed based on different mathematical ideals. However, amongst all base classifiers, some classfiers might tend to be more correlated to others. For example, random forest is by its own aready an emsemble classifier which is built from decision trees. Therefore, by definition it cannot be independent from decision trees. In such case, even if both can achieve very good prediction results separetely, if put as base classifiers as the same time this stacking classifier might be outperformed by other choices of base classifiers.\n",
    "This could happened between other based classifiers as well, but their correlation will be difficult to see.\n",
    "\n",
    "2. Stacking classifiers also requires each based classifier is better than a random classifier in terms of prediction accuracy. We believe this condition is definitely satisfied as we have already tested the base classifiers individually.\n",
    "\n",
    "3. It could also be the case that some based classifier, when used together, will cause the stacking classifier to overfit more towards the training data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rEno1_MgYbM9"
   },
   "source": [
    "##Voting Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BSjS1gTVYb6y"
   },
   "source": [
    "We use 3-fold cross valisation to evaluate the accuacy of the stacking classifier. Soft voting scheme (predicts the class label based on the argmax of the sums of the predicted probabilities) is adopted since it gives a better prediction result. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "UYHgukfTYaek",
    "outputId": "f237cd54-0767-4dc4-9b45-4593c15c40b6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.821598\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "base_learners  = [('1_1',SVC(gamma=2, C=1,probability=True)),\n",
    "                  ('1_2',DecisionTreeClassifier(max_depth=8)),\n",
    "                  ('1_3',MLPClassifier(alpha=1, max_iter=1000)),\n",
    "                  ('1_4', KNeighborsClassifier(n_neighbors=7,weights='distance')),\n",
    "                  ('1_5', BaggingClassifier(DecisionTreeClassifier(max_depth=5), n_estimators=10, random_state=0, warm_start=True)),\n",
    "                  ('1_6',GaussianProcessClassifier(0.949**2 * RBF(length_scale=1))),\n",
    "                  ('1_7',GradientBoostingClassifier(n_estimators=100, learning_rate=1.0,max_depth=1, random_state=0)) ]\n",
    "v_clf = VotingClassifier(estimators=base_learners,voting='soft')\n",
    "\n",
    "score=cross_validate(v_clf, X, y, cv=10, scoring=\"accuracy\")[\"test_score\"].mean()\n",
    "print(f\"{score:.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "i-c5ZKJeA-bJ"
   },
   "source": [
    "### Generating Predicion Result for submission in .csv format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4005f1mbBCDC"
   },
   "outputs": [],
   "source": [
    "df2 = pd.read_csv(url2)\n",
    "v_clf.fit(X, y)\n",
    "pred=v_clf.predict(X_test2)\n",
    "pd.DataFrame({\"PassengerId\": df2[\"PassengerId\"], \"Survived\": pred}).to_csv(\"voting_submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "aYRAbL-Z5ukN"
   },
   "source": [
    "###Kaggle Submission Score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fV0oKXYZ5yJr"
   },
   "source": [
    "![alt text](https://raw.githubusercontent.com/zyzhang1130/CE9010/master/Titanic/voting.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pS-76Wc9d9SS"
   },
   "source": [
    "The issue with stacking classidier exists for the voting classidier as well (optimal classifiers may not give optimal result when used together as base classifier). And we reckon the cause could be the same as well. Through multiple testing, we notice that soft voting classifier in general out performs stacking classsifier given the same base classifiers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HI8hEj526FKy"
   },
   "source": [
    "#Kaggle Ranking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fBlELTwI6Kss"
   },
   "source": [
    "we chose the best classifiers among all the trained ones: voting classifiers. Its score 0.81339 corresponds to 568th-713th positions on the public leaderboard (top 2.96% to top 3.72% on the leaderboard)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7ixGlEJ9GAWY"
   },
   "source": [
    "# Observations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ujymllTLGEAL"
   },
   "source": [
    "1. The actual submission score is lower than the cross-validation score for all classifiers. This is expected as overfitting always exists.\n",
    "\n",
    "2. When tuned carefully and appropriately, ensemble learning methods can outperform individual machine learning models. \n",
    "\n",
    "3. According to theory, ensemble methods always outperform the individual classifiers as long as the 2 necessary conditions:\n",
    "\n",
    "The base classifiers are independent of each other\n",
    "\n",
    "The base classifiers should do better than a random classifier \n",
    "\n",
    "   are satisfied. However, during the trial and error, we noticed that it is actually quite common that the ensemble methods performance was lower than that of the best individual classifier used as one of the base classifiers. This sugguests that the based classifiers with lower accuracy comprimosed the best classifier instead of helping to improve the overall accuacy.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "m0uFk30BJj1q"
   },
   "source": [
    "# Attempt with Principal Component Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_C-Gd_19JrfO"
   },
   "source": [
    "We applied Principal Component Analysis on the preprocessed data in the hope that it could find the most important linear combinations of features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 474,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 299
    },
    "colab_type": "code",
    "id": "Y7QsuDzvSXt6",
    "outputId": "c102d35c-a33e-4f4d-dcd0-7dc613cfe2c0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Percentage of data variances captured by the first 15 principal directions')"
      ]
     },
     "execution_count": 474,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import scipy.linalg as la\n",
    "from scipy.sparse.linalg import eigsh\n",
    "import time\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "def EVD(X):\n",
    "    s, U = np.linalg.eig(X)\n",
    "    #s, U = eigsh(X,k=10000)\n",
    "    idx = s.argsort()[::-1] # decreasing order\n",
    "    return s[idx], U[:,idx]\n",
    "  \n",
    "X -= X.mean(axis=0)\n",
    "X /= np.std(X,axis=0)\n",
    "cov = X.T.dot(X) / X.shape[0]\n",
    "t = time.time()\n",
    "s, U = EVD(cov)\n",
    "elapsed = time.time() - t\n",
    "s, U = np.real(s), np.real(U)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(s[:]/np.sum(s))\n",
    "plt.title('Percentage of data variances captured by the first 15 principal directions')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 475,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "lNxTXjQ6TWfO",
    "outputId": "04c3b35a-fa97-46bd-92cb-364933de63e1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15, 15)"
      ]
     },
     "execution_count": 475,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cov.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sa0tXrL7_-UF"
   },
   "source": [
    "## Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 495,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 69
    },
    "colab_type": "code",
    "id": "Dy-VMdemO7xY",
    "outputId": "59af1800-2285-49d1-b021-fbf141a9b6f5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.50673939  0.14345671 -0.22631347  0.00597827 -0.05491334 -0.38756222\n",
      " -0.03493063 -0.11518565 -0.28103787 -0.29322774 -0.18845802 -0.16007677\n",
      " -0.03174686 -0.00837895  0.52582331]\n"
     ]
    }
   ],
   "source": [
    "print(U[:,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SSHjEVjx8w0B"
   },
   "source": [
    "By observing the eigenvector with the largest variance, we can tell the importance of each original feature by comparing the absolute value of it each component. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 508,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 69
    },
    "colab_type": "code",
    "id": "DIlMN1Ia93MH",
    "outputId": "d66788d8-74c4-4370-ef9b-8bfedb8f8b35"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.52582331 0.50673939 0.38756222 0.29322774 0.28103787 0.22631347\n",
      " 0.18845802 0.16007677 0.14345671 0.11518565 0.05491334 0.03493063\n",
      " 0.03174686 0.00837895 0.00597827]\n"
     ]
    }
   ],
   "source": [
    "sortedarray=np.flip(np.sort(abs(U[:,0])))\n",
    "print(sortedarray)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YspNNXuyDyYc"
   },
   "source": [
    "Find the index of the important original features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 514,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "ujd0QO4yAeVZ",
    "outputId": "902753fe-48af-4cd9-92c9-f38559a9f674"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([14]),)"
      ]
     },
     "execution_count": 514,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.where(np.isclose(abs(U[:,0]), sortedarray[0]) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 515,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "rclJ-BhTDvyq",
    "outputId": "8eb1d299-1812-43a8-abe6-c92345157ed7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0]),)"
      ]
     },
     "execution_count": 515,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.where(np.isclose(abs(U[:,0]), sortedarray[1]) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 504,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 222
    },
    "colab_type": "code",
    "id": "fsMUOi8O-xRr",
    "outputId": "69d08527-82ba-409f-cac3-b53b6204ded8"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>Cabin_A</th>\n",
       "      <th>Cabin_B</th>\n",
       "      <th>Cabin_C</th>\n",
       "      <th>Cabin_D</th>\n",
       "      <th>Cabin_E</th>\n",
       "      <th>Cabin_F</th>\n",
       "      <th>Cabin_G</th>\n",
       "      <th>Cabin_U</th>\n",
       "      <th>Survived</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pclass  Sex   Age  SibSp  ...  Cabin_F  Cabin_G  Cabin_U  Survived\n",
       "0       3    1  22.0      1  ...        0        0        1         0\n",
       "1       1    0  38.0      1  ...        0        0        0         1\n",
       "2       3    0  26.0      0  ...        0        0        1         1\n",
       "3       1    0  35.0      1  ...        0        0        0         1\n",
       "4       3    1  35.0      0  ...        0        0        1         0\n",
       "\n",
       "[5 rows x 16 columns]"
      ]
     },
     "execution_count": 504,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HCfMU6_H--KN"
   },
   "source": [
    "Since 0.52582331 corresponds to the NaN one-hot-encoded label, we ignore it. The next largest value 0.52582331 corresponds to the feature 'Ticket class'. It does make sense as the higher class passenger is likely to get to access of evacuation facilities with relative ease. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9WtPYGECU6fO"
   },
   "source": [
    "##New representation in the eigenspace:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gYW0jGqEU4lc"
   },
   "outputs": [],
   "source": [
    "n1 = data.shape[0]\n",
    "n2 = data.shape[1]\n",
    "new_X=np.zeros((n1,n2-1))\n",
    "for i in range(n1):\n",
    "  for j in range(n2-1):\n",
    "    new_X[i,j]=X[i,:].dot(U[:,j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 478,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "SNQlrXpkW7NP",
    "outputId": "7dd124e0-92ba-41a2-edfc-2746eea63008"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(891, 15)"
      ]
     },
     "execution_count": 478,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 479,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "N2Xb3TB_XXwp",
    "outputId": "cde64e17-70b9-4530-a2cf-faa67ccb9328"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15,)"
      ]
     },
     "execution_count": 479,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "46nlGNj9UQWe"
   },
   "source": [
    "We now scale each new features by its eigenvalues to reflect is importance in training: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZefGJO_AUMa7"
   },
   "outputs": [],
   "source": [
    "for j in range(n2-1):\n",
    "    new_X[:,j]=new_X[:,j]*s[j]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SOp9Fy1GNmFG"
   },
   "source": [
    "Now we use by far the best model we have to test on the modified dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 481,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "5ceSXyRtN19v",
    "outputId": "936c00ea-dba7-4909-c300-70ff0d89b07d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.818202\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "base_learners  = [     ('1_1',SVC(gamma=2, C=1,probability=True)),\n",
    "                  ('1_2',DecisionTreeClassifier(max_depth=8)),\n",
    "                  ('1_3',MLPClassifier(alpha=1, max_iter=1000)),\n",
    "                  ('1_4', KNeighborsClassifier(n_neighbors=7,weights='distance')),\n",
    "                  ('1_5', BaggingClassifier(DecisionTreeClassifier(max_depth=5), n_estimators=10, random_state=0, warm_start=True)),\n",
    "                  ('1_6',GaussianProcessClassifier(0.949**2 * RBF(length_scale=1))),\n",
    "                  ('1_7',GradientBoostingClassifier(n_estimators=100, learning_rate=1.0,max_depth=1, random_state=0)) ]\n",
    "v_clf = VotingClassifier(estimators=base_learners,voting='soft')\n",
    "\n",
    "score=cross_validate(v_clf, new_X, y, cv=10, scoring=\"accuracy\")[\"test_score\"].mean()\n",
    "print(f\"{score:.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cOsOxSXvzmS6"
   },
   "source": [
    "New representation for test data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vgQ5A39TyErH"
   },
   "outputs": [],
   "source": [
    "n1 = data2.shape[0]\n",
    "n2 = data2.shape[1]\n",
    "new_X_test2=np.zeros((n1,n2))\n",
    "for i in range(n1):\n",
    "  for j in range(n2-1):\n",
    "    new_X_test2[i,j]=X_test2[i,:].dot(U[:,j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "U4bXimjRx_xz"
   },
   "outputs": [],
   "source": [
    "df2 = pd.read_csv(url2)\n",
    "v_clf.fit(new_X, y)\n",
    "pred=v_clf.predict(new_X_test2)\n",
    "pd.DataFrame({\"PassengerId\": df2[\"PassengerId\"], \"Survived\": pred}).to_csv(\"pca_voting_submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "eHt1Y5Lr1Cmy"
   },
   "source": [
    "![alt text](https://raw.githubusercontent.com/zyzhang1130/CE9010/master/Titanic/pca_voting.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "aT-00Ypf1PJN"
   },
   "source": [
    "Turns out that in reality, using eigenvalues of covariacne matrix to scale the feature did not give a better prediction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uYLWr6B1hrB0"
   },
   "source": [
    "#Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Pjk2pcF23SBr"
   },
   "source": [
    "Through this data science challenge project, we have learnt that:\n",
    "1. The overall pipeline for doing a data sceince project;\n",
    "2. Preprocessing: How to select relevant features and effectively encode each type of feature;\n",
    "3. Machine learning: how to use a variety of machine learning models from scikit-learn library as well as select appropriate models and tune their hyperparameters during training.\n",
    "4. Evaluation: how to evaluate the prediction results by certain metrics.\n",
    "5. Analysis: how to infer from the prediction result about certain properties of the data, and how to use such knowledge improve encoding methods. \n",
    "6. Platform: familiarized with Kaggle competition and the entire pipeline of participating in its challenge. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wg3iaRU7C0gm"
   },
   "source": [
    "what you have learned from the project\n",
    "By doing this project, we learnt the following aspects about machine learning:\n",
    "1. The overall pipeline of complete a machine learning task,\n",
    "2. Preprocessing: How to select relevant features and effectively encode each type of feature;\n",
    "3. Machine learning: how to use a variety of machine learning models from scikit-learn library as well as select appropriate models and tune their hyperparameters during training.\n",
    "4. Evaluation: how to evaluate the prediction results by different metrics.\n",
    "5. Analysis: how to infer from the prediction result about certain properties of the data, and how to use such knowledge improve encoding methods. \n",
    "6. Platform: familiarized with Kaggle competition and the entire pipeline of participating in its challenge. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "aUe4aX-7Cqrx"
   },
   "source": [
    "Challenges encounterd:\n",
    "1. Trial and error is the theme of applying machine learning techniques to solve prediction problems. Throughout the entire process, each step involves trial and error. This is through educated guess, expertise and experience that this process could be shortened. For example, by observing the characteristics of the features of the given data, many encoding methods could be eliminated and a few be shortlisted to do testing.\n",
    "2. Parameter tuning is a tedious and time consuming process. Patience is needed to get the better hyperparameters.\n",
    "3. It is usual that something unexpected will happen at the deployment stage such that the theories for idealistic situations do not apply. In these cases, one needs to be adaptive and think of alternatives to fix the issues.  \n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Untitled1.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
