{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sgwBhXkUD6HB"
   },
   "source": [
    "# Problem Statement\n",
    "Based on the given features and the causualities of part of the passanger on Titanic, predict whether some other passanger has survied the sinking of Titanic given some of the features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "y_EbZycGYNN2"
   },
   "source": [
    "# Group Members and Contributions "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "v3eXqcA5YUwc"
   },
   "source": [
    "Zhang Zeyu (1620474K): part of feature encoding, PCA, machine learning model selection, model evaluation and parameter tuning, prediction results analysis \n",
    "\n",
    "Lim Chiun Hao (U1821328D): data exploration, data visualisation and familiarisation\n",
    "\n",
    "Gabriel Hsu (U1840197K): data pre-processing, machine learning techniques"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cyiWVPFJfKuW"
   },
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 70
    },
    "colab_type": "code",
    "id": "Tcxj7haTfJFG",
    "outputId": "1bb9bb9f-9b9c-462d-c24a-142fc3f505fd"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
      "  import pandas.util.testing as tm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sb\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from collections import Counter\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cRM3StI6VBqc"
   },
   "source": [
    "# Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 197
    },
    "colab_type": "code",
    "id": "QN5sFqILVxn8",
    "outputId": "282c3f08-6bfb-4b55-9bec-40f425854b4a"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  ...     Fare Cabin  Embarked\n",
       "0            1         0       3  ...   7.2500   NaN         S\n",
       "1            2         1       1  ...  71.2833   C85         C\n",
       "2            3         1       3  ...   7.9250   NaN         S\n",
       "3            4         1       1  ...  53.1000  C123         S\n",
       "4            5         0       3  ...   8.0500   NaN         S\n",
       "\n",
       "[5 rows x 12 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#import io\n",
    "#import requests\n",
    "url = 'https://raw.githubusercontent.com/zyzhang1130/CE9010/master/Titanic/train.csv'\n",
    "df = pd.read_csv(url)\n",
    "#s=requests.get(url).content\n",
    "#df=pd.read_csv(io.StringIO(s.decode('utf-8')))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Cj-S8xiNV1xw"
   },
   "source": [
    "# Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 287
    },
    "colab_type": "code",
    "id": "ok-f71IthfAC",
    "outputId": "866b6fa0-1c67-429f-9451-78d6c561520d"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>714.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>446.000000</td>\n",
       "      <td>0.383838</td>\n",
       "      <td>2.308642</td>\n",
       "      <td>29.699118</td>\n",
       "      <td>0.523008</td>\n",
       "      <td>0.381594</td>\n",
       "      <td>32.204208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>257.353842</td>\n",
       "      <td>0.486592</td>\n",
       "      <td>0.836071</td>\n",
       "      <td>14.526497</td>\n",
       "      <td>1.102743</td>\n",
       "      <td>0.806057</td>\n",
       "      <td>49.693429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.420000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>223.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>20.125000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.910400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>446.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14.454200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>668.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>31.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>891.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>512.329200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       PassengerId    Survived      Pclass  ...       SibSp       Parch        Fare\n",
       "count   891.000000  891.000000  891.000000  ...  891.000000  891.000000  891.000000\n",
       "mean    446.000000    0.383838    2.308642  ...    0.523008    0.381594   32.204208\n",
       "std     257.353842    0.486592    0.836071  ...    1.102743    0.806057   49.693429\n",
       "min       1.000000    0.000000    1.000000  ...    0.000000    0.000000    0.000000\n",
       "25%     223.500000    0.000000    2.000000  ...    0.000000    0.000000    7.910400\n",
       "50%     446.000000    0.000000    3.000000  ...    0.000000    0.000000   14.454200\n",
       "75%     668.500000    1.000000    3.000000  ...    1.000000    0.000000   31.000000\n",
       "max     891.000000    1.000000    3.000000  ...    8.000000    6.000000  512.329200\n",
       "\n",
       "[8 rows x 7 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wtmgZ27ggoKe"
   },
   "source": [
    "Observation:\n",
    "\n",
    "1. All features, except \"Age\", have 891 training data.\n",
    "2. \"Age\" consists of a few missing data.\n",
    "3. Mean for \"Survived\" is less than 0.5, indicating most passengers/crews on board did not survive."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wBmSy36aW8JD"
   },
   "source": [
    "## Visualise \"Survived\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 296
    },
    "colab_type": "code",
    "id": "pw8hu7SGWBeH",
    "outputId": "443d1a50-62eb-4c1b-da22-e79d91784a0d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f241f5f7b38>"
      ]
     },
     "execution_count": 34,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sb.countplot(df[\"Survived\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 83
    },
    "colab_type": "code",
    "id": "aLbMqHd8XbMo",
    "outputId": "5d318da4-4c58-4e95-ff92-82b31cffac2f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Survived=0 and Survived=1\n",
      "0    549\n",
      "1    342\n",
      "Name: Survived, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of Survived=0 and Survived=1\") \n",
    "print(df[\"Survived\"].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_dFmd8kmgrN7"
   },
   "source": [
    "Observations:\n",
    "1. Most of the passengers/crews on board did not survive.\n",
    "2. 549 passengers/crews out of 891 died."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sJPoY1lTXtD3"
   },
   "source": [
    "## Visualise \"Sex\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 296
    },
    "colab_type": "code",
    "id": "ksROeWseX4NG",
    "outputId": "d47a4b01-4e23-4b09-a905-26cc30c9df1d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f241f527438>"
      ]
     },
     "execution_count": 36,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sb.barplot(x=\"Sex\", y=\"Survived\", data=df, palette=\"ch:0.6\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 67
    },
    "colab_type": "code",
    "id": "GmvMpGsXX-E2",
    "outputId": "f7bd9224-af0c-4fdd-cb20-0920c71b4daf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Survival rate:\n",
      "Female:  0.7420382165605095\n",
      "Male:  0.18890814558058924\n"
     ]
    }
   ],
   "source": [
    "print(\"Survival rate:\")\n",
    "print(\"Female: \", df['Survived'][df['Sex'] == \"female\"].value_counts(normalize=True)[1])\n",
    "print(\"Male: \", df['Survived'][df['Sex'] == \"male\"].value_counts(normalize=True)[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "J2E3cT4mgwW3"
   },
   "source": [
    "Observations:\n",
    "1. The survival rate for females is much higher than that for males.\n",
    "2. Less than 20% of males survived but more than 70% of females survived."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "q2m7twelYPmn"
   },
   "source": [
    "## Visualise \"Age\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 296
    },
    "colab_type": "code",
    "id": "R-ga9Sy8YSl7",
    "outputId": "aacbd956-c56d-4cec-e62b-8dfa2fbbcb59"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f241f042208>"
      ]
     },
     "execution_count": 38,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABCQAAAEGCAYAAAC9ykSTAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAAgAElEQVR4nO3deZwdVZn4/88DYVMQQYIiIYCCCrgMGBEdRnEPqAQBEVxARXFB3FCH+eHXUdDXuIs6iOCKiCC7KAgiio4Lsu+BEBKWDjuoIKIInt8f5xS3+nbVvQ1yK53k83698krf7qfPfU7VqapTz62qjpQSkiRJkiRJXVpucScgSZIkSZKWPRYkJEmSJElS5yxISJIkSZKkzlmQkCRJkiRJnbMgIUmSJEmSOjdtcSfwUK211lppgw02WNxpSJIkSZKkmvPPP//2lNL0ycYvcQWJDTbYgPPOO29xpyFJkiRJkmoi4rqHEu8tG5IkSZIkqXMWJCRJkiRJUucsSEiSJEmSpM5ZkJAkSZIkSZ2zICFJkiRJkjpnQUKSJEmSJHVuZAWJiPh2RNwaEZe1/Dwi4isRMT8iLomILUaViyRJkiRJmlpGeYXEd4HZA36+LbBx+bcXcMgIc5EkSZIkSVPIyAoSKaVfA3cOCJkDfC9lZwOPjYh1RpWPJEmSJEmaOqYtxvdeF7ih9nqsfO+m/sCI2It8FQUzZ87ktkO+P7Tx6e9644Nf33bIdyYR/5Yc+/VDh8e+8x0A3Pr1Lw+NBVj7ne8D4JZDPj009vHv2m9SbU5Vcw/efmjMJnuf3EEmS6affHvboTGveutPAThxErGvKbGSJElLs18fcdvQmBe8aXoHmahLtxx0wdCYx7/fJwM8Em792jFDY9Z+9y4Pud0l4qGWKaXDUkqzUkqzpk93RyJJkiRJ0pJucRYkFgHr1V7PKN+TJEmSJElLucVZkDgZ2L38tY2tgD+nlCbcriFJkiRJkpY+I3uGREQcBWwDrBURY8B/AysApJS+DpwKbAfMB/4KvGVUuUiSJEmSpKllZAWJlNJuQ36egL1H9f6SJEmSJGnqWiIeailJkiRJkpYuFiQkSZIkSVLnLEhIkiRJkqTOWZCQJEmSJEmdsyAhSZIkSZI6Z0FCkiRJkiR1zoKEJEmSJEnqnAUJSZIkSZLUOQsSkiRJkiSpcxYkJEmSJElS5yxISJIkSZKkzlmQkCRJkiRJnbMgIUmSJEmSOmdBQpIkSZIkdc6ChCRJkiRJ6pwFCUmSJEmS1DkLEpIkSZIkqXMWJCRJkiRJUucsSEiSJEmSpM5ZkJAkSZIkSZ2zICFJkiRJkjpnQUKSJEmSJHXOgoQkSZIkSeqcBQlJkiRJktQ5CxKSJEmSJKlzFiQkSZIkSVLnLEhIkiRJkqTOWZCQJEmSJEmdm7a4E1D3bvjqG4fGrLfP9zvIRJIkSZK0rPIKCUmSJEmS1DkLEpIkSZIkqXMWJCRJkiRJUudGWpCIiNkRcVVEzI+I/Rp+PjMifhkRF0bEJRGx3SjzkSRJkiRJU8PIChIRsTxwMLAtsCmwW0Rs2hf2UeCYlNLmwK7A10aVjyRJkiRJmjpGeYXElsD8lNKClNJ9wNHAnL6YBDymfL06cOMI85EkSZIkSVPEKP/s57rADbXXY8Bz+2I+DvwsIvYBHg28tKmhiNgL2Atg5syZj3iikh6+w7/78knF7fHmn404E0mSJElLksX9UMvdgO+mlGYA2wFHRMSEnFJKh6WUZqWUZk2fPr3zJCVJkiRJ0iNrlAWJRcB6tdczyvfq9gSOAUgp/R5YGVhrhDlJkiRJkqQpYJQFiXOBjSNiw4hYkfzQypP7Yq4HXgIQEZuQCxK3jTAnSZIkSZI0BYysIJFSuh94D3A6MJf81zQuj4gDImL7ErYv8PaIuBg4CnhzSimNKidJkiRJkjQ1jPKhlqSUTgVO7fvex2pfXwH8+yhzkCRJkiRJU8/ifqilJEmSJElaBlmQkCRJkiRJnbMgIUmSJEmSOmdBQpIkSZIkdc6ChCRJkiRJ6pwFCUmSJEmS1DkLEpIkSZIkqXMWJCRJkiRJUucsSEiSJEmSpM5ZkJAkSZIkSZ2zICFJkiRJkjpnQUKSJEmSJHVu2uJOQM1u+tr/GxqzzrsP7CATSZIkSZIeeV4hIUmSJEmSOmdBQpIkSZIkdc5bNjTUNV+dMzTmyfv8qINMJEmSJElLC6+QkCRJkiRJnbMgIUmSJEmSOmdBQpIkSZIkdc6ChCRJkiRJ6pwFCUmSJEmS1DkLEpIkSZIkqXP+2U8tNhcfsv3QmGe96+QOMpEkSVp6fe+E24bG7L7j9Ae/Pub424fG77LTWv9STpIEXiEhSZIkSZIWAwsSkiRJkiSpcxYkJEmSJElS5yxISJIkSZKkzlmQkCRJkiRJnbMgIUmSJEmSOmdBQpIkSZIkdc6ChCRJkiRJ6pwFCUmSJEmS1LmRFiQiYnZEXBUR8yNiv5aYXSLiioi4PCJ+MMp8JEmSJEnS1DBt0A8j4m4gtf08pfSYAb+7PHAw8DJgDDg3Ik5OKV1Ri9kY+C/g31NKf4yItR9i/pIkTdp2Jx4wNObU13ysg0w0Vb36uBOGxvx45x07yESSpKXfwIJESmk1gIg4ELgJOAII4A3AOkPa3hKYn1JaUNo4GpgDXFGLeTtwcErpj+X9bn0YfZAkSZIkSUuYyd6ysX1K6WsppbtTSnellA4hFxcGWRe4ofZ6rHyv7inAUyLitxFxdkTMnmQ+kiRJkiRpCTbwComaeyLiDcDR5Fs4dgPueYTef2NgG2AG8OuIeEZK6U/1oIjYC9gLYObMmY/A20qSJEnS0mvsCzcPjZmx7xM6yERqN9krJF4P7ALcUv69tnxvkEXAerXXM8r36saAk1NK/0gpLQTmkQsU46SUDkspzUopzZo+ffokU5YkSZIkSVPVpK6QSCldy/BbNPqdC2wcERuSCxG7MrGIcRL5aovvRMRa5Fs4FjzE95EkSZIkSUuYSV0hERFPiYgzI+Ky8vqZEfHRQb+TUrofeA9wOjAXOCaldHlEHBAR25ew04E7IuIK4JfAh1NKdzzczkiSJEmSpCXDZJ8h8Q3gw8ChACmlSyLiB8AnB/1SSulU4NS+732s9nUCPlj+SZIkSZKkZcRknyHxqJTSOX3fu/+RTkaSJEmSJC0bJluQuD0inkz+CxtExM7ATSPLSpIkSZIkLdUme8vG3sBhwNMiYhGwEHjDyLKSJEmSJElLtckWJK5LKb00Ih4NLJdSunuUSUmSJEmSpKXbZG/ZWBgRhwFbAX8ZYT6SJEmSJGkZMNmCxNOAn5Nv3VgYEf8bEVuPLi1JkiRJkrQ0m1RBIqX015TSMSmlHYHNgccAvxppZpIkSZIkaak12SskiIgXRsTXgPOBlYFdRpaVJEmSJElaqk3qoZYRcS1wIXAM8OGU0j2jTEqSJEmSJC3dJvtXNp6ZUrprpJlIkiRJkqRlxsCCRER8JKX0WeBTEZH6f55Seu/IMpMkSZIkSUutYVdIzC3/nzfqRCRJkiRJ0rJjYEEipfTj8uWlKaULOshHkiRJkiQtAyb7Vza+EBFzI+LAiHj6SDOSJEmSJElLvUkVJFJKLwJeBNwGHBoRl0bER0eamSRJkiRJWmpN9q9skFK6GfhKRPwS+AjwMeCTo0pM+lf87rBXDY15/l4/6SCTqePY78weGvPat5zWQSZaGmz7o9cNjfnpnB92kIm69KrjvzM05ic7vSXHHve94bE77/4v57Q4bX/cj4bGnLzznA4ykRafHx17+9CYOa9d62G1feYPbhsa85LXT39YbT8U53/r1qExz95z7YfV9pVfu2VozNPe/fiH1fYo3fz5BUNjnvChJz30dr946aTinvDBZzzktjU1TeoKiYjYJCI+HhGXAl8FfgfMGGlmkiRJkiRpqTXZKyS+DRwNvCKldOMI85EkSZIkScuAoQWJiFgeWJhS+nIH+UiSJEmSpGXA0Fs2UkoPAOtFxIod5CNJkiRJkpYBk71lYyHw24g4Gbin+mZK6YsjyUqSJEmSJC3VJluQuKb8Ww5YbXTpSJKkrrzy+G8OjTllp7d1kIkkSVoWTaogkVL6xKgTkSRJkiRJy45JFSQi4pdA6v9+SunFj3hGklQcesQrhsa8402nd5CJJC2bdjz+N0NjTthp65Hn8drjL5tU3LE7PX3EmUiSHkmTvWXjQ7WvVwZ2Au5/5NORJEmSJEnLgsnesnF+37d+GxHnjCAfSZIkPQQ7HPfzoTEn7fzSDjKRJOmhmewtG2vWXi4HzAJWH0lGkiRJkiRpqTfZWzbOp/cMifuBa4E9R5GQJEmSJEla+g0sSETEc4AbUkobltd7kJ8fcS1wxcizkyRJkiRJS6Xlhvz8UOA+gIh4AfA/wOHAn4HDRpuaJEmSJElaWg27ZWP5lNKd5evXAYellI4Hjo+Ii0abmiRJkiRJWloNu0Ji+YioihYvAX5R+9lknz8hSZIkSZI0zrCiwlHAryLiduBe4P8AImIj8m0bkiRJkiRJD9nAgkRK6VMRcSawDvCzlFL1lzaWA/YZ1nhEzAa+DCwPfDOl9OmWuJ2A44DnpJTOewj5S5IkSZ350IljQ2M+/5oZHWQiSUu+obddpJTObvjevGG/FxHLAwcDLwPGgHMj4uSU0hV9casB7wP+MNmkJWlZ9cHjZw+N+eJOp3WQiSRJkvSvGfYMiX/FlsD8lNKClNJ9wNHAnIa4A4HPAH8bYS6SJEmSJGkKGeWDKdcFbqi9HgOeWw+IiC2A9VJKp0TEh9saioi9gL0AZs6cOYJUJUnqzitP+PLQmFN2fF+JPXgSsXv/yzktTq867shJxf1k5zeU+KMnEbvrv5STJEkavVFeITFQRCwHfBHYd1hsSumwlNKslNKs6dOnjz45SZIkSZI0UqMsSCwC1qu9nlG+V1kNeDpwVkRcC2wFnBwRs0aYkyRJkiRJmgJGWZA4F9g4IjaMiBWBXYGTqx+mlP6cUlorpbRBSmkD4Gxge//KhiRJkiRJS7+RFSRSSvcD7wFOB+YCx6SULo+IAyJi+1G9ryRJkiRJmvpG+VBLUkqnAqf2fe9jLbHbjDIXSZIkSQI4+/DbhsZstYfPrpNGbbE91FKSJEmSJC27LEhIkiRJkqTOjfSWDUmaqr70g1cMjfnA60/vIBNJkiRp2WRBQpIkaRnymuPPGhpz4k7bjDwPSZIsSEjq1Le+9/KhMXvu/rMOMpEkSZK0OFmQkLTU+N8jh9+G8Z43eBuGJEmSNBX4UEtJkiRJktQ5CxKSJEmSJKlz3rKhJca5h756aMxz3vHjDjKRlgx7nTh7aMxhrzmtg0xGZ7uTPjo05tQdPtlBJpIeqp2Pv2BozHE7bTHyPPY44bqhMYfvuP7I85CkZZFXSEiSJEmSpM5ZkJAkSZIkSZ2zICFJkiRJkjpnQUKSJEmSJHXOgoQkSZIkSeqcBQlJkiRJktQ5/+znUuLGg98/NOaJex/UQSaSJEmSJA3nFRKSJEmSJKlzFiQkSZIkSVLnvGVDkiRJUid++sPbh8Zs+7q1OshE0lRgQUKSpAbbnfjpoTGnvma/DjKRJElaOnnLhiRJkiRJ6pwFCUmSJEmS1DkLEpIkSZIkqXM+Q0KSNKVsd9K+Q2NO3eELHWQiSZKkUfIKCUmSJEmS1DmvkJCAX33jlUNjXvj2Ux5yu6d9a7tJxc3e89SH3LYkSZIkLcm8QkKSJEmSJHXOgoQkSZIkSeqcBQlJkiRJktQ5CxKSJEmSJKlzFiQkSZIkSVLnLEhIkiRJkqTOjbQgERGzI+KqiJgfEfs1/PyDEXFFRFwSEWdGxPqjzEeSJEmSJE0NIytIRMTywMHAtsCmwG4RsWlf2IXArJTSM4HjgM+OKh9JkiRJkjR1TBth21sC81NKCwAi4mhgDnBFFZBS+mUt/mzgjSPMR5KmnP2PnT2puE+99rQRZyJJkiR1a5QFiXWBG2qvx4DnDojfE/hp0w8iYi9gL4CZM2c+UvlJ0qR99uhXDI35yK6nd5CJJGmY1x1/9dCYH+60cQeZSJIGmRIPtYyINwKzgM81/TyldFhKaVZKadb06dO7TU6SJEmSJD3iRnmFxCJgvdrrGeV740TES4H9gRemlP4+wnwkSZIkSdIUMcorJM4FNo6IDSNiRWBX4OR6QERsDhwKbJ9SunWEuUiSJEmSpClkZAWJlNL9wHuA04G5wDEppcsj4oCI2L6EfQ5YFTg2Ii6KiJNbmpMkSZIkSUuRUd6yQUrpVODUvu99rPb1S0f5/pIkSZIkaWqaEg+1lCRJkiRJy5aRXiEhSZKkh27OcacNjfnRzrM7yESSpNHxCglJkiRJktQ5CxKSJEmSJKlzFiQkSZIkSVLnLEhIkiRJkqTOWZCQJEmSJEmdsyAhSZIkSZI6Z0FCkiRJkiR1zoKEJEmSJEnqnAUJSZIkSZLUOQsSkiRJkiSpcxYkJEmSJElS56Yt7gQkSZIkPTSHnnDr0Jh37Lh2B5lI0sPnFRKSJEmSJKlzFiQkSZIkSVLnLEhIkiRJkqTOWZCQJEmSJEmdsyAhSZIkSZI6Z0FCkiRJkiR1zoKEJEmSJEnqnAUJSZIkSZLUOQsSkiRJkiSpcxYkJEmSJElS5yxISJIkSZKkzlmQkCRJkiRJnbMgIUmSJEmSOmdBQpIkSZIkdc6ChCRJkiRJ6pwFCUmSJEmS1DkLEpIkSZIkqXMWJCRJkiRJUucsSEiSJEmSpM6NtCAREbMj4qqImB8R+zX8fKWI+GH5+R8iYoNR5iNJkiRJkqaGkRUkImJ54GBgW2BTYLeI2LQvbE/gjymljYAvAZ8ZVT6SJEmSJGnqGOUVElsC81NKC1JK9wFHA3P6YuYAh5evjwNeEhExwpwkSZIkSdIUECml0TQcsTMwO6X0tvL6TcBzU0rvqcVcVmLGyutrSsztfW3tBexVXj4VuKrhLdcCbm/4fpOHEjvKtqdKHktq21Mlj1G2PVXyGGXbUyWPJbXtqZLHKNueKnksqW1PlTxG2fZUyWOUbU+VPJbUtqdKHqNse6rkMcq2p0oeS2rbUyWPUbY9VfJYUtt+JPJYP6U0fdItpJRG8g/YGfhm7fWbgP/ti7kMmFF7fQ2w1sN8v/NGETvKtqdKHktq21MlD/u4dOSxpLY9VfKwj1O37amSh31cOvJYUtueKnnYx6UjjyW17amSh32cum2PMo+2f6O8ZWMRsF7t9YzyvcaYiJgGrA7cMcKcJEmSJEnSFDDKgsS5wMYRsWFErAjsCpzcF3MysEf5emfgF6mUWiRJkiRJ0tJr2qgaTindHxHvAU4Hlge+nVK6PCIOIF/acTLwLeCIiJgP3EkuWjxch40odpRtT5U8ltS2p0oeo2x7quQxyranSh5LattTJY9Rtj1V8lhS254qeYyy7amSxyjbnip5LKltT5U8Rtn2VMljlG1PlTyW1LanSh6jbHuq5LGktj3KPBqN7KGWkiRJkiRJbUZ5y4YkSZIkSVIjCxKSJEmSJKl7/+qf6Rj1P2A2cBUwH9hvQNxOQAL2KfGLgDHgUuB84MW12F2AK4DrgLtK24cBF9X+/Y380M3q9TzgL7Vc/ln72cml3ZnAL4ELgQXl/ecD/1uLvRh4DbA+cCZwCXAW5c+fAicB/yjvfwnwur5+BvCV0u5c8sNDrwAuB97XsFzq8ZeS/9TqxSX+Ew3xKwE/LPF/AJ5U+vOTIbF/B64sfZzw51/68rgEeAFwXPmducDzWuKvA+4ty/2isr7eP6DtG8l/PvYy4Chg5SH9+0SJvby/3RL/beCvpX+XAFsAawJnAFeX/9eoxd4KXFZe7wHcVH73n8CsvnbrsbPJz1G5r/zOicBjm+LpbRN3ltiLgJ8BTxyQx9Xl31Hk7WStlrbrsXsA+9bjG9p+ALi55P3nkst2A/p4FXBb+f7lwGeH9PHusk4vAq4FLhrQ9rXk7eZG4DxgyyF9vI7edvFj4DEldj3ydlxtV4eUXBbUls0ZwBoNse8r7V9DHjc3M36M9MdX+5GF5LH94DhpabtxnAyIvZ08/m5k/Bjpj/9+6dcdwA3UxlRL2w/Q26ddzvgx0tb2hDE1oO0JY2pAHxvH1ID1OGFMDWj7WhrG1IA+VmPqoip+QB+vBO4p670+/lYGzqG3n/5+yfta4PrS/g+BFRtiPwH8V4m9l3wcbIs9qMSMkcdI/36hP/6k0se7yGPvMvJ2tUJLHnuU2PvKe3wbWKGl7Wo7uKOs80vIx4dVB/RxflkuJwF/aWm3NbYhfh752HsReRu7i94Y/7cBfby6xN9MPpa9d8jyu5o8t5hXxbe0/QB5znFvWSY3AicNaXuM3pj+DbDRgGWyiDy2rwUOB6bVlsvylON+6ePCEnsLZTy1xDaOvb5j6vIlj2ofMlb6N278teTROJ4a4i8qy+PP5G3mwfE0IO/GMdIQP7fE/rms8wfHyJC8/0HePwyKrZbJzWXdPzieBvTx3lq7D46RljzGynq8rhofQ/p4Q3mPy+pjpKzjS+nt51qPeQ3xC0ubN5V8+udG/W0PmxvV4+cxeG7UlHfj3Kgl9g7g/try3m4SeVTHsPrcqL/t6vVYWZ/9c6OmttvmRk3L71qaj2NNfazm3DdQOy6V+MfSm7dfX2InzIsaYucCB9AyHx7Q9h/Jx/VLqK33hrbfT8tcpyH+RnrjummO25R343pvyaNtPvJUxp9j3lNimuaV/bF3AUfSPq/sj0/k/W/TvLKp7a/TO7c9pW95fKD0ozqnehsDjgd967S+X31FU8y4+GEBi/Mfeed4DfmkeEXyAXXThrjVgF8DZ5M36CcBzykLcVPg6cCiErsxeYf7uNL2c/rbJp9w3gk8qvYe7y0rrsrlgf5cyEWNd5W8ry+5rEjemJ5RYtYpg/A4YI/yvRcDR5SvXw/MKSv/ieQNuL7z3Q74Kfkk/JXApbVlMK8hp3r8VsC55fsrkE/It+qLfzfw9fL1rmVZ/YDmgkQ99jbgxAHrsj+P24C3lZ+tWO9jS/wfynK9GVi/JXZd8s7mnPL9Y4A3D8j5Q+SDxaPID3j9ORMP0B8BflvWR5XHZynFMWA/4DPl6xeQCxaXlTG0oPzOc8g7+BfV2q3HVuN8d2AV8lj8ZtVuQ3y1TTyuxG5KHp9fH5DHmuTt4K/knfFaDW3PrcWuQd75nln+X6u/7fL6L8DHgQ81rPOmPr6eXiFuU2DtIX18cNsEvgB8bEDb/we8usS/AzhrSB8vII+XNYC3AgfWttEtyterkydCLwc+T94eN63We1/savQmcV8hT/wXlP8/09D2auQDxabAJuQDxVn0Dhz9sfPI+5UJ42RA7DNry/BT9MZIPX5m6ePzytcLyjJ5L/lA1dT2PeX1euQHF9fHSFvbE8ZUW9s0jKkBfWwcUwPW44QxNaDtxjE1oI+/II+RNcj7pbMG9PFc4IXl+/XxF5QTJ3IB9W/AjuRjxnUl76+TjzX12BXKMri6xO5D3i4ObYm9sPx8c2AD8uS0vl+ox69d8ng5uaBfjZGjWto+jzwh2qXELSg5vauh7RXIx9OtGD/5/SJ5O2vr40rA9uSJ+V9a2m2NbYjfiLx/3Ar4LrBz3/hr6+N7gKNry2TtIctv75LHmrWf9bf9B+Cvfe9/PLD7kLar/c8a5GPddwcskxvIc49rgAOBPWvv9UHycf/00q+TgD3L19+u1mNf7Fnk7WTC2OvrxweBHwF3ldeN468lj8bx1Bd/HHn7WpPx+7MvUvtQqyHvxjHSF/8T8jxwpfI+NwPLt8TW8/4B+eRnAbUT9b7Yn5CPp28BvgcsV63fIX2slsca9THSksd84Lnl632B7w7o48rk4+P15GPsAdUYqa8renOMxmNePZ7x85Hnksfgb5hYkKjanszcqGq7fr7QNjdqyrtxbtQS+xng/7Wsx6Y8DizLsH9e/mDbtddzyHPQlfrXe0vbbXOjpuXXdhxr6uMF5HOLBeR924G1PA4nn5BW7T6LhnlRPbZ8/fjyXo3z4QFtb1fr42da2l6ZfILcONfpa7vq4wa0z3Gb8m5c7y15tM5xa7+3ArnAsXXb8qvFLk8+8b+eAdtYX/w/yR96T5hXNsTeXPr/pPLvLvKYXYt8TrUQWKXEn0Q+f209HtTa3pTefnXDsk4n7Cvr/6b6LRtbAvNTSgtSSveRD/pzGuIOJA+YFYEbSvy55E+W5pALE6tExErA24GDgaeUts9taHtn4Kcppb/W3uNtwLxaLvc35JKAx5S8bwSuL7FHAa8qMSuXuE3Ik1fIn57NAUgp/YC8Ekkp3Uhe+dNr7zEH+F7KTgFWjIh1Ukp3k0+21u3LqR5/NvCYiFiHvEGsUHLpjz+8fP17YDPyAaBJPfYe4AUREQNiv5fySJ1LPkE4pfTzvpTSn4bk/VjgtcA1KaXrmmLL1w8Aa0TEDHKh4cYBOd9A3ljuTSndD/yKPPGvezJ5bFDLY8daG4cDO5Sf/5pcyAJ4BXBGSunsMhb/SD5hoSG2GuffSyndW95vJWBGQ/wq9LaJO+iN20dT1mVLHneST/JOIY9BGtpetYpNKf2xLMufURsjfW0P1NTHsqz+h7xNzEkp3Tqkj/Vtc5fye21t/5W8zo8GtqG27pv6SF63PyZ/gnAG+SorUko3pZQuKL+6KfCnsgxeDXyH3hjaoR5btsE/kbffV5BPGs8g7/B36G+7xP8TWDelNDeldFXf8uuPvRm4tWmcDIi9pLYMn01vjNT7+O9lWa2aUrq+5DybMqYa2p5L73a/L5GLdvUx0tb2hDE1pO1x2vpIy5hqW49NY2pA241jqq2P5E9BLy/Lb3XgxgF9fAq5kA7jx19KKf2lfP955GLHovL+hzF+/NVjVyBPxM8osYeQt4vzWmJXKO93YUrp2oblXY/flnyi9ueU0jH0xsg55PHXlMc5KaVjyno/oyzLGQ1tr1B7y7sAynFklV5oYx/vJ396c15Znk3ttsY2xE8jn7z3HxObYh/sI/lk6aPVMqmNv8blRz4x/Ql5H0FK6da2dVOJiMeQiwcnDWn7AXqfilbjr22Z3JdS+gV5jCyijL9y7Hwl+bg/vcRuTR5zZ5An6Ds0xD6e3nYybuzV+lHFHy5PGl0AABdaSURBVF1bro3jrymPtvHUF38lcHvKx7H6/mwVyrptybtxjPTF30T+cOvv5OLBzeTjz8C8ydvwPbVcmmIr7wIOSCn9syyfWxvi632slsdrqI2RljweKE2dAcyidozs7yO5eHoveX+1JbV9VJ9XlJ81HvOaYkvefwBOJZ8kthk6N2qIbZ0bteVCy9yooY/3ln/j1mNbHvSueGk6b+n3FuDTZWyNW+9NbTcdx9riGTA3qqn6+GTyejmDvNyq/cLq5A92vlXL42Ia5kV9sZDH5empZT7c1nZK6dRaH88GZjS0vTn53KxxrtMXX63za1PDfKQtbxrWe1seDJjj1rwbuDul9Jum5dcX+xLy3OWnTG4bewn5EHFdaphXNsTeClxZxutnSy6r1GKmkc+fp5ELvOfScjzoMwc4OqX095TSQvI43LIhbtwbTWXrkk8aK2PkquqDImILYL2U0ikR8VlyFak/fifggpTS3yPiKeVnHwLWjIjZKaXT+trelVxNr95jffIngSfU2p4GfCAi5pB3IieRd2o/I0/QVwWeX8tj+4i4nFy1ehP55HpH4MvkA8lqEfG4siOt3ndLcpHlmiHLZN1SbNmc/MkKQ+LPKt8/uBwU2uK/QK7MrUazemwqfb4wIr6WUur/EzD12A3JG/dh5SB4Pvl2k3uG5L0bzTvddcmFqEUR8fmS96XAqSmlnw3I4xLyxGOjiFhErsae1xB/Rl8eW6aUbiqvbyZPaBpzqr3+O/mTrCZNfd2LXJHtt0Jf7FbkneZ1wIva2i7jdBH5sraXtOQxrWq7xN9CbwLTZuWS6+PKn/n9BbBv2dlPyIM8CfoP4A3kndzPywFqUB/HyNvILSmlq9v6SF7vp5MnICuRi2mtfSSfOK5afv+15G2837+RD+R/IK/nueT9xIT1HhEbkA/mPwW2TindFBFjJZ8JY6TELw98JiIOBD7d8P712E3IE4VK4zjpj42ITwHvLD9+U0PzTycX2qp9wdOA15X2x42p0vbmwArlzzU/mrw9t3mw7WFjqt42Q8ZUXx+fxfAxVV+PMGBM9bX9aYaPqfryez+5kDuLfALy/HpgXx8fAK6MiP8kfzKxXi1uefJ+8ankSc415EnJ9eTxN0YpPtdiNyJfGnkJ8PKU//T2GHkf1xR7BLB7RFxI71PfcWrxmwB/qB0vxkq+u5JvQelv+5zydeVG8ocBuzW0vRG5EHBwRNxfltvTybe47NvSx9+RP707ucRu1dLuwNi++I3J22N1VdCLI+Jj5E+79ivzh6Y+voC8vbwKeGFEnFeNqablFxFPJhcPPhsRu5Mvyb+6r+2DgWdGxHnkE+WzgTOrgs2Att9GHq8vKst8qwHL5JURMausy1fTG38Hkecwq5H373cAf6qNpxXpffDRH/vHvtjlGP8hSRW/MfCo2tj7KBP1t10/JkwYT7X4t5HnF5XnkD+1PI8ynlrabh0jtfiPkq9GqWwAHB0RJ1DGSEvbG5E/tV0d2CQiTmiIpcRvAfwiIu4jX8ny3to+qq2PY8DLGD9GmvJ4G3m/Nq30Y+MBfby9FrcueR9bjZEE/CwiEvlT0ouBxw845iXy3Hhtxs+xxpi436m3fS7D50ZV26sz/kS7aW40Ie8Bc6OmPk4jj5OVgc0j4rTacaktj+cAW0bExvSOY/W2Dy2vX17i/lb6/KHacayt7abjWNPya5sbNfXxcvLJ5Bj5BLha5xuSr2z+DvBC4O8RUa3n/nnRg7ER8SxyQe60Wt798+HGtss5QXVu9nzy7QH9bd9RYtrmOvW2XwbcVPJ+KRPnI4PyHrfeyedyTXn8G8PnI3PKMqNl+dXtSj4W3sDgbaweT+3Y0TqvLLHnlPhqOziPXByjdk51Pb3beC4GntpyPKhbl3zcqoy1xD1oql8hMVBELEcuHOw7IGxN8tUT7yivp5F3wv9Nnuh+IyIeW2tzHeAZ5I23sit5klmvsn6AfEvA64GDyiRjN/Ilku8ov39EyRHyDmMz8s7pv4D9yZOXC8kb4CLGbxjTyBPGt1SV8gFWIV+q9/76hGWAN5ArzFtGxNObAiLiVeTK2X2TaA9yxWyMvKz2jogXDIidRj5IHpdS2pw8Ad1vSPtBXk7HtgZErEHe0H9H+YQ3It7YFp9Smkue5B9L3ulcxPAT8P42Ei2fqP0Ltid/cn7kJGKPI1cqjyTvMJusAPx/5EvTh4qIR5X4MycRvj75BKs6wN1LPvi1mUbeJj9BvhXmmPJp6DAb01yMqnsXebt8P/ky0G8NDuet5IPA+8njcdxYj4hVyYXLs/u3q/71XmKPJ1+K/PeG9xo3Rmrxb08pbUHZj9DwCU0t9rvkT+ArE8ZJU2xKaf/Sx3n0jZESvwe5eFf18efAJ+kbU7W2308+Ub6DvJ0dRENxu942+cDYOqb62h44phr6OHBMDViPE8ZUQ9sDx1TD8nsXuSD1yfJ732pou+rjLPI+9of0bvsAIKX0QErp38jHkunkIlGjWuwM8gTliZOM3YRcuNicfKn2dHKBrin+QPKnU/XjxY7Ar1NK/9fQ9kzGTzhfDSyoYhvifw+8mbwdPJl8PJlLPtFv6uNTyUXEr05iebTG9sVvSC4qvYm8ToN8QrMm8J8D+ljdVvN18gTs20OW30rk7eHLwDeq+L62tySvm1llmexF74rKQW1/gDxv+CR5Av7FlmUyg3ys/hJ5P3Iv8EB13E8p1YtJjR5KbEP8HeST52rs/YC8vCfb9rjxNCT+RPLtBnOB17XEVldgThgjA9r+L/L2/J+UMTIk9mnkMfKoAbHrk8fSEeT92smU8TGJZbI5ZX82IPYD5A9ePk8+EfliW3w5xu1KPkb+D/kqnGp+tHU5bm1LvkJs/YZ86se8Kv6bwHOHzA/rbc8GnlD7WdPcqIr/FLBpre2muVFT3m1zo6bYQ8j7p6+RC2lfaIiv53EI+fzkaPKVJ19oaHvvErOAfKy8u+RcP4619REmHseall/bcaypj28lf4L/TvK+qjouTSMXyw4BPkzeh42bt9fmRQ/Glm38PnLhts2wtp9dvndkQ9t/J38o0TbXqbf9pZLLx2mej7Tl3bTe2/IYNh9ZkXzsX9C/EBrmlSuSx/zFLcutf15ZxW9RO3a0zSur2N+TC/ETtoPaOdWG5HnFiowvYj6ipnpBYhHjP7WcUb5XWY1czT4rIq4lV6Fnl6o/5Mt0X0a+p666ymCMvJO/nnwP0TzyAq7a3oX8LIT6xH9X8mVw9VweTb50bwH5ioPNyffUHFPaWYk8CNaq511Ogv8CPC6ltGMZyPuXn1W3LaxK3jHsn/JtAsOWyQHAkSmlE5iocRmW9/olEy87q+L/nTxYNyBXcF8cEd8f0PYt5OrtVeQJQP+lOfXYMXqXSkE+cGwxJO+nkh/ac8uAPr6UfL/T48nr9wT6PqGstxv5EqTlgM1TSi8gf7ozryF+ndrrGcAtpXBVFbCaLsnqz3+llrj+nN5MXnaHl51Tv3/QvE0cSfPllIvI28GG5J3aR8jr6YKIeEJf7P2l7SeX+PeRJ1szWuJJKS1KKd2SUppP3g4uo/myrKqPY+T1MoN8D/s/ydvIoD7OJI/DHza0W297j1rbv2rJo+ojKaUryQekD5MP6A9eiRQRK5Anm9WDxiCP8U2ARfX1Xos9klyIXI/eGJlB7+FF/W0fmVL6Zsml2o+Muxqpr+0TGDBO2mKLapns1ND2L8mToHrsuDHVl/MJ5En1huQCTPUsiAfHSEPbrWOqv+1BY6qlj61jqmU9QsOYamm7dUy1LL89yBOWReRC54S8a328MqX0H/TGXv1KuMrV5PHzPPJJ08zSdv+xsDp+zCVPdh5b9m8zyvJoiv1FaZdyInI/eT01uYZeAQryJGV58snkOKXtC8nFdyLiv8m3CXy9qeESfzr5dodqO3gWeRK/U0PsXPKnnxuRLwN9PbBS5Ct2HlZsib+V3m0Xp5c+b0A+sd+yL7bex/r4O518L3O/+vIbIx9rFpGPlePia8fm6ph4F/k41X/VWX/b21Im5vQeKDnu+FdbJi9IKf2+jL8LyPeYz6Mc98t86mjyeHgt48fTP0r7/bHrkk9i2sZePf4I4D8i4vtl7F3D+NtUmvLYHVrHUz1+N+DJtfnKDPIyr8ZTU96fo32M1ONfCmxW8r6ptH0dvTHSmHfKt20l8n7y1JbYF5M/PBsjn7ifRf4Ethofg/q4UenHKQOW39uBZ6V8lVM1Vp/fEF/v4+/J84bdybeXzYN83C//30r+AOjpDDjmVfH0HjhfbU8z6Cvg97X9c8oJUNvcqNb2XPI2Um973HGsIe+qEDlhbtTUx3JceqAs6x/V3qsxjzJfXbfk8Y0qvq/tE8lXyI2VXE8k3/r94HFsQB8nHMdall/jcaylj1emlF5OPmaeRu+4NAaMlfGziLyOt6B5XlSPhTzPehI9/fPhtrYhn4c8EXhDWe/9bf+Y8bfw9M91+tu+rbQ9YT5CHosT8m5Z7215DJvjbktej9Wt+I3zylrsBeTtZuC8sh6f8q00rfPKvravIN8+Wm0HXyGf315AfnzBwpTSbeWc+Nfk84mm40G/YefvE6UBD5hY3P/IlaYFZUFVDyvZbED8r8iDYUPyyr6Xvr88QZ4QHF7avpZ8+dMTqrbJn3DUHz74tBJXz2Vt8mWxm5EH2tVlJf2U/ClPdVn4LSXvucAzS3vrl/d8Cr2HFn2KfM8gJf63wE0tfXwl4x/2eDtw0IBlUo+fDZxfvr8KeRLyqr74vRn/UMtjyPecNT3Ucm/ypODRpd/HlK9/R57UDcr7bvJlP5CrlZ8bEn8H+WqRQX2sHtZ0Xvm9w4F9hvTvR+XrmeT7MvsfrvlKeidFW5E/Vfgc4x9qWX8a8gb0Hia5kFz0WoM8Fl/c13YVW42tPcg7h8toGOe1+GocVg+N2Yz8ELHjJpHHQnKxpv/hYRuQx2l/7JpMfABT1fYa5APLOvS2g0+T7xtr6+P+5E/vLiZ/UnMDEAP6uGL5+twBy6Nqez55MnUxucp//pA+bly+fhz5GSRvLXFRXh/E+O3+C+RPOTar1ns9tvxutbyrhw8tLP9/tqHtNeg9wKpafufQe6hlf9ut42RA7IsY/6Cn4xryqI+RZ9fW+z7kYmF/2015L6L3UKi2tieMqba2aRhTA/rYOKYGrMcJY2pA241jakAfryKPkTXJl/+eP6CPa9f6+CN64286vaeJr0red+xJ76GWm5H3u+/ui12lvN8CcvFjn/L1oS2xZwPbl9dPIhckNqotk3r8E8mf3L6O/JC4vzH+Keb9bf+efPnpe8lXHVxLeYhjQ/w65E/tXk0+wa+Op58v/9r6WD0sawG9h1pOOrYhfj3KMZF8LFlU1uNB5DHY1scvkT+NW1j6cO6Q5fcl8qR4TfKx9dyWtncor/clFyU2ncS6uYM8/tckj5njByyTGbVlciYTj0/bkE9aF9J7iNlC8sn3uxtizyJvJxPGXsO+ew5lTkEee4toOC415NE4nvriX02+Z34N8olHtc/5PPD5AXk3jpG++DfTu71pyxK7fDVGBuT9NHr7v0MGxK5EHmvvpfdXAJqOffU+rkGeBx7VknM9jzvIBctqWR4/pI/VJ7mrVGOEPMdbrcQ+mnzMupn2Y149fgZ5rO5cWx6/oXfM62/7d+T9aePcqC/+MaXtPWiYGw3Ie8LcaEBsfT3uT5nrDMhjZi2PD5CPY/1tn02+7eKd5CtRfkfe1qrjWFvbTcextuU34Tg2oI8b1/p4NOW4VOL+j/zh4DRyYeQwGuZF9djy9WfIVyMPmg83tf2q0t+tm2LL1weUthvnOn1tr1na/gotc9yWvNvWe1Mew+a4R9N7IGTjvLIv9i0MmVf2xe/NgHllQ9tN59mLyu8+l3wLz6PIY/Eo8j5k4PGgtL8ZE/erAx9q+bCLBV39Kyu0uod2/9qK374h9izyTnZeWWj30fsTSgvoPc36i+Sd27VlIFxTBtEG5B3xnFqbH6ccPGq5jJU2LyYXHb5Sfr4puZhwcWlzrPx/bFmpN5fXO5B3yFeX9r5ZG0C/I1+Gk0r+15fB/c7y8yDfX1p9opbIxZHqT7hsR96xNcVfTT7pvoS8Y/9Y//IkX9VxLHkHdg55srANvclDU+y15IPj3NLPaj215XEpvXs6LyEP7jUGxF9G3tBXr62XtthbSj6XkT+FWWlI/6o/m3ox8JKGto8iVyITuRJ4APkE9syyPH9O72npp5fl8A/yuv8OeXzdX753C/nBPpQ+/60We1BZ3/fT+3NVVeHkieQi1k0l/nZ6fxbslrIMf0x+OGJbHvPLv7cwfuc7qyy3qu07S5vzKQWgvvh621Ul/M7SlxvIVx+tM6CP88jFqFvIFdgXD+njNSXunX3belPb15Mr3DeRJ63PHtLH28p7zCNPAqPEz2H8dlVtywvpbUc/Jx8kti6xd9LbBr9E3t/8tbxPfYzsWWt7HvnAvIB8onlnyf+Wspyrtu+qtf0xGsbJgNi7S5s3M36M1PO4qCy7G8ljaozamGro4zzymLiYvC3vyfgx0tb2hDE1oO0JY2pAH9vGVNt6nDCmBrTdNqba+jhWWzZ/IBd42vq4qLZu6uPvJfT+9GW1H5tHHiM3lOV4LHnf9kx6+73LSs770/vTbTcOiD2avL8eI4+pB0r8N0seu5K3wyqPE8t7J/K2X19OzyQfW+6s5fFWevvN66vYhrarnC4m72vHShtHkifgbX28hlwA2pZeQWLSsSV+n7JuLyk5Vv26m95x5PvkwlBbHxfU8v49+VPoQcuvulf70iq+oe1vlJ9fTN4mv9S3/2tr+6aSx8Xk+dCTBiyTP1E+EaT2J6/J+8tvUo77pY/X0vszb8fSm69sTz4mVrGNY68eW76u9k0Xkcf07eR9Wn38NeXRNp5m1X5vm9L/+fT+rO2D42lA3m1jpJ73NmU9XUNe5wupjZEBef+1tqzbYn9LXueXkvdD/eOprY/zS079HwI15XFTyeN6yvgY0sc7S+xVlDFCHlPVHPvysuyq7aDpmDenxFbPJzie3ljtP+Y9qcTcVWt7O9rnRluV2Krtw0tuE+ZGA/KeMDcaEHtXybd/rtOWR/WA5EvoHcf6+/j58nuXkLfJ/uNYW9tNx7G25TfhODagj7eV5d1/XHoi+QS8mrf/viy3CfOiEv/60lY1x38P7fPhtrb/UZZJdayp1vvLyvertnehfa4zi3zFQtX2BfQ+bGia4zbl3bbem/IYNMc9vSzv1emdT7Ytv63J+9zVy+tB29gs8m2md5ScqmPHhHlliX9yWcdV2+POs/uWx2Glj9VcZC+GHA9q43HcfnXY+X410CRJkiRJkjoz1Z8hIUmSJEmSlkIWJCRJkiRJUucsSEiSJEmSpM5ZkJAkSZIkSZ2zICFJkiRJkjpnQUKSJI1UROwQESkinra4c5EkSVOHBQlJkjRquwG/Kf9LkiQBFiQkSdIIRcSqwNbAnsCu5XvLRcTXIuLKiDgjIk6NiJ3Lz54dEb+KiPMj4vSIWGcxpi9JkkbIgoQkSRqlOcBpKaV5wB0R8WxgR2ADYFPgTcDzACJiBeCrwM4ppWcD3wY+tTiSliRJozdtcScgSZKWarsBXy5fH11eTwOOTSn9E7g5In5Zfv5U4OnAGREBsDxwU7fpSpKkrliQkCRJIxERawIvBp4REYlcYEjAiW2/AlyeUnpeRylKkqTFyFs2JEnSqOwMHJFSWj+ltEFKaT1gIXAnsFN5lsTjgW1K/FXA9Ih48BaOiNhscSQuSZJGz4KEJEkald2YeDXE8cATgDHgCuD7wAXAn1NK95GLGJ+JiIuBi4Dnd5euJEnqUqSUFncOkiRpGRMRq6aU/hIRjwPOAf49pXTz4s5LkiR1x2dISJKkxeEnEfFYYEXgQIsRkiQte7xCQpIkSZIkdc5nSEiSJEmSpM5ZkJAkSZIkSZ2zICFJkiRJkjpnQUKSJEmSJHXOgoQkSZIkSerc/w807Vu8yZ0VLwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 1296x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, axis1 = plt.subplots(1,1,figsize=(18,4))\n",
    "sb.barplot(x='Age', y='Survived', data=df[[\"Age\", \"Survived\"]].groupby(['Age'],as_index=False).mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1z8MrB4vg2O4"
   },
   "source": [
    "Observation:\n",
    "1. The age distribution can be divided into 4 groups with a general decreasing trend in the survival rate.\n",
    "2. First group (Age 0 to 2) has a very high survival rate.\n",
    "3. Second group (Age 2 to 15) has a lower survival rate than the first group.\n",
    "4. Third group (Age 15 to 50) has an even lower survival rate.\n",
    "5. The last group (Age 50 to 80) has an increase in survival rate. This could be due to a smaller number of data in this age range which caused some anomaly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 542
    },
    "colab_type": "code",
    "id": "BP-xQfGlcGHw",
    "outputId": "bab6b593-c6ce-4846-b56f-611cb6298d83"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<html>\n",
       "<head><meta charset=\"utf-8\" /></head>\n",
       "<body>\n",
       "    <div>\n",
       "            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>\n",
       "                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
       "        <script src=\"https://cdn.plot.ly/plotly-latest.min.js\"></script>    \n",
       "            <div id=\"df5341db-4e50-493d-a03a-449e20916434\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>\n",
       "            <script type=\"text/javascript\">\n",
       "                \n",
       "                    window.PLOTLYENV=window.PLOTLYENV || {};\n",
       "                    \n",
       "                if (document.getElementById(\"df5341db-4e50-493d-a03a-449e20916434\")) {\n",
       "                    Plotly.newPlot(\n",
       "                        'df5341db-4e50-493d-a03a-449e20916434',\n",
       "                        [{\"coloraxis\": \"coloraxis\", \"hoverlabel\": {\"namelength\": 0}, \"hovertemplate\": \"Age=%{x}<br>Survived=%{y}<br>count=%{z}\", \"name\": \"\", \"type\": \"histogram2d\", \"x\": [22.0, 38.0, 26.0, 35.0, 35.0, null, 54.0, 2.0, 27.0, 14.0, 4.0, 58.0, 20.0, 39.0, 14.0, 55.0, 2.0, null, 31.0, null, 35.0, 34.0, 15.0, 28.0, 8.0, 38.0, null, 19.0, null, null, 40.0, null, null, 66.0, 28.0, 42.0, null, 21.0, 18.0, 14.0, 40.0, 27.0, null, 3.0, 19.0, null, null, null, null, 18.0, 7.0, 21.0, 49.0, 29.0, 65.0, null, 21.0, 28.5, 5.0, 11.0, 22.0, 38.0, 45.0, 4.0, null, null, 29.0, 19.0, 17.0, 26.0, 32.0, 16.0, 21.0, 26.0, 32.0, 25.0, null, null, 0.83, 30.0, 22.0, 29.0, null, 28.0, 17.0, 33.0, 16.0, null, 23.0, 24.0, 29.0, 20.0, 46.0, 26.0, 59.0, null, 71.0, 23.0, 34.0, 34.0, 28.0, null, 21.0, 33.0, 37.0, 28.0, 21.0, null, 38.0, null, 47.0, 14.5, 22.0, 20.0, 17.0, 21.0, 70.5, 29.0, 24.0, 2.0, 21.0, null, 32.5, 32.5, 54.0, 12.0, null, 24.0, null, 45.0, 33.0, 20.0, 47.0, 29.0, 25.0, 23.0, 19.0, 37.0, 16.0, 24.0, null, 22.0, 24.0, 19.0, 18.0, 19.0, 27.0, 9.0, 36.5, 42.0, 51.0, 22.0, 55.5, 40.5, null, 51.0, 16.0, 30.0, null, null, 44.0, 40.0, 26.0, 17.0, 1.0, 9.0, null, 45.0, null, 28.0, 61.0, 4.0, 1.0, 21.0, 56.0, 18.0, null, 50.0, 30.0, 36.0, null, null, 9.0, 1.0, 4.0, null, null, 45.0, 40.0, 36.0, 32.0, 19.0, 19.0, 3.0, 44.0, 58.0, null, 42.0, null, 24.0, 28.0, null, 34.0, 45.5, 18.0, 2.0, 32.0, 26.0, 16.0, 40.0, 24.0, 35.0, 22.0, 30.0, null, 31.0, 27.0, 42.0, 32.0, 30.0, 16.0, 27.0, 51.0, null, 38.0, 22.0, 19.0, 20.5, 18.0, null, 35.0, 29.0, 59.0, 5.0, 24.0, null, 44.0, 8.0, 19.0, 33.0, null, null, 29.0, 22.0, 30.0, 44.0, 25.0, 24.0, 37.0, 54.0, null, 29.0, 62.0, 30.0, 41.0, 29.0, null, 30.0, 35.0, 50.0, null, 3.0, 52.0, 40.0, null, 36.0, 16.0, 25.0, 58.0, 35.0, null, 25.0, 41.0, 37.0, null, 63.0, 45.0, null, 7.0, 35.0, 65.0, 28.0, 16.0, 19.0, null, 33.0, 30.0, 22.0, 42.0, 22.0, 26.0, 19.0, 36.0, 24.0, 24.0, null, 23.5, 2.0, null, 50.0, null, null, 19.0, null, null, 0.92, null, 17.0, 30.0, 30.0, 24.0, 18.0, 26.0, 28.0, 43.0, 26.0, 24.0, 54.0, 31.0, 40.0, 22.0, 27.0, 30.0, 22.0, null, 36.0, 61.0, 36.0, 31.0, 16.0, null, 45.5, 38.0, 16.0, null, null, 29.0, 41.0, 45.0, 45.0, 2.0, 24.0, 28.0, 25.0, 36.0, 24.0, 40.0, null, 3.0, 42.0, 23.0, null, 15.0, 25.0, null, 28.0, 22.0, 38.0, null, null, 40.0, 29.0, 45.0, 35.0, null, 30.0, 60.0, null, null, 24.0, 25.0, 18.0, 19.0, 22.0, 3.0, null, 22.0, 27.0, 20.0, 19.0, 42.0, 1.0, 32.0, 35.0, null, 18.0, 1.0, 36.0, null, 17.0, 36.0, 21.0, 28.0, 23.0, 24.0, 22.0, 31.0, 46.0, 23.0, 28.0, 39.0, 26.0, 21.0, 28.0, 20.0, 34.0, 51.0, 3.0, 21.0, null, null, null, 33.0, null, 44.0, null, 34.0, 18.0, 30.0, 10.0, null, 21.0, 29.0, 28.0, 18.0, null, 28.0, 19.0, null, 32.0, 28.0, null, 42.0, 17.0, 50.0, 14.0, 21.0, 24.0, 64.0, 31.0, 45.0, 20.0, 25.0, 28.0, null, 4.0, 13.0, 34.0, 5.0, 52.0, 36.0, null, 30.0, 49.0, null, 29.0, 65.0, null, 50.0, null, 48.0, 34.0, 47.0, 48.0, null, 38.0, null, 56.0, null, 0.75, null, 38.0, 33.0, 23.0, 22.0, null, 34.0, 29.0, 22.0, 2.0, 9.0, null, 50.0, 63.0, 25.0, null, 35.0, 58.0, 30.0, 9.0, null, 21.0, 55.0, 71.0, 21.0, null, 54.0, null, 25.0, 24.0, 17.0, 21.0, null, 37.0, 16.0, 18.0, 33.0, null, 28.0, 26.0, 29.0, null, 36.0, 54.0, 24.0, 47.0, 34.0, null, 36.0, 32.0, 30.0, 22.0, null, 44.0, null, 40.5, 50.0, null, 39.0, 23.0, 2.0, null, 17.0, null, 30.0, 7.0, 45.0, 30.0, null, 22.0, 36.0, 9.0, 11.0, 32.0, 50.0, 64.0, 19.0, null, 33.0, 8.0, 17.0, 27.0, null, 22.0, 22.0, 62.0, 48.0, null, 39.0, 36.0, null, 40.0, 28.0, null, null, 24.0, 19.0, 29.0, null, 32.0, 62.0, 53.0, 36.0, null, 16.0, 19.0, 34.0, 39.0, null, 32.0, 25.0, 39.0, 54.0, 36.0, null, 18.0, 47.0, 60.0, 22.0, null, 35.0, 52.0, 47.0, null, 37.0, 36.0, null, 49.0, null, 49.0, 24.0, null, null, 44.0, 35.0, 36.0, 30.0, 27.0, 22.0, 40.0, 39.0, null, null, null, 35.0, 24.0, 34.0, 26.0, 4.0, 26.0, 27.0, 42.0, 20.0, 21.0, 21.0, 61.0, 57.0, 21.0, 26.0, null, 80.0, 51.0, 32.0, null, 9.0, 28.0, 32.0, 31.0, 41.0, null, 20.0, 24.0, 2.0, null, 0.75, 48.0, 19.0, 56.0, null, 23.0, null, 18.0, 21.0, null, 18.0, 24.0, null, 32.0, 23.0, 58.0, 50.0, 40.0, 47.0, 36.0, 20.0, 32.0, 25.0, null, 43.0, null, 40.0, 31.0, 70.0, 31.0, null, 18.0, 24.5, 18.0, 43.0, 36.0, null, 27.0, 20.0, 14.0, 60.0, 25.0, 14.0, 19.0, 18.0, 15.0, 31.0, 4.0, null, 25.0, 60.0, 52.0, 44.0, null, 49.0, 42.0, 18.0, 35.0, 18.0, 25.0, 26.0, 39.0, 45.0, 42.0, 22.0, null, 24.0, null, 48.0, 29.0, 52.0, 19.0, 38.0, 27.0, null, 33.0, 6.0, 17.0, 34.0, 50.0, 27.0, 20.0, 30.0, null, 25.0, 25.0, 29.0, 11.0, null, 23.0, 23.0, 28.5, 48.0, 35.0, null, null, null, 36.0, 21.0, 24.0, 31.0, 70.0, 16.0, 30.0, 19.0, 31.0, 4.0, 6.0, 33.0, 23.0, 48.0, 0.67, 28.0, 18.0, 34.0, 33.0, null, 41.0, 20.0, 36.0, 16.0, 51.0, null, 30.5, null, 32.0, 24.0, 48.0, 57.0, null, 54.0, 18.0, null, 5.0, null, 43.0, 13.0, 17.0, 29.0, null, 25.0, 25.0, 18.0, 8.0, 1.0, 46.0, null, 16.0, null, null, 25.0, 39.0, 49.0, 31.0, 30.0, 30.0, 34.0, 31.0, 11.0, 0.42, 27.0, 31.0, 39.0, 18.0, 39.0, 33.0, 26.0, 39.0, 35.0, 6.0, 30.5, null, 23.0, 31.0, 43.0, 10.0, 52.0, 27.0, 38.0, 27.0, 2.0, null, null, 1.0, null, 62.0, 15.0, 0.83, null, 23.0, 18.0, 39.0, 21.0, null, 32.0, null, 20.0, 16.0, 30.0, 34.5, 17.0, 42.0, null, 35.0, 28.0, null, 4.0, 74.0, 9.0, 16.0, 44.0, 18.0, 45.0, 51.0, 24.0, null, 41.0, 21.0, 48.0, null, 24.0, 42.0, 27.0, 31.0, null, 4.0, 26.0, 47.0, 33.0, 47.0, 28.0, 15.0, 20.0, 19.0, null, 56.0, 25.0, 33.0, 22.0, 28.0, 25.0, 39.0, 27.0, 19.0, null, 26.0, 32.0], \"xaxis\": \"x\", \"xbingroup\": \"x\", \"y\": [0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0], \"yaxis\": \"y\", \"ybingroup\": \"y\"}, {\"alignmentgroup\": \"True\", \"bingroup\": \"x\", \"hoverlabel\": {\"namelength\": 0}, \"hovertemplate\": \"Age=%{x}<br>count=%{y}\", \"legendgroup\": \"\", \"marker\": {\"color\": \"#0d0887\"}, \"name\": \"\", \"offsetgroup\": \"\", \"opacity\": 0.5, \"showlegend\": false, \"type\": \"histogram\", \"x\": [22.0, 38.0, 26.0, 35.0, 35.0, null, 54.0, 2.0, 27.0, 14.0, 4.0, 58.0, 20.0, 39.0, 14.0, 55.0, 2.0, null, 31.0, null, 35.0, 34.0, 15.0, 28.0, 8.0, 38.0, null, 19.0, null, null, 40.0, null, null, 66.0, 28.0, 42.0, null, 21.0, 18.0, 14.0, 40.0, 27.0, null, 3.0, 19.0, null, null, null, null, 18.0, 7.0, 21.0, 49.0, 29.0, 65.0, null, 21.0, 28.5, 5.0, 11.0, 22.0, 38.0, 45.0, 4.0, null, null, 29.0, 19.0, 17.0, 26.0, 32.0, 16.0, 21.0, 26.0, 32.0, 25.0, null, null, 0.83, 30.0, 22.0, 29.0, null, 28.0, 17.0, 33.0, 16.0, null, 23.0, 24.0, 29.0, 20.0, 46.0, 26.0, 59.0, null, 71.0, 23.0, 34.0, 34.0, 28.0, null, 21.0, 33.0, 37.0, 28.0, 21.0, null, 38.0, null, 47.0, 14.5, 22.0, 20.0, 17.0, 21.0, 70.5, 29.0, 24.0, 2.0, 21.0, null, 32.5, 32.5, 54.0, 12.0, null, 24.0, null, 45.0, 33.0, 20.0, 47.0, 29.0, 25.0, 23.0, 19.0, 37.0, 16.0, 24.0, null, 22.0, 24.0, 19.0, 18.0, 19.0, 27.0, 9.0, 36.5, 42.0, 51.0, 22.0, 55.5, 40.5, null, 51.0, 16.0, 30.0, null, null, 44.0, 40.0, 26.0, 17.0, 1.0, 9.0, null, 45.0, null, 28.0, 61.0, 4.0, 1.0, 21.0, 56.0, 18.0, null, 50.0, 30.0, 36.0, null, null, 9.0, 1.0, 4.0, null, null, 45.0, 40.0, 36.0, 32.0, 19.0, 19.0, 3.0, 44.0, 58.0, null, 42.0, null, 24.0, 28.0, null, 34.0, 45.5, 18.0, 2.0, 32.0, 26.0, 16.0, 40.0, 24.0, 35.0, 22.0, 30.0, null, 31.0, 27.0, 42.0, 32.0, 30.0, 16.0, 27.0, 51.0, null, 38.0, 22.0, 19.0, 20.5, 18.0, null, 35.0, 29.0, 59.0, 5.0, 24.0, null, 44.0, 8.0, 19.0, 33.0, null, null, 29.0, 22.0, 30.0, 44.0, 25.0, 24.0, 37.0, 54.0, null, 29.0, 62.0, 30.0, 41.0, 29.0, null, 30.0, 35.0, 50.0, null, 3.0, 52.0, 40.0, null, 36.0, 16.0, 25.0, 58.0, 35.0, null, 25.0, 41.0, 37.0, null, 63.0, 45.0, null, 7.0, 35.0, 65.0, 28.0, 16.0, 19.0, null, 33.0, 30.0, 22.0, 42.0, 22.0, 26.0, 19.0, 36.0, 24.0, 24.0, null, 23.5, 2.0, null, 50.0, null, null, 19.0, null, null, 0.92, null, 17.0, 30.0, 30.0, 24.0, 18.0, 26.0, 28.0, 43.0, 26.0, 24.0, 54.0, 31.0, 40.0, 22.0, 27.0, 30.0, 22.0, null, 36.0, 61.0, 36.0, 31.0, 16.0, null, 45.5, 38.0, 16.0, null, null, 29.0, 41.0, 45.0, 45.0, 2.0, 24.0, 28.0, 25.0, 36.0, 24.0, 40.0, null, 3.0, 42.0, 23.0, null, 15.0, 25.0, null, 28.0, 22.0, 38.0, null, null, 40.0, 29.0, 45.0, 35.0, null, 30.0, 60.0, null, null, 24.0, 25.0, 18.0, 19.0, 22.0, 3.0, null, 22.0, 27.0, 20.0, 19.0, 42.0, 1.0, 32.0, 35.0, null, 18.0, 1.0, 36.0, null, 17.0, 36.0, 21.0, 28.0, 23.0, 24.0, 22.0, 31.0, 46.0, 23.0, 28.0, 39.0, 26.0, 21.0, 28.0, 20.0, 34.0, 51.0, 3.0, 21.0, null, null, null, 33.0, null, 44.0, null, 34.0, 18.0, 30.0, 10.0, null, 21.0, 29.0, 28.0, 18.0, null, 28.0, 19.0, null, 32.0, 28.0, null, 42.0, 17.0, 50.0, 14.0, 21.0, 24.0, 64.0, 31.0, 45.0, 20.0, 25.0, 28.0, null, 4.0, 13.0, 34.0, 5.0, 52.0, 36.0, null, 30.0, 49.0, null, 29.0, 65.0, null, 50.0, null, 48.0, 34.0, 47.0, 48.0, null, 38.0, null, 56.0, null, 0.75, null, 38.0, 33.0, 23.0, 22.0, null, 34.0, 29.0, 22.0, 2.0, 9.0, null, 50.0, 63.0, 25.0, null, 35.0, 58.0, 30.0, 9.0, null, 21.0, 55.0, 71.0, 21.0, null, 54.0, null, 25.0, 24.0, 17.0, 21.0, null, 37.0, 16.0, 18.0, 33.0, null, 28.0, 26.0, 29.0, null, 36.0, 54.0, 24.0, 47.0, 34.0, null, 36.0, 32.0, 30.0, 22.0, null, 44.0, null, 40.5, 50.0, null, 39.0, 23.0, 2.0, null, 17.0, null, 30.0, 7.0, 45.0, 30.0, null, 22.0, 36.0, 9.0, 11.0, 32.0, 50.0, 64.0, 19.0, null, 33.0, 8.0, 17.0, 27.0, null, 22.0, 22.0, 62.0, 48.0, null, 39.0, 36.0, null, 40.0, 28.0, null, null, 24.0, 19.0, 29.0, null, 32.0, 62.0, 53.0, 36.0, null, 16.0, 19.0, 34.0, 39.0, null, 32.0, 25.0, 39.0, 54.0, 36.0, null, 18.0, 47.0, 60.0, 22.0, null, 35.0, 52.0, 47.0, null, 37.0, 36.0, null, 49.0, null, 49.0, 24.0, null, null, 44.0, 35.0, 36.0, 30.0, 27.0, 22.0, 40.0, 39.0, null, null, null, 35.0, 24.0, 34.0, 26.0, 4.0, 26.0, 27.0, 42.0, 20.0, 21.0, 21.0, 61.0, 57.0, 21.0, 26.0, null, 80.0, 51.0, 32.0, null, 9.0, 28.0, 32.0, 31.0, 41.0, null, 20.0, 24.0, 2.0, null, 0.75, 48.0, 19.0, 56.0, null, 23.0, null, 18.0, 21.0, null, 18.0, 24.0, null, 32.0, 23.0, 58.0, 50.0, 40.0, 47.0, 36.0, 20.0, 32.0, 25.0, null, 43.0, null, 40.0, 31.0, 70.0, 31.0, null, 18.0, 24.5, 18.0, 43.0, 36.0, null, 27.0, 20.0, 14.0, 60.0, 25.0, 14.0, 19.0, 18.0, 15.0, 31.0, 4.0, null, 25.0, 60.0, 52.0, 44.0, null, 49.0, 42.0, 18.0, 35.0, 18.0, 25.0, 26.0, 39.0, 45.0, 42.0, 22.0, null, 24.0, null, 48.0, 29.0, 52.0, 19.0, 38.0, 27.0, null, 33.0, 6.0, 17.0, 34.0, 50.0, 27.0, 20.0, 30.0, null, 25.0, 25.0, 29.0, 11.0, null, 23.0, 23.0, 28.5, 48.0, 35.0, null, null, null, 36.0, 21.0, 24.0, 31.0, 70.0, 16.0, 30.0, 19.0, 31.0, 4.0, 6.0, 33.0, 23.0, 48.0, 0.67, 28.0, 18.0, 34.0, 33.0, null, 41.0, 20.0, 36.0, 16.0, 51.0, null, 30.5, null, 32.0, 24.0, 48.0, 57.0, null, 54.0, 18.0, null, 5.0, null, 43.0, 13.0, 17.0, 29.0, null, 25.0, 25.0, 18.0, 8.0, 1.0, 46.0, null, 16.0, null, null, 25.0, 39.0, 49.0, 31.0, 30.0, 30.0, 34.0, 31.0, 11.0, 0.42, 27.0, 31.0, 39.0, 18.0, 39.0, 33.0, 26.0, 39.0, 35.0, 6.0, 30.5, null, 23.0, 31.0, 43.0, 10.0, 52.0, 27.0, 38.0, 27.0, 2.0, null, null, 1.0, null, 62.0, 15.0, 0.83, null, 23.0, 18.0, 39.0, 21.0, null, 32.0, null, 20.0, 16.0, 30.0, 34.5, 17.0, 42.0, null, 35.0, 28.0, null, 4.0, 74.0, 9.0, 16.0, 44.0, 18.0, 45.0, 51.0, 24.0, null, 41.0, 21.0, 48.0, null, 24.0, 42.0, 27.0, 31.0, null, 4.0, 26.0, 47.0, 33.0, 47.0, 28.0, 15.0, 20.0, 19.0, null, 56.0, 25.0, 33.0, 22.0, 28.0, 25.0, 39.0, 27.0, 19.0, null, 26.0, 32.0], \"xaxis\": \"x3\", \"yaxis\": \"y3\"}, {\"alignmentgroup\": \"True\", \"bingroup\": \"y\", \"hoverlabel\": {\"namelength\": 0}, \"hovertemplate\": \"Survived=%{y}<br>count=%{x}\", \"legendgroup\": \"\", \"marker\": {\"color\": \"#0d0887\"}, \"name\": \"\", \"offsetgroup\": \"\", \"opacity\": 0.5, \"showlegend\": false, \"type\": \"histogram\", \"xaxis\": \"x2\", \"y\": [0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0], \"yaxis\": \"y2\"}],\n",
       "                        {\"barmode\": \"overlay\", \"coloraxis\": {\"colorbar\": {\"title\": {\"text\": \"count\"}}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]]}, \"legend\": {\"tracegroupgap\": 0}, \"margin\": {\"t\": 60}, \"template\": {\"data\": {\"bar\": [{\"error_x\": {\"color\": \"#2a3f5f\"}, \"error_y\": {\"color\": \"#2a3f5f\"}, \"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"bar\"}], \"barpolar\": [{\"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"barpolar\"}], \"carpet\": [{\"aaxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"baxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"type\": \"carpet\"}], \"choropleth\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"choropleth\"}], \"contour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"contour\"}], \"contourcarpet\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"contourcarpet\"}], \"heatmap\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmap\"}], \"heatmapgl\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmapgl\"}], \"histogram\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"histogram\"}], \"histogram2d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2d\"}], \"histogram2dcontour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2dcontour\"}], \"mesh3d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"mesh3d\"}], \"parcoords\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"parcoords\"}], \"pie\": [{\"automargin\": true, \"type\": \"pie\"}], \"scatter\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter\"}], \"scatter3d\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter3d\"}], \"scattercarpet\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattercarpet\"}], \"scattergeo\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergeo\"}], \"scattergl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergl\"}], \"scattermapbox\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattermapbox\"}], \"scatterpolar\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolar\"}], \"scatterpolargl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolargl\"}], \"scatterternary\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterternary\"}], \"surface\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"surface\"}], \"table\": [{\"cells\": {\"fill\": {\"color\": \"#EBF0F8\"}, \"line\": {\"color\": \"white\"}}, \"header\": {\"fill\": {\"color\": \"#C8D4E3\"}, \"line\": {\"color\": \"white\"}}, \"type\": \"table\"}]}, \"layout\": {\"annotationdefaults\": {\"arrowcolor\": \"#2a3f5f\", \"arrowhead\": 0, \"arrowwidth\": 1}, \"coloraxis\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"colorscale\": {\"diverging\": [[0, \"#8e0152\"], [0.1, \"#c51b7d\"], [0.2, \"#de77ae\"], [0.3, \"#f1b6da\"], [0.4, \"#fde0ef\"], [0.5, \"#f7f7f7\"], [0.6, \"#e6f5d0\"], [0.7, \"#b8e186\"], [0.8, \"#7fbc41\"], [0.9, \"#4d9221\"], [1, \"#276419\"]], \"sequential\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"sequentialminus\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]]}, \"colorway\": [\"#636efa\", \"#EF553B\", \"#00cc96\", \"#ab63fa\", \"#FFA15A\", \"#19d3f3\", \"#FF6692\", \"#B6E880\", \"#FF97FF\", \"#FECB52\"], \"font\": {\"color\": \"#2a3f5f\"}, \"geo\": {\"bgcolor\": \"white\", \"lakecolor\": \"white\", \"landcolor\": \"#E5ECF6\", \"showlakes\": true, \"showland\": true, \"subunitcolor\": \"white\"}, \"hoverlabel\": {\"align\": \"left\"}, \"hovermode\": \"closest\", \"mapbox\": {\"style\": \"light\"}, \"paper_bgcolor\": \"white\", \"plot_bgcolor\": \"#E5ECF6\", \"polar\": {\"angularaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"radialaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"scene\": {\"xaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"yaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"zaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}}, \"shapedefaults\": {\"line\": {\"color\": \"#2a3f5f\"}}, \"ternary\": {\"aaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"baxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"caxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"title\": {\"x\": 0.05}, \"xaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}, \"yaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}}}, \"xaxis\": {\"anchor\": \"y\", \"domain\": [0.0, 0.7363], \"title\": {\"text\": \"Age\"}}, \"xaxis2\": {\"anchor\": \"y2\", \"domain\": [0.7413, 1.0], \"matches\": \"x2\", \"showgrid\": true, \"showline\": false, \"showticklabels\": false, \"ticks\": \"\"}, \"xaxis3\": {\"anchor\": \"y3\", \"domain\": [0.0, 0.7363], \"matches\": \"x\", \"showgrid\": true, \"showticklabels\": false}, \"xaxis4\": {\"anchor\": \"y4\", \"domain\": [0.7413, 1.0], \"matches\": \"x2\", \"showgrid\": true, \"showline\": false, \"showticklabels\": false, \"ticks\": \"\"}, \"yaxis\": {\"anchor\": \"x\", \"domain\": [0.0, 0.7326], \"title\": {\"text\": \"Survived\"}}, \"yaxis2\": {\"anchor\": \"x2\", \"domain\": [0.0, 0.7326], \"matches\": \"y\", \"showgrid\": true, \"showticklabels\": false}, \"yaxis3\": {\"anchor\": \"x3\", \"domain\": [0.7426, 1.0], \"matches\": \"y3\", \"showgrid\": true, \"showline\": false, \"showticklabels\": false, \"ticks\": \"\"}, \"yaxis4\": {\"anchor\": \"x4\", \"domain\": [0.7426, 1.0], \"matches\": \"y3\", \"showgrid\": true, \"showline\": false, \"showticklabels\": false, \"ticks\": \"\"}},\n",
       "                        {\"responsive\": true}\n",
       "                    ).then(function(){\n",
       "                            \n",
       "var gd = document.getElementById('df5341db-4e50-493d-a03a-449e20916434');\n",
       "var x = new MutationObserver(function (mutations, observer) {{\n",
       "        var display = window.getComputedStyle(gd).display;\n",
       "        if (!display || display === 'none') {{\n",
       "            console.log([gd, 'removed!']);\n",
       "            Plotly.purge(gd);\n",
       "            observer.disconnect();\n",
       "        }}\n",
       "}});\n",
       "\n",
       "// Listen for the removal of the full notebook cells\n",
       "var notebookContainer = gd.closest('#notebook-container');\n",
       "if (notebookContainer) {{\n",
       "    x.observe(notebookContainer, {childList: true});\n",
       "}}\n",
       "\n",
       "// Listen for the clearing of the current output cell\n",
       "var outputEl = gd.closest('.output');\n",
       "if (outputEl) {{\n",
       "    x.observe(outputEl, {childList: true});\n",
       "}}\n",
       "\n",
       "                        })\n",
       "                };\n",
       "                \n",
       "            </script>\n",
       "        </div>\n",
       "</body>\n",
       "</html>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import plotly.express as px\n",
    "\n",
    "fig = px.density_heatmap(df, x=\"Age\", y=\"Survived\", marginal_x=\"histogram\", marginal_y=\"histogram\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7_JhY3t9wTBe"
   },
   "source": [
    "![alt text](https://raw.githubusercontent.com/zyzhang1130/CE9010/master/Titanic/heatmap.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UJ4q5dsMg7_a"
   },
   "source": [
    "Observations:\n",
    "1. Most of the passengers/crews who survived are within the age range of 20-30.\n",
    "2. Most of the passengers/crews who did not survive are also within the age range of 20-30.\n",
    "3. This is consistent with the fact that the population with age 20-30 is the highest."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pkBsh-8kYr4k"
   },
   "source": [
    "## Visualise \"Pclass\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 296
    },
    "colab_type": "code",
    "id": "rfywCxCsYu7o",
    "outputId": "8d4f28a0-0745-4b1a-86f0-05c9440f4847"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f241b5a0f60>"
      ]
     },
     "execution_count": 40,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sb.barplot(x=\"Pclass\", y=\"Survived\", data=df, palette=\"ch:0.1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 83
    },
    "colab_type": "code",
    "id": "zbxFjF9GYw2N",
    "outputId": "1888d7d5-0653-4f65-9a88-987ffc5e6552"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Survival rate:\n",
      "Pclass=1:  0.6296296296296297\n",
      "Pclass=2:  0.47282608695652173\n",
      "Pclass=3:  0.24236252545824846\n"
     ]
    }
   ],
   "source": [
    "print(\"Survival rate:\")\n",
    "print(\"Pclass=1: \", df['Survived'][df['Pclass'] == 1].value_counts(normalize=True)[1])\n",
    "print(\"Pclass=2: \", df['Survived'][df['Pclass'] == 2].value_counts(normalize=True)[1])\n",
    "print(\"Pclass=3: \", df['Survived'][df['Pclass'] == 3].value_counts(normalize=True)[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KYGUANzihBGC"
   },
   "source": [
    "Observation:\n",
    "1. Class 1 passengers have the highest survival rate.\n",
    "2. Class 3 passengers have the lowest survival rate.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gmuJyfEjD_Gw"
   },
   "source": [
    "# Data Pre-processing\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Drn4vx9bE0JL"
   },
   "source": [
    "The data provided contained a mix of numerical, nominal, ordinal and binary data. We used different encoding methods for the data which will be examined below.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rVdfXYWiFF0n"
   },
   "source": [
    "## Feature Encoding\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-ixJTNgLnaFm"
   },
   "source": [
    "'PassengerId' is the same as index therefore it is not needed in as a feature:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uM10OZZrnU9M"
   },
   "outputs": [],
   "source": [
    "df = df.drop(columns=\"PassengerId\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TC9somNWi7WP"
   },
   "source": [
    "### Binary Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-9Aj8VXPjJSz"
   },
   "source": [
    "Amongst all the fearues given, only 'Sex' is binary. We now use dictionary to map its value 'male' and 'female' to binary value '0' and '1':"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jOVz13LQklVQ"
   },
   "outputs": [],
   "source": [
    "sex_map = {'male': 1, 'female': 0}\n",
    "df['Sex'] = df['Sex'].map(sex_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5Dnaz80SlAyW"
   },
   "source": [
    "### Ordinal Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UT0sOHpmlNbr"
   },
   "source": [
    "'Ticket class' is the only nominal feature given. Since it value is already '1', '2' and '3', no encoding is needed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CVAVh25Al26D"
   },
   "source": [
    "### Nominal Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2KR1c6f5mCHU"
   },
   "source": [
    "'Name', 'Ticket', 'Cabin' and 'Embarked' are nominal features. We think 'Name' has little to do with the survial of the passangers and it is unique for each passanger, therefore it is not a relevant feature. To double check that it is true, we count the number of times every name appeared in the training dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 83
    },
    "colab_type": "code",
    "id": "YHh2DORoo07T",
    "outputId": "44f5bb1d-91ad-4013-ca85-dae1421c39e3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of the instances: 891\n",
      "number of unique names: 891\n",
      "most frequently appeared name: van Melkebeke, Mr. Philemon\n",
      "maximum number of appearance: 1\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "count_no=[]\n",
    "count = Counter(df['Name'])\n",
    "for i in count:\n",
    "    count_no.append(count[i])\n",
    "#print(count)\n",
    "print('number of the instances:',len(df['Name']))\n",
    "print('number of unique names:',len(count))\n",
    "print('most frequently appeared name:',max(count))\n",
    "print('maximum number of appearance:',max(count_no))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZlXGioiHsNs_"
   },
   "source": [
    "Which is what we expected. We drop 'Name':"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "K9g-mMFPsTkB"
   },
   "outputs": [],
   "source": [
    "df = df.drop(columns=\"Name\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RST5RERoq4pk"
   },
   "source": [
    "We check the feature 'Ticket' which is supposed to be similar to 'Name':"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 83
    },
    "colab_type": "code",
    "id": "S6iY5ohCobqj",
    "outputId": "ee9bc239-3f39-4ce2-8450-d87116823454"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of the instances: 891\n",
      "number of unique tickets: 681\n",
      "most frequently appeared ticket: WE/P 5735\n",
      "maximum number of apperance: 7\n"
     ]
    }
   ],
   "source": [
    "count_no=[]\n",
    "count = Counter(df['Ticket'])\n",
    "for i in count:\n",
    "    count_no.append(count[i])\n",
    "#print(count)\n",
    "print('number of the instances:',len(df['Ticket']))\n",
    "print('number of unique tickets:',len(count))\n",
    "print('most frequently appeared ticket:',max(count))\n",
    "print('maximum number of apperance:',max(count_no))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "c-ZKuGCKtMzV"
   },
   "source": [
    "So 'Ticket' is a sparse feature rather than unique for every instance. But since it is difficult to generalize (understand the similarities betweeen instances), we drop it for now:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tuMK2l6hnqd2"
   },
   "outputs": [],
   "source": [
    "df = df.drop(columns=\"Ticket\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-92cGLjse2Pu"
   },
   "source": [
    "We treat 'Cabin' as a nominal feature for now and investigate it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 67
    },
    "colab_type": "code",
    "id": "KWFh0hi-oA7d",
    "outputId": "20eb8e21-013d-46cb-98a2-5651776483b1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of the instances: 891\n",
      "number of unique cabins: 148\n",
      "maximum number of apperance: 687\n"
     ]
    }
   ],
   "source": [
    "count_no=[]\n",
    "count = Counter(df['Cabin'])\n",
    "for i in count:\n",
    "    count_no.append(count[i])\n",
    "#print(count)\n",
    "print('number of the instances:',len(df['Cabin']))\n",
    "print('number of unique cabins:',len(count))\n",
    "print('maximum number of apperance:',max(count_no))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "k_-ejR83ghUE"
   },
   "source": [
    "We can see that this feature is also quite sqarse and there are a lot of missing values for many instances.\n",
    "Therefore, we use the first alphabet appeared as the value of the feature and label the missing value with a different string. After that, we use one-hot encoding to encode this featrue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "b7Cx_ACghLaR"
   },
   "outputs": [],
   "source": [
    "df['Cabin'] = df['Cabin'].replace(np.nan, 'U', regex=True)\n",
    "for i in range(df.shape[0]):\n",
    "    df.loc[i,'Cabin'] = df.loc[i,'Cabin'][0]\n",
    "df = pd.concat([df,pd.get_dummies(df['Cabin'], prefix='Cabin')],axis=1)\n",
    "df = df.drop(columns=\"Cabin\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RTKCNkxWhr6_"
   },
   "source": [
    "It is worth noting that, after checking the test data, there is no value 'T' ('Cabin' started with alphabet 'T'). Therefore, we drop the 'T' column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MIHvvTvMiFv1"
   },
   "outputs": [],
   "source": [
    "df = df.drop(columns=\"Cabin_T\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FWKnRsy6iQa7"
   },
   "source": [
    "### Numerical Feature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NF6hbaLTijuc"
   },
   "source": [
    "'Age', 'SibSp'(no. of siblings / spouses aboard the Titanic), 'Parch'(no. of parents / children aboard the Titanic) and 'Fare'(Passenger fare) have numerical values, some are integers while others are can be non-integers. They can be directly used as labels but there are again missing values. After trial and error, we cound that it is most effective by filling those missing values with the median of all values in that that particalr feature:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "J9yiIDpqiYMc"
   },
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer \n",
    "imputer = SimpleImputer(missing_values=np.nan, strategy='median')\n",
    "df[['Age']] = imputer.fit_transform(df[['Age']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AgYSk51d0dDL"
   },
   "source": [
    "### Exception"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wOgQDvPl0lJ9"
   },
   "source": [
    "'Embarked' fearture is supposed to be a nominal featrue; however, we discovered that it will give a higher accuracy if it is encoded as a ordinal feature (is misisng values under 'embarked' is encoded as another integer as well): "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JE8dlvpN0487"
   },
   "outputs": [],
   "source": [
    "Embarked_map = {'S':0, 'C': 1, 'Q': 2}\n",
    "df['Embarked'] = df['Embarked'].map(Embarked_map)\n",
    "df['Embarked'] = df['Embarked'].replace(np.nan, 3, regex=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Cu6mpBatlR3s"
   },
   "source": [
    "move the label to the last column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "udpyfbty4DY7"
   },
   "outputs": [],
   "source": [
    "Survived = df[\"Survived\"]\n",
    "df = df.drop(columns=\"Survived\")\n",
    "df = pd.concat([df,Survived],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 197
    },
    "colab_type": "code",
    "id": "w7ob0kzs0T-n",
    "outputId": "d782fd84-d4e7-4050-f439-20c14955854a"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>Cabin_A</th>\n",
       "      <th>Cabin_B</th>\n",
       "      <th>Cabin_C</th>\n",
       "      <th>Cabin_D</th>\n",
       "      <th>Cabin_E</th>\n",
       "      <th>Cabin_F</th>\n",
       "      <th>Cabin_G</th>\n",
       "      <th>Cabin_U</th>\n",
       "      <th>Survived</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pclass  Sex   Age  SibSp  ...  Cabin_F  Cabin_G  Cabin_U  Survived\n",
       "0       3    1  22.0      1  ...        0        0        1         0\n",
       "1       1    0  38.0      1  ...        0        0        0         1\n",
       "2       3    0  26.0      0  ...        0        0        1         1\n",
       "3       1    0  35.0      1  ...        0        0        0         1\n",
       "4       3    1  35.0      0  ...        0        0        1         0\n",
       "\n",
       "[5 rows x 16 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FAjQDjpar1Bc"
   },
   "source": [
    "## Feature scaling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "s8Yjk_fb1iRq"
   },
   "source": [
    "We tried different order. Applyinh z-scoring first then max normalization gives better prediction accuracy for this dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CLTXUVfSz0u6"
   },
   "source": [
    "### z-scoring"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "X8YhbUCf5L4R"
   },
   "source": [
    "We considered the possibility of only doing z-scoreing for numerical freatures while leaving categorical features unchanged. However, z-scoring all features gives a better accuracy for this dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xkGpfTIqr5WY"
   },
   "outputs": [],
   "source": [
    "data=df.to_numpy()\n",
    "n1 = data.shape[0]\n",
    "n2 = data.shape[1]\n",
    "m=int(0.8*n1)\n",
    "for i in range(n2-1):\n",
    "    data[:,i] = (data[:,i] - data[:,i].mean())/data[:,i].std()  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7NnGC2jUsXig"
   },
   "source": [
    "### Max normalization\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ABOyayKo2pzz"
   },
   "source": [
    "We considered the possibility of doing max normalization for all freaturesd. However, only applying max normalization for numerical freatures while leaving categorical features unchanged gives a better accuracy for this dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9e9CyU4v7m9N"
   },
   "outputs": [],
   "source": [
    "for i in range(n1):\n",
    "        data[i,2]=data[i,2]/abs(max(data[:,2]))\n",
    "        data[i,5]=data[i,5]/abs(max(data[:,5]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iXKrktUdCx-x"
   },
   "source": [
    "To double check if there are still NaN enties in that dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 33
    },
    "colab_type": "code",
    "id": "_qCY4-6r2O9f",
    "outputId": "07a7377e-acd4-4e9d-f391-afe59a2ca40d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 20,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.isnan(data).any()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "B9poF9qpCskW"
   },
   "source": [
    "To check which entries is/are NaN if there is any:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 33
    },
    "colab_type": "code",
    "id": "Nme_E6kh2vfI",
    "outputId": "9614f5ca-9970-4344-9357-0d41b5f745e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "nan=[]\n",
    "for i in range(n1):\n",
    "    for j in range(n2):\n",
    "        if np.isnan(data[i,j]):\n",
    "            nan.append([i,j])\n",
    "print(nan)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0or6pt2Zsb7C"
   },
   "source": [
    "# Split into training set and testing set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "r74QzXdwiMc9"
   },
   "outputs": [],
   "source": [
    "train=data[:m,:]\n",
    "test=data[m:-1,:]\n",
    "X = data[:,0:(n2-1)]\n",
    "y = data[:,(n2-1)]\n",
    "X_train = train[:,0:(n2-1)]\n",
    "y_train = train[:,(n2-1)]\n",
    "X_test = test[:,0:(n2-1)]\n",
    "y_test = test[:,(n2-1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "b89XZF52Gxi5"
   },
   "source": [
    "# Machine Learning Model Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sNd4Ujx7HEuy"
   },
   "source": [
    "We tried a variety of machine learning (ML) models to see which one suits our task the most. \n",
    "This models include:\n",
    "K nearest neighbors classifier,\n",
    "Support vector machine,\n",
    "Gaussian process classifier,\n",
    "Decision tree classifier,\n",
    "Random forest classifier,\n",
    "Multilayer perceptron classifier,\n",
    "Artificial neural network classifier,\n",
    "Logistic regression classifier,\n",
    "AdaBoost classifier,\n",
    "Naive Bayes classifier,\n",
    "Quadratic discriminant analysis classifier,\n",
    "XGBoost classifier,\n",
    "Gradient boost classifier,\n",
    "Ensemble learning classifier (by voting)\n",
    "Ensemble learning classifier (by stacking)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "X1MBCOewHKv7"
   },
   "source": [
    "The available data are splitted into training data and test data first with 8:2 ratio after encoding phase. Then all models are given the identical encoded training data and certain metric to compare which one is better at the given task after being optimized.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "orDMv2o3HWYd"
   },
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "\n",
    "names = [\"Nearest Neighbors\", \"Linear SVM\", \"RBF SVM\", \"Gaussian Process\",\n",
    "          \"Decision Tree\", \"Random Forest\", \"Neural Net\", \"AdaBoost\",\n",
    "          \"Naive Bayes\", \"QDA\",\"GradientBoosting\",\"LogisticRegression\"]\n",
    "\n",
    "\n",
    "\n",
    "classifiers = [\n",
    "    KNeighborsClassifier(n_neighbors=7,weights='distance'),\n",
    "    SVC(kernel=\"linear\", C=0.025),\n",
    "    SVC(gamma=2, C=1),\n",
    "    GaussianProcessClassifier(1.0 * RBF(1.0)),\n",
    "    DecisionTreeClassifier(max_depth=5),\n",
    "    RandomForestClassifier(max_depth=5, n_estimators=10, max_features=1),\n",
    "    MLPClassifier(alpha=1, max_iter=1000),\n",
    "    AdaBoostClassifier(),\n",
    "    GaussianNB(),\n",
    "    QuadraticDiscriminantAnalysis(),\n",
    "    GradientBoostingClassifier(n_estimators=100, learning_rate=1.0,max_depth=1, random_state=0),\n",
    "    LogisticRegression(C=0.123456789, solver=\"lbfgs\", max_iter=5000)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NnkqmbwtG6ZG"
   },
   "source": [
    "# Parameter Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "m9I1CW5YHSBs"
   },
   "source": [
    "The optimization is done by tuning the hyperparameters of the given ML model. The selection of the optimal set of hyperparameters is done through grid search. \n",
    "\n",
    "Grid search is a brute force method to find the optimal set of hyper parameters. Basically, for a given ML model, assume it has n number of adjustable hyperparameters, then we have a search space of n dimensions, in which any point corresponds to a specific set of hyperparameters. The hyperparameters can be either continuous or discrete. For example, for support vector machine (SVM), we can choose its kernel type and the strength of the regularization as dimension x and y, where x is discrete with values linear, poly, rbf, sigmoid, precomputed or callable and y a positive real number. If we discretize y then the search space is the 2-dimensional grid formed by all possible combinations of x and y. The idea of grid search is to execute all possible instances in the grids and to select the best set of hyperparameters. Just like the strength of the regularization for SVM, many hyperparameters are continuous and the interval is infinitely large, therefore practically there is no way to exhaust all possible combinations. A trick is used here to make such a formidable task possible. For continuous parameters, we try to find  the optimal order of magnitude first. Still use SVM as an example, we can try all the combination of all values of x with y set to 10^-3,10^-2,10^-1,10^0,10^1,10^2,10^3, when the best set amongst the combinations of these values are selected, say 101, then set y to from 1 to 100 and choose the best y. This approach can drastically reduce the amount of computations needed to be done without missing the optimal solution, assuming the performance of the ML model does not change abruptly with respect to the values of its hyperparameters within the same order of magnitude.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "t233dbIsriRn",
    "outputId": "2b7ce83d-1dbb-4f44-e94c-0c68213a576f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "tuned_parameters = [{'kernel': ['rbf'], 'gamma': [10, 1, 1e-1,1e-2, 1e-3],\n",
    "                     'C': [1, 10, 100, 1000, 10000]},\n",
    "                    {'kernel': ['linear'], 'C': [1, 10, 100, 1000, 10000]}]\n",
    "\n",
    "\n",
    "print()\n",
    "\n",
    "clf = GridSearchCV(\n",
    "    SVC(), tuned_parameters, scoring='accuracy',cv=10\n",
    ")\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best parameters set found on development set:\")\n",
    "print()\n",
    "print(clf.best_params_)\n",
    "print()\n",
    "print(\"Grid scores on development set:\")\n",
    "print()\n",
    "means = clf.cv_results_['mean_test_score']\n",
    "stds = clf.cv_results_['std_test_score']\n",
    "for mean, std, params in zip(means, stds, clf.cv_results_['params']):\n",
    "    print(\"%0.3f (+/-%0.03f) for %r\"\n",
    "          % (mean, std * 2, params))\n",
    "print()\n",
    "\n",
    "print(\"Detailed classification report:\")\n",
    "print()\n",
    "print(\"The model is trained on the full development set.\")\n",
    "print(\"The scores are computed on the full evaluation set.\")\n",
    "print()\n",
    "y_true, y_pred = y_test, clf.predict(X_test)\n",
    "print(classification_report(y_true, y_pred))\n",
    "print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0Rm_WZtJcflc"
   },
   "source": [
    "Based on the best parameters, we shorten the range:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "pQ5I9bVkrJvq",
    "outputId": "6a4e5ff8-2f82-46cf-bb56-09bedd0d9afe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best parameters set found on development set:\n",
      "\n",
      "{'C': 0.5, 'gamma': 0.004, 'kernel': 'rbf', 'probability': True}\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "0.615 (+/-0.034) for {'C': 0.4, 'gamma': 0.001, 'kernel': 'rbf', 'probability': True}\n",
      "0.615 (+/-0.034) for {'C': 0.4, 'gamma': 0.001, 'kernel': 'rbf', 'probability': False}\n",
      "0.701 (+/-0.071) for {'C': 0.4, 'gamma': 0.002, 'kernel': 'rbf', 'probability': True}\n",
      "0.701 (+/-0.071) for {'C': 0.4, 'gamma': 0.002, 'kernel': 'rbf', 'probability': False}\n",
      "0.768 (+/-0.098) for {'C': 0.4, 'gamma': 0.003, 'kernel': 'rbf', 'probability': True}\n",
      "0.768 (+/-0.098) for {'C': 0.4, 'gamma': 0.003, 'kernel': 'rbf', 'probability': False}\n",
      "0.775 (+/-0.090) for {'C': 0.4, 'gamma': 0.004, 'kernel': 'rbf', 'probability': True}\n",
      "0.775 (+/-0.090) for {'C': 0.4, 'gamma': 0.004, 'kernel': 'rbf', 'probability': False}\n",
      "0.674 (+/-0.032) for {'C': 0.5, 'gamma': 0.001, 'kernel': 'rbf', 'probability': True}\n",
      "0.674 (+/-0.032) for {'C': 0.5, 'gamma': 0.001, 'kernel': 'rbf', 'probability': False}\n",
      "0.756 (+/-0.136) for {'C': 0.5, 'gamma': 0.002, 'kernel': 'rbf', 'probability': True}\n",
      "0.756 (+/-0.136) for {'C': 0.5, 'gamma': 0.002, 'kernel': 'rbf', 'probability': False}\n",
      "0.775 (+/-0.089) for {'C': 0.5, 'gamma': 0.003, 'kernel': 'rbf', 'probability': True}\n",
      "0.775 (+/-0.089) for {'C': 0.5, 'gamma': 0.003, 'kernel': 'rbf', 'probability': False}\n",
      "0.781 (+/-0.090) for {'C': 0.5, 'gamma': 0.004, 'kernel': 'rbf', 'probability': True}\n",
      "0.781 (+/-0.090) for {'C': 0.5, 'gamma': 0.004, 'kernel': 'rbf', 'probability': False}\n",
      "0.695 (+/-0.069) for {'C': 0.6, 'gamma': 0.001, 'kernel': 'rbf', 'probability': True}\n",
      "0.695 (+/-0.069) for {'C': 0.6, 'gamma': 0.001, 'kernel': 'rbf', 'probability': False}\n",
      "0.767 (+/-0.096) for {'C': 0.6, 'gamma': 0.002, 'kernel': 'rbf', 'probability': True}\n",
      "0.767 (+/-0.096) for {'C': 0.6, 'gamma': 0.002, 'kernel': 'rbf', 'probability': False}\n",
      "0.781 (+/-0.090) for {'C': 0.6, 'gamma': 0.003, 'kernel': 'rbf', 'probability': True}\n",
      "0.781 (+/-0.090) for {'C': 0.6, 'gamma': 0.003, 'kernel': 'rbf', 'probability': False}\n",
      "0.781 (+/-0.090) for {'C': 0.6, 'gamma': 0.004, 'kernel': 'rbf', 'probability': True}\n",
      "0.781 (+/-0.090) for {'C': 0.6, 'gamma': 0.004, 'kernel': 'rbf', 'probability': False}\n",
      "0.684 (+/-0.079) for {'C': 0.7, 'gamma': 0.001, 'kernel': 'rbf', 'probability': True}\n",
      "0.684 (+/-0.079) for {'C': 0.7, 'gamma': 0.001, 'kernel': 'rbf', 'probability': False}\n",
      "0.775 (+/-0.091) for {'C': 0.7, 'gamma': 0.002, 'kernel': 'rbf', 'probability': True}\n",
      "0.775 (+/-0.091) for {'C': 0.7, 'gamma': 0.002, 'kernel': 'rbf', 'probability': False}\n",
      "0.781 (+/-0.090) for {'C': 0.7, 'gamma': 0.003, 'kernel': 'rbf', 'probability': True}\n",
      "0.781 (+/-0.090) for {'C': 0.7, 'gamma': 0.003, 'kernel': 'rbf', 'probability': False}\n",
      "0.781 (+/-0.090) for {'C': 0.7, 'gamma': 0.004, 'kernel': 'rbf', 'probability': True}\n",
      "0.781 (+/-0.090) for {'C': 0.7, 'gamma': 0.004, 'kernel': 'rbf', 'probability': False}\n",
      "0.704 (+/-0.079) for {'C': 0.8, 'gamma': 0.001, 'kernel': 'rbf', 'probability': True}\n",
      "0.704 (+/-0.079) for {'C': 0.8, 'gamma': 0.001, 'kernel': 'rbf', 'probability': False}\n",
      "0.781 (+/-0.090) for {'C': 0.8, 'gamma': 0.002, 'kernel': 'rbf', 'probability': True}\n",
      "0.781 (+/-0.090) for {'C': 0.8, 'gamma': 0.002, 'kernel': 'rbf', 'probability': False}\n",
      "0.781 (+/-0.090) for {'C': 0.8, 'gamma': 0.003, 'kernel': 'rbf', 'probability': True}\n",
      "0.781 (+/-0.090) for {'C': 0.8, 'gamma': 0.003, 'kernel': 'rbf', 'probability': False}\n",
      "0.781 (+/-0.090) for {'C': 0.8, 'gamma': 0.004, 'kernel': 'rbf', 'probability': True}\n",
      "0.781 (+/-0.090) for {'C': 0.8, 'gamma': 0.004, 'kernel': 'rbf', 'probability': False}\n",
      "0.714 (+/-0.094) for {'C': 0.9, 'gamma': 0.001, 'kernel': 'rbf', 'probability': True}\n",
      "0.714 (+/-0.094) for {'C': 0.9, 'gamma': 0.001, 'kernel': 'rbf', 'probability': False}\n",
      "0.781 (+/-0.090) for {'C': 0.9, 'gamma': 0.002, 'kernel': 'rbf', 'probability': True}\n",
      "0.781 (+/-0.090) for {'C': 0.9, 'gamma': 0.002, 'kernel': 'rbf', 'probability': False}\n",
      "0.781 (+/-0.090) for {'C': 0.9, 'gamma': 0.003, 'kernel': 'rbf', 'probability': True}\n",
      "0.781 (+/-0.090) for {'C': 0.9, 'gamma': 0.003, 'kernel': 'rbf', 'probability': False}\n",
      "0.781 (+/-0.090) for {'C': 0.9, 'gamma': 0.004, 'kernel': 'rbf', 'probability': True}\n",
      "0.781 (+/-0.090) for {'C': 0.9, 'gamma': 0.004, 'kernel': 'rbf', 'probability': False}\n",
      "0.753 (+/-0.115) for {'C': 1, 'gamma': 0.001, 'kernel': 'rbf', 'probability': True}\n",
      "0.753 (+/-0.115) for {'C': 1, 'gamma': 0.001, 'kernel': 'rbf', 'probability': False}\n",
      "0.781 (+/-0.090) for {'C': 1, 'gamma': 0.002, 'kernel': 'rbf', 'probability': True}\n",
      "0.781 (+/-0.090) for {'C': 1, 'gamma': 0.002, 'kernel': 'rbf', 'probability': False}\n",
      "0.781 (+/-0.090) for {'C': 1, 'gamma': 0.003, 'kernel': 'rbf', 'probability': True}\n",
      "0.781 (+/-0.090) for {'C': 1, 'gamma': 0.003, 'kernel': 'rbf', 'probability': False}\n",
      "0.781 (+/-0.090) for {'C': 1, 'gamma': 0.004, 'kernel': 'rbf', 'probability': True}\n",
      "0.781 (+/-0.090) for {'C': 1, 'gamma': 0.004, 'kernel': 'rbf', 'probability': False}\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.82      0.87      0.85       114\n",
      "         1.0       0.74      0.67      0.70        64\n",
      "\n",
      "    accuracy                           0.80       178\n",
      "   macro avg       0.78      0.77      0.78       178\n",
      "weighted avg       0.79      0.80      0.80       178\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score\n",
    "tuned_parameters = [{'kernel': ['rbf'], 'gamma': [0.001,0.002,0.003,0.004],\n",
    "                     'C': [0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1],'probability':[True,False]}]\n",
    "\n",
    "\n",
    "print()\n",
    "\n",
    "clf = GridSearchCV(\n",
    "    SVC(), tuned_parameters, scoring='accuracy',cv=10\n",
    ")\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best parameters set found on development set:\")\n",
    "print()\n",
    "print(clf.best_params_)\n",
    "print()\n",
    "print(\"Grid scores on development set:\")\n",
    "print()\n",
    "means = clf.cv_results_['mean_test_score']\n",
    "stds = clf.cv_results_['std_test_score']\n",
    "for mean, std, params in zip(means, stds, clf.cv_results_['params']):\n",
    "    print(\"%0.3f (+/-%0.03f) for %r\"\n",
    "          % (mean, std * 2, params))\n",
    "print()\n",
    "\n",
    "print(\"Detailed classification report:\")\n",
    "print()\n",
    "print(\"The model is trained on the full development set.\")\n",
    "print(\"The scores are computed on the full evaluation set.\")\n",
    "print()\n",
    "y_true, y_pred = y_test, clf.predict(X_test)\n",
    "print(classification_report(y_true, y_pred))\n",
    "print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "blzsJjcH8J3g"
   },
   "source": [
    "F1-score, which is a combined metric of both precision and recall, is also included. Since the Titanic dataset is unbalanced in terms of the survival rate, it is good to use f1-score as a measure to determine the reliability of the accuracy for this binary classification problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xdciB29yG9F6"
   },
   "source": [
    "# Model Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QF0XFLC7HaAh"
   },
   "source": [
    "In the grid search phase, the optimal set of hyperparameters are selected based on the accuracy on the pre-split test data result. The models are trained using the splited traning set earlier. Afterwards, the model with selected hyperparameters are evaluated with 10-fold cross-validation to provide a benchmark to compare to the real submission scores. For the sake of practicality and the interest of time limit, the grid search is not done exhuastively with respect to all adjustable hyperparameters the some of  the ranges for numerical values are more based on educated guess and intuition."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nKPs8jvGXtTr"
   },
   "source": [
    "## Import Test Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VWUjBvZsXw20"
   },
   "outputs": [],
   "source": [
    "url2 = 'https://raw.githubusercontent.com/zyzhang1130/CE9010/master/Titanic/test.csv'\n",
    "df2 = pd.read_csv(url2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 237
    },
    "colab_type": "code",
    "id": "Z1PvK7GLpCyt",
    "outputId": "0627f1ef-9178-4bae-b49b-f30d67130f83"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>892</td>\n",
       "      <td>3</td>\n",
       "      <td>Kelly, Mr. James</td>\n",
       "      <td>male</td>\n",
       "      <td>34.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>330911</td>\n",
       "      <td>7.8292</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>893</td>\n",
       "      <td>3</td>\n",
       "      <td>Wilkes, Mrs. James (Ellen Needs)</td>\n",
       "      <td>female</td>\n",
       "      <td>47.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>363272</td>\n",
       "      <td>7.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>894</td>\n",
       "      <td>2</td>\n",
       "      <td>Myles, Mr. Thomas Francis</td>\n",
       "      <td>male</td>\n",
       "      <td>62.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>240276</td>\n",
       "      <td>9.6875</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>895</td>\n",
       "      <td>3</td>\n",
       "      <td>Wirz, Mr. Albert</td>\n",
       "      <td>male</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>315154</td>\n",
       "      <td>8.6625</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>896</td>\n",
       "      <td>3</td>\n",
       "      <td>Hirvonen, Mrs. Alexander (Helga E Lindqvist)</td>\n",
       "      <td>female</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3101298</td>\n",
       "      <td>12.2875</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Pclass  ... Cabin Embarked\n",
       "0          892       3  ...   NaN        Q\n",
       "1          893       3  ...   NaN        S\n",
       "2          894       2  ...   NaN        Q\n",
       "3          895       3  ...   NaN        S\n",
       "4          896       3  ...   NaN        S\n",
       "\n",
       "[5 rows x 11 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BUX2hWHQhdBB"
   },
   "source": [
    "## Test Set Pre-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hS9DoqADhQBf"
   },
   "source": [
    "we preprocess the testset in exactally the same manner as training set: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 222
    },
    "colab_type": "code",
    "id": "iybum0d9hiQn",
    "outputId": "2a40ab92-51b0-4316-8daa-89c149e728e0"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>Cabin_A</th>\n",
       "      <th>Cabin_B</th>\n",
       "      <th>Cabin_C</th>\n",
       "      <th>Cabin_D</th>\n",
       "      <th>Cabin_E</th>\n",
       "      <th>Cabin_F</th>\n",
       "      <th>Cabin_G</th>\n",
       "      <th>Cabin_U</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>34.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.8292</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>62.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9.6875</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.6625</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>12.2875</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pclass  Sex   Age  SibSp  Parch  ...  Cabin_D  Cabin_E  Cabin_F  Cabin_G  Cabin_U\n",
       "0       3    1  34.5      0      0  ...        0        0        0        0        1\n",
       "1       3    0  47.0      1      0  ...        0        0        0        0        1\n",
       "2       2    1  62.0      0      0  ...        0        0        0        0        1\n",
       "3       3    1  27.0      0      0  ...        0        0        0        0        1\n",
       "4       3    0  22.0      1      1  ...        0        0        0        0        1\n",
       "\n",
       "[5 rows x 15 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Embarked_map = {'S':0, 'C': 1, 'Q': 2}\n",
    "sex_map = {'male': 1, 'female': 0}\n",
    "\n",
    "\n",
    "df2['Embarked'] = df2['Embarked'].map(Embarked_map)\n",
    "df2['Sex'] = df2['Sex'].map(sex_map)\n",
    "\n",
    "\n",
    "df2 = df2.drop(columns=\"PassengerId\")\n",
    "df2 = df2.drop(columns=\"Name\")\n",
    "df2 = df2.drop(columns=\"Ticket\")\n",
    "\n",
    "#data cleaning (replace this missing numerical feature entries with the median of that entry. Can try other methods)\n",
    "imputer = SimpleImputer(missing_values=np.nan, strategy='median')\n",
    "df2[['Age']] = imputer.fit_transform(df2[['Age']])\n",
    "df2[['Fare']] = imputer.fit_transform(df2[['Fare']])\n",
    "\n",
    "\n",
    "#data cleaning (replace NaN in categorical features with the same string can try other methods)\n",
    "df2['Embarked'] = df2['Embarked'].replace(np.nan, 3, regex=True)\n",
    "df2['Cabin'] = df2['Cabin'].replace(np.nan, 'U', regex=True)\n",
    "for i in range(df2.shape[0]):\n",
    "    df2.loc[i,'Cabin'] = df2.loc[i,'Cabin'][0]\n",
    "df2 = pd.concat([df2,pd.get_dummies(df2['Cabin'], prefix='Cabin')],axis=1)\n",
    "df2 = df2.drop(columns=\"Cabin\")\n",
    "\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "VfWNhvqAoLnW",
    "outputId": "788e22b0-2579-40cf-ed5f-02cca7ae5e27"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "data2=df2.to_numpy()\n",
    "n1 = data2.shape[0]\n",
    "n2 = data2.shape[1]\n",
    "print(np.isnan(data2).any())\n",
    "nan=[]\n",
    "for i in range(n1):\n",
    "    for j in range(n2):\n",
    "        if np.isnan(data2[i,j]):\n",
    "            nan.append([i,j])\n",
    "print(nan)\n",
    "\n",
    "for i in range(n2-1):\n",
    "    data2[:,i] = (data2[:,i] - data2[:,i].mean())/data2[:,i].std()  \n",
    "for i in range(n1):\n",
    "        data2[i,2]=data2[i,2]/abs(max(data2[:,2]))\n",
    "        data2[i,5]=data2[i,5]/abs(max(data2[:,5]))\n",
    "X_test2=data2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "faRkqkeo6lxC"
   },
   "source": [
    "## Support Vector Machine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NkYDXjQY6rIj"
   },
   "source": [
    "Support vector machine is already tuned as an example in the previous section"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hNQP5lDWTd0I"
   },
   "source": [
    "### Cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "wudR6ySwTW8j",
    "outputId": "584d3e3d-b6e2-44b2-d8e2-ad11890df451"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.784494\n"
     ]
    }
   ],
   "source": [
    "clf = SVC(C= 0.5, gamma= 0.004, kernel= 'rbf', probability= True)\n",
    "score=cross_validate(clf, X, y, cv=10, scoring=\"accuracy\")[\"test_score\"].mean()\n",
    "print(f\"{score:.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dxDJEfMzZb6U"
   },
   "source": [
    "### Generating Predicion Result for submission in .csv format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WnXdlR9eZTZB"
   },
   "outputs": [],
   "source": [
    "df2 = pd.read_csv(url2)\n",
    "clf = SVC(C= 0.5, gamma= 0.004, kernel= 'rbf', probability= True)\n",
    "clf.fit(X, y)\n",
    "pred=clf.predict(X_test2)\n",
    "pd.DataFrame({\"PassengerId\": df2[\"PassengerId\"], \"Survived\": pred}).to_csv(\"svm_submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QGj95d0_ekVV"
   },
   "source": [
    "![alt text](https://raw.githubusercontent.com/zyzhang1130/CE9010/master/Titanic/svm.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZmMz70SH4vW9"
   },
   "source": [
    "## Logistic Regression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "BXriifFZ4247",
    "outputId": "eccc1146-81ba-4cf6-dec9-7bc47bfeb5a0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n",
      "\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: l1_ratio must be between 0 and 1; got (l1_ratio=None)\n",
      "\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: penalty='none' is not supported for the liblinear solver\n",
      "\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n",
      "\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: l1_ratio must be between 0 and 1; got (l1_ratio=None)\n",
      "\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: penalty='none' is not supported for the liblinear solver\n",
      "\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n",
      "\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: l1_ratio must be between 0 and 1; got (l1_ratio=None)\n",
      "\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: penalty='none' is not supported for the liblinear solver\n",
      "\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n",
      "\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: l1_ratio must be between 0 and 1; got (l1_ratio=None)\n",
      "\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: penalty='none' is not supported for the liblinear solver\n",
      "\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n",
      "\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: l1_ratio must be between 0 and 1; got (l1_ratio=None)\n",
      "\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: penalty='none' is not supported for the liblinear solver\n",
      "\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n",
      "\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: l1_ratio must be between 0 and 1; got (l1_ratio=None)\n",
      "\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: penalty='none' is not supported for the liblinear solver\n",
      "\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n",
      "\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: l1_ratio must be between 0 and 1; got (l1_ratio=None)\n",
      "\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning:\n",
      "\n",
      "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: penalty='none' is not supported for the liblinear solver\n",
      "\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning:\n",
      "\n",
      "The max_iter was reached which means the coef_ did not converge\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:1505: UserWarning:\n",
      "\n",
      "Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set found on development set:\n",
      "\n",
      "{'C': 10, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': False}\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "0.773 (+/-0.074) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': True}\n",
      "0.773 (+/-0.074) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': False}\n",
      "0.773 (+/-0.074) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': True}\n",
      "0.773 (+/-0.074) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': False}\n",
      "0.773 (+/-0.074) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': True}\n",
      "0.773 (+/-0.074) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': False}\n",
      "0.773 (+/-0.074) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': True}\n",
      "0.773 (+/-0.074) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': False}\n",
      "0.774 (+/-0.071) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': True}\n",
      "0.774 (+/-0.071) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': False}\n",
      "0.785 (+/-0.084) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 1e-05, 'warm_start': True}\n",
      "0.785 (+/-0.084) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 1e-05, 'warm_start': False}\n",
      "0.785 (+/-0.084) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.0001, 'warm_start': True}\n",
      "0.785 (+/-0.084) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.0001, 'warm_start': False}\n",
      "0.785 (+/-0.084) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.001, 'warm_start': True}\n",
      "0.785 (+/-0.084) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.001, 'warm_start': False}\n",
      "0.785 (+/-0.084) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.01, 'warm_start': True}\n",
      "0.785 (+/-0.084) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.01, 'warm_start': False}\n",
      "0.785 (+/-0.084) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.1, 'warm_start': True}\n",
      "0.785 (+/-0.084) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.1, 'warm_start': False}\n",
      "0.785 (+/-0.084) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 1e-05, 'warm_start': True}\n",
      "0.785 (+/-0.084) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 1e-05, 'warm_start': False}\n",
      "0.785 (+/-0.084) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.0001, 'warm_start': True}\n",
      "0.785 (+/-0.084) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.0001, 'warm_start': False}\n",
      "0.785 (+/-0.084) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.001, 'warm_start': True}\n",
      "0.785 (+/-0.084) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.001, 'warm_start': False}\n",
      "0.785 (+/-0.084) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.01, 'warm_start': True}\n",
      "0.785 (+/-0.084) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.01, 'warm_start': False}\n",
      "0.785 (+/-0.084) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.1, 'warm_start': True}\n",
      "0.785 (+/-0.084) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.1, 'warm_start': False}\n",
      "0.785 (+/-0.084) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l2', 'solver': 'sag', 'tol': 1e-05, 'warm_start': True}\n",
      "0.785 (+/-0.084) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l2', 'solver': 'sag', 'tol': 1e-05, 'warm_start': False}\n",
      "0.785 (+/-0.084) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.0001, 'warm_start': True}\n",
      "0.785 (+/-0.084) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.0001, 'warm_start': False}\n",
      "0.785 (+/-0.084) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.001, 'warm_start': True}\n",
      "0.784 (+/-0.085) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.001, 'warm_start': False}\n",
      "0.788 (+/-0.090) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.01, 'warm_start': True}\n",
      "0.787 (+/-0.088) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.01, 'warm_start': False}\n",
      "0.796 (+/-0.091) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.1, 'warm_start': True}\n",
      "0.796 (+/-0.101) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.1, 'warm_start': False}\n",
      "0.785 (+/-0.084) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l2', 'solver': 'saga', 'tol': 1e-05, 'warm_start': True}\n",
      "0.785 (+/-0.084) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l2', 'solver': 'saga', 'tol': 1e-05, 'warm_start': False}\n",
      "0.785 (+/-0.084) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.0001, 'warm_start': True}\n",
      "0.785 (+/-0.084) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.0001, 'warm_start': False}\n",
      "0.785 (+/-0.084) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.001, 'warm_start': True}\n",
      "0.785 (+/-0.084) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.001, 'warm_start': False}\n",
      "0.785 (+/-0.088) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.01, 'warm_start': True}\n",
      "0.785 (+/-0.084) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.01, 'warm_start': False}\n",
      "0.775 (+/-0.084) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.1, 'warm_start': True}\n",
      "0.781 (+/-0.080) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.1, 'warm_start': False}\n",
      "0.773 (+/-0.074) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': True}\n",
      "0.773 (+/-0.074) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': False}\n",
      "0.773 (+/-0.074) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': True}\n",
      "0.773 (+/-0.074) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': False}\n",
      "0.773 (+/-0.074) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': True}\n",
      "0.773 (+/-0.074) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': False}\n",
      "0.773 (+/-0.074) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': True}\n",
      "0.773 (+/-0.074) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': False}\n",
      "0.774 (+/-0.071) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': True}\n",
      "0.774 (+/-0.071) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': False}\n",
      "0.785 (+/-0.084) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 1e-05, 'warm_start': True}\n",
      "0.785 (+/-0.084) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 1e-05, 'warm_start': False}\n",
      "0.785 (+/-0.084) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.0001, 'warm_start': True}\n",
      "0.785 (+/-0.084) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.0001, 'warm_start': False}\n",
      "0.785 (+/-0.084) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.001, 'warm_start': True}\n",
      "0.785 (+/-0.084) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.001, 'warm_start': False}\n",
      "0.785 (+/-0.084) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.01, 'warm_start': True}\n",
      "0.785 (+/-0.084) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.01, 'warm_start': False}\n",
      "0.785 (+/-0.084) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.1, 'warm_start': True}\n",
      "0.785 (+/-0.084) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.1, 'warm_start': False}\n",
      "0.785 (+/-0.084) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 1e-05, 'warm_start': True}\n",
      "0.785 (+/-0.084) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 1e-05, 'warm_start': False}\n",
      "0.785 (+/-0.084) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.0001, 'warm_start': True}\n",
      "0.785 (+/-0.084) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.0001, 'warm_start': False}\n",
      "0.785 (+/-0.084) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.001, 'warm_start': True}\n",
      "0.785 (+/-0.084) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.001, 'warm_start': False}\n",
      "0.785 (+/-0.084) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.01, 'warm_start': True}\n",
      "0.785 (+/-0.084) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.01, 'warm_start': False}\n",
      "0.785 (+/-0.084) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.1, 'warm_start': True}\n",
      "0.785 (+/-0.084) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.1, 'warm_start': False}\n",
      "0.785 (+/-0.084) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l2', 'solver': 'sag', 'tol': 1e-05, 'warm_start': True}\n",
      "0.785 (+/-0.084) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l2', 'solver': 'sag', 'tol': 1e-05, 'warm_start': False}\n",
      "0.785 (+/-0.084) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.0001, 'warm_start': True}\n",
      "0.785 (+/-0.084) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.0001, 'warm_start': False}\n",
      "0.785 (+/-0.084) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.001, 'warm_start': True}\n",
      "0.785 (+/-0.084) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.001, 'warm_start': False}\n",
      "0.787 (+/-0.086) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.01, 'warm_start': True}\n",
      "0.780 (+/-0.100) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.01, 'warm_start': False}\n",
      "0.795 (+/-0.088) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.1, 'warm_start': True}\n",
      "0.780 (+/-0.085) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.1, 'warm_start': False}\n",
      "0.785 (+/-0.084) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l2', 'solver': 'saga', 'tol': 1e-05, 'warm_start': True}\n",
      "0.785 (+/-0.084) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l2', 'solver': 'saga', 'tol': 1e-05, 'warm_start': False}\n",
      "0.785 (+/-0.084) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.0001, 'warm_start': True}\n",
      "0.785 (+/-0.084) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.0001, 'warm_start': False}\n",
      "0.785 (+/-0.089) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.001, 'warm_start': True}\n",
      "0.785 (+/-0.084) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.001, 'warm_start': False}\n",
      "0.785 (+/-0.084) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.01, 'warm_start': True}\n",
      "0.785 (+/-0.081) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.01, 'warm_start': False}\n",
      "0.778 (+/-0.076) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.1, 'warm_start': True}\n",
      "0.775 (+/-0.075) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.1, 'warm_start': False}\n",
      "0.773 (+/-0.074) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': True}\n",
      "0.773 (+/-0.074) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': False}\n",
      "0.773 (+/-0.074) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': True}\n",
      "0.773 (+/-0.074) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': False}\n",
      "0.773 (+/-0.074) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': True}\n",
      "0.773 (+/-0.074) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': False}\n",
      "0.773 (+/-0.074) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': True}\n",
      "0.773 (+/-0.074) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': False}\n",
      "0.774 (+/-0.071) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': True}\n",
      "0.774 (+/-0.071) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': False}\n",
      "0.785 (+/-0.084) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 1e-05, 'warm_start': True}\n",
      "0.785 (+/-0.084) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 1e-05, 'warm_start': False}\n",
      "0.785 (+/-0.084) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.0001, 'warm_start': True}\n",
      "0.785 (+/-0.084) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.0001, 'warm_start': False}\n",
      "0.785 (+/-0.084) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.001, 'warm_start': True}\n",
      "0.785 (+/-0.084) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.001, 'warm_start': False}\n",
      "0.785 (+/-0.084) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.01, 'warm_start': True}\n",
      "0.785 (+/-0.084) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.01, 'warm_start': False}\n",
      "0.785 (+/-0.084) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.1, 'warm_start': True}\n",
      "0.785 (+/-0.084) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.1, 'warm_start': False}\n",
      "0.785 (+/-0.084) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 1e-05, 'warm_start': True}\n",
      "0.785 (+/-0.084) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 1e-05, 'warm_start': False}\n",
      "0.785 (+/-0.084) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.0001, 'warm_start': True}\n",
      "0.785 (+/-0.084) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.0001, 'warm_start': False}\n",
      "0.785 (+/-0.084) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.001, 'warm_start': True}\n",
      "0.785 (+/-0.084) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.001, 'warm_start': False}\n",
      "0.785 (+/-0.084) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.01, 'warm_start': True}\n",
      "0.785 (+/-0.084) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.01, 'warm_start': False}\n",
      "0.785 (+/-0.084) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.1, 'warm_start': True}\n",
      "0.785 (+/-0.084) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.1, 'warm_start': False}\n",
      "0.785 (+/-0.084) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'sag', 'tol': 1e-05, 'warm_start': True}\n",
      "0.785 (+/-0.084) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'sag', 'tol': 1e-05, 'warm_start': False}\n",
      "0.785 (+/-0.084) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.0001, 'warm_start': True}\n",
      "0.785 (+/-0.084) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.0001, 'warm_start': False}\n",
      "0.785 (+/-0.084) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.001, 'warm_start': True}\n",
      "0.785 (+/-0.084) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.001, 'warm_start': False}\n",
      "0.781 (+/-0.087) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.01, 'warm_start': True}\n",
      "0.784 (+/-0.084) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.01, 'warm_start': False}\n",
      "0.791 (+/-0.102) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.1, 'warm_start': True}\n",
      "0.791 (+/-0.086) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.1, 'warm_start': False}\n",
      "0.785 (+/-0.084) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'saga', 'tol': 1e-05, 'warm_start': True}\n",
      "0.785 (+/-0.084) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'saga', 'tol': 1e-05, 'warm_start': False}\n",
      "0.785 (+/-0.084) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.0001, 'warm_start': True}\n",
      "0.785 (+/-0.084) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.0001, 'warm_start': False}\n",
      "0.785 (+/-0.084) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.001, 'warm_start': True}\n",
      "0.784 (+/-0.085) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.001, 'warm_start': False}\n",
      "0.785 (+/-0.080) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.01, 'warm_start': True}\n",
      "0.785 (+/-0.089) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.01, 'warm_start': False}\n",
      "0.777 (+/-0.074) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.1, 'warm_start': True}\n",
      "0.775 (+/-0.088) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.1, 'warm_start': False}\n",
      "0.773 (+/-0.074) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': True}\n",
      "0.773 (+/-0.074) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': False}\n",
      "0.773 (+/-0.074) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': True}\n",
      "0.773 (+/-0.074) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': False}\n",
      "0.773 (+/-0.074) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': True}\n",
      "0.773 (+/-0.074) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': False}\n",
      "0.773 (+/-0.074) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': True}\n",
      "0.773 (+/-0.074) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': False}\n",
      "0.774 (+/-0.071) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': True}\n",
      "0.774 (+/-0.071) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': False}\n",
      "0.785 (+/-0.084) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 1e-05, 'warm_start': True}\n",
      "0.785 (+/-0.084) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 1e-05, 'warm_start': False}\n",
      "0.785 (+/-0.084) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.0001, 'warm_start': True}\n",
      "0.785 (+/-0.084) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.0001, 'warm_start': False}\n",
      "0.785 (+/-0.084) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.001, 'warm_start': True}\n",
      "0.785 (+/-0.084) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.001, 'warm_start': False}\n",
      "0.785 (+/-0.084) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.01, 'warm_start': True}\n",
      "0.785 (+/-0.084) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.01, 'warm_start': False}\n",
      "0.785 (+/-0.084) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.1, 'warm_start': True}\n",
      "0.785 (+/-0.084) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.1, 'warm_start': False}\n",
      "0.785 (+/-0.084) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 1e-05, 'warm_start': True}\n",
      "0.785 (+/-0.084) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 1e-05, 'warm_start': False}\n",
      "0.785 (+/-0.084) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.0001, 'warm_start': True}\n",
      "0.785 (+/-0.084) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.0001, 'warm_start': False}\n",
      "0.785 (+/-0.084) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.001, 'warm_start': True}\n",
      "0.785 (+/-0.084) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.001, 'warm_start': False}\n",
      "0.785 (+/-0.084) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.01, 'warm_start': True}\n",
      "0.785 (+/-0.084) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.01, 'warm_start': False}\n",
      "0.785 (+/-0.084) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.1, 'warm_start': True}\n",
      "0.785 (+/-0.084) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.1, 'warm_start': False}\n",
      "0.785 (+/-0.084) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'sag', 'tol': 1e-05, 'warm_start': True}\n",
      "0.785 (+/-0.084) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'sag', 'tol': 1e-05, 'warm_start': False}\n",
      "0.785 (+/-0.084) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.0001, 'warm_start': True}\n",
      "0.785 (+/-0.084) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.0001, 'warm_start': False}\n",
      "0.787 (+/-0.088) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.001, 'warm_start': True}\n",
      "0.784 (+/-0.084) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.001, 'warm_start': False}\n",
      "0.784 (+/-0.084) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.01, 'warm_start': True}\n",
      "0.785 (+/-0.089) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.01, 'warm_start': False}\n",
      "0.785 (+/-0.094) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.1, 'warm_start': True}\n",
      "0.785 (+/-0.101) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.1, 'warm_start': False}\n",
      "0.785 (+/-0.084) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'saga', 'tol': 1e-05, 'warm_start': True}\n",
      "0.785 (+/-0.084) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'saga', 'tol': 1e-05, 'warm_start': False}\n",
      "0.785 (+/-0.084) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.0001, 'warm_start': True}\n",
      "0.785 (+/-0.084) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.0001, 'warm_start': False}\n",
      "0.785 (+/-0.084) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.001, 'warm_start': True}\n",
      "0.782 (+/-0.087) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.001, 'warm_start': False}\n",
      "0.785 (+/-0.084) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.01, 'warm_start': True}\n",
      "0.778 (+/-0.084) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.01, 'warm_start': False}\n",
      "0.771 (+/-0.080) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.1, 'warm_start': True}\n",
      "0.778 (+/-0.087) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.1, 'warm_start': False}\n",
      "0.773 (+/-0.074) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': True}\n",
      "0.773 (+/-0.074) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': False}\n",
      "0.773 (+/-0.074) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': True}\n",
      "0.773 (+/-0.074) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': False}\n",
      "0.773 (+/-0.074) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': True}\n",
      "0.773 (+/-0.074) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': False}\n",
      "0.773 (+/-0.074) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': True}\n",
      "0.773 (+/-0.074) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': False}\n",
      "0.774 (+/-0.071) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': True}\n",
      "0.774 (+/-0.071) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': False}\n",
      "0.785 (+/-0.084) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 1e-05, 'warm_start': True}\n",
      "0.785 (+/-0.084) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 1e-05, 'warm_start': False}\n",
      "0.785 (+/-0.084) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.0001, 'warm_start': True}\n",
      "0.785 (+/-0.084) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.0001, 'warm_start': False}\n",
      "0.785 (+/-0.084) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.001, 'warm_start': True}\n",
      "0.785 (+/-0.084) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.001, 'warm_start': False}\n",
      "0.785 (+/-0.084) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.01, 'warm_start': True}\n",
      "0.785 (+/-0.084) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.01, 'warm_start': False}\n",
      "0.785 (+/-0.084) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.1, 'warm_start': True}\n",
      "0.785 (+/-0.084) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.1, 'warm_start': False}\n",
      "0.785 (+/-0.084) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 1e-05, 'warm_start': True}\n",
      "0.785 (+/-0.084) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 1e-05, 'warm_start': False}\n",
      "0.785 (+/-0.084) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.0001, 'warm_start': True}\n",
      "0.785 (+/-0.084) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.0001, 'warm_start': False}\n",
      "0.785 (+/-0.084) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.001, 'warm_start': True}\n",
      "0.785 (+/-0.084) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.001, 'warm_start': False}\n",
      "0.785 (+/-0.084) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.01, 'warm_start': True}\n",
      "0.785 (+/-0.084) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.01, 'warm_start': False}\n",
      "0.785 (+/-0.084) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.1, 'warm_start': True}\n",
      "0.785 (+/-0.084) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.1, 'warm_start': False}\n",
      "0.785 (+/-0.084) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'sag', 'tol': 1e-05, 'warm_start': True}\n",
      "0.785 (+/-0.084) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'sag', 'tol': 1e-05, 'warm_start': False}\n",
      "0.785 (+/-0.084) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.0001, 'warm_start': True}\n",
      "0.785 (+/-0.084) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.0001, 'warm_start': False}\n",
      "0.787 (+/-0.088) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.001, 'warm_start': True}\n",
      "0.788 (+/-0.091) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.001, 'warm_start': False}\n",
      "0.784 (+/-0.086) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.01, 'warm_start': True}\n",
      "0.785 (+/-0.080) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.01, 'warm_start': False}\n",
      "0.788 (+/-0.096) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.1, 'warm_start': True}\n",
      "0.785 (+/-0.090) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.1, 'warm_start': False}\n",
      "0.785 (+/-0.084) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'saga', 'tol': 1e-05, 'warm_start': True}\n",
      "0.785 (+/-0.084) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'saga', 'tol': 1e-05, 'warm_start': False}\n",
      "0.785 (+/-0.084) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.0001, 'warm_start': True}\n",
      "0.785 (+/-0.084) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.0001, 'warm_start': False}\n",
      "0.787 (+/-0.088) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.001, 'warm_start': True}\n",
      "0.785 (+/-0.084) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.001, 'warm_start': False}\n",
      "0.785 (+/-0.083) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.01, 'warm_start': True}\n",
      "0.785 (+/-0.084) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.01, 'warm_start': False}\n",
      "0.778 (+/-0.102) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.1, 'warm_start': True}\n",
      "0.778 (+/-0.068) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.1, 'warm_start': False}\n",
      "0.763 (+/-0.084) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': True}\n",
      "0.763 (+/-0.084) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': False}\n",
      "0.763 (+/-0.084) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': True}\n",
      "0.763 (+/-0.084) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': False}\n",
      "0.763 (+/-0.084) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': True}\n",
      "0.763 (+/-0.084) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': False}\n",
      "0.763 (+/-0.084) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': True}\n",
      "0.763 (+/-0.084) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': False}\n",
      "0.764 (+/-0.088) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': True}\n",
      "0.764 (+/-0.088) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': False}\n",
      "0.763 (+/-0.084) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 1e-05, 'warm_start': True}\n",
      "0.763 (+/-0.084) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 1e-05, 'warm_start': False}\n",
      "0.763 (+/-0.084) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.0001, 'warm_start': True}\n",
      "0.763 (+/-0.084) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.0001, 'warm_start': False}\n",
      "0.763 (+/-0.084) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.001, 'warm_start': True}\n",
      "0.763 (+/-0.084) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.001, 'warm_start': False}\n",
      "0.763 (+/-0.084) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.01, 'warm_start': True}\n",
      "0.763 (+/-0.084) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.01, 'warm_start': False}\n",
      "0.763 (+/-0.084) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.1, 'warm_start': True}\n",
      "0.763 (+/-0.084) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.1, 'warm_start': False}\n",
      "0.763 (+/-0.084) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 1e-05, 'warm_start': True}\n",
      "0.763 (+/-0.084) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 1e-05, 'warm_start': False}\n",
      "0.763 (+/-0.084) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.0001, 'warm_start': True}\n",
      "0.763 (+/-0.084) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.0001, 'warm_start': False}\n",
      "0.763 (+/-0.084) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.001, 'warm_start': True}\n",
      "0.763 (+/-0.084) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.001, 'warm_start': False}\n",
      "0.763 (+/-0.084) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.01, 'warm_start': True}\n",
      "0.763 (+/-0.084) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.01, 'warm_start': False}\n",
      "0.763 (+/-0.084) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.1, 'warm_start': True}\n",
      "0.763 (+/-0.084) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.1, 'warm_start': False}\n",
      "0.763 (+/-0.084) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l2', 'solver': 'sag', 'tol': 1e-05, 'warm_start': True}\n",
      "0.763 (+/-0.084) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l2', 'solver': 'sag', 'tol': 1e-05, 'warm_start': False}\n",
      "0.763 (+/-0.084) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.0001, 'warm_start': True}\n",
      "0.763 (+/-0.084) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.0001, 'warm_start': False}\n",
      "0.763 (+/-0.084) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.001, 'warm_start': True}\n",
      "0.763 (+/-0.084) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.001, 'warm_start': False}\n",
      "0.764 (+/-0.088) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.01, 'warm_start': True}\n",
      "0.763 (+/-0.084) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.01, 'warm_start': False}\n",
      "0.765 (+/-0.082) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.1, 'warm_start': True}\n",
      "0.764 (+/-0.086) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.1, 'warm_start': False}\n",
      "0.763 (+/-0.084) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l2', 'solver': 'saga', 'tol': 1e-05, 'warm_start': True}\n",
      "0.763 (+/-0.084) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l2', 'solver': 'saga', 'tol': 1e-05, 'warm_start': False}\n",
      "0.763 (+/-0.084) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.0001, 'warm_start': True}\n",
      "0.763 (+/-0.084) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.0001, 'warm_start': False}\n",
      "0.763 (+/-0.084) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.001, 'warm_start': True}\n",
      "0.763 (+/-0.084) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.001, 'warm_start': False}\n",
      "0.763 (+/-0.084) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.01, 'warm_start': True}\n",
      "0.763 (+/-0.087) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.01, 'warm_start': False}\n",
      "0.763 (+/-0.075) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.1, 'warm_start': True}\n",
      "0.770 (+/-0.085) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.1, 'warm_start': False}\n",
      "0.763 (+/-0.084) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': True}\n",
      "0.763 (+/-0.084) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': False}\n",
      "0.763 (+/-0.084) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': True}\n",
      "0.763 (+/-0.084) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': False}\n",
      "0.763 (+/-0.084) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': True}\n",
      "0.763 (+/-0.084) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': False}\n",
      "0.763 (+/-0.084) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': True}\n",
      "0.763 (+/-0.084) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': False}\n",
      "0.764 (+/-0.088) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': True}\n",
      "0.764 (+/-0.088) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': False}\n",
      "0.763 (+/-0.084) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 1e-05, 'warm_start': True}\n",
      "0.763 (+/-0.084) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 1e-05, 'warm_start': False}\n",
      "0.763 (+/-0.084) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.0001, 'warm_start': True}\n",
      "0.763 (+/-0.084) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.0001, 'warm_start': False}\n",
      "0.763 (+/-0.084) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.001, 'warm_start': True}\n",
      "0.763 (+/-0.084) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.001, 'warm_start': False}\n",
      "0.763 (+/-0.084) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.01, 'warm_start': True}\n",
      "0.763 (+/-0.084) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.01, 'warm_start': False}\n",
      "0.763 (+/-0.084) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.1, 'warm_start': True}\n",
      "0.763 (+/-0.084) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.1, 'warm_start': False}\n",
      "0.763 (+/-0.084) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 1e-05, 'warm_start': True}\n",
      "0.763 (+/-0.084) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 1e-05, 'warm_start': False}\n",
      "0.763 (+/-0.084) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.0001, 'warm_start': True}\n",
      "0.763 (+/-0.084) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.0001, 'warm_start': False}\n",
      "0.763 (+/-0.084) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.001, 'warm_start': True}\n",
      "0.763 (+/-0.084) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.001, 'warm_start': False}\n",
      "0.763 (+/-0.084) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.01, 'warm_start': True}\n",
      "0.763 (+/-0.084) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.01, 'warm_start': False}\n",
      "0.763 (+/-0.084) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.1, 'warm_start': True}\n",
      "0.763 (+/-0.084) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.1, 'warm_start': False}\n",
      "0.763 (+/-0.084) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l2', 'solver': 'sag', 'tol': 1e-05, 'warm_start': True}\n",
      "0.763 (+/-0.084) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l2', 'solver': 'sag', 'tol': 1e-05, 'warm_start': False}\n",
      "0.763 (+/-0.084) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.0001, 'warm_start': True}\n",
      "0.763 (+/-0.084) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.0001, 'warm_start': False}\n",
      "0.763 (+/-0.084) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.001, 'warm_start': True}\n",
      "0.763 (+/-0.084) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.001, 'warm_start': False}\n",
      "0.764 (+/-0.088) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.01, 'warm_start': True}\n",
      "0.764 (+/-0.088) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.01, 'warm_start': False}\n",
      "0.761 (+/-0.082) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.1, 'warm_start': True}\n",
      "0.761 (+/-0.077) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.1, 'warm_start': False}\n",
      "0.763 (+/-0.084) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l2', 'solver': 'saga', 'tol': 1e-05, 'warm_start': True}\n",
      "0.763 (+/-0.084) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l2', 'solver': 'saga', 'tol': 1e-05, 'warm_start': False}\n",
      "0.763 (+/-0.084) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.0001, 'warm_start': True}\n",
      "0.763 (+/-0.084) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.0001, 'warm_start': False}\n",
      "0.763 (+/-0.084) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.001, 'warm_start': True}\n",
      "0.763 (+/-0.084) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.001, 'warm_start': False}\n",
      "0.764 (+/-0.088) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.01, 'warm_start': True}\n",
      "0.763 (+/-0.084) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.01, 'warm_start': False}\n",
      "0.763 (+/-0.083) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.1, 'warm_start': True}\n",
      "0.760 (+/-0.075) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.1, 'warm_start': False}\n",
      "0.763 (+/-0.084) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': True}\n",
      "0.763 (+/-0.084) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': False}\n",
      "0.763 (+/-0.084) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': True}\n",
      "0.763 (+/-0.084) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': False}\n",
      "0.763 (+/-0.084) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': True}\n",
      "0.763 (+/-0.084) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': False}\n",
      "0.763 (+/-0.084) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': True}\n",
      "0.763 (+/-0.084) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': False}\n",
      "0.764 (+/-0.088) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': True}\n",
      "0.764 (+/-0.088) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': False}\n",
      "0.763 (+/-0.084) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 1e-05, 'warm_start': True}\n",
      "0.763 (+/-0.084) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 1e-05, 'warm_start': False}\n",
      "0.763 (+/-0.084) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.0001, 'warm_start': True}\n",
      "0.763 (+/-0.084) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.0001, 'warm_start': False}\n",
      "0.763 (+/-0.084) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.001, 'warm_start': True}\n",
      "0.763 (+/-0.084) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.001, 'warm_start': False}\n",
      "0.763 (+/-0.084) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.01, 'warm_start': True}\n",
      "0.763 (+/-0.084) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.01, 'warm_start': False}\n",
      "0.763 (+/-0.084) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.1, 'warm_start': True}\n",
      "0.763 (+/-0.084) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.1, 'warm_start': False}\n",
      "0.763 (+/-0.084) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 1e-05, 'warm_start': True}\n",
      "0.763 (+/-0.084) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 1e-05, 'warm_start': False}\n",
      "0.763 (+/-0.084) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.0001, 'warm_start': True}\n",
      "0.763 (+/-0.084) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.0001, 'warm_start': False}\n",
      "0.763 (+/-0.084) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.001, 'warm_start': True}\n",
      "0.763 (+/-0.084) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.001, 'warm_start': False}\n",
      "0.763 (+/-0.084) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.01, 'warm_start': True}\n",
      "0.763 (+/-0.084) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.01, 'warm_start': False}\n",
      "0.763 (+/-0.084) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.1, 'warm_start': True}\n",
      "0.763 (+/-0.084) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.1, 'warm_start': False}\n",
      "0.763 (+/-0.084) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'sag', 'tol': 1e-05, 'warm_start': True}\n",
      "0.763 (+/-0.084) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'sag', 'tol': 1e-05, 'warm_start': False}\n",
      "0.763 (+/-0.084) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.0001, 'warm_start': True}\n",
      "0.763 (+/-0.084) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.0001, 'warm_start': False}\n",
      "0.763 (+/-0.084) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.001, 'warm_start': True}\n",
      "0.763 (+/-0.084) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.001, 'warm_start': False}\n",
      "0.763 (+/-0.084) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.01, 'warm_start': True}\n",
      "0.763 (+/-0.084) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.01, 'warm_start': False}\n",
      "0.761 (+/-0.081) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.1, 'warm_start': True}\n",
      "0.765 (+/-0.081) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.1, 'warm_start': False}\n",
      "0.763 (+/-0.084) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'saga', 'tol': 1e-05, 'warm_start': True}\n",
      "0.763 (+/-0.084) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'saga', 'tol': 1e-05, 'warm_start': False}\n",
      "0.763 (+/-0.084) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.0001, 'warm_start': True}\n",
      "0.763 (+/-0.084) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.0001, 'warm_start': False}\n",
      "0.763 (+/-0.084) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.001, 'warm_start': True}\n",
      "0.763 (+/-0.084) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.001, 'warm_start': False}\n",
      "0.763 (+/-0.084) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.01, 'warm_start': True}\n",
      "0.764 (+/-0.088) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.01, 'warm_start': False}\n",
      "0.761 (+/-0.065) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.1, 'warm_start': True}\n",
      "0.764 (+/-0.080) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.1, 'warm_start': False}\n",
      "0.763 (+/-0.084) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': True}\n",
      "0.763 (+/-0.084) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': False}\n",
      "0.763 (+/-0.084) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': True}\n",
      "0.763 (+/-0.084) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': False}\n",
      "0.763 (+/-0.084) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': True}\n",
      "0.763 (+/-0.084) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': False}\n",
      "0.763 (+/-0.084) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': True}\n",
      "0.763 (+/-0.084) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': False}\n",
      "0.764 (+/-0.088) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': True}\n",
      "0.764 (+/-0.088) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': False}\n",
      "0.763 (+/-0.084) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 1e-05, 'warm_start': True}\n",
      "0.763 (+/-0.084) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 1e-05, 'warm_start': False}\n",
      "0.763 (+/-0.084) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.0001, 'warm_start': True}\n",
      "0.763 (+/-0.084) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.0001, 'warm_start': False}\n",
      "0.763 (+/-0.084) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.001, 'warm_start': True}\n",
      "0.763 (+/-0.084) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.001, 'warm_start': False}\n",
      "0.763 (+/-0.084) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.01, 'warm_start': True}\n",
      "0.763 (+/-0.084) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.01, 'warm_start': False}\n",
      "0.763 (+/-0.084) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.1, 'warm_start': True}\n",
      "0.763 (+/-0.084) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.1, 'warm_start': False}\n",
      "0.763 (+/-0.084) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 1e-05, 'warm_start': True}\n",
      "0.763 (+/-0.084) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 1e-05, 'warm_start': False}\n",
      "0.763 (+/-0.084) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.0001, 'warm_start': True}\n",
      "0.763 (+/-0.084) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.0001, 'warm_start': False}\n",
      "0.763 (+/-0.084) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.001, 'warm_start': True}\n",
      "0.763 (+/-0.084) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.001, 'warm_start': False}\n",
      "0.763 (+/-0.084) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.01, 'warm_start': True}\n",
      "0.763 (+/-0.084) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.01, 'warm_start': False}\n",
      "0.763 (+/-0.084) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.1, 'warm_start': True}\n",
      "0.763 (+/-0.084) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.1, 'warm_start': False}\n",
      "0.763 (+/-0.084) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'sag', 'tol': 1e-05, 'warm_start': True}\n",
      "0.763 (+/-0.084) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'sag', 'tol': 1e-05, 'warm_start': False}\n",
      "0.763 (+/-0.084) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.0001, 'warm_start': True}\n",
      "0.763 (+/-0.084) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.0001, 'warm_start': False}\n",
      "0.763 (+/-0.084) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.001, 'warm_start': True}\n",
      "0.763 (+/-0.084) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.001, 'warm_start': False}\n",
      "0.763 (+/-0.084) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.01, 'warm_start': True}\n",
      "0.764 (+/-0.088) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.01, 'warm_start': False}\n",
      "0.764 (+/-0.083) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.1, 'warm_start': True}\n",
      "0.765 (+/-0.077) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.1, 'warm_start': False}\n",
      "0.763 (+/-0.084) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'saga', 'tol': 1e-05, 'warm_start': True}\n",
      "0.763 (+/-0.084) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'saga', 'tol': 1e-05, 'warm_start': False}\n",
      "0.763 (+/-0.084) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.0001, 'warm_start': True}\n",
      "0.763 (+/-0.084) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.0001, 'warm_start': False}\n",
      "0.763 (+/-0.084) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.001, 'warm_start': True}\n",
      "0.763 (+/-0.084) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.001, 'warm_start': False}\n",
      "0.763 (+/-0.087) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.01, 'warm_start': True}\n",
      "0.763 (+/-0.084) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.01, 'warm_start': False}\n",
      "0.760 (+/-0.068) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.1, 'warm_start': True}\n",
      "0.761 (+/-0.082) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.1, 'warm_start': False}\n",
      "0.763 (+/-0.084) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': True}\n",
      "0.763 (+/-0.084) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': False}\n",
      "0.763 (+/-0.084) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': True}\n",
      "0.763 (+/-0.084) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': False}\n",
      "0.763 (+/-0.084) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': True}\n",
      "0.763 (+/-0.084) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': False}\n",
      "0.763 (+/-0.084) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': True}\n",
      "0.763 (+/-0.084) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': False}\n",
      "0.764 (+/-0.088) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': True}\n",
      "0.764 (+/-0.088) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': False}\n",
      "0.763 (+/-0.084) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 1e-05, 'warm_start': True}\n",
      "0.763 (+/-0.084) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 1e-05, 'warm_start': False}\n",
      "0.763 (+/-0.084) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.0001, 'warm_start': True}\n",
      "0.763 (+/-0.084) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.0001, 'warm_start': False}\n",
      "0.763 (+/-0.084) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.001, 'warm_start': True}\n",
      "0.763 (+/-0.084) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.001, 'warm_start': False}\n",
      "0.763 (+/-0.084) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.01, 'warm_start': True}\n",
      "0.763 (+/-0.084) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.01, 'warm_start': False}\n",
      "0.763 (+/-0.084) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.1, 'warm_start': True}\n",
      "0.763 (+/-0.084) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.1, 'warm_start': False}\n",
      "0.763 (+/-0.084) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 1e-05, 'warm_start': True}\n",
      "0.763 (+/-0.084) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 1e-05, 'warm_start': False}\n",
      "0.763 (+/-0.084) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.0001, 'warm_start': True}\n",
      "0.763 (+/-0.084) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.0001, 'warm_start': False}\n",
      "0.763 (+/-0.084) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.001, 'warm_start': True}\n",
      "0.763 (+/-0.084) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.001, 'warm_start': False}\n",
      "0.763 (+/-0.084) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.01, 'warm_start': True}\n",
      "0.763 (+/-0.084) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.01, 'warm_start': False}\n",
      "0.763 (+/-0.084) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.1, 'warm_start': True}\n",
      "0.763 (+/-0.084) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.1, 'warm_start': False}\n",
      "0.763 (+/-0.084) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'sag', 'tol': 1e-05, 'warm_start': True}\n",
      "0.763 (+/-0.084) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'sag', 'tol': 1e-05, 'warm_start': False}\n",
      "0.763 (+/-0.084) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.0001, 'warm_start': True}\n",
      "0.763 (+/-0.084) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.0001, 'warm_start': False}\n",
      "0.763 (+/-0.084) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.001, 'warm_start': True}\n",
      "0.763 (+/-0.084) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.001, 'warm_start': False}\n",
      "0.764 (+/-0.088) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.01, 'warm_start': True}\n",
      "0.764 (+/-0.088) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.01, 'warm_start': False}\n",
      "0.771 (+/-0.080) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.1, 'warm_start': True}\n",
      "0.761 (+/-0.077) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.1, 'warm_start': False}\n",
      "0.763 (+/-0.084) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'saga', 'tol': 1e-05, 'warm_start': True}\n",
      "0.763 (+/-0.084) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'saga', 'tol': 1e-05, 'warm_start': False}\n",
      "0.763 (+/-0.084) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.0001, 'warm_start': True}\n",
      "0.763 (+/-0.084) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.0001, 'warm_start': False}\n",
      "0.763 (+/-0.084) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.001, 'warm_start': True}\n",
      "0.763 (+/-0.084) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.001, 'warm_start': False}\n",
      "0.764 (+/-0.088) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.01, 'warm_start': True}\n",
      "0.764 (+/-0.088) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.01, 'warm_start': False}\n",
      "0.763 (+/-0.077) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.1, 'warm_start': True}\n",
      "0.764 (+/-0.083) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.1, 'warm_start': False}\n",
      "0.780 (+/-0.081) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': True}\n",
      "0.780 (+/-0.081) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': False}\n",
      "0.780 (+/-0.081) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': True}\n",
      "0.780 (+/-0.081) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': False}\n",
      "0.780 (+/-0.081) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': True}\n",
      "0.780 (+/-0.081) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': False}\n",
      "0.780 (+/-0.081) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': True}\n",
      "0.780 (+/-0.081) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': False}\n",
      "0.780 (+/-0.079) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': True}\n",
      "0.780 (+/-0.079) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': False}\n",
      "0.791 (+/-0.070) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 1e-05, 'warm_start': True}\n",
      "0.791 (+/-0.070) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 1e-05, 'warm_start': False}\n",
      "0.791 (+/-0.070) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.0001, 'warm_start': True}\n",
      "0.791 (+/-0.070) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.0001, 'warm_start': False}\n",
      "0.791 (+/-0.070) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.001, 'warm_start': True}\n",
      "0.791 (+/-0.070) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.001, 'warm_start': False}\n",
      "0.791 (+/-0.070) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.01, 'warm_start': True}\n",
      "0.791 (+/-0.070) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.01, 'warm_start': False}\n",
      "0.791 (+/-0.070) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.1, 'warm_start': True}\n",
      "0.791 (+/-0.070) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.1, 'warm_start': False}\n",
      "0.791 (+/-0.070) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 1e-05, 'warm_start': True}\n",
      "0.791 (+/-0.070) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 1e-05, 'warm_start': False}\n",
      "0.791 (+/-0.070) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.0001, 'warm_start': True}\n",
      "0.791 (+/-0.070) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.0001, 'warm_start': False}\n",
      "0.791 (+/-0.070) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.001, 'warm_start': True}\n",
      "0.791 (+/-0.070) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.001, 'warm_start': False}\n",
      "0.791 (+/-0.070) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.01, 'warm_start': True}\n",
      "0.791 (+/-0.070) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.01, 'warm_start': False}\n",
      "0.791 (+/-0.070) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.1, 'warm_start': True}\n",
      "0.791 (+/-0.070) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.1, 'warm_start': False}\n",
      "0.791 (+/-0.070) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l2', 'solver': 'sag', 'tol': 1e-05, 'warm_start': True}\n",
      "0.791 (+/-0.070) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l2', 'solver': 'sag', 'tol': 1e-05, 'warm_start': False}\n",
      "0.791 (+/-0.070) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.0001, 'warm_start': True}\n",
      "0.791 (+/-0.070) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.0001, 'warm_start': False}\n",
      "0.791 (+/-0.070) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.001, 'warm_start': True}\n",
      "0.791 (+/-0.070) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.001, 'warm_start': False}\n",
      "0.789 (+/-0.068) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.01, 'warm_start': True}\n",
      "0.788 (+/-0.074) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.01, 'warm_start': False}\n",
      "0.780 (+/-0.074) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.1, 'warm_start': True}\n",
      "0.792 (+/-0.089) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.1, 'warm_start': False}\n",
      "0.791 (+/-0.070) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l2', 'solver': 'saga', 'tol': 1e-05, 'warm_start': True}\n",
      "0.791 (+/-0.070) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l2', 'solver': 'saga', 'tol': 1e-05, 'warm_start': False}\n",
      "0.791 (+/-0.070) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.0001, 'warm_start': True}\n",
      "0.791 (+/-0.070) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.0001, 'warm_start': False}\n",
      "0.791 (+/-0.070) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.001, 'warm_start': True}\n",
      "0.791 (+/-0.070) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.001, 'warm_start': False}\n",
      "0.782 (+/-0.077) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.01, 'warm_start': True}\n",
      "0.782 (+/-0.077) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.01, 'warm_start': False}\n",
      "0.771 (+/-0.082) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.1, 'warm_start': True}\n",
      "0.780 (+/-0.070) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.1, 'warm_start': False}\n",
      "0.780 (+/-0.081) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': True}\n",
      "0.780 (+/-0.081) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': False}\n",
      "0.780 (+/-0.081) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': True}\n",
      "0.780 (+/-0.081) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': False}\n",
      "0.780 (+/-0.081) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': True}\n",
      "0.780 (+/-0.081) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': False}\n",
      "0.780 (+/-0.081) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': True}\n",
      "0.780 (+/-0.081) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': False}\n",
      "0.780 (+/-0.079) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': True}\n",
      "0.780 (+/-0.079) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': False}\n",
      "0.791 (+/-0.070) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 1e-05, 'warm_start': True}\n",
      "0.791 (+/-0.070) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 1e-05, 'warm_start': False}\n",
      "0.791 (+/-0.070) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.0001, 'warm_start': True}\n",
      "0.791 (+/-0.070) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.0001, 'warm_start': False}\n",
      "0.791 (+/-0.070) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.001, 'warm_start': True}\n",
      "0.791 (+/-0.070) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.001, 'warm_start': False}\n",
      "0.791 (+/-0.070) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.01, 'warm_start': True}\n",
      "0.791 (+/-0.070) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.01, 'warm_start': False}\n",
      "0.791 (+/-0.070) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.1, 'warm_start': True}\n",
      "0.791 (+/-0.070) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.1, 'warm_start': False}\n",
      "0.791 (+/-0.070) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 1e-05, 'warm_start': True}\n",
      "0.791 (+/-0.070) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 1e-05, 'warm_start': False}\n",
      "0.791 (+/-0.070) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.0001, 'warm_start': True}\n",
      "0.791 (+/-0.070) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.0001, 'warm_start': False}\n",
      "0.791 (+/-0.070) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.001, 'warm_start': True}\n",
      "0.791 (+/-0.070) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.001, 'warm_start': False}\n",
      "0.791 (+/-0.070) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.01, 'warm_start': True}\n",
      "0.791 (+/-0.070) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.01, 'warm_start': False}\n",
      "0.791 (+/-0.070) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.1, 'warm_start': True}\n",
      "0.791 (+/-0.070) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.1, 'warm_start': False}\n",
      "0.791 (+/-0.070) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l2', 'solver': 'sag', 'tol': 1e-05, 'warm_start': True}\n",
      "0.791 (+/-0.070) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l2', 'solver': 'sag', 'tol': 1e-05, 'warm_start': False}\n",
      "0.791 (+/-0.070) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.0001, 'warm_start': True}\n",
      "0.791 (+/-0.070) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.0001, 'warm_start': False}\n",
      "0.791 (+/-0.070) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.001, 'warm_start': True}\n",
      "0.791 (+/-0.070) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.001, 'warm_start': False}\n",
      "0.789 (+/-0.073) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.01, 'warm_start': True}\n",
      "0.788 (+/-0.069) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.01, 'warm_start': False}\n",
      "0.780 (+/-0.077) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.1, 'warm_start': True}\n",
      "0.788 (+/-0.071) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.1, 'warm_start': False}\n",
      "0.791 (+/-0.070) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l2', 'solver': 'saga', 'tol': 1e-05, 'warm_start': True}\n",
      "0.791 (+/-0.070) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l2', 'solver': 'saga', 'tol': 1e-05, 'warm_start': False}\n",
      "0.791 (+/-0.070) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.0001, 'warm_start': True}\n",
      "0.791 (+/-0.070) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.0001, 'warm_start': False}\n",
      "0.791 (+/-0.070) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.001, 'warm_start': True}\n",
      "0.791 (+/-0.070) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.001, 'warm_start': False}\n",
      "0.782 (+/-0.077) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.01, 'warm_start': True}\n",
      "0.784 (+/-0.075) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.01, 'warm_start': False}\n",
      "0.774 (+/-0.080) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.1, 'warm_start': True}\n",
      "0.777 (+/-0.079) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.1, 'warm_start': False}\n",
      "0.780 (+/-0.081) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': True}\n",
      "0.780 (+/-0.081) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': False}\n",
      "0.780 (+/-0.081) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': True}\n",
      "0.780 (+/-0.081) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': False}\n",
      "0.780 (+/-0.081) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': True}\n",
      "0.780 (+/-0.081) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': False}\n",
      "0.780 (+/-0.081) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': True}\n",
      "0.780 (+/-0.081) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': False}\n",
      "0.780 (+/-0.079) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': True}\n",
      "0.780 (+/-0.079) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': False}\n",
      "0.791 (+/-0.070) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 1e-05, 'warm_start': True}\n",
      "0.791 (+/-0.070) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 1e-05, 'warm_start': False}\n",
      "0.791 (+/-0.070) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.0001, 'warm_start': True}\n",
      "0.791 (+/-0.070) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.0001, 'warm_start': False}\n",
      "0.791 (+/-0.070) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.001, 'warm_start': True}\n",
      "0.791 (+/-0.070) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.001, 'warm_start': False}\n",
      "0.791 (+/-0.070) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.01, 'warm_start': True}\n",
      "0.791 (+/-0.070) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.01, 'warm_start': False}\n",
      "0.791 (+/-0.070) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.1, 'warm_start': True}\n",
      "0.791 (+/-0.070) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.1, 'warm_start': False}\n",
      "0.791 (+/-0.070) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 1e-05, 'warm_start': True}\n",
      "0.791 (+/-0.070) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 1e-05, 'warm_start': False}\n",
      "0.791 (+/-0.070) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.0001, 'warm_start': True}\n",
      "0.791 (+/-0.070) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.0001, 'warm_start': False}\n",
      "0.791 (+/-0.070) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.001, 'warm_start': True}\n",
      "0.791 (+/-0.070) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.001, 'warm_start': False}\n",
      "0.791 (+/-0.070) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.01, 'warm_start': True}\n",
      "0.791 (+/-0.070) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.01, 'warm_start': False}\n",
      "0.791 (+/-0.070) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.1, 'warm_start': True}\n",
      "0.791 (+/-0.070) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.1, 'warm_start': False}\n",
      "0.791 (+/-0.070) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'sag', 'tol': 1e-05, 'warm_start': True}\n",
      "0.791 (+/-0.070) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'sag', 'tol': 1e-05, 'warm_start': False}\n",
      "0.791 (+/-0.070) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.0001, 'warm_start': True}\n",
      "0.791 (+/-0.070) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.0001, 'warm_start': False}\n",
      "0.791 (+/-0.070) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.001, 'warm_start': True}\n",
      "0.791 (+/-0.070) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.001, 'warm_start': False}\n",
      "0.791 (+/-0.070) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.01, 'warm_start': True}\n",
      "0.788 (+/-0.074) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.01, 'warm_start': False}\n",
      "0.789 (+/-0.083) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.1, 'warm_start': True}\n",
      "0.784 (+/-0.084) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.1, 'warm_start': False}\n",
      "0.791 (+/-0.070) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'saga', 'tol': 1e-05, 'warm_start': True}\n",
      "0.791 (+/-0.070) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'saga', 'tol': 1e-05, 'warm_start': False}\n",
      "0.791 (+/-0.070) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.0001, 'warm_start': True}\n",
      "0.791 (+/-0.070) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.0001, 'warm_start': False}\n",
      "0.791 (+/-0.070) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.001, 'warm_start': True}\n",
      "0.791 (+/-0.070) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.001, 'warm_start': False}\n",
      "0.785 (+/-0.076) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.01, 'warm_start': True}\n",
      "0.782 (+/-0.077) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.01, 'warm_start': False}\n",
      "0.771 (+/-0.083) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.1, 'warm_start': True}\n",
      "0.778 (+/-0.073) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.1, 'warm_start': False}\n",
      "0.780 (+/-0.081) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': True}\n",
      "0.780 (+/-0.081) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': False}\n",
      "0.780 (+/-0.081) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': True}\n",
      "0.780 (+/-0.081) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': False}\n",
      "0.780 (+/-0.081) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': True}\n",
      "0.780 (+/-0.081) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': False}\n",
      "0.780 (+/-0.081) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': True}\n",
      "0.780 (+/-0.081) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': False}\n",
      "0.780 (+/-0.079) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': True}\n",
      "0.780 (+/-0.079) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': False}\n",
      "0.791 (+/-0.070) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 1e-05, 'warm_start': True}\n",
      "0.791 (+/-0.070) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 1e-05, 'warm_start': False}\n",
      "0.791 (+/-0.070) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.0001, 'warm_start': True}\n",
      "0.791 (+/-0.070) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.0001, 'warm_start': False}\n",
      "0.791 (+/-0.070) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.001, 'warm_start': True}\n",
      "0.791 (+/-0.070) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.001, 'warm_start': False}\n",
      "0.791 (+/-0.070) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.01, 'warm_start': True}\n",
      "0.791 (+/-0.070) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.01, 'warm_start': False}\n",
      "0.791 (+/-0.070) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.1, 'warm_start': True}\n",
      "0.791 (+/-0.070) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.1, 'warm_start': False}\n",
      "0.791 (+/-0.070) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 1e-05, 'warm_start': True}\n",
      "0.791 (+/-0.070) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 1e-05, 'warm_start': False}\n",
      "0.791 (+/-0.070) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.0001, 'warm_start': True}\n",
      "0.791 (+/-0.070) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.0001, 'warm_start': False}\n",
      "0.791 (+/-0.070) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.001, 'warm_start': True}\n",
      "0.791 (+/-0.070) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.001, 'warm_start': False}\n",
      "0.791 (+/-0.070) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.01, 'warm_start': True}\n",
      "0.791 (+/-0.070) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.01, 'warm_start': False}\n",
      "0.791 (+/-0.070) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.1, 'warm_start': True}\n",
      "0.791 (+/-0.070) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.1, 'warm_start': False}\n",
      "0.791 (+/-0.070) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'sag', 'tol': 1e-05, 'warm_start': True}\n",
      "0.791 (+/-0.070) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'sag', 'tol': 1e-05, 'warm_start': False}\n",
      "0.791 (+/-0.070) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.0001, 'warm_start': True}\n",
      "0.791 (+/-0.070) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.0001, 'warm_start': False}\n",
      "0.791 (+/-0.070) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.001, 'warm_start': True}\n",
      "0.791 (+/-0.070) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.001, 'warm_start': False}\n",
      "0.788 (+/-0.074) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.01, 'warm_start': True}\n",
      "0.788 (+/-0.072) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.01, 'warm_start': False}\n",
      "0.781 (+/-0.074) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.1, 'warm_start': True}\n",
      "0.781 (+/-0.081) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.1, 'warm_start': False}\n",
      "0.791 (+/-0.070) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'saga', 'tol': 1e-05, 'warm_start': True}\n",
      "0.791 (+/-0.070) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'saga', 'tol': 1e-05, 'warm_start': False}\n",
      "0.791 (+/-0.070) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.0001, 'warm_start': True}\n",
      "0.791 (+/-0.070) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.0001, 'warm_start': False}\n",
      "0.791 (+/-0.070) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.001, 'warm_start': True}\n",
      "0.791 (+/-0.070) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.001, 'warm_start': False}\n",
      "0.782 (+/-0.077) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.01, 'warm_start': True}\n",
      "0.782 (+/-0.077) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.01, 'warm_start': False}\n",
      "0.775 (+/-0.068) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.1, 'warm_start': True}\n",
      "0.777 (+/-0.082) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.1, 'warm_start': False}\n",
      "0.780 (+/-0.081) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': True}\n",
      "0.780 (+/-0.081) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': False}\n",
      "0.780 (+/-0.081) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': True}\n",
      "0.780 (+/-0.081) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': False}\n",
      "0.780 (+/-0.081) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': True}\n",
      "0.780 (+/-0.081) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': False}\n",
      "0.780 (+/-0.081) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': True}\n",
      "0.780 (+/-0.081) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': False}\n",
      "0.780 (+/-0.079) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': True}\n",
      "0.780 (+/-0.079) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': False}\n",
      "0.791 (+/-0.070) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 1e-05, 'warm_start': True}\n",
      "0.791 (+/-0.070) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 1e-05, 'warm_start': False}\n",
      "0.791 (+/-0.070) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.0001, 'warm_start': True}\n",
      "0.791 (+/-0.070) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.0001, 'warm_start': False}\n",
      "0.791 (+/-0.070) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.001, 'warm_start': True}\n",
      "0.791 (+/-0.070) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.001, 'warm_start': False}\n",
      "0.791 (+/-0.070) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.01, 'warm_start': True}\n",
      "0.791 (+/-0.070) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.01, 'warm_start': False}\n",
      "0.791 (+/-0.070) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.1, 'warm_start': True}\n",
      "0.791 (+/-0.070) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.1, 'warm_start': False}\n",
      "0.791 (+/-0.070) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 1e-05, 'warm_start': True}\n",
      "0.791 (+/-0.070) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 1e-05, 'warm_start': False}\n",
      "0.791 (+/-0.070) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.0001, 'warm_start': True}\n",
      "0.791 (+/-0.070) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.0001, 'warm_start': False}\n",
      "0.791 (+/-0.070) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.001, 'warm_start': True}\n",
      "0.791 (+/-0.070) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.001, 'warm_start': False}\n",
      "0.791 (+/-0.070) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.01, 'warm_start': True}\n",
      "0.791 (+/-0.070) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.01, 'warm_start': False}\n",
      "0.791 (+/-0.070) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.1, 'warm_start': True}\n",
      "0.791 (+/-0.070) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.1, 'warm_start': False}\n",
      "0.791 (+/-0.070) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'sag', 'tol': 1e-05, 'warm_start': True}\n",
      "0.791 (+/-0.070) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'sag', 'tol': 1e-05, 'warm_start': False}\n",
      "0.791 (+/-0.070) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.0001, 'warm_start': True}\n",
      "0.791 (+/-0.070) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.0001, 'warm_start': False}\n",
      "0.791 (+/-0.070) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.001, 'warm_start': True}\n",
      "0.791 (+/-0.070) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.001, 'warm_start': False}\n",
      "0.792 (+/-0.069) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.01, 'warm_start': True}\n",
      "0.789 (+/-0.073) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.01, 'warm_start': False}\n",
      "0.791 (+/-0.063) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.1, 'warm_start': True}\n",
      "0.780 (+/-0.087) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.1, 'warm_start': False}\n",
      "0.791 (+/-0.070) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'saga', 'tol': 1e-05, 'warm_start': True}\n",
      "0.791 (+/-0.070) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'saga', 'tol': 1e-05, 'warm_start': False}\n",
      "0.791 (+/-0.070) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.0001, 'warm_start': True}\n",
      "0.791 (+/-0.070) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.0001, 'warm_start': False}\n",
      "0.791 (+/-0.070) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.001, 'warm_start': True}\n",
      "0.791 (+/-0.070) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.001, 'warm_start': False}\n",
      "0.782 (+/-0.077) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.01, 'warm_start': True}\n",
      "0.782 (+/-0.077) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.01, 'warm_start': False}\n",
      "0.781 (+/-0.077) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.1, 'warm_start': True}\n",
      "0.771 (+/-0.086) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.1, 'warm_start': False}\n",
      "0.767 (+/-0.067) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': True}\n",
      "0.767 (+/-0.067) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': False}\n",
      "0.767 (+/-0.067) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': True}\n",
      "0.767 (+/-0.067) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': False}\n",
      "0.767 (+/-0.067) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': True}\n",
      "0.767 (+/-0.067) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': False}\n",
      "0.767 (+/-0.067) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': True}\n",
      "0.767 (+/-0.067) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': False}\n",
      "0.766 (+/-0.068) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': True}\n",
      "0.766 (+/-0.068) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': False}\n",
      "0.767 (+/-0.067) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 1e-05, 'warm_start': True}\n",
      "0.767 (+/-0.067) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 1e-05, 'warm_start': False}\n",
      "0.767 (+/-0.067) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.0001, 'warm_start': True}\n",
      "0.767 (+/-0.067) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.0001, 'warm_start': False}\n",
      "0.767 (+/-0.067) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.001, 'warm_start': True}\n",
      "0.767 (+/-0.067) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.001, 'warm_start': False}\n",
      "0.767 (+/-0.067) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.01, 'warm_start': True}\n",
      "0.767 (+/-0.067) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.01, 'warm_start': False}\n",
      "0.767 (+/-0.067) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.1, 'warm_start': True}\n",
      "0.767 (+/-0.067) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.1, 'warm_start': False}\n",
      "0.767 (+/-0.067) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 1e-05, 'warm_start': True}\n",
      "0.767 (+/-0.067) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 1e-05, 'warm_start': False}\n",
      "0.767 (+/-0.067) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.0001, 'warm_start': True}\n",
      "0.767 (+/-0.067) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.0001, 'warm_start': False}\n",
      "0.767 (+/-0.067) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.001, 'warm_start': True}\n",
      "0.767 (+/-0.067) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.001, 'warm_start': False}\n",
      "0.767 (+/-0.067) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.01, 'warm_start': True}\n",
      "0.767 (+/-0.067) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.01, 'warm_start': False}\n",
      "0.767 (+/-0.067) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.1, 'warm_start': True}\n",
      "0.767 (+/-0.067) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.1, 'warm_start': False}\n",
      "0.767 (+/-0.067) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l2', 'solver': 'sag', 'tol': 1e-05, 'warm_start': True}\n",
      "0.767 (+/-0.067) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l2', 'solver': 'sag', 'tol': 1e-05, 'warm_start': False}\n",
      "0.767 (+/-0.067) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.0001, 'warm_start': True}\n",
      "0.767 (+/-0.067) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.0001, 'warm_start': False}\n",
      "0.767 (+/-0.067) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.001, 'warm_start': True}\n",
      "0.767 (+/-0.067) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.001, 'warm_start': False}\n",
      "0.767 (+/-0.067) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.01, 'warm_start': True}\n",
      "0.767 (+/-0.067) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.01, 'warm_start': False}\n",
      "0.766 (+/-0.058) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.1, 'warm_start': True}\n",
      "0.763 (+/-0.071) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.1, 'warm_start': False}\n",
      "0.767 (+/-0.067) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l2', 'solver': 'saga', 'tol': 1e-05, 'warm_start': True}\n",
      "0.767 (+/-0.067) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l2', 'solver': 'saga', 'tol': 1e-05, 'warm_start': False}\n",
      "0.767 (+/-0.067) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.0001, 'warm_start': True}\n",
      "0.767 (+/-0.067) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.0001, 'warm_start': False}\n",
      "0.767 (+/-0.067) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.001, 'warm_start': True}\n",
      "0.767 (+/-0.067) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.001, 'warm_start': False}\n",
      "0.767 (+/-0.067) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.01, 'warm_start': True}\n",
      "0.767 (+/-0.067) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.01, 'warm_start': False}\n",
      "0.768 (+/-0.053) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.1, 'warm_start': True}\n",
      "0.771 (+/-0.078) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.1, 'warm_start': False}\n",
      "0.767 (+/-0.067) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': True}\n",
      "0.767 (+/-0.067) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': False}\n",
      "0.767 (+/-0.067) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': True}\n",
      "0.767 (+/-0.067) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': False}\n",
      "0.767 (+/-0.067) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': True}\n",
      "0.767 (+/-0.067) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': False}\n",
      "0.767 (+/-0.067) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': True}\n",
      "0.767 (+/-0.067) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': False}\n",
      "0.766 (+/-0.068) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': True}\n",
      "0.766 (+/-0.068) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': False}\n",
      "0.767 (+/-0.067) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 1e-05, 'warm_start': True}\n",
      "0.767 (+/-0.067) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 1e-05, 'warm_start': False}\n",
      "0.767 (+/-0.067) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.0001, 'warm_start': True}\n",
      "0.767 (+/-0.067) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.0001, 'warm_start': False}\n",
      "0.767 (+/-0.067) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.001, 'warm_start': True}\n",
      "0.767 (+/-0.067) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.001, 'warm_start': False}\n",
      "0.767 (+/-0.067) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.01, 'warm_start': True}\n",
      "0.767 (+/-0.067) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.01, 'warm_start': False}\n",
      "0.767 (+/-0.067) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.1, 'warm_start': True}\n",
      "0.767 (+/-0.067) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.1, 'warm_start': False}\n",
      "0.767 (+/-0.067) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 1e-05, 'warm_start': True}\n",
      "0.767 (+/-0.067) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 1e-05, 'warm_start': False}\n",
      "0.767 (+/-0.067) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.0001, 'warm_start': True}\n",
      "0.767 (+/-0.067) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.0001, 'warm_start': False}\n",
      "0.767 (+/-0.067) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.001, 'warm_start': True}\n",
      "0.767 (+/-0.067) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.001, 'warm_start': False}\n",
      "0.767 (+/-0.067) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.01, 'warm_start': True}\n",
      "0.767 (+/-0.067) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.01, 'warm_start': False}\n",
      "0.767 (+/-0.067) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.1, 'warm_start': True}\n",
      "0.767 (+/-0.067) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.1, 'warm_start': False}\n",
      "0.767 (+/-0.067) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l2', 'solver': 'sag', 'tol': 1e-05, 'warm_start': True}\n",
      "0.767 (+/-0.067) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l2', 'solver': 'sag', 'tol': 1e-05, 'warm_start': False}\n",
      "0.767 (+/-0.067) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.0001, 'warm_start': True}\n",
      "0.767 (+/-0.067) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.0001, 'warm_start': False}\n",
      "0.767 (+/-0.067) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.001, 'warm_start': True}\n",
      "0.767 (+/-0.067) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.001, 'warm_start': False}\n",
      "0.767 (+/-0.067) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.01, 'warm_start': True}\n",
      "0.768 (+/-0.068) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.01, 'warm_start': False}\n",
      "0.763 (+/-0.059) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.1, 'warm_start': True}\n",
      "0.764 (+/-0.059) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.1, 'warm_start': False}\n",
      "0.767 (+/-0.067) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l2', 'solver': 'saga', 'tol': 1e-05, 'warm_start': True}\n",
      "0.767 (+/-0.067) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l2', 'solver': 'saga', 'tol': 1e-05, 'warm_start': False}\n",
      "0.767 (+/-0.067) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.0001, 'warm_start': True}\n",
      "0.767 (+/-0.067) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.0001, 'warm_start': False}\n",
      "0.767 (+/-0.067) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.001, 'warm_start': True}\n",
      "0.767 (+/-0.067) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.001, 'warm_start': False}\n",
      "0.767 (+/-0.067) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.01, 'warm_start': True}\n",
      "0.767 (+/-0.067) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.01, 'warm_start': False}\n",
      "0.770 (+/-0.065) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.1, 'warm_start': True}\n",
      "0.774 (+/-0.068) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.1, 'warm_start': False}\n",
      "0.767 (+/-0.067) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': True}\n",
      "0.767 (+/-0.067) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': False}\n",
      "0.767 (+/-0.067) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': True}\n",
      "0.767 (+/-0.067) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': False}\n",
      "0.767 (+/-0.067) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': True}\n",
      "0.767 (+/-0.067) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': False}\n",
      "0.767 (+/-0.067) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': True}\n",
      "0.767 (+/-0.067) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': False}\n",
      "0.766 (+/-0.068) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': True}\n",
      "0.766 (+/-0.068) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': False}\n",
      "0.767 (+/-0.067) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 1e-05, 'warm_start': True}\n",
      "0.767 (+/-0.067) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 1e-05, 'warm_start': False}\n",
      "0.767 (+/-0.067) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.0001, 'warm_start': True}\n",
      "0.767 (+/-0.067) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.0001, 'warm_start': False}\n",
      "0.767 (+/-0.067) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.001, 'warm_start': True}\n",
      "0.767 (+/-0.067) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.001, 'warm_start': False}\n",
      "0.767 (+/-0.067) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.01, 'warm_start': True}\n",
      "0.767 (+/-0.067) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.01, 'warm_start': False}\n",
      "0.767 (+/-0.067) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.1, 'warm_start': True}\n",
      "0.767 (+/-0.067) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.1, 'warm_start': False}\n",
      "0.767 (+/-0.067) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 1e-05, 'warm_start': True}\n",
      "0.767 (+/-0.067) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 1e-05, 'warm_start': False}\n",
      "0.767 (+/-0.067) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.0001, 'warm_start': True}\n",
      "0.767 (+/-0.067) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.0001, 'warm_start': False}\n",
      "0.767 (+/-0.067) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.001, 'warm_start': True}\n",
      "0.767 (+/-0.067) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.001, 'warm_start': False}\n",
      "0.767 (+/-0.067) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.01, 'warm_start': True}\n",
      "0.767 (+/-0.067) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.01, 'warm_start': False}\n",
      "0.767 (+/-0.067) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.1, 'warm_start': True}\n",
      "0.767 (+/-0.067) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.1, 'warm_start': False}\n",
      "0.767 (+/-0.067) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'sag', 'tol': 1e-05, 'warm_start': True}\n",
      "0.767 (+/-0.067) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'sag', 'tol': 1e-05, 'warm_start': False}\n",
      "0.767 (+/-0.067) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.0001, 'warm_start': True}\n",
      "0.767 (+/-0.067) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.0001, 'warm_start': False}\n",
      "0.767 (+/-0.067) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.001, 'warm_start': True}\n",
      "0.767 (+/-0.067) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.001, 'warm_start': False}\n",
      "0.768 (+/-0.068) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.01, 'warm_start': True}\n",
      "0.767 (+/-0.067) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.01, 'warm_start': False}\n",
      "0.766 (+/-0.068) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.1, 'warm_start': True}\n",
      "0.765 (+/-0.063) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.1, 'warm_start': False}\n",
      "0.767 (+/-0.067) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'saga', 'tol': 1e-05, 'warm_start': True}\n",
      "0.767 (+/-0.067) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'saga', 'tol': 1e-05, 'warm_start': False}\n",
      "0.767 (+/-0.067) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.0001, 'warm_start': True}\n",
      "0.767 (+/-0.067) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.0001, 'warm_start': False}\n",
      "0.767 (+/-0.067) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.001, 'warm_start': True}\n",
      "0.767 (+/-0.067) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.001, 'warm_start': False}\n",
      "0.767 (+/-0.067) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.01, 'warm_start': True}\n",
      "0.767 (+/-0.067) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.01, 'warm_start': False}\n",
      "0.771 (+/-0.061) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.1, 'warm_start': True}\n",
      "0.774 (+/-0.064) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.1, 'warm_start': False}\n",
      "0.767 (+/-0.067) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': True}\n",
      "0.767 (+/-0.067) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': False}\n",
      "0.767 (+/-0.067) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': True}\n",
      "0.767 (+/-0.067) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': False}\n",
      "0.767 (+/-0.067) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': True}\n",
      "0.767 (+/-0.067) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': False}\n",
      "0.767 (+/-0.067) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': True}\n",
      "0.767 (+/-0.067) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': False}\n",
      "0.766 (+/-0.068) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': True}\n",
      "0.766 (+/-0.068) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': False}\n",
      "0.767 (+/-0.067) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 1e-05, 'warm_start': True}\n",
      "0.767 (+/-0.067) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 1e-05, 'warm_start': False}\n",
      "0.767 (+/-0.067) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.0001, 'warm_start': True}\n",
      "0.767 (+/-0.067) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.0001, 'warm_start': False}\n",
      "0.767 (+/-0.067) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.001, 'warm_start': True}\n",
      "0.767 (+/-0.067) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.001, 'warm_start': False}\n",
      "0.767 (+/-0.067) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.01, 'warm_start': True}\n",
      "0.767 (+/-0.067) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.01, 'warm_start': False}\n",
      "0.767 (+/-0.067) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.1, 'warm_start': True}\n",
      "0.767 (+/-0.067) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.1, 'warm_start': False}\n",
      "0.767 (+/-0.067) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 1e-05, 'warm_start': True}\n",
      "0.767 (+/-0.067) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 1e-05, 'warm_start': False}\n",
      "0.767 (+/-0.067) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.0001, 'warm_start': True}\n",
      "0.767 (+/-0.067) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.0001, 'warm_start': False}\n",
      "0.767 (+/-0.067) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.001, 'warm_start': True}\n",
      "0.767 (+/-0.067) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.001, 'warm_start': False}\n",
      "0.767 (+/-0.067) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.01, 'warm_start': True}\n",
      "0.767 (+/-0.067) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.01, 'warm_start': False}\n",
      "0.767 (+/-0.067) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.1, 'warm_start': True}\n",
      "0.767 (+/-0.067) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.1, 'warm_start': False}\n",
      "0.767 (+/-0.067) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'sag', 'tol': 1e-05, 'warm_start': True}\n",
      "0.767 (+/-0.067) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'sag', 'tol': 1e-05, 'warm_start': False}\n",
      "0.767 (+/-0.067) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.0001, 'warm_start': True}\n",
      "0.767 (+/-0.067) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.0001, 'warm_start': False}\n",
      "0.767 (+/-0.067) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.001, 'warm_start': True}\n",
      "0.767 (+/-0.067) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.001, 'warm_start': False}\n",
      "0.765 (+/-0.065) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.01, 'warm_start': True}\n",
      "0.767 (+/-0.067) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.01, 'warm_start': False}\n",
      "0.765 (+/-0.062) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.1, 'warm_start': True}\n",
      "0.764 (+/-0.053) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.1, 'warm_start': False}\n",
      "0.767 (+/-0.067) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'saga', 'tol': 1e-05, 'warm_start': True}\n",
      "0.767 (+/-0.067) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'saga', 'tol': 1e-05, 'warm_start': False}\n",
      "0.767 (+/-0.067) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.0001, 'warm_start': True}\n",
      "0.767 (+/-0.067) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.0001, 'warm_start': False}\n",
      "0.767 (+/-0.067) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.001, 'warm_start': True}\n",
      "0.767 (+/-0.067) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.001, 'warm_start': False}\n",
      "0.767 (+/-0.067) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.01, 'warm_start': True}\n",
      "0.767 (+/-0.067) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.01, 'warm_start': False}\n",
      "0.768 (+/-0.070) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.1, 'warm_start': True}\n",
      "0.767 (+/-0.071) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.1, 'warm_start': False}\n",
      "0.767 (+/-0.067) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': True}\n",
      "0.767 (+/-0.067) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': False}\n",
      "0.767 (+/-0.067) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': True}\n",
      "0.767 (+/-0.067) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': False}\n",
      "0.767 (+/-0.067) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': True}\n",
      "0.767 (+/-0.067) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': False}\n",
      "0.767 (+/-0.067) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': True}\n",
      "0.767 (+/-0.067) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': False}\n",
      "0.766 (+/-0.068) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': True}\n",
      "0.766 (+/-0.068) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': False}\n",
      "0.767 (+/-0.067) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 1e-05, 'warm_start': True}\n",
      "0.767 (+/-0.067) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 1e-05, 'warm_start': False}\n",
      "0.767 (+/-0.067) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.0001, 'warm_start': True}\n",
      "0.767 (+/-0.067) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.0001, 'warm_start': False}\n",
      "0.767 (+/-0.067) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.001, 'warm_start': True}\n",
      "0.767 (+/-0.067) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.001, 'warm_start': False}\n",
      "0.767 (+/-0.067) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.01, 'warm_start': True}\n",
      "0.767 (+/-0.067) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.01, 'warm_start': False}\n",
      "0.767 (+/-0.067) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.1, 'warm_start': True}\n",
      "0.767 (+/-0.067) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.1, 'warm_start': False}\n",
      "0.767 (+/-0.067) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 1e-05, 'warm_start': True}\n",
      "0.767 (+/-0.067) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 1e-05, 'warm_start': False}\n",
      "0.767 (+/-0.067) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.0001, 'warm_start': True}\n",
      "0.767 (+/-0.067) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.0001, 'warm_start': False}\n",
      "0.767 (+/-0.067) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.001, 'warm_start': True}\n",
      "0.767 (+/-0.067) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.001, 'warm_start': False}\n",
      "0.767 (+/-0.067) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.01, 'warm_start': True}\n",
      "0.767 (+/-0.067) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.01, 'warm_start': False}\n",
      "0.767 (+/-0.067) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.1, 'warm_start': True}\n",
      "0.767 (+/-0.067) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.1, 'warm_start': False}\n",
      "0.767 (+/-0.067) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'sag', 'tol': 1e-05, 'warm_start': True}\n",
      "0.767 (+/-0.067) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'sag', 'tol': 1e-05, 'warm_start': False}\n",
      "0.767 (+/-0.067) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.0001, 'warm_start': True}\n",
      "0.767 (+/-0.067) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.0001, 'warm_start': False}\n",
      "0.767 (+/-0.067) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.001, 'warm_start': True}\n",
      "0.767 (+/-0.067) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.001, 'warm_start': False}\n",
      "0.768 (+/-0.068) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.01, 'warm_start': True}\n",
      "0.768 (+/-0.068) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.01, 'warm_start': False}\n",
      "0.763 (+/-0.075) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.1, 'warm_start': True}\n",
      "0.760 (+/-0.060) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.1, 'warm_start': False}\n",
      "0.767 (+/-0.067) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'saga', 'tol': 1e-05, 'warm_start': True}\n",
      "0.767 (+/-0.067) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'saga', 'tol': 1e-05, 'warm_start': False}\n",
      "0.767 (+/-0.067) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.0001, 'warm_start': True}\n",
      "0.767 (+/-0.067) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.0001, 'warm_start': False}\n",
      "0.767 (+/-0.067) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.001, 'warm_start': True}\n",
      "0.767 (+/-0.067) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.001, 'warm_start': False}\n",
      "0.767 (+/-0.067) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.01, 'warm_start': True}\n",
      "0.767 (+/-0.067) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.01, 'warm_start': False}\n",
      "0.765 (+/-0.065) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.1, 'warm_start': True}\n",
      "0.772 (+/-0.075) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.1, 'warm_start': False}\n",
      "0.794 (+/-0.077) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': True}\n",
      "0.794 (+/-0.077) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': False}\n",
      "0.794 (+/-0.077) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': True}\n",
      "0.794 (+/-0.077) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': False}\n",
      "0.794 (+/-0.077) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': True}\n",
      "0.794 (+/-0.077) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': False}\n",
      "0.795 (+/-0.076) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': True}\n",
      "0.795 (+/-0.076) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': False}\n",
      "0.792 (+/-0.076) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': True}\n",
      "0.792 (+/-0.076) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': False}\n",
      "0.794 (+/-0.077) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 1e-05, 'warm_start': True}\n",
      "0.794 (+/-0.077) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 1e-05, 'warm_start': False}\n",
      "0.794 (+/-0.077) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.0001, 'warm_start': True}\n",
      "0.794 (+/-0.077) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.0001, 'warm_start': False}\n",
      "0.794 (+/-0.077) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.001, 'warm_start': True}\n",
      "0.794 (+/-0.077) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.001, 'warm_start': False}\n",
      "0.794 (+/-0.077) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.01, 'warm_start': True}\n",
      "0.794 (+/-0.077) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.01, 'warm_start': False}\n",
      "0.792 (+/-0.070) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.1, 'warm_start': True}\n",
      "0.792 (+/-0.070) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.1, 'warm_start': False}\n",
      "0.794 (+/-0.077) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 1e-05, 'warm_start': True}\n",
      "0.794 (+/-0.077) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 1e-05, 'warm_start': False}\n",
      "0.794 (+/-0.077) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.0001, 'warm_start': True}\n",
      "0.794 (+/-0.077) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.0001, 'warm_start': False}\n",
      "0.794 (+/-0.077) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.001, 'warm_start': True}\n",
      "0.794 (+/-0.077) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.001, 'warm_start': False}\n",
      "0.794 (+/-0.077) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.01, 'warm_start': True}\n",
      "0.794 (+/-0.077) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.01, 'warm_start': False}\n",
      "0.794 (+/-0.077) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.1, 'warm_start': True}\n",
      "0.794 (+/-0.077) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.1, 'warm_start': False}\n",
      "0.794 (+/-0.077) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l2', 'solver': 'sag', 'tol': 1e-05, 'warm_start': True}\n",
      "0.794 (+/-0.077) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l2', 'solver': 'sag', 'tol': 1e-05, 'warm_start': False}\n",
      "0.794 (+/-0.077) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.0001, 'warm_start': True}\n",
      "0.794 (+/-0.077) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.0001, 'warm_start': False}\n",
      "0.792 (+/-0.070) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.001, 'warm_start': True}\n",
      "0.792 (+/-0.070) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.001, 'warm_start': False}\n",
      "0.795 (+/-0.070) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.01, 'warm_start': True}\n",
      "0.795 (+/-0.070) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.01, 'warm_start': False}\n",
      "0.787 (+/-0.083) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.1, 'warm_start': True}\n",
      "0.788 (+/-0.082) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.1, 'warm_start': False}\n",
      "0.792 (+/-0.070) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l2', 'solver': 'saga', 'tol': 1e-05, 'warm_start': True}\n",
      "0.792 (+/-0.070) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l2', 'solver': 'saga', 'tol': 1e-05, 'warm_start': False}\n",
      "0.792 (+/-0.070) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.0001, 'warm_start': True}\n",
      "0.792 (+/-0.070) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.0001, 'warm_start': False}\n",
      "0.794 (+/-0.069) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.001, 'warm_start': True}\n",
      "0.794 (+/-0.069) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.001, 'warm_start': False}\n",
      "0.795 (+/-0.067) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.01, 'warm_start': True}\n",
      "0.795 (+/-0.067) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.01, 'warm_start': False}\n",
      "0.774 (+/-0.076) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.1, 'warm_start': True}\n",
      "0.777 (+/-0.086) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.1, 'warm_start': False}\n",
      "0.794 (+/-0.077) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': True}\n",
      "0.794 (+/-0.077) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': False}\n",
      "0.794 (+/-0.077) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': True}\n",
      "0.794 (+/-0.077) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': False}\n",
      "0.794 (+/-0.077) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': True}\n",
      "0.794 (+/-0.077) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': False}\n",
      "0.795 (+/-0.076) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': True}\n",
      "0.795 (+/-0.076) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': False}\n",
      "0.792 (+/-0.076) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': True}\n",
      "0.792 (+/-0.076) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': False}\n",
      "0.794 (+/-0.077) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 1e-05, 'warm_start': True}\n",
      "0.794 (+/-0.077) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 1e-05, 'warm_start': False}\n",
      "0.794 (+/-0.077) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.0001, 'warm_start': True}\n",
      "0.794 (+/-0.077) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.0001, 'warm_start': False}\n",
      "0.794 (+/-0.077) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.001, 'warm_start': True}\n",
      "0.794 (+/-0.077) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.001, 'warm_start': False}\n",
      "0.794 (+/-0.077) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.01, 'warm_start': True}\n",
      "0.794 (+/-0.077) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.01, 'warm_start': False}\n",
      "0.792 (+/-0.070) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.1, 'warm_start': True}\n",
      "0.792 (+/-0.070) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.1, 'warm_start': False}\n",
      "0.794 (+/-0.077) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 1e-05, 'warm_start': True}\n",
      "0.794 (+/-0.077) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 1e-05, 'warm_start': False}\n",
      "0.794 (+/-0.077) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.0001, 'warm_start': True}\n",
      "0.794 (+/-0.077) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.0001, 'warm_start': False}\n",
      "0.794 (+/-0.077) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.001, 'warm_start': True}\n",
      "0.794 (+/-0.077) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.001, 'warm_start': False}\n",
      "0.794 (+/-0.077) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.01, 'warm_start': True}\n",
      "0.794 (+/-0.077) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.01, 'warm_start': False}\n",
      "0.794 (+/-0.077) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.1, 'warm_start': True}\n",
      "0.794 (+/-0.077) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.1, 'warm_start': False}\n",
      "0.794 (+/-0.077) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l2', 'solver': 'sag', 'tol': 1e-05, 'warm_start': True}\n",
      "0.794 (+/-0.077) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l2', 'solver': 'sag', 'tol': 1e-05, 'warm_start': False}\n",
      "0.794 (+/-0.077) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.0001, 'warm_start': True}\n",
      "0.794 (+/-0.077) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.0001, 'warm_start': False}\n",
      "0.792 (+/-0.070) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.001, 'warm_start': True}\n",
      "0.792 (+/-0.070) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.001, 'warm_start': False}\n",
      "0.795 (+/-0.070) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.01, 'warm_start': True}\n",
      "0.794 (+/-0.069) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.01, 'warm_start': False}\n",
      "0.784 (+/-0.080) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.1, 'warm_start': True}\n",
      "0.785 (+/-0.071) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.1, 'warm_start': False}\n",
      "0.794 (+/-0.077) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l2', 'solver': 'saga', 'tol': 1e-05, 'warm_start': True}\n",
      "0.794 (+/-0.077) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l2', 'solver': 'saga', 'tol': 1e-05, 'warm_start': False}\n",
      "0.794 (+/-0.077) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.0001, 'warm_start': True}\n",
      "0.794 (+/-0.077) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.0001, 'warm_start': False}\n",
      "0.794 (+/-0.069) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.001, 'warm_start': True}\n",
      "0.794 (+/-0.069) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.001, 'warm_start': False}\n",
      "0.795 (+/-0.067) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.01, 'warm_start': True}\n",
      "0.795 (+/-0.067) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.01, 'warm_start': False}\n",
      "0.775 (+/-0.075) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.1, 'warm_start': True}\n",
      "0.782 (+/-0.078) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.1, 'warm_start': False}\n",
      "0.794 (+/-0.077) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': True}\n",
      "0.794 (+/-0.077) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': False}\n",
      "0.794 (+/-0.077) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': True}\n",
      "0.794 (+/-0.077) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': False}\n",
      "0.794 (+/-0.077) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': True}\n",
      "0.794 (+/-0.077) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': False}\n",
      "0.795 (+/-0.076) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': True}\n",
      "0.795 (+/-0.076) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': False}\n",
      "0.792 (+/-0.076) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': True}\n",
      "0.792 (+/-0.076) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': False}\n",
      "0.794 (+/-0.077) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 1e-05, 'warm_start': True}\n",
      "0.794 (+/-0.077) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 1e-05, 'warm_start': False}\n",
      "0.794 (+/-0.077) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.0001, 'warm_start': True}\n",
      "0.794 (+/-0.077) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.0001, 'warm_start': False}\n",
      "0.794 (+/-0.077) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.001, 'warm_start': True}\n",
      "0.794 (+/-0.077) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.001, 'warm_start': False}\n",
      "0.794 (+/-0.077) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.01, 'warm_start': True}\n",
      "0.794 (+/-0.077) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.01, 'warm_start': False}\n",
      "0.792 (+/-0.070) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.1, 'warm_start': True}\n",
      "0.792 (+/-0.070) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.1, 'warm_start': False}\n",
      "0.794 (+/-0.077) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 1e-05, 'warm_start': True}\n",
      "0.794 (+/-0.077) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 1e-05, 'warm_start': False}\n",
      "0.794 (+/-0.077) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.0001, 'warm_start': True}\n",
      "0.794 (+/-0.077) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.0001, 'warm_start': False}\n",
      "0.794 (+/-0.077) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.001, 'warm_start': True}\n",
      "0.794 (+/-0.077) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.001, 'warm_start': False}\n",
      "0.794 (+/-0.077) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.01, 'warm_start': True}\n",
      "0.794 (+/-0.077) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.01, 'warm_start': False}\n",
      "0.794 (+/-0.077) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.1, 'warm_start': True}\n",
      "0.794 (+/-0.077) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.1, 'warm_start': False}\n",
      "0.794 (+/-0.077) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'sag', 'tol': 1e-05, 'warm_start': True}\n",
      "0.794 (+/-0.077) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'sag', 'tol': 1e-05, 'warm_start': False}\n",
      "0.794 (+/-0.077) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.0001, 'warm_start': True}\n",
      "0.794 (+/-0.077) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.0001, 'warm_start': False}\n",
      "0.792 (+/-0.070) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.001, 'warm_start': True}\n",
      "0.792 (+/-0.070) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.001, 'warm_start': False}\n",
      "0.795 (+/-0.070) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.01, 'warm_start': True}\n",
      "0.794 (+/-0.069) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.01, 'warm_start': False}\n",
      "0.787 (+/-0.076) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.1, 'warm_start': True}\n",
      "0.785 (+/-0.070) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.1, 'warm_start': False}\n",
      "0.794 (+/-0.077) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'saga', 'tol': 1e-05, 'warm_start': True}\n",
      "0.794 (+/-0.077) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'saga', 'tol': 1e-05, 'warm_start': False}\n",
      "0.794 (+/-0.077) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.0001, 'warm_start': True}\n",
      "0.794 (+/-0.077) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.0001, 'warm_start': False}\n",
      "0.794 (+/-0.069) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.001, 'warm_start': True}\n",
      "0.794 (+/-0.069) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.001, 'warm_start': False}\n",
      "0.795 (+/-0.067) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.01, 'warm_start': True}\n",
      "0.795 (+/-0.067) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.01, 'warm_start': False}\n",
      "0.775 (+/-0.082) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.1, 'warm_start': True}\n",
      "0.778 (+/-0.076) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.1, 'warm_start': False}\n",
      "0.794 (+/-0.077) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': True}\n",
      "0.794 (+/-0.077) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': False}\n",
      "0.794 (+/-0.077) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': True}\n",
      "0.794 (+/-0.077) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': False}\n",
      "0.794 (+/-0.077) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': True}\n",
      "0.794 (+/-0.077) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': False}\n",
      "0.795 (+/-0.076) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': True}\n",
      "0.795 (+/-0.076) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': False}\n",
      "0.792 (+/-0.076) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': True}\n",
      "0.792 (+/-0.076) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': False}\n",
      "0.794 (+/-0.077) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 1e-05, 'warm_start': True}\n",
      "0.794 (+/-0.077) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 1e-05, 'warm_start': False}\n",
      "0.794 (+/-0.077) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.0001, 'warm_start': True}\n",
      "0.794 (+/-0.077) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.0001, 'warm_start': False}\n",
      "0.794 (+/-0.077) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.001, 'warm_start': True}\n",
      "0.794 (+/-0.077) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.001, 'warm_start': False}\n",
      "0.794 (+/-0.077) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.01, 'warm_start': True}\n",
      "0.794 (+/-0.077) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.01, 'warm_start': False}\n",
      "0.792 (+/-0.070) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.1, 'warm_start': True}\n",
      "0.792 (+/-0.070) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.1, 'warm_start': False}\n",
      "0.794 (+/-0.077) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 1e-05, 'warm_start': True}\n",
      "0.794 (+/-0.077) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 1e-05, 'warm_start': False}\n",
      "0.794 (+/-0.077) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.0001, 'warm_start': True}\n",
      "0.794 (+/-0.077) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.0001, 'warm_start': False}\n",
      "0.794 (+/-0.077) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.001, 'warm_start': True}\n",
      "0.794 (+/-0.077) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.001, 'warm_start': False}\n",
      "0.794 (+/-0.077) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.01, 'warm_start': True}\n",
      "0.794 (+/-0.077) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.01, 'warm_start': False}\n",
      "0.794 (+/-0.077) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.1, 'warm_start': True}\n",
      "0.794 (+/-0.077) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.1, 'warm_start': False}\n",
      "0.794 (+/-0.077) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'sag', 'tol': 1e-05, 'warm_start': True}\n",
      "0.794 (+/-0.077) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'sag', 'tol': 1e-05, 'warm_start': False}\n",
      "0.794 (+/-0.077) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.0001, 'warm_start': True}\n",
      "0.794 (+/-0.077) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.0001, 'warm_start': False}\n",
      "0.792 (+/-0.070) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.001, 'warm_start': True}\n",
      "0.792 (+/-0.070) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.001, 'warm_start': False}\n",
      "0.795 (+/-0.070) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.01, 'warm_start': True}\n",
      "0.795 (+/-0.070) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.01, 'warm_start': False}\n",
      "0.789 (+/-0.083) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.1, 'warm_start': True}\n",
      "0.782 (+/-0.080) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.1, 'warm_start': False}\n",
      "0.794 (+/-0.077) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'saga', 'tol': 1e-05, 'warm_start': True}\n",
      "0.794 (+/-0.077) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'saga', 'tol': 1e-05, 'warm_start': False}\n",
      "0.794 (+/-0.077) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.0001, 'warm_start': True}\n",
      "0.794 (+/-0.077) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.0001, 'warm_start': False}\n",
      "0.794 (+/-0.069) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.001, 'warm_start': True}\n",
      "0.794 (+/-0.069) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.001, 'warm_start': False}\n",
      "0.795 (+/-0.067) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.01, 'warm_start': True}\n",
      "0.795 (+/-0.067) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.01, 'warm_start': False}\n",
      "0.781 (+/-0.075) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.1, 'warm_start': True}\n",
      "0.777 (+/-0.081) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.1, 'warm_start': False}\n",
      "0.794 (+/-0.077) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': True}\n",
      "0.794 (+/-0.077) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': False}\n",
      "0.794 (+/-0.077) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': True}\n",
      "0.794 (+/-0.077) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': False}\n",
      "0.794 (+/-0.077) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': True}\n",
      "0.794 (+/-0.077) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': False}\n",
      "0.795 (+/-0.076) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': True}\n",
      "0.795 (+/-0.076) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': False}\n",
      "0.792 (+/-0.076) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': True}\n",
      "0.792 (+/-0.076) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': False}\n",
      "0.794 (+/-0.077) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 1e-05, 'warm_start': True}\n",
      "0.794 (+/-0.077) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 1e-05, 'warm_start': False}\n",
      "0.794 (+/-0.077) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.0001, 'warm_start': True}\n",
      "0.794 (+/-0.077) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.0001, 'warm_start': False}\n",
      "0.794 (+/-0.077) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.001, 'warm_start': True}\n",
      "0.794 (+/-0.077) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.001, 'warm_start': False}\n",
      "0.794 (+/-0.077) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.01, 'warm_start': True}\n",
      "0.794 (+/-0.077) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.01, 'warm_start': False}\n",
      "0.792 (+/-0.070) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.1, 'warm_start': True}\n",
      "0.792 (+/-0.070) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.1, 'warm_start': False}\n",
      "0.794 (+/-0.077) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 1e-05, 'warm_start': True}\n",
      "0.794 (+/-0.077) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 1e-05, 'warm_start': False}\n",
      "0.794 (+/-0.077) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.0001, 'warm_start': True}\n",
      "0.794 (+/-0.077) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.0001, 'warm_start': False}\n",
      "0.794 (+/-0.077) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.001, 'warm_start': True}\n",
      "0.794 (+/-0.077) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.001, 'warm_start': False}\n",
      "0.794 (+/-0.077) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.01, 'warm_start': True}\n",
      "0.794 (+/-0.077) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.01, 'warm_start': False}\n",
      "0.794 (+/-0.077) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.1, 'warm_start': True}\n",
      "0.794 (+/-0.077) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.1, 'warm_start': False}\n",
      "0.794 (+/-0.077) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'sag', 'tol': 1e-05, 'warm_start': True}\n",
      "0.794 (+/-0.077) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'sag', 'tol': 1e-05, 'warm_start': False}\n",
      "0.794 (+/-0.077) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.0001, 'warm_start': True}\n",
      "0.794 (+/-0.077) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.0001, 'warm_start': False}\n",
      "0.792 (+/-0.070) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.001, 'warm_start': True}\n",
      "0.792 (+/-0.070) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.001, 'warm_start': False}\n",
      "0.795 (+/-0.070) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.01, 'warm_start': True}\n",
      "0.795 (+/-0.070) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.01, 'warm_start': False}\n",
      "0.788 (+/-0.079) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.1, 'warm_start': True}\n",
      "0.785 (+/-0.071) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.1, 'warm_start': False}\n",
      "0.794 (+/-0.077) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'saga', 'tol': 1e-05, 'warm_start': True}\n",
      "0.794 (+/-0.077) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'saga', 'tol': 1e-05, 'warm_start': False}\n",
      "0.794 (+/-0.077) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.0001, 'warm_start': True}\n",
      "0.794 (+/-0.077) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.0001, 'warm_start': False}\n",
      "0.794 (+/-0.069) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.001, 'warm_start': True}\n",
      "0.794 (+/-0.069) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.001, 'warm_start': False}\n",
      "0.795 (+/-0.067) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.01, 'warm_start': True}\n",
      "0.795 (+/-0.067) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.01, 'warm_start': False}\n",
      "0.774 (+/-0.076) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.1, 'warm_start': True}\n",
      "0.771 (+/-0.076) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.1, 'warm_start': False}\n",
      "0.761 (+/-0.064) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': True}\n",
      "0.761 (+/-0.064) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': False}\n",
      "0.761 (+/-0.064) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': True}\n",
      "0.761 (+/-0.064) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': False}\n",
      "0.761 (+/-0.064) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': True}\n",
      "0.761 (+/-0.064) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': False}\n",
      "0.763 (+/-0.065) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': True}\n",
      "0.763 (+/-0.065) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': False}\n",
      "0.758 (+/-0.068) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': True}\n",
      "0.758 (+/-0.068) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': False}\n",
      "0.761 (+/-0.064) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 1e-05, 'warm_start': True}\n",
      "0.761 (+/-0.064) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 1e-05, 'warm_start': False}\n",
      "0.761 (+/-0.064) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.0001, 'warm_start': True}\n",
      "0.761 (+/-0.064) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.0001, 'warm_start': False}\n",
      "0.761 (+/-0.064) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.001, 'warm_start': True}\n",
      "0.761 (+/-0.064) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.001, 'warm_start': False}\n",
      "0.761 (+/-0.064) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.01, 'warm_start': True}\n",
      "0.761 (+/-0.064) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.01, 'warm_start': False}\n",
      "0.763 (+/-0.069) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.1, 'warm_start': True}\n",
      "0.763 (+/-0.069) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.1, 'warm_start': False}\n",
      "0.761 (+/-0.064) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 1e-05, 'warm_start': True}\n",
      "0.761 (+/-0.064) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 1e-05, 'warm_start': False}\n",
      "0.761 (+/-0.064) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.0001, 'warm_start': True}\n",
      "0.761 (+/-0.064) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.0001, 'warm_start': False}\n",
      "0.761 (+/-0.064) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.001, 'warm_start': True}\n",
      "0.761 (+/-0.064) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.001, 'warm_start': False}\n",
      "0.761 (+/-0.064) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.01, 'warm_start': True}\n",
      "0.761 (+/-0.064) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.01, 'warm_start': False}\n",
      "0.761 (+/-0.064) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.1, 'warm_start': True}\n",
      "0.761 (+/-0.064) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.1, 'warm_start': False}\n",
      "0.761 (+/-0.064) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l2', 'solver': 'sag', 'tol': 1e-05, 'warm_start': True}\n",
      "0.761 (+/-0.064) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l2', 'solver': 'sag', 'tol': 1e-05, 'warm_start': False}\n",
      "0.761 (+/-0.064) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.0001, 'warm_start': True}\n",
      "0.761 (+/-0.064) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.0001, 'warm_start': False}\n",
      "0.761 (+/-0.064) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.001, 'warm_start': True}\n",
      "0.761 (+/-0.064) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.001, 'warm_start': False}\n",
      "0.763 (+/-0.069) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.01, 'warm_start': True}\n",
      "0.763 (+/-0.069) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.01, 'warm_start': False}\n",
      "0.763 (+/-0.066) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.1, 'warm_start': True}\n",
      "0.764 (+/-0.081) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.1, 'warm_start': False}\n",
      "0.761 (+/-0.064) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l2', 'solver': 'saga', 'tol': 1e-05, 'warm_start': True}\n",
      "0.761 (+/-0.064) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l2', 'solver': 'saga', 'tol': 1e-05, 'warm_start': False}\n",
      "0.761 (+/-0.064) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.0001, 'warm_start': True}\n",
      "0.761 (+/-0.064) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.0001, 'warm_start': False}\n",
      "0.761 (+/-0.064) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.001, 'warm_start': True}\n",
      "0.761 (+/-0.064) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.001, 'warm_start': False}\n",
      "0.760 (+/-0.071) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.01, 'warm_start': True}\n",
      "0.760 (+/-0.071) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.01, 'warm_start': False}\n",
      "0.768 (+/-0.056) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.1, 'warm_start': True}\n",
      "0.775 (+/-0.070) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.1, 'warm_start': False}\n",
      "0.761 (+/-0.064) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': True}\n",
      "0.761 (+/-0.064) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': False}\n",
      "0.761 (+/-0.064) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': True}\n",
      "0.761 (+/-0.064) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': False}\n",
      "0.761 (+/-0.064) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': True}\n",
      "0.761 (+/-0.064) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': False}\n",
      "0.763 (+/-0.065) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': True}\n",
      "0.763 (+/-0.065) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': False}\n",
      "0.758 (+/-0.068) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': True}\n",
      "0.758 (+/-0.068) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': False}\n",
      "0.761 (+/-0.064) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 1e-05, 'warm_start': True}\n",
      "0.761 (+/-0.064) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 1e-05, 'warm_start': False}\n",
      "0.761 (+/-0.064) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.0001, 'warm_start': True}\n",
      "0.761 (+/-0.064) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.0001, 'warm_start': False}\n",
      "0.761 (+/-0.064) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.001, 'warm_start': True}\n",
      "0.761 (+/-0.064) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.001, 'warm_start': False}\n",
      "0.761 (+/-0.064) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.01, 'warm_start': True}\n",
      "0.761 (+/-0.064) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.01, 'warm_start': False}\n",
      "0.763 (+/-0.069) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.1, 'warm_start': True}\n",
      "0.763 (+/-0.069) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.1, 'warm_start': False}\n",
      "0.761 (+/-0.064) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 1e-05, 'warm_start': True}\n",
      "0.761 (+/-0.064) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 1e-05, 'warm_start': False}\n",
      "0.761 (+/-0.064) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.0001, 'warm_start': True}\n",
      "0.761 (+/-0.064) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.0001, 'warm_start': False}\n",
      "0.761 (+/-0.064) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.001, 'warm_start': True}\n",
      "0.761 (+/-0.064) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.001, 'warm_start': False}\n",
      "0.761 (+/-0.064) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.01, 'warm_start': True}\n",
      "0.761 (+/-0.064) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.01, 'warm_start': False}\n",
      "0.761 (+/-0.064) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.1, 'warm_start': True}\n",
      "0.761 (+/-0.064) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.1, 'warm_start': False}\n",
      "0.761 (+/-0.064) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l2', 'solver': 'sag', 'tol': 1e-05, 'warm_start': True}\n",
      "0.761 (+/-0.064) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l2', 'solver': 'sag', 'tol': 1e-05, 'warm_start': False}\n",
      "0.761 (+/-0.064) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.0001, 'warm_start': True}\n",
      "0.761 (+/-0.064) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.0001, 'warm_start': False}\n",
      "0.761 (+/-0.064) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.001, 'warm_start': True}\n",
      "0.761 (+/-0.064) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.001, 'warm_start': False}\n",
      "0.763 (+/-0.069) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.01, 'warm_start': True}\n",
      "0.763 (+/-0.069) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.01, 'warm_start': False}\n",
      "0.767 (+/-0.065) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.1, 'warm_start': True}\n",
      "0.761 (+/-0.074) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.1, 'warm_start': False}\n",
      "0.761 (+/-0.064) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l2', 'solver': 'saga', 'tol': 1e-05, 'warm_start': True}\n",
      "0.761 (+/-0.064) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l2', 'solver': 'saga', 'tol': 1e-05, 'warm_start': False}\n",
      "0.761 (+/-0.064) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.0001, 'warm_start': True}\n",
      "0.761 (+/-0.064) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.0001, 'warm_start': False}\n",
      "0.761 (+/-0.064) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.001, 'warm_start': True}\n",
      "0.761 (+/-0.064) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.001, 'warm_start': False}\n",
      "0.761 (+/-0.071) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.01, 'warm_start': True}\n",
      "0.760 (+/-0.071) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.01, 'warm_start': False}\n",
      "0.771 (+/-0.079) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.1, 'warm_start': True}\n",
      "0.775 (+/-0.075) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.1, 'warm_start': False}\n",
      "0.761 (+/-0.064) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': True}\n",
      "0.761 (+/-0.064) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': False}\n",
      "0.761 (+/-0.064) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': True}\n",
      "0.761 (+/-0.064) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': False}\n",
      "0.761 (+/-0.064) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': True}\n",
      "0.761 (+/-0.064) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': False}\n",
      "0.763 (+/-0.065) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': True}\n",
      "0.763 (+/-0.065) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': False}\n",
      "0.758 (+/-0.068) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': True}\n",
      "0.758 (+/-0.068) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': False}\n",
      "0.761 (+/-0.064) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 1e-05, 'warm_start': True}\n",
      "0.761 (+/-0.064) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 1e-05, 'warm_start': False}\n",
      "0.761 (+/-0.064) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.0001, 'warm_start': True}\n",
      "0.761 (+/-0.064) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.0001, 'warm_start': False}\n",
      "0.761 (+/-0.064) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.001, 'warm_start': True}\n",
      "0.761 (+/-0.064) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.001, 'warm_start': False}\n",
      "0.761 (+/-0.064) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.01, 'warm_start': True}\n",
      "0.761 (+/-0.064) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.01, 'warm_start': False}\n",
      "0.763 (+/-0.069) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.1, 'warm_start': True}\n",
      "0.763 (+/-0.069) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.1, 'warm_start': False}\n",
      "0.761 (+/-0.064) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 1e-05, 'warm_start': True}\n",
      "0.761 (+/-0.064) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 1e-05, 'warm_start': False}\n",
      "0.761 (+/-0.064) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.0001, 'warm_start': True}\n",
      "0.761 (+/-0.064) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.0001, 'warm_start': False}\n",
      "0.761 (+/-0.064) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.001, 'warm_start': True}\n",
      "0.761 (+/-0.064) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.001, 'warm_start': False}\n",
      "0.761 (+/-0.064) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.01, 'warm_start': True}\n",
      "0.761 (+/-0.064) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.01, 'warm_start': False}\n",
      "0.761 (+/-0.064) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.1, 'warm_start': True}\n",
      "0.761 (+/-0.064) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.1, 'warm_start': False}\n",
      "0.761 (+/-0.064) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'sag', 'tol': 1e-05, 'warm_start': True}\n",
      "0.761 (+/-0.064) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'sag', 'tol': 1e-05, 'warm_start': False}\n",
      "0.761 (+/-0.064) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.0001, 'warm_start': True}\n",
      "0.761 (+/-0.064) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.0001, 'warm_start': False}\n",
      "0.761 (+/-0.064) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.001, 'warm_start': True}\n",
      "0.761 (+/-0.064) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.001, 'warm_start': False}\n",
      "0.763 (+/-0.069) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.01, 'warm_start': True}\n",
      "0.763 (+/-0.069) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.01, 'warm_start': False}\n",
      "0.761 (+/-0.079) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.1, 'warm_start': True}\n",
      "0.765 (+/-0.062) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.1, 'warm_start': False}\n",
      "0.761 (+/-0.064) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'saga', 'tol': 1e-05, 'warm_start': True}\n",
      "0.761 (+/-0.064) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'saga', 'tol': 1e-05, 'warm_start': False}\n",
      "0.761 (+/-0.064) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.0001, 'warm_start': True}\n",
      "0.761 (+/-0.064) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.0001, 'warm_start': False}\n",
      "0.761 (+/-0.064) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.001, 'warm_start': True}\n",
      "0.761 (+/-0.064) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.001, 'warm_start': False}\n",
      "0.761 (+/-0.071) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.01, 'warm_start': True}\n",
      "0.760 (+/-0.071) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.01, 'warm_start': False}\n",
      "0.771 (+/-0.059) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.1, 'warm_start': True}\n",
      "0.763 (+/-0.056) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.1, 'warm_start': False}\n",
      "0.761 (+/-0.064) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': True}\n",
      "0.761 (+/-0.064) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': False}\n",
      "0.761 (+/-0.064) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': True}\n",
      "0.761 (+/-0.064) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': False}\n",
      "0.761 (+/-0.064) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': True}\n",
      "0.761 (+/-0.064) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': False}\n",
      "0.763 (+/-0.065) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': True}\n",
      "0.763 (+/-0.065) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': False}\n",
      "0.758 (+/-0.068) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': True}\n",
      "0.758 (+/-0.068) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': False}\n",
      "0.761 (+/-0.064) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 1e-05, 'warm_start': True}\n",
      "0.761 (+/-0.064) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 1e-05, 'warm_start': False}\n",
      "0.761 (+/-0.064) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.0001, 'warm_start': True}\n",
      "0.761 (+/-0.064) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.0001, 'warm_start': False}\n",
      "0.761 (+/-0.064) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.001, 'warm_start': True}\n",
      "0.761 (+/-0.064) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.001, 'warm_start': False}\n",
      "0.761 (+/-0.064) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.01, 'warm_start': True}\n",
      "0.761 (+/-0.064) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.01, 'warm_start': False}\n",
      "0.763 (+/-0.069) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.1, 'warm_start': True}\n",
      "0.763 (+/-0.069) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.1, 'warm_start': False}\n",
      "0.761 (+/-0.064) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 1e-05, 'warm_start': True}\n",
      "0.761 (+/-0.064) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 1e-05, 'warm_start': False}\n",
      "0.761 (+/-0.064) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.0001, 'warm_start': True}\n",
      "0.761 (+/-0.064) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.0001, 'warm_start': False}\n",
      "0.761 (+/-0.064) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.001, 'warm_start': True}\n",
      "0.761 (+/-0.064) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.001, 'warm_start': False}\n",
      "0.761 (+/-0.064) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.01, 'warm_start': True}\n",
      "0.761 (+/-0.064) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.01, 'warm_start': False}\n",
      "0.761 (+/-0.064) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.1, 'warm_start': True}\n",
      "0.761 (+/-0.064) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.1, 'warm_start': False}\n",
      "0.761 (+/-0.064) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'sag', 'tol': 1e-05, 'warm_start': True}\n",
      "0.761 (+/-0.064) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'sag', 'tol': 1e-05, 'warm_start': False}\n",
      "0.761 (+/-0.064) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.0001, 'warm_start': True}\n",
      "0.761 (+/-0.064) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.0001, 'warm_start': False}\n",
      "0.761 (+/-0.064) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.001, 'warm_start': True}\n",
      "0.761 (+/-0.064) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.001, 'warm_start': False}\n",
      "0.763 (+/-0.069) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.01, 'warm_start': True}\n",
      "0.763 (+/-0.069) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.01, 'warm_start': False}\n",
      "0.757 (+/-0.074) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.1, 'warm_start': True}\n",
      "0.766 (+/-0.069) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.1, 'warm_start': False}\n",
      "0.761 (+/-0.064) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'saga', 'tol': 1e-05, 'warm_start': True}\n",
      "0.761 (+/-0.064) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'saga', 'tol': 1e-05, 'warm_start': False}\n",
      "0.761 (+/-0.064) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.0001, 'warm_start': True}\n",
      "0.761 (+/-0.064) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.0001, 'warm_start': False}\n",
      "0.761 (+/-0.064) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.001, 'warm_start': True}\n",
      "0.761 (+/-0.064) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.001, 'warm_start': False}\n",
      "0.760 (+/-0.071) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.01, 'warm_start': True}\n",
      "0.760 (+/-0.071) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.01, 'warm_start': False}\n",
      "0.773 (+/-0.062) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.1, 'warm_start': True}\n",
      "0.771 (+/-0.085) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.1, 'warm_start': False}\n",
      "0.761 (+/-0.064) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': True}\n",
      "0.761 (+/-0.064) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': False}\n",
      "0.761 (+/-0.064) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': True}\n",
      "0.761 (+/-0.064) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': False}\n",
      "0.761 (+/-0.064) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': True}\n",
      "0.761 (+/-0.064) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': False}\n",
      "0.763 (+/-0.065) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': True}\n",
      "0.763 (+/-0.065) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': False}\n",
      "0.758 (+/-0.068) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': True}\n",
      "0.758 (+/-0.068) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': False}\n",
      "0.761 (+/-0.064) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 1e-05, 'warm_start': True}\n",
      "0.761 (+/-0.064) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 1e-05, 'warm_start': False}\n",
      "0.761 (+/-0.064) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.0001, 'warm_start': True}\n",
      "0.761 (+/-0.064) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.0001, 'warm_start': False}\n",
      "0.761 (+/-0.064) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.001, 'warm_start': True}\n",
      "0.761 (+/-0.064) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.001, 'warm_start': False}\n",
      "0.761 (+/-0.064) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.01, 'warm_start': True}\n",
      "0.761 (+/-0.064) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.01, 'warm_start': False}\n",
      "0.763 (+/-0.069) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.1, 'warm_start': True}\n",
      "0.763 (+/-0.069) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.1, 'warm_start': False}\n",
      "0.761 (+/-0.064) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 1e-05, 'warm_start': True}\n",
      "0.761 (+/-0.064) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 1e-05, 'warm_start': False}\n",
      "0.761 (+/-0.064) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.0001, 'warm_start': True}\n",
      "0.761 (+/-0.064) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.0001, 'warm_start': False}\n",
      "0.761 (+/-0.064) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.001, 'warm_start': True}\n",
      "0.761 (+/-0.064) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.001, 'warm_start': False}\n",
      "0.761 (+/-0.064) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.01, 'warm_start': True}\n",
      "0.761 (+/-0.064) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.01, 'warm_start': False}\n",
      "0.761 (+/-0.064) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.1, 'warm_start': True}\n",
      "0.761 (+/-0.064) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.1, 'warm_start': False}\n",
      "0.761 (+/-0.064) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'sag', 'tol': 1e-05, 'warm_start': True}\n",
      "0.761 (+/-0.064) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'sag', 'tol': 1e-05, 'warm_start': False}\n",
      "0.761 (+/-0.064) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.0001, 'warm_start': True}\n",
      "0.761 (+/-0.064) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.0001, 'warm_start': False}\n",
      "0.761 (+/-0.064) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.001, 'warm_start': True}\n",
      "0.761 (+/-0.064) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.001, 'warm_start': False}\n",
      "0.763 (+/-0.069) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.01, 'warm_start': True}\n",
      "0.763 (+/-0.069) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.01, 'warm_start': False}\n",
      "0.770 (+/-0.069) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.1, 'warm_start': True}\n",
      "0.771 (+/-0.068) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.1, 'warm_start': False}\n",
      "0.761 (+/-0.064) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'saga', 'tol': 1e-05, 'warm_start': True}\n",
      "0.761 (+/-0.064) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'saga', 'tol': 1e-05, 'warm_start': False}\n",
      "0.761 (+/-0.064) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.0001, 'warm_start': True}\n",
      "0.761 (+/-0.064) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.0001, 'warm_start': False}\n",
      "0.761 (+/-0.064) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.001, 'warm_start': True}\n",
      "0.761 (+/-0.064) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.001, 'warm_start': False}\n",
      "0.760 (+/-0.071) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.01, 'warm_start': True}\n",
      "0.760 (+/-0.071) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.01, 'warm_start': False}\n",
      "0.771 (+/-0.065) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.1, 'warm_start': True}\n",
      "0.774 (+/-0.081) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.1, 'warm_start': False}\n",
      "0.794 (+/-0.085) for {'C': 10, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': True}\n",
      "0.794 (+/-0.085) for {'C': 10, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': False}\n",
      "0.794 (+/-0.085) for {'C': 10, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': True}\n",
      "0.794 (+/-0.085) for {'C': 10, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': False}\n",
      "0.791 (+/-0.087) for {'C': 10, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': True}\n",
      "0.791 (+/-0.087) for {'C': 10, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': False}\n",
      "0.794 (+/-0.085) for {'C': 10, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': True}\n",
      "0.794 (+/-0.085) for {'C': 10, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': False}\n",
      "0.795 (+/-0.076) for {'C': 10, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': True}\n",
      "0.795 (+/-0.076) for {'C': 10, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': False}\n",
      "0.794 (+/-0.085) for {'C': 10, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 1e-05, 'warm_start': True}\n",
      "0.794 (+/-0.085) for {'C': 10, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 1e-05, 'warm_start': False}\n",
      "0.794 (+/-0.085) for {'C': 10, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.0001, 'warm_start': True}\n",
      "0.794 (+/-0.085) for {'C': 10, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.0001, 'warm_start': False}\n",
      "0.794 (+/-0.085) for {'C': 10, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.001, 'warm_start': True}\n",
      "0.794 (+/-0.085) for {'C': 10, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.001, 'warm_start': False}\n",
      "0.794 (+/-0.085) for {'C': 10, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.01, 'warm_start': True}\n",
      "0.794 (+/-0.085) for {'C': 10, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.01, 'warm_start': False}\n",
      "0.794 (+/-0.085) for {'C': 10, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.1, 'warm_start': True}\n",
      "0.794 (+/-0.085) for {'C': 10, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.1, 'warm_start': False}\n",
      "0.794 (+/-0.085) for {'C': 10, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 1e-05, 'warm_start': True}\n",
      "0.794 (+/-0.085) for {'C': 10, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 1e-05, 'warm_start': False}\n",
      "0.794 (+/-0.085) for {'C': 10, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.0001, 'warm_start': True}\n",
      "0.794 (+/-0.085) for {'C': 10, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.0001, 'warm_start': False}\n",
      "0.794 (+/-0.085) for {'C': 10, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.001, 'warm_start': True}\n",
      "0.794 (+/-0.085) for {'C': 10, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.001, 'warm_start': False}\n",
      "0.794 (+/-0.085) for {'C': 10, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.01, 'warm_start': True}\n",
      "0.794 (+/-0.085) for {'C': 10, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.01, 'warm_start': False}\n",
      "0.791 (+/-0.087) for {'C': 10, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.1, 'warm_start': True}\n",
      "0.791 (+/-0.087) for {'C': 10, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.1, 'warm_start': False}\n",
      "0.796 (+/-0.080) for {'C': 10, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l2', 'solver': 'sag', 'tol': 1e-05, 'warm_start': True}\n",
      "0.796 (+/-0.080) for {'C': 10, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l2', 'solver': 'sag', 'tol': 1e-05, 'warm_start': False}\n",
      "0.796 (+/-0.080) for {'C': 10, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.0001, 'warm_start': True}\n",
      "0.796 (+/-0.080) for {'C': 10, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.0001, 'warm_start': False}\n",
      "0.796 (+/-0.080) for {'C': 10, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.001, 'warm_start': True}\n",
      "0.796 (+/-0.080) for {'C': 10, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.001, 'warm_start': False}\n",
      "0.795 (+/-0.078) for {'C': 10, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.01, 'warm_start': True}\n",
      "0.794 (+/-0.077) for {'C': 10, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.01, 'warm_start': False}\n",
      "0.794 (+/-0.071) for {'C': 10, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.1, 'warm_start': True}\n",
      "0.789 (+/-0.066) for {'C': 10, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.1, 'warm_start': False}\n",
      "0.796 (+/-0.080) for {'C': 10, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l2', 'solver': 'saga', 'tol': 1e-05, 'warm_start': True}\n",
      "0.796 (+/-0.080) for {'C': 10, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l2', 'solver': 'saga', 'tol': 1e-05, 'warm_start': False}\n",
      "0.796 (+/-0.080) for {'C': 10, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.0001, 'warm_start': True}\n",
      "0.796 (+/-0.080) for {'C': 10, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.0001, 'warm_start': False}\n",
      "0.796 (+/-0.080) for {'C': 10, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.001, 'warm_start': True}\n",
      "0.796 (+/-0.080) for {'C': 10, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.001, 'warm_start': False}\n",
      "0.795 (+/-0.070) for {'C': 10, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.01, 'warm_start': True}\n",
      "0.795 (+/-0.070) for {'C': 10, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.01, 'warm_start': False}\n",
      "0.781 (+/-0.079) for {'C': 10, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.1, 'warm_start': True}\n",
      "0.781 (+/-0.075) for {'C': 10, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.1, 'warm_start': False}\n",
      "0.794 (+/-0.085) for {'C': 10, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': True}\n",
      "0.794 (+/-0.085) for {'C': 10, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': False}\n",
      "0.794 (+/-0.085) for {'C': 10, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': True}\n",
      "0.794 (+/-0.085) for {'C': 10, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': False}\n",
      "0.791 (+/-0.087) for {'C': 10, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': True}\n",
      "0.791 (+/-0.087) for {'C': 10, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': False}\n",
      "0.794 (+/-0.085) for {'C': 10, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': True}\n",
      "0.794 (+/-0.085) for {'C': 10, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': False}\n",
      "0.795 (+/-0.076) for {'C': 10, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': True}\n",
      "0.795 (+/-0.076) for {'C': 10, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': False}\n",
      "0.794 (+/-0.085) for {'C': 10, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 1e-05, 'warm_start': True}\n",
      "0.794 (+/-0.085) for {'C': 10, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 1e-05, 'warm_start': False}\n",
      "0.794 (+/-0.085) for {'C': 10, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.0001, 'warm_start': True}\n",
      "0.794 (+/-0.085) for {'C': 10, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.0001, 'warm_start': False}\n",
      "0.794 (+/-0.085) for {'C': 10, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.001, 'warm_start': True}\n",
      "0.794 (+/-0.085) for {'C': 10, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.001, 'warm_start': False}\n",
      "0.794 (+/-0.085) for {'C': 10, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.01, 'warm_start': True}\n",
      "0.794 (+/-0.085) for {'C': 10, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.01, 'warm_start': False}\n",
      "0.794 (+/-0.085) for {'C': 10, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.1, 'warm_start': True}\n",
      "0.794 (+/-0.085) for {'C': 10, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.1, 'warm_start': False}\n",
      "0.794 (+/-0.085) for {'C': 10, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 1e-05, 'warm_start': True}\n",
      "0.794 (+/-0.085) for {'C': 10, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 1e-05, 'warm_start': False}\n",
      "0.794 (+/-0.085) for {'C': 10, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.0001, 'warm_start': True}\n",
      "0.794 (+/-0.085) for {'C': 10, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.0001, 'warm_start': False}\n",
      "0.794 (+/-0.085) for {'C': 10, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.001, 'warm_start': True}\n",
      "0.794 (+/-0.085) for {'C': 10, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.001, 'warm_start': False}\n",
      "0.794 (+/-0.085) for {'C': 10, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.01, 'warm_start': True}\n",
      "0.794 (+/-0.085) for {'C': 10, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.01, 'warm_start': False}\n",
      "0.791 (+/-0.087) for {'C': 10, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.1, 'warm_start': True}\n",
      "0.791 (+/-0.087) for {'C': 10, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.1, 'warm_start': False}\n",
      "0.794 (+/-0.085) for {'C': 10, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l2', 'solver': 'sag', 'tol': 1e-05, 'warm_start': True}\n",
      "0.794 (+/-0.085) for {'C': 10, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l2', 'solver': 'sag', 'tol': 1e-05, 'warm_start': False}\n",
      "0.794 (+/-0.085) for {'C': 10, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.0001, 'warm_start': True}\n",
      "0.794 (+/-0.085) for {'C': 10, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.0001, 'warm_start': False}\n",
      "0.794 (+/-0.085) for {'C': 10, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.001, 'warm_start': True}\n",
      "0.794 (+/-0.085) for {'C': 10, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.001, 'warm_start': False}\n",
      "0.795 (+/-0.076) for {'C': 10, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.01, 'warm_start': True}\n",
      "0.795 (+/-0.078) for {'C': 10, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.01, 'warm_start': False}\n",
      "0.787 (+/-0.081) for {'C': 10, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.1, 'warm_start': True}\n",
      "0.791 (+/-0.089) for {'C': 10, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.1, 'warm_start': False}\n",
      "0.794 (+/-0.085) for {'C': 10, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l2', 'solver': 'saga', 'tol': 1e-05, 'warm_start': True}\n",
      "0.794 (+/-0.085) for {'C': 10, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l2', 'solver': 'saga', 'tol': 1e-05, 'warm_start': False}\n",
      "0.794 (+/-0.085) for {'C': 10, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.0001, 'warm_start': True}\n",
      "0.794 (+/-0.085) for {'C': 10, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.0001, 'warm_start': False}\n",
      "0.796 (+/-0.080) for {'C': 10, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.001, 'warm_start': True}\n",
      "0.796 (+/-0.080) for {'C': 10, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.001, 'warm_start': False}\n",
      "0.795 (+/-0.070) for {'C': 10, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.01, 'warm_start': True}\n",
      "0.795 (+/-0.070) for {'C': 10, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.01, 'warm_start': False}\n",
      "0.778 (+/-0.084) for {'C': 10, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.1, 'warm_start': True}\n",
      "0.773 (+/-0.081) for {'C': 10, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.1, 'warm_start': False}\n",
      "0.794 (+/-0.085) for {'C': 10, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': True}\n",
      "0.794 (+/-0.085) for {'C': 10, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': False}\n",
      "0.794 (+/-0.085) for {'C': 10, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': True}\n",
      "0.794 (+/-0.085) for {'C': 10, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': False}\n",
      "0.791 (+/-0.087) for {'C': 10, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': True}\n",
      "0.791 (+/-0.087) for {'C': 10, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': False}\n",
      "0.794 (+/-0.085) for {'C': 10, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': True}\n",
      "0.794 (+/-0.085) for {'C': 10, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': False}\n",
      "0.795 (+/-0.076) for {'C': 10, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': True}\n",
      "0.795 (+/-0.076) for {'C': 10, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': False}\n",
      "0.794 (+/-0.085) for {'C': 10, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 1e-05, 'warm_start': True}\n",
      "0.794 (+/-0.085) for {'C': 10, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 1e-05, 'warm_start': False}\n",
      "0.794 (+/-0.085) for {'C': 10, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.0001, 'warm_start': True}\n",
      "0.794 (+/-0.085) for {'C': 10, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.0001, 'warm_start': False}\n",
      "0.794 (+/-0.085) for {'C': 10, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.001, 'warm_start': True}\n",
      "0.794 (+/-0.085) for {'C': 10, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.001, 'warm_start': False}\n",
      "0.794 (+/-0.085) for {'C': 10, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.01, 'warm_start': True}\n",
      "0.794 (+/-0.085) for {'C': 10, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.01, 'warm_start': False}\n",
      "0.794 (+/-0.085) for {'C': 10, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.1, 'warm_start': True}\n",
      "0.794 (+/-0.085) for {'C': 10, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.1, 'warm_start': False}\n",
      "0.794 (+/-0.085) for {'C': 10, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 1e-05, 'warm_start': True}\n",
      "0.794 (+/-0.085) for {'C': 10, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 1e-05, 'warm_start': False}\n",
      "0.794 (+/-0.085) for {'C': 10, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.0001, 'warm_start': True}\n",
      "0.794 (+/-0.085) for {'C': 10, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.0001, 'warm_start': False}\n",
      "0.794 (+/-0.085) for {'C': 10, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.001, 'warm_start': True}\n",
      "0.794 (+/-0.085) for {'C': 10, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.001, 'warm_start': False}\n",
      "0.794 (+/-0.085) for {'C': 10, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.01, 'warm_start': True}\n",
      "0.794 (+/-0.085) for {'C': 10, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.01, 'warm_start': False}\n",
      "0.791 (+/-0.087) for {'C': 10, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.1, 'warm_start': True}\n",
      "0.791 (+/-0.087) for {'C': 10, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.1, 'warm_start': False}\n",
      "0.794 (+/-0.085) for {'C': 10, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'sag', 'tol': 1e-05, 'warm_start': True}\n",
      "0.794 (+/-0.085) for {'C': 10, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'sag', 'tol': 1e-05, 'warm_start': False}\n",
      "0.794 (+/-0.085) for {'C': 10, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.0001, 'warm_start': True}\n",
      "0.794 (+/-0.085) for {'C': 10, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.0001, 'warm_start': False}\n",
      "0.794 (+/-0.085) for {'C': 10, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.001, 'warm_start': True}\n",
      "0.794 (+/-0.085) for {'C': 10, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.001, 'warm_start': False}\n",
      "0.794 (+/-0.077) for {'C': 10, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.01, 'warm_start': True}\n",
      "0.794 (+/-0.077) for {'C': 10, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.01, 'warm_start': False}\n",
      "0.782 (+/-0.081) for {'C': 10, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.1, 'warm_start': True}\n",
      "0.785 (+/-0.073) for {'C': 10, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.1, 'warm_start': False}\n",
      "0.794 (+/-0.085) for {'C': 10, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'saga', 'tol': 1e-05, 'warm_start': True}\n",
      "0.794 (+/-0.085) for {'C': 10, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'saga', 'tol': 1e-05, 'warm_start': False}\n",
      "0.794 (+/-0.085) for {'C': 10, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.0001, 'warm_start': True}\n",
      "0.794 (+/-0.085) for {'C': 10, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.0001, 'warm_start': False}\n",
      "0.796 (+/-0.080) for {'C': 10, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.001, 'warm_start': True}\n",
      "0.796 (+/-0.080) for {'C': 10, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.001, 'warm_start': False}\n",
      "0.795 (+/-0.070) for {'C': 10, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.01, 'warm_start': True}\n",
      "0.795 (+/-0.070) for {'C': 10, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.01, 'warm_start': False}\n",
      "0.780 (+/-0.079) for {'C': 10, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.1, 'warm_start': True}\n",
      "0.775 (+/-0.071) for {'C': 10, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.1, 'warm_start': False}\n",
      "0.794 (+/-0.085) for {'C': 10, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': True}\n",
      "0.794 (+/-0.085) for {'C': 10, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': False}\n",
      "0.794 (+/-0.085) for {'C': 10, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': True}\n",
      "0.794 (+/-0.085) for {'C': 10, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': False}\n",
      "0.791 (+/-0.087) for {'C': 10, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': True}\n",
      "0.791 (+/-0.087) for {'C': 10, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': False}\n",
      "0.794 (+/-0.085) for {'C': 10, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': True}\n",
      "0.794 (+/-0.085) for {'C': 10, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': False}\n",
      "0.795 (+/-0.076) for {'C': 10, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': True}\n",
      "0.795 (+/-0.076) for {'C': 10, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': False}\n",
      "0.794 (+/-0.085) for {'C': 10, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 1e-05, 'warm_start': True}\n",
      "0.794 (+/-0.085) for {'C': 10, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 1e-05, 'warm_start': False}\n",
      "0.794 (+/-0.085) for {'C': 10, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.0001, 'warm_start': True}\n",
      "0.794 (+/-0.085) for {'C': 10, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.0001, 'warm_start': False}\n",
      "0.794 (+/-0.085) for {'C': 10, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.001, 'warm_start': True}\n",
      "0.794 (+/-0.085) for {'C': 10, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.001, 'warm_start': False}\n",
      "0.794 (+/-0.085) for {'C': 10, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.01, 'warm_start': True}\n",
      "0.794 (+/-0.085) for {'C': 10, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.01, 'warm_start': False}\n",
      "0.794 (+/-0.085) for {'C': 10, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.1, 'warm_start': True}\n",
      "0.794 (+/-0.085) for {'C': 10, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.1, 'warm_start': False}\n",
      "0.794 (+/-0.085) for {'C': 10, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 1e-05, 'warm_start': True}\n",
      "0.794 (+/-0.085) for {'C': 10, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 1e-05, 'warm_start': False}\n",
      "0.794 (+/-0.085) for {'C': 10, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.0001, 'warm_start': True}\n",
      "0.794 (+/-0.085) for {'C': 10, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.0001, 'warm_start': False}\n",
      "0.794 (+/-0.085) for {'C': 10, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.001, 'warm_start': True}\n",
      "0.794 (+/-0.085) for {'C': 10, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.001, 'warm_start': False}\n",
      "0.794 (+/-0.085) for {'C': 10, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.01, 'warm_start': True}\n",
      "0.794 (+/-0.085) for {'C': 10, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.01, 'warm_start': False}\n",
      "0.791 (+/-0.087) for {'C': 10, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.1, 'warm_start': True}\n",
      "0.791 (+/-0.087) for {'C': 10, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.1, 'warm_start': False}\n",
      "0.794 (+/-0.085) for {'C': 10, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'sag', 'tol': 1e-05, 'warm_start': True}\n",
      "0.794 (+/-0.085) for {'C': 10, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'sag', 'tol': 1e-05, 'warm_start': False}\n",
      "0.794 (+/-0.085) for {'C': 10, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.0001, 'warm_start': True}\n",
      "0.794 (+/-0.085) for {'C': 10, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.0001, 'warm_start': False}\n",
      "0.794 (+/-0.085) for {'C': 10, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.001, 'warm_start': True}\n",
      "0.794 (+/-0.085) for {'C': 10, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.001, 'warm_start': False}\n",
      "0.795 (+/-0.076) for {'C': 10, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.01, 'warm_start': True}\n",
      "0.795 (+/-0.076) for {'C': 10, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.01, 'warm_start': False}\n",
      "0.785 (+/-0.094) for {'C': 10, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.1, 'warm_start': True}\n",
      "0.784 (+/-0.083) for {'C': 10, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.1, 'warm_start': False}\n",
      "0.794 (+/-0.085) for {'C': 10, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'saga', 'tol': 1e-05, 'warm_start': True}\n",
      "0.794 (+/-0.085) for {'C': 10, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'saga', 'tol': 1e-05, 'warm_start': False}\n",
      "0.794 (+/-0.085) for {'C': 10, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.0001, 'warm_start': True}\n",
      "0.794 (+/-0.085) for {'C': 10, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.0001, 'warm_start': False}\n",
      "0.796 (+/-0.080) for {'C': 10, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.001, 'warm_start': True}\n",
      "0.796 (+/-0.080) for {'C': 10, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.001, 'warm_start': False}\n",
      "0.795 (+/-0.070) for {'C': 10, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.01, 'warm_start': True}\n",
      "0.794 (+/-0.069) for {'C': 10, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.01, 'warm_start': False}\n",
      "0.771 (+/-0.080) for {'C': 10, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.1, 'warm_start': True}\n",
      "0.774 (+/-0.080) for {'C': 10, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.1, 'warm_start': False}\n",
      "0.794 (+/-0.085) for {'C': 10, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': True}\n",
      "0.794 (+/-0.085) for {'C': 10, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': False}\n",
      "0.794 (+/-0.085) for {'C': 10, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': True}\n",
      "0.794 (+/-0.085) for {'C': 10, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': False}\n",
      "0.791 (+/-0.087) for {'C': 10, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': True}\n",
      "0.791 (+/-0.087) for {'C': 10, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': False}\n",
      "0.794 (+/-0.085) for {'C': 10, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': True}\n",
      "0.794 (+/-0.085) for {'C': 10, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': False}\n",
      "0.795 (+/-0.076) for {'C': 10, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': True}\n",
      "0.795 (+/-0.076) for {'C': 10, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': False}\n",
      "0.794 (+/-0.085) for {'C': 10, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 1e-05, 'warm_start': True}\n",
      "0.794 (+/-0.085) for {'C': 10, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 1e-05, 'warm_start': False}\n",
      "0.794 (+/-0.085) for {'C': 10, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.0001, 'warm_start': True}\n",
      "0.794 (+/-0.085) for {'C': 10, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.0001, 'warm_start': False}\n",
      "0.794 (+/-0.085) for {'C': 10, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.001, 'warm_start': True}\n",
      "0.794 (+/-0.085) for {'C': 10, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.001, 'warm_start': False}\n",
      "0.794 (+/-0.085) for {'C': 10, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.01, 'warm_start': True}\n",
      "0.794 (+/-0.085) for {'C': 10, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.01, 'warm_start': False}\n",
      "0.794 (+/-0.085) for {'C': 10, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.1, 'warm_start': True}\n",
      "0.794 (+/-0.085) for {'C': 10, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.1, 'warm_start': False}\n",
      "0.794 (+/-0.085) for {'C': 10, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 1e-05, 'warm_start': True}\n",
      "0.794 (+/-0.085) for {'C': 10, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 1e-05, 'warm_start': False}\n",
      "0.794 (+/-0.085) for {'C': 10, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.0001, 'warm_start': True}\n",
      "0.794 (+/-0.085) for {'C': 10, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.0001, 'warm_start': False}\n",
      "0.794 (+/-0.085) for {'C': 10, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.001, 'warm_start': True}\n",
      "0.794 (+/-0.085) for {'C': 10, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.001, 'warm_start': False}\n",
      "0.794 (+/-0.085) for {'C': 10, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.01, 'warm_start': True}\n",
      "0.794 (+/-0.085) for {'C': 10, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.01, 'warm_start': False}\n",
      "0.791 (+/-0.087) for {'C': 10, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.1, 'warm_start': True}\n",
      "0.791 (+/-0.087) for {'C': 10, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.1, 'warm_start': False}\n",
      "0.794 (+/-0.085) for {'C': 10, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'sag', 'tol': 1e-05, 'warm_start': True}\n",
      "0.794 (+/-0.085) for {'C': 10, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'sag', 'tol': 1e-05, 'warm_start': False}\n",
      "0.794 (+/-0.085) for {'C': 10, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.0001, 'warm_start': True}\n",
      "0.794 (+/-0.085) for {'C': 10, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.0001, 'warm_start': False}\n",
      "0.794 (+/-0.085) for {'C': 10, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.001, 'warm_start': True}\n",
      "0.794 (+/-0.085) for {'C': 10, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.001, 'warm_start': False}\n",
      "0.794 (+/-0.077) for {'C': 10, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.01, 'warm_start': True}\n",
      "0.795 (+/-0.078) for {'C': 10, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.01, 'warm_start': False}\n",
      "0.784 (+/-0.072) for {'C': 10, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.1, 'warm_start': True}\n",
      "0.788 (+/-0.077) for {'C': 10, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.1, 'warm_start': False}\n",
      "0.794 (+/-0.085) for {'C': 10, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'saga', 'tol': 1e-05, 'warm_start': True}\n",
      "0.794 (+/-0.085) for {'C': 10, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'saga', 'tol': 1e-05, 'warm_start': False}\n",
      "0.794 (+/-0.085) for {'C': 10, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.0001, 'warm_start': True}\n",
      "0.794 (+/-0.085) for {'C': 10, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.0001, 'warm_start': False}\n",
      "0.796 (+/-0.080) for {'C': 10, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.001, 'warm_start': True}\n",
      "0.796 (+/-0.080) for {'C': 10, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.001, 'warm_start': False}\n",
      "0.795 (+/-0.070) for {'C': 10, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.01, 'warm_start': True}\n",
      "0.795 (+/-0.070) for {'C': 10, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.01, 'warm_start': False}\n",
      "0.778 (+/-0.084) for {'C': 10, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.1, 'warm_start': True}\n",
      "0.771 (+/-0.085) for {'C': 10, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.1, 'warm_start': False}\n",
      "0.764 (+/-0.073) for {'C': 10, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': True}\n",
      "0.764 (+/-0.073) for {'C': 10, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': False}\n",
      "0.764 (+/-0.073) for {'C': 10, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': True}\n",
      "0.764 (+/-0.073) for {'C': 10, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': False}\n",
      "0.764 (+/-0.073) for {'C': 10, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': True}\n",
      "0.764 (+/-0.073) for {'C': 10, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': False}\n",
      "0.764 (+/-0.073) for {'C': 10, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': True}\n",
      "0.764 (+/-0.073) for {'C': 10, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': False}\n",
      "0.763 (+/-0.063) for {'C': 10, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': True}\n",
      "0.763 (+/-0.063) for {'C': 10, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': False}\n",
      "0.764 (+/-0.073) for {'C': 10, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 1e-05, 'warm_start': True}\n",
      "0.764 (+/-0.073) for {'C': 10, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 1e-05, 'warm_start': False}\n",
      "0.764 (+/-0.073) for {'C': 10, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.0001, 'warm_start': True}\n",
      "0.764 (+/-0.073) for {'C': 10, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.0001, 'warm_start': False}\n",
      "0.764 (+/-0.073) for {'C': 10, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.001, 'warm_start': True}\n",
      "0.764 (+/-0.073) for {'C': 10, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.001, 'warm_start': False}\n",
      "0.764 (+/-0.073) for {'C': 10, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.01, 'warm_start': True}\n",
      "0.764 (+/-0.073) for {'C': 10, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.01, 'warm_start': False}\n",
      "0.764 (+/-0.073) for {'C': 10, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.1, 'warm_start': True}\n",
      "0.764 (+/-0.073) for {'C': 10, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.1, 'warm_start': False}\n",
      "0.764 (+/-0.073) for {'C': 10, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 1e-05, 'warm_start': True}\n",
      "0.764 (+/-0.073) for {'C': 10, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 1e-05, 'warm_start': False}\n",
      "0.764 (+/-0.073) for {'C': 10, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.0001, 'warm_start': True}\n",
      "0.764 (+/-0.073) for {'C': 10, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.0001, 'warm_start': False}\n",
      "0.764 (+/-0.073) for {'C': 10, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.001, 'warm_start': True}\n",
      "0.764 (+/-0.073) for {'C': 10, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.001, 'warm_start': False}\n",
      "0.764 (+/-0.073) for {'C': 10, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.01, 'warm_start': True}\n",
      "0.764 (+/-0.073) for {'C': 10, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.01, 'warm_start': False}\n",
      "0.764 (+/-0.073) for {'C': 10, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.1, 'warm_start': True}\n",
      "0.764 (+/-0.073) for {'C': 10, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.1, 'warm_start': False}\n",
      "0.764 (+/-0.070) for {'C': 10, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l2', 'solver': 'sag', 'tol': 1e-05, 'warm_start': True}\n",
      "0.764 (+/-0.070) for {'C': 10, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l2', 'solver': 'sag', 'tol': 1e-05, 'warm_start': False}\n",
      "0.764 (+/-0.070) for {'C': 10, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.0001, 'warm_start': True}\n",
      "0.764 (+/-0.070) for {'C': 10, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.0001, 'warm_start': False}\n",
      "0.764 (+/-0.070) for {'C': 10, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.001, 'warm_start': True}\n",
      "0.764 (+/-0.070) for {'C': 10, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.001, 'warm_start': False}\n",
      "0.765 (+/-0.065) for {'C': 10, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.01, 'warm_start': True}\n",
      "0.765 (+/-0.065) for {'C': 10, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.01, 'warm_start': False}\n",
      "0.763 (+/-0.064) for {'C': 10, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.1, 'warm_start': True}\n",
      "0.753 (+/-0.060) for {'C': 10, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.1, 'warm_start': False}\n",
      "0.763 (+/-0.064) for {'C': 10, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l2', 'solver': 'saga', 'tol': 1e-05, 'warm_start': True}\n",
      "0.763 (+/-0.064) for {'C': 10, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l2', 'solver': 'saga', 'tol': 1e-05, 'warm_start': False}\n",
      "0.763 (+/-0.064) for {'C': 10, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.0001, 'warm_start': True}\n",
      "0.763 (+/-0.064) for {'C': 10, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.0001, 'warm_start': False}\n",
      "0.763 (+/-0.064) for {'C': 10, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.001, 'warm_start': True}\n",
      "0.763 (+/-0.064) for {'C': 10, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.001, 'warm_start': False}\n",
      "0.763 (+/-0.069) for {'C': 10, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.01, 'warm_start': True}\n",
      "0.763 (+/-0.069) for {'C': 10, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.01, 'warm_start': False}\n",
      "0.767 (+/-0.071) for {'C': 10, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.1, 'warm_start': True}\n",
      "0.770 (+/-0.072) for {'C': 10, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.1, 'warm_start': False}\n",
      "0.764 (+/-0.073) for {'C': 10, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': True}\n",
      "0.764 (+/-0.073) for {'C': 10, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': False}\n",
      "0.764 (+/-0.073) for {'C': 10, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': True}\n",
      "0.764 (+/-0.073) for {'C': 10, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': False}\n",
      "0.764 (+/-0.073) for {'C': 10, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': True}\n",
      "0.764 (+/-0.073) for {'C': 10, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': False}\n",
      "0.764 (+/-0.073) for {'C': 10, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': True}\n",
      "0.764 (+/-0.073) for {'C': 10, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': False}\n",
      "0.763 (+/-0.063) for {'C': 10, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': True}\n",
      "0.763 (+/-0.063) for {'C': 10, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': False}\n",
      "0.764 (+/-0.073) for {'C': 10, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 1e-05, 'warm_start': True}\n",
      "0.764 (+/-0.073) for {'C': 10, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 1e-05, 'warm_start': False}\n",
      "0.764 (+/-0.073) for {'C': 10, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.0001, 'warm_start': True}\n",
      "0.764 (+/-0.073) for {'C': 10, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.0001, 'warm_start': False}\n",
      "0.764 (+/-0.073) for {'C': 10, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.001, 'warm_start': True}\n",
      "0.764 (+/-0.073) for {'C': 10, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.001, 'warm_start': False}\n",
      "0.764 (+/-0.073) for {'C': 10, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.01, 'warm_start': True}\n",
      "0.764 (+/-0.073) for {'C': 10, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.01, 'warm_start': False}\n",
      "0.764 (+/-0.073) for {'C': 10, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.1, 'warm_start': True}\n",
      "0.764 (+/-0.073) for {'C': 10, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.1, 'warm_start': False}\n",
      "0.764 (+/-0.073) for {'C': 10, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 1e-05, 'warm_start': True}\n",
      "0.764 (+/-0.073) for {'C': 10, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 1e-05, 'warm_start': False}\n",
      "0.764 (+/-0.073) for {'C': 10, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.0001, 'warm_start': True}\n",
      "0.764 (+/-0.073) for {'C': 10, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.0001, 'warm_start': False}\n",
      "0.764 (+/-0.073) for {'C': 10, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.001, 'warm_start': True}\n",
      "0.764 (+/-0.073) for {'C': 10, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.001, 'warm_start': False}\n",
      "0.764 (+/-0.073) for {'C': 10, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.01, 'warm_start': True}\n",
      "0.764 (+/-0.073) for {'C': 10, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.01, 'warm_start': False}\n",
      "0.764 (+/-0.073) for {'C': 10, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.1, 'warm_start': True}\n",
      "0.764 (+/-0.073) for {'C': 10, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.1, 'warm_start': False}\n",
      "0.764 (+/-0.073) for {'C': 10, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l2', 'solver': 'sag', 'tol': 1e-05, 'warm_start': True}\n",
      "0.764 (+/-0.073) for {'C': 10, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l2', 'solver': 'sag', 'tol': 1e-05, 'warm_start': False}\n",
      "0.764 (+/-0.073) for {'C': 10, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.0001, 'warm_start': True}\n",
      "0.764 (+/-0.073) for {'C': 10, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.0001, 'warm_start': False}\n",
      "0.765 (+/-0.074) for {'C': 10, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.001, 'warm_start': True}\n",
      "0.765 (+/-0.074) for {'C': 10, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.001, 'warm_start': False}\n",
      "0.765 (+/-0.065) for {'C': 10, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.01, 'warm_start': True}\n",
      "0.765 (+/-0.065) for {'C': 10, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.01, 'warm_start': False}\n",
      "0.765 (+/-0.057) for {'C': 10, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.1, 'warm_start': True}\n",
      "0.766 (+/-0.072) for {'C': 10, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.1, 'warm_start': False}\n",
      "0.765 (+/-0.074) for {'C': 10, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l2', 'solver': 'saga', 'tol': 1e-05, 'warm_start': True}\n",
      "0.765 (+/-0.074) for {'C': 10, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l2', 'solver': 'saga', 'tol': 1e-05, 'warm_start': False}\n",
      "0.765 (+/-0.074) for {'C': 10, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.0001, 'warm_start': True}\n",
      "0.765 (+/-0.074) for {'C': 10, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.0001, 'warm_start': False}\n",
      "0.764 (+/-0.069) for {'C': 10, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.001, 'warm_start': True}\n",
      "0.764 (+/-0.069) for {'C': 10, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.001, 'warm_start': False}\n",
      "0.763 (+/-0.069) for {'C': 10, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.01, 'warm_start': True}\n",
      "0.763 (+/-0.069) for {'C': 10, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.01, 'warm_start': False}\n",
      "0.768 (+/-0.062) for {'C': 10, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.1, 'warm_start': True}\n",
      "0.771 (+/-0.083) for {'C': 10, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.1, 'warm_start': False}\n",
      "0.764 (+/-0.073) for {'C': 10, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': True}\n",
      "0.764 (+/-0.073) for {'C': 10, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': False}\n",
      "0.764 (+/-0.073) for {'C': 10, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': True}\n",
      "0.764 (+/-0.073) for {'C': 10, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': False}\n",
      "0.764 (+/-0.073) for {'C': 10, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': True}\n",
      "0.764 (+/-0.073) for {'C': 10, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': False}\n",
      "0.764 (+/-0.073) for {'C': 10, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': True}\n",
      "0.764 (+/-0.073) for {'C': 10, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': False}\n",
      "0.763 (+/-0.063) for {'C': 10, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': True}\n",
      "0.763 (+/-0.063) for {'C': 10, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': False}\n",
      "0.764 (+/-0.073) for {'C': 10, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 1e-05, 'warm_start': True}\n",
      "0.764 (+/-0.073) for {'C': 10, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 1e-05, 'warm_start': False}\n",
      "0.764 (+/-0.073) for {'C': 10, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.0001, 'warm_start': True}\n",
      "0.764 (+/-0.073) for {'C': 10, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.0001, 'warm_start': False}\n",
      "0.764 (+/-0.073) for {'C': 10, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.001, 'warm_start': True}\n",
      "0.764 (+/-0.073) for {'C': 10, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.001, 'warm_start': False}\n",
      "0.764 (+/-0.073) for {'C': 10, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.01, 'warm_start': True}\n",
      "0.764 (+/-0.073) for {'C': 10, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.01, 'warm_start': False}\n",
      "0.764 (+/-0.073) for {'C': 10, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.1, 'warm_start': True}\n",
      "0.764 (+/-0.073) for {'C': 10, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.1, 'warm_start': False}\n",
      "0.764 (+/-0.073) for {'C': 10, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 1e-05, 'warm_start': True}\n",
      "0.764 (+/-0.073) for {'C': 10, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 1e-05, 'warm_start': False}\n",
      "0.764 (+/-0.073) for {'C': 10, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.0001, 'warm_start': True}\n",
      "0.764 (+/-0.073) for {'C': 10, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.0001, 'warm_start': False}\n",
      "0.764 (+/-0.073) for {'C': 10, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.001, 'warm_start': True}\n",
      "0.764 (+/-0.073) for {'C': 10, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.001, 'warm_start': False}\n",
      "0.764 (+/-0.073) for {'C': 10, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.01, 'warm_start': True}\n",
      "0.764 (+/-0.073) for {'C': 10, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.01, 'warm_start': False}\n",
      "0.764 (+/-0.073) for {'C': 10, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.1, 'warm_start': True}\n",
      "0.764 (+/-0.073) for {'C': 10, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.1, 'warm_start': False}\n",
      "0.764 (+/-0.073) for {'C': 10, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'sag', 'tol': 1e-05, 'warm_start': True}\n",
      "0.764 (+/-0.073) for {'C': 10, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'sag', 'tol': 1e-05, 'warm_start': False}\n",
      "0.764 (+/-0.073) for {'C': 10, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.0001, 'warm_start': True}\n",
      "0.764 (+/-0.073) for {'C': 10, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.0001, 'warm_start': False}\n",
      "0.765 (+/-0.074) for {'C': 10, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.001, 'warm_start': True}\n",
      "0.765 (+/-0.074) for {'C': 10, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.001, 'warm_start': False}\n",
      "0.765 (+/-0.065) for {'C': 10, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.01, 'warm_start': True}\n",
      "0.765 (+/-0.065) for {'C': 10, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.01, 'warm_start': False}\n",
      "0.764 (+/-0.073) for {'C': 10, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.1, 'warm_start': True}\n",
      "0.765 (+/-0.069) for {'C': 10, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.1, 'warm_start': False}\n",
      "0.764 (+/-0.073) for {'C': 10, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'saga', 'tol': 1e-05, 'warm_start': True}\n",
      "0.764 (+/-0.073) for {'C': 10, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'saga', 'tol': 1e-05, 'warm_start': False}\n",
      "0.764 (+/-0.073) for {'C': 10, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.0001, 'warm_start': True}\n",
      "0.764 (+/-0.073) for {'C': 10, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.0001, 'warm_start': False}\n",
      "0.764 (+/-0.069) for {'C': 10, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.001, 'warm_start': True}\n",
      "0.764 (+/-0.069) for {'C': 10, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.001, 'warm_start': False}\n",
      "0.763 (+/-0.069) for {'C': 10, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.01, 'warm_start': True}\n",
      "0.763 (+/-0.069) for {'C': 10, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.01, 'warm_start': False}\n",
      "0.770 (+/-0.087) for {'C': 10, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.1, 'warm_start': True}\n",
      "0.773 (+/-0.063) for {'C': 10, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.1, 'warm_start': False}\n",
      "0.764 (+/-0.073) for {'C': 10, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': True}\n",
      "0.764 (+/-0.073) for {'C': 10, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': False}\n",
      "0.764 (+/-0.073) for {'C': 10, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': True}\n",
      "0.764 (+/-0.073) for {'C': 10, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': False}\n",
      "0.764 (+/-0.073) for {'C': 10, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': True}\n",
      "0.764 (+/-0.073) for {'C': 10, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': False}\n",
      "0.764 (+/-0.073) for {'C': 10, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': True}\n",
      "0.764 (+/-0.073) for {'C': 10, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': False}\n",
      "0.763 (+/-0.063) for {'C': 10, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': True}\n",
      "0.763 (+/-0.063) for {'C': 10, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': False}\n",
      "0.764 (+/-0.073) for {'C': 10, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 1e-05, 'warm_start': True}\n",
      "0.764 (+/-0.073) for {'C': 10, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 1e-05, 'warm_start': False}\n",
      "0.764 (+/-0.073) for {'C': 10, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.0001, 'warm_start': True}\n",
      "0.764 (+/-0.073) for {'C': 10, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.0001, 'warm_start': False}\n",
      "0.764 (+/-0.073) for {'C': 10, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.001, 'warm_start': True}\n",
      "0.764 (+/-0.073) for {'C': 10, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.001, 'warm_start': False}\n",
      "0.764 (+/-0.073) for {'C': 10, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.01, 'warm_start': True}\n",
      "0.764 (+/-0.073) for {'C': 10, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.01, 'warm_start': False}\n",
      "0.764 (+/-0.073) for {'C': 10, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.1, 'warm_start': True}\n",
      "0.764 (+/-0.073) for {'C': 10, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.1, 'warm_start': False}\n",
      "0.764 (+/-0.073) for {'C': 10, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 1e-05, 'warm_start': True}\n",
      "0.764 (+/-0.073) for {'C': 10, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 1e-05, 'warm_start': False}\n",
      "0.764 (+/-0.073) for {'C': 10, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.0001, 'warm_start': True}\n",
      "0.764 (+/-0.073) for {'C': 10, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.0001, 'warm_start': False}\n",
      "0.764 (+/-0.073) for {'C': 10, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.001, 'warm_start': True}\n",
      "0.764 (+/-0.073) for {'C': 10, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.001, 'warm_start': False}\n",
      "0.764 (+/-0.073) for {'C': 10, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.01, 'warm_start': True}\n",
      "0.764 (+/-0.073) for {'C': 10, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.01, 'warm_start': False}\n",
      "0.764 (+/-0.073) for {'C': 10, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.1, 'warm_start': True}\n",
      "0.764 (+/-0.073) for {'C': 10, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.1, 'warm_start': False}\n",
      "0.764 (+/-0.073) for {'C': 10, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'sag', 'tol': 1e-05, 'warm_start': True}\n",
      "0.764 (+/-0.073) for {'C': 10, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'sag', 'tol': 1e-05, 'warm_start': False}\n",
      "0.764 (+/-0.073) for {'C': 10, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.0001, 'warm_start': True}\n",
      "0.764 (+/-0.073) for {'C': 10, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.0001, 'warm_start': False}\n",
      "0.765 (+/-0.074) for {'C': 10, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.001, 'warm_start': True}\n",
      "0.765 (+/-0.074) for {'C': 10, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.001, 'warm_start': False}\n",
      "0.765 (+/-0.065) for {'C': 10, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.01, 'warm_start': True}\n",
      "0.765 (+/-0.065) for {'C': 10, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.01, 'warm_start': False}\n",
      "0.763 (+/-0.065) for {'C': 10, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.1, 'warm_start': True}\n",
      "0.767 (+/-0.090) for {'C': 10, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.1, 'warm_start': False}\n",
      "0.764 (+/-0.073) for {'C': 10, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'saga', 'tol': 1e-05, 'warm_start': True}\n",
      "0.764 (+/-0.073) for {'C': 10, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'saga', 'tol': 1e-05, 'warm_start': False}\n",
      "0.764 (+/-0.073) for {'C': 10, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.0001, 'warm_start': True}\n",
      "0.764 (+/-0.073) for {'C': 10, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.0001, 'warm_start': False}\n",
      "0.764 (+/-0.069) for {'C': 10, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.001, 'warm_start': True}\n",
      "0.764 (+/-0.069) for {'C': 10, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.001, 'warm_start': False}\n",
      "0.763 (+/-0.069) for {'C': 10, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.01, 'warm_start': True}\n",
      "0.763 (+/-0.069) for {'C': 10, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.01, 'warm_start': False}\n",
      "0.764 (+/-0.051) for {'C': 10, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.1, 'warm_start': True}\n",
      "0.774 (+/-0.074) for {'C': 10, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.1, 'warm_start': False}\n",
      "0.764 (+/-0.073) for {'C': 10, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': True}\n",
      "0.764 (+/-0.073) for {'C': 10, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': False}\n",
      "0.764 (+/-0.073) for {'C': 10, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': True}\n",
      "0.764 (+/-0.073) for {'C': 10, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': False}\n",
      "0.764 (+/-0.073) for {'C': 10, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': True}\n",
      "0.764 (+/-0.073) for {'C': 10, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': False}\n",
      "0.764 (+/-0.073) for {'C': 10, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': True}\n",
      "0.764 (+/-0.073) for {'C': 10, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': False}\n",
      "0.763 (+/-0.063) for {'C': 10, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': True}\n",
      "0.763 (+/-0.063) for {'C': 10, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': False}\n",
      "0.764 (+/-0.073) for {'C': 10, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 1e-05, 'warm_start': True}\n",
      "0.764 (+/-0.073) for {'C': 10, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 1e-05, 'warm_start': False}\n",
      "0.764 (+/-0.073) for {'C': 10, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.0001, 'warm_start': True}\n",
      "0.764 (+/-0.073) for {'C': 10, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.0001, 'warm_start': False}\n",
      "0.764 (+/-0.073) for {'C': 10, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.001, 'warm_start': True}\n",
      "0.764 (+/-0.073) for {'C': 10, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.001, 'warm_start': False}\n",
      "0.764 (+/-0.073) for {'C': 10, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.01, 'warm_start': True}\n",
      "0.764 (+/-0.073) for {'C': 10, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.01, 'warm_start': False}\n",
      "0.764 (+/-0.073) for {'C': 10, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.1, 'warm_start': True}\n",
      "0.764 (+/-0.073) for {'C': 10, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.1, 'warm_start': False}\n",
      "0.764 (+/-0.073) for {'C': 10, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 1e-05, 'warm_start': True}\n",
      "0.764 (+/-0.073) for {'C': 10, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 1e-05, 'warm_start': False}\n",
      "0.764 (+/-0.073) for {'C': 10, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.0001, 'warm_start': True}\n",
      "0.764 (+/-0.073) for {'C': 10, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.0001, 'warm_start': False}\n",
      "0.764 (+/-0.073) for {'C': 10, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.001, 'warm_start': True}\n",
      "0.764 (+/-0.073) for {'C': 10, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.001, 'warm_start': False}\n",
      "0.764 (+/-0.073) for {'C': 10, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.01, 'warm_start': True}\n",
      "0.764 (+/-0.073) for {'C': 10, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.01, 'warm_start': False}\n",
      "0.764 (+/-0.073) for {'C': 10, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.1, 'warm_start': True}\n",
      "0.764 (+/-0.073) for {'C': 10, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'lbfgs', 'tol': 0.1, 'warm_start': False}\n",
      "0.764 (+/-0.073) for {'C': 10, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'sag', 'tol': 1e-05, 'warm_start': True}\n",
      "0.764 (+/-0.073) for {'C': 10, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'sag', 'tol': 1e-05, 'warm_start': False}\n",
      "0.764 (+/-0.073) for {'C': 10, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.0001, 'warm_start': True}\n",
      "0.764 (+/-0.073) for {'C': 10, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.0001, 'warm_start': False}\n",
      "0.765 (+/-0.074) for {'C': 10, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.001, 'warm_start': True}\n",
      "0.765 (+/-0.074) for {'C': 10, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.001, 'warm_start': False}\n",
      "0.765 (+/-0.065) for {'C': 10, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.01, 'warm_start': True}\n",
      "0.765 (+/-0.065) for {'C': 10, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.01, 'warm_start': False}\n",
      "0.765 (+/-0.069) for {'C': 10, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.1, 'warm_start': True}\n",
      "0.760 (+/-0.075) for {'C': 10, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'sag', 'tol': 0.1, 'warm_start': False}\n",
      "0.764 (+/-0.073) for {'C': 10, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'saga', 'tol': 1e-05, 'warm_start': True}\n",
      "0.764 (+/-0.073) for {'C': 10, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'saga', 'tol': 1e-05, 'warm_start': False}\n",
      "0.764 (+/-0.073) for {'C': 10, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.0001, 'warm_start': True}\n",
      "0.764 (+/-0.073) for {'C': 10, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.0001, 'warm_start': False}\n",
      "0.764 (+/-0.069) for {'C': 10, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.001, 'warm_start': True}\n",
      "0.764 (+/-0.069) for {'C': 10, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.001, 'warm_start': False}\n",
      "0.763 (+/-0.069) for {'C': 10, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.01, 'warm_start': True}\n",
      "0.763 (+/-0.069) for {'C': 10, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.01, 'warm_start': False}\n",
      "0.771 (+/-0.056) for {'C': 10, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.1, 'warm_start': True}\n",
      "0.774 (+/-0.080) for {'C': 10, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l2', 'solver': 'saga', 'tol': 0.1, 'warm_start': False}\n",
      "0.784 (+/-0.090) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': True}\n",
      "0.784 (+/-0.090) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': False}\n",
      "0.784 (+/-0.090) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': True}\n",
      "0.784 (+/-0.090) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': False}\n",
      "0.784 (+/-0.090) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': True}\n",
      "0.784 (+/-0.090) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': False}\n",
      "0.784 (+/-0.090) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': True}\n",
      "0.784 (+/-0.090) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': False}\n",
      "0.784 (+/-0.090) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': True}\n",
      "0.784 (+/-0.090) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': False}\n",
      "0.784 (+/-0.090) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l1', 'solver': 'saga', 'tol': 1e-05, 'warm_start': True}\n",
      "0.784 (+/-0.090) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l1', 'solver': 'saga', 'tol': 1e-05, 'warm_start': False}\n",
      "0.784 (+/-0.090) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.0001, 'warm_start': True}\n",
      "0.784 (+/-0.090) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.0001, 'warm_start': False}\n",
      "0.784 (+/-0.090) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.001, 'warm_start': True}\n",
      "0.784 (+/-0.090) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.001, 'warm_start': False}\n",
      "0.784 (+/-0.090) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.01, 'warm_start': True}\n",
      "0.784 (+/-0.090) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.01, 'warm_start': False}\n",
      "0.784 (+/-0.090) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.1, 'warm_start': True}\n",
      "0.784 (+/-0.090) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.1, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 1e-05, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 1e-05, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.0001, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.0001, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.001, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.001, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.01, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.01, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.1, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.1, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'none', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'none', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': False}\n",
      "0.796 (+/-0.080) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'none', 'solver': 'saga', 'tol': 1e-05, 'warm_start': True}\n",
      "0.796 (+/-0.080) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'none', 'solver': 'saga', 'tol': 1e-05, 'warm_start': False}\n",
      "0.796 (+/-0.080) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'none', 'solver': 'saga', 'tol': 0.0001, 'warm_start': True}\n",
      "0.796 (+/-0.080) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'none', 'solver': 'saga', 'tol': 0.0001, 'warm_start': False}\n",
      "0.796 (+/-0.080) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'none', 'solver': 'saga', 'tol': 0.001, 'warm_start': True}\n",
      "0.796 (+/-0.080) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'none', 'solver': 'saga', 'tol': 0.001, 'warm_start': False}\n",
      "0.795 (+/-0.070) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'none', 'solver': 'saga', 'tol': 0.01, 'warm_start': True}\n",
      "0.795 (+/-0.070) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'none', 'solver': 'saga', 'tol': 0.01, 'warm_start': False}\n",
      "0.777 (+/-0.082) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'none', 'solver': 'saga', 'tol': 0.1, 'warm_start': True}\n",
      "0.778 (+/-0.075) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'none', 'solver': 'saga', 'tol': 0.1, 'warm_start': False}\n",
      "0.784 (+/-0.090) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': True}\n",
      "0.784 (+/-0.090) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': False}\n",
      "0.784 (+/-0.090) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': True}\n",
      "0.784 (+/-0.090) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': False}\n",
      "0.784 (+/-0.090) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': True}\n",
      "0.784 (+/-0.090) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': False}\n",
      "0.784 (+/-0.090) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': True}\n",
      "0.784 (+/-0.090) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': False}\n",
      "0.784 (+/-0.090) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': True}\n",
      "0.784 (+/-0.090) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': False}\n",
      "0.784 (+/-0.090) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l1', 'solver': 'saga', 'tol': 1e-05, 'warm_start': True}\n",
      "0.784 (+/-0.090) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l1', 'solver': 'saga', 'tol': 1e-05, 'warm_start': False}\n",
      "0.784 (+/-0.090) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.0001, 'warm_start': True}\n",
      "0.784 (+/-0.090) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.0001, 'warm_start': False}\n",
      "0.784 (+/-0.090) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.001, 'warm_start': True}\n",
      "0.784 (+/-0.090) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.001, 'warm_start': False}\n",
      "0.784 (+/-0.090) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.01, 'warm_start': True}\n",
      "0.784 (+/-0.090) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.01, 'warm_start': False}\n",
      "0.784 (+/-0.090) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.1, 'warm_start': True}\n",
      "0.784 (+/-0.090) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.1, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 1e-05, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 1e-05, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.0001, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.0001, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.001, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.001, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.01, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.01, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.1, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.1, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'none', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'none', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': False}\n",
      "0.792 (+/-0.089) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'none', 'solver': 'saga', 'tol': 1e-05, 'warm_start': True}\n",
      "0.792 (+/-0.089) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'none', 'solver': 'saga', 'tol': 1e-05, 'warm_start': False}\n",
      "0.792 (+/-0.089) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'none', 'solver': 'saga', 'tol': 0.0001, 'warm_start': True}\n",
      "0.792 (+/-0.089) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'none', 'solver': 'saga', 'tol': 0.0001, 'warm_start': False}\n",
      "0.794 (+/-0.085) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'none', 'solver': 'saga', 'tol': 0.001, 'warm_start': True}\n",
      "0.794 (+/-0.085) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'none', 'solver': 'saga', 'tol': 0.001, 'warm_start': False}\n",
      "0.795 (+/-0.070) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'none', 'solver': 'saga', 'tol': 0.01, 'warm_start': True}\n",
      "0.795 (+/-0.070) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'none', 'solver': 'saga', 'tol': 0.01, 'warm_start': False}\n",
      "0.781 (+/-0.082) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'none', 'solver': 'saga', 'tol': 0.1, 'warm_start': True}\n",
      "0.774 (+/-0.077) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'none', 'solver': 'saga', 'tol': 0.1, 'warm_start': False}\n",
      "0.784 (+/-0.090) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': True}\n",
      "0.784 (+/-0.090) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': False}\n",
      "0.784 (+/-0.090) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': True}\n",
      "0.784 (+/-0.090) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': False}\n",
      "0.784 (+/-0.090) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': True}\n",
      "0.784 (+/-0.090) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': False}\n",
      "0.784 (+/-0.090) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': True}\n",
      "0.784 (+/-0.090) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': False}\n",
      "0.784 (+/-0.090) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': True}\n",
      "0.784 (+/-0.090) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': False}\n",
      "0.784 (+/-0.090) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l1', 'solver': 'saga', 'tol': 1e-05, 'warm_start': True}\n",
      "0.784 (+/-0.090) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l1', 'solver': 'saga', 'tol': 1e-05, 'warm_start': False}\n",
      "0.784 (+/-0.090) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.0001, 'warm_start': True}\n",
      "0.784 (+/-0.090) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.0001, 'warm_start': False}\n",
      "0.784 (+/-0.090) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.001, 'warm_start': True}\n",
      "0.784 (+/-0.090) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.001, 'warm_start': False}\n",
      "0.784 (+/-0.090) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.01, 'warm_start': True}\n",
      "0.784 (+/-0.090) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.01, 'warm_start': False}\n",
      "0.784 (+/-0.090) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.1, 'warm_start': True}\n",
      "0.784 (+/-0.090) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.1, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 1e-05, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 1e-05, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.0001, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.0001, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.001, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.001, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.01, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.01, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.1, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.1, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'none', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'none', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': False}\n",
      "0.791 (+/-0.087) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'none', 'solver': 'saga', 'tol': 1e-05, 'warm_start': True}\n",
      "0.791 (+/-0.087) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'none', 'solver': 'saga', 'tol': 1e-05, 'warm_start': False}\n",
      "0.791 (+/-0.087) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'none', 'solver': 'saga', 'tol': 0.0001, 'warm_start': True}\n",
      "0.791 (+/-0.087) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'none', 'solver': 'saga', 'tol': 0.0001, 'warm_start': False}\n",
      "0.794 (+/-0.085) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'none', 'solver': 'saga', 'tol': 0.001, 'warm_start': True}\n",
      "0.794 (+/-0.085) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'none', 'solver': 'saga', 'tol': 0.001, 'warm_start': False}\n",
      "0.795 (+/-0.070) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'none', 'solver': 'saga', 'tol': 0.01, 'warm_start': True}\n",
      "0.794 (+/-0.069) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'none', 'solver': 'saga', 'tol': 0.01, 'warm_start': False}\n",
      "0.785 (+/-0.089) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'none', 'solver': 'saga', 'tol': 0.1, 'warm_start': True}\n",
      "0.775 (+/-0.077) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'none', 'solver': 'saga', 'tol': 0.1, 'warm_start': False}\n",
      "0.784 (+/-0.090) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': True}\n",
      "0.784 (+/-0.090) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': False}\n",
      "0.784 (+/-0.090) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': True}\n",
      "0.784 (+/-0.090) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': False}\n",
      "0.784 (+/-0.090) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': True}\n",
      "0.784 (+/-0.090) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': False}\n",
      "0.784 (+/-0.090) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': True}\n",
      "0.784 (+/-0.090) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': False}\n",
      "0.784 (+/-0.090) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': True}\n",
      "0.784 (+/-0.090) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': False}\n",
      "0.784 (+/-0.090) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l1', 'solver': 'saga', 'tol': 1e-05, 'warm_start': True}\n",
      "0.784 (+/-0.090) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l1', 'solver': 'saga', 'tol': 1e-05, 'warm_start': False}\n",
      "0.784 (+/-0.090) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.0001, 'warm_start': True}\n",
      "0.784 (+/-0.090) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.0001, 'warm_start': False}\n",
      "0.784 (+/-0.090) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.001, 'warm_start': True}\n",
      "0.784 (+/-0.090) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.001, 'warm_start': False}\n",
      "0.784 (+/-0.090) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.01, 'warm_start': True}\n",
      "0.784 (+/-0.090) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.01, 'warm_start': False}\n",
      "0.784 (+/-0.090) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.1, 'warm_start': True}\n",
      "0.784 (+/-0.090) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.1, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 1e-05, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 1e-05, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.0001, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.0001, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.001, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.001, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.01, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.01, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.1, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.1, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'none', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'none', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': False}\n",
      "0.791 (+/-0.087) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'none', 'solver': 'saga', 'tol': 1e-05, 'warm_start': True}\n",
      "0.791 (+/-0.087) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'none', 'solver': 'saga', 'tol': 1e-05, 'warm_start': False}\n",
      "0.791 (+/-0.087) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'none', 'solver': 'saga', 'tol': 0.0001, 'warm_start': True}\n",
      "0.791 (+/-0.087) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'none', 'solver': 'saga', 'tol': 0.0001, 'warm_start': False}\n",
      "0.794 (+/-0.085) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'none', 'solver': 'saga', 'tol': 0.001, 'warm_start': True}\n",
      "0.794 (+/-0.085) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'none', 'solver': 'saga', 'tol': 0.001, 'warm_start': False}\n",
      "0.795 (+/-0.070) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'none', 'solver': 'saga', 'tol': 0.01, 'warm_start': True}\n",
      "0.795 (+/-0.070) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'none', 'solver': 'saga', 'tol': 0.01, 'warm_start': False}\n",
      "0.778 (+/-0.077) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'none', 'solver': 'saga', 'tol': 0.1, 'warm_start': True}\n",
      "0.784 (+/-0.082) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'none', 'solver': 'saga', 'tol': 0.1, 'warm_start': False}\n",
      "0.784 (+/-0.090) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': True}\n",
      "0.784 (+/-0.090) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': False}\n",
      "0.784 (+/-0.090) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': True}\n",
      "0.784 (+/-0.090) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': False}\n",
      "0.784 (+/-0.090) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': True}\n",
      "0.784 (+/-0.090) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': False}\n",
      "0.784 (+/-0.090) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': True}\n",
      "0.784 (+/-0.090) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': False}\n",
      "0.784 (+/-0.090) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': True}\n",
      "0.784 (+/-0.090) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': False}\n",
      "0.784 (+/-0.090) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l1', 'solver': 'saga', 'tol': 1e-05, 'warm_start': True}\n",
      "0.784 (+/-0.090) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l1', 'solver': 'saga', 'tol': 1e-05, 'warm_start': False}\n",
      "0.784 (+/-0.090) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.0001, 'warm_start': True}\n",
      "0.784 (+/-0.090) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.0001, 'warm_start': False}\n",
      "0.784 (+/-0.090) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.001, 'warm_start': True}\n",
      "0.784 (+/-0.090) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.001, 'warm_start': False}\n",
      "0.784 (+/-0.090) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.01, 'warm_start': True}\n",
      "0.784 (+/-0.090) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.01, 'warm_start': False}\n",
      "0.784 (+/-0.090) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.1, 'warm_start': True}\n",
      "0.784 (+/-0.090) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.1, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 1e-05, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 1e-05, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.0001, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.0001, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.001, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.001, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.01, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.01, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.1, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.1, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'none', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'none', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': False}\n",
      "0.791 (+/-0.087) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'none', 'solver': 'saga', 'tol': 1e-05, 'warm_start': True}\n",
      "0.791 (+/-0.087) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'none', 'solver': 'saga', 'tol': 1e-05, 'warm_start': False}\n",
      "0.791 (+/-0.087) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'none', 'solver': 'saga', 'tol': 0.0001, 'warm_start': True}\n",
      "0.791 (+/-0.087) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'none', 'solver': 'saga', 'tol': 0.0001, 'warm_start': False}\n",
      "0.794 (+/-0.085) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'none', 'solver': 'saga', 'tol': 0.001, 'warm_start': True}\n",
      "0.794 (+/-0.085) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'none', 'solver': 'saga', 'tol': 0.001, 'warm_start': False}\n",
      "0.795 (+/-0.070) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'none', 'solver': 'saga', 'tol': 0.01, 'warm_start': True}\n",
      "0.795 (+/-0.070) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'none', 'solver': 'saga', 'tol': 0.01, 'warm_start': False}\n",
      "0.774 (+/-0.074) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'none', 'solver': 'saga', 'tol': 0.1, 'warm_start': True}\n",
      "0.774 (+/-0.079) for {'C': 0.01, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'none', 'solver': 'saga', 'tol': 0.1, 'warm_start': False}\n",
      "0.784 (+/-0.090) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': True}\n",
      "0.784 (+/-0.090) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': False}\n",
      "0.784 (+/-0.090) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': True}\n",
      "0.784 (+/-0.090) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': False}\n",
      "0.784 (+/-0.090) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': True}\n",
      "0.784 (+/-0.090) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': False}\n",
      "0.784 (+/-0.090) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': True}\n",
      "0.784 (+/-0.090) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': False}\n",
      "0.784 (+/-0.090) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': True}\n",
      "0.784 (+/-0.090) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': False}\n",
      "0.784 (+/-0.090) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l1', 'solver': 'saga', 'tol': 1e-05, 'warm_start': True}\n",
      "0.784 (+/-0.090) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l1', 'solver': 'saga', 'tol': 1e-05, 'warm_start': False}\n",
      "0.784 (+/-0.090) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.0001, 'warm_start': True}\n",
      "0.784 (+/-0.090) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.0001, 'warm_start': False}\n",
      "0.784 (+/-0.090) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.001, 'warm_start': True}\n",
      "0.784 (+/-0.090) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.001, 'warm_start': False}\n",
      "0.784 (+/-0.090) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.01, 'warm_start': True}\n",
      "0.784 (+/-0.090) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.01, 'warm_start': False}\n",
      "0.784 (+/-0.090) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.1, 'warm_start': True}\n",
      "0.784 (+/-0.090) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.1, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 1e-05, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 1e-05, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.0001, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.0001, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.001, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.001, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.01, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.01, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.1, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.1, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'none', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'none', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': False}\n",
      "0.764 (+/-0.070) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'none', 'solver': 'saga', 'tol': 1e-05, 'warm_start': True}\n",
      "0.764 (+/-0.070) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'none', 'solver': 'saga', 'tol': 1e-05, 'warm_start': False}\n",
      "0.763 (+/-0.064) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'none', 'solver': 'saga', 'tol': 0.0001, 'warm_start': True}\n",
      "0.764 (+/-0.070) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'none', 'solver': 'saga', 'tol': 0.0001, 'warm_start': False}\n",
      "0.763 (+/-0.064) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'none', 'solver': 'saga', 'tol': 0.001, 'warm_start': True}\n",
      "0.763 (+/-0.064) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'none', 'solver': 'saga', 'tol': 0.001, 'warm_start': False}\n",
      "0.763 (+/-0.069) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'none', 'solver': 'saga', 'tol': 0.01, 'warm_start': True}\n",
      "0.763 (+/-0.069) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'none', 'solver': 'saga', 'tol': 0.01, 'warm_start': False}\n",
      "0.767 (+/-0.050) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'none', 'solver': 'saga', 'tol': 0.1, 'warm_start': True}\n",
      "0.770 (+/-0.067) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'none', 'solver': 'saga', 'tol': 0.1, 'warm_start': False}\n",
      "0.784 (+/-0.090) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': True}\n",
      "0.784 (+/-0.090) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': False}\n",
      "0.784 (+/-0.090) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': True}\n",
      "0.784 (+/-0.090) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': False}\n",
      "0.784 (+/-0.090) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': True}\n",
      "0.784 (+/-0.090) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': False}\n",
      "0.784 (+/-0.090) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': True}\n",
      "0.784 (+/-0.090) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': False}\n",
      "0.784 (+/-0.090) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': True}\n",
      "0.784 (+/-0.090) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': False}\n",
      "0.784 (+/-0.090) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l1', 'solver': 'saga', 'tol': 1e-05, 'warm_start': True}\n",
      "0.784 (+/-0.090) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l1', 'solver': 'saga', 'tol': 1e-05, 'warm_start': False}\n",
      "0.784 (+/-0.090) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.0001, 'warm_start': True}\n",
      "0.784 (+/-0.090) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.0001, 'warm_start': False}\n",
      "0.784 (+/-0.090) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.001, 'warm_start': True}\n",
      "0.784 (+/-0.090) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.001, 'warm_start': False}\n",
      "0.784 (+/-0.090) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.01, 'warm_start': True}\n",
      "0.784 (+/-0.090) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.01, 'warm_start': False}\n",
      "0.784 (+/-0.090) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.1, 'warm_start': True}\n",
      "0.784 (+/-0.090) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.1, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 1e-05, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 1e-05, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.0001, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.0001, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.001, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.001, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.01, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.01, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.1, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.1, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'none', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'none', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': False}\n",
      "0.764 (+/-0.073) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'none', 'solver': 'saga', 'tol': 1e-05, 'warm_start': True}\n",
      "0.764 (+/-0.073) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'none', 'solver': 'saga', 'tol': 1e-05, 'warm_start': False}\n",
      "0.764 (+/-0.073) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'none', 'solver': 'saga', 'tol': 0.0001, 'warm_start': True}\n",
      "0.764 (+/-0.073) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'none', 'solver': 'saga', 'tol': 0.0001, 'warm_start': False}\n",
      "0.763 (+/-0.068) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'none', 'solver': 'saga', 'tol': 0.001, 'warm_start': True}\n",
      "0.763 (+/-0.068) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'none', 'solver': 'saga', 'tol': 0.001, 'warm_start': False}\n",
      "0.764 (+/-0.075) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'none', 'solver': 'saga', 'tol': 0.01, 'warm_start': True}\n",
      "0.764 (+/-0.075) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'none', 'solver': 'saga', 'tol': 0.01, 'warm_start': False}\n",
      "0.770 (+/-0.064) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'none', 'solver': 'saga', 'tol': 0.1, 'warm_start': True}\n",
      "0.774 (+/-0.069) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'none', 'solver': 'saga', 'tol': 0.1, 'warm_start': False}\n",
      "0.784 (+/-0.090) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': True}\n",
      "0.784 (+/-0.090) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': False}\n",
      "0.784 (+/-0.090) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': True}\n",
      "0.784 (+/-0.090) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': False}\n",
      "0.784 (+/-0.090) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': True}\n",
      "0.784 (+/-0.090) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': False}\n",
      "0.784 (+/-0.090) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': True}\n",
      "0.784 (+/-0.090) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': False}\n",
      "0.784 (+/-0.090) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': True}\n",
      "0.784 (+/-0.090) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': False}\n",
      "0.784 (+/-0.090) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l1', 'solver': 'saga', 'tol': 1e-05, 'warm_start': True}\n",
      "0.784 (+/-0.090) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l1', 'solver': 'saga', 'tol': 1e-05, 'warm_start': False}\n",
      "0.784 (+/-0.090) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.0001, 'warm_start': True}\n",
      "0.784 (+/-0.090) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.0001, 'warm_start': False}\n",
      "0.784 (+/-0.090) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.001, 'warm_start': True}\n",
      "0.784 (+/-0.090) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.001, 'warm_start': False}\n",
      "0.784 (+/-0.090) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.01, 'warm_start': True}\n",
      "0.784 (+/-0.090) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.01, 'warm_start': False}\n",
      "0.784 (+/-0.090) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.1, 'warm_start': True}\n",
      "0.784 (+/-0.090) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.1, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 1e-05, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 1e-05, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.0001, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.0001, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.001, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.001, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.01, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.01, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.1, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.1, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'none', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'none', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': False}\n",
      "0.761 (+/-0.072) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'none', 'solver': 'saga', 'tol': 1e-05, 'warm_start': True}\n",
      "0.761 (+/-0.072) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'none', 'solver': 'saga', 'tol': 1e-05, 'warm_start': False}\n",
      "0.761 (+/-0.072) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'none', 'solver': 'saga', 'tol': 0.0001, 'warm_start': True}\n",
      "0.761 (+/-0.072) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'none', 'solver': 'saga', 'tol': 0.0001, 'warm_start': False}\n",
      "0.763 (+/-0.068) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'none', 'solver': 'saga', 'tol': 0.001, 'warm_start': True}\n",
      "0.763 (+/-0.068) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'none', 'solver': 'saga', 'tol': 0.001, 'warm_start': False}\n",
      "0.763 (+/-0.069) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'none', 'solver': 'saga', 'tol': 0.01, 'warm_start': True}\n",
      "0.763 (+/-0.069) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'none', 'solver': 'saga', 'tol': 0.01, 'warm_start': False}\n",
      "0.774 (+/-0.073) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'none', 'solver': 'saga', 'tol': 0.1, 'warm_start': True}\n",
      "0.774 (+/-0.069) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'none', 'solver': 'saga', 'tol': 0.1, 'warm_start': False}\n",
      "0.784 (+/-0.090) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': True}\n",
      "0.784 (+/-0.090) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': False}\n",
      "0.784 (+/-0.090) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': True}\n",
      "0.784 (+/-0.090) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': False}\n",
      "0.784 (+/-0.090) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': True}\n",
      "0.784 (+/-0.090) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': False}\n",
      "0.784 (+/-0.090) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': True}\n",
      "0.784 (+/-0.090) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': False}\n",
      "0.784 (+/-0.090) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': True}\n",
      "0.784 (+/-0.090) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': False}\n",
      "0.784 (+/-0.090) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l1', 'solver': 'saga', 'tol': 1e-05, 'warm_start': True}\n",
      "0.784 (+/-0.090) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l1', 'solver': 'saga', 'tol': 1e-05, 'warm_start': False}\n",
      "0.784 (+/-0.090) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.0001, 'warm_start': True}\n",
      "0.784 (+/-0.090) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.0001, 'warm_start': False}\n",
      "0.784 (+/-0.090) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.001, 'warm_start': True}\n",
      "0.784 (+/-0.090) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.001, 'warm_start': False}\n",
      "0.784 (+/-0.090) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.01, 'warm_start': True}\n",
      "0.784 (+/-0.090) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.01, 'warm_start': False}\n",
      "0.784 (+/-0.090) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.1, 'warm_start': True}\n",
      "0.784 (+/-0.090) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.1, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 1e-05, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 1e-05, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.0001, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.0001, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.001, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.001, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.01, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.01, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.1, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.1, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'none', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'none', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': False}\n",
      "0.761 (+/-0.072) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'none', 'solver': 'saga', 'tol': 1e-05, 'warm_start': True}\n",
      "0.761 (+/-0.072) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'none', 'solver': 'saga', 'tol': 1e-05, 'warm_start': False}\n",
      "0.761 (+/-0.072) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'none', 'solver': 'saga', 'tol': 0.0001, 'warm_start': True}\n",
      "0.761 (+/-0.072) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'none', 'solver': 'saga', 'tol': 0.0001, 'warm_start': False}\n",
      "0.763 (+/-0.068) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'none', 'solver': 'saga', 'tol': 0.001, 'warm_start': True}\n",
      "0.763 (+/-0.068) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'none', 'solver': 'saga', 'tol': 0.001, 'warm_start': False}\n",
      "0.763 (+/-0.069) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'none', 'solver': 'saga', 'tol': 0.01, 'warm_start': True}\n",
      "0.763 (+/-0.069) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'none', 'solver': 'saga', 'tol': 0.01, 'warm_start': False}\n",
      "0.772 (+/-0.068) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'none', 'solver': 'saga', 'tol': 0.1, 'warm_start': True}\n",
      "0.771 (+/-0.072) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'none', 'solver': 'saga', 'tol': 0.1, 'warm_start': False}\n",
      "0.784 (+/-0.090) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': True}\n",
      "0.784 (+/-0.090) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': False}\n",
      "0.784 (+/-0.090) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': True}\n",
      "0.784 (+/-0.090) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': False}\n",
      "0.784 (+/-0.090) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': True}\n",
      "0.784 (+/-0.090) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': False}\n",
      "0.784 (+/-0.090) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': True}\n",
      "0.784 (+/-0.090) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': False}\n",
      "0.784 (+/-0.090) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': True}\n",
      "0.784 (+/-0.090) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': False}\n",
      "0.784 (+/-0.090) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l1', 'solver': 'saga', 'tol': 1e-05, 'warm_start': True}\n",
      "0.784 (+/-0.090) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l1', 'solver': 'saga', 'tol': 1e-05, 'warm_start': False}\n",
      "0.784 (+/-0.090) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.0001, 'warm_start': True}\n",
      "0.784 (+/-0.090) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.0001, 'warm_start': False}\n",
      "0.784 (+/-0.090) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.001, 'warm_start': True}\n",
      "0.784 (+/-0.090) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.001, 'warm_start': False}\n",
      "0.784 (+/-0.090) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.01, 'warm_start': True}\n",
      "0.784 (+/-0.090) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.01, 'warm_start': False}\n",
      "0.784 (+/-0.090) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.1, 'warm_start': True}\n",
      "0.784 (+/-0.090) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.1, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 1e-05, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 1e-05, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.0001, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.0001, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.001, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.001, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.01, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.01, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.1, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.1, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'none', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'none', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': False}\n",
      "0.761 (+/-0.072) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'none', 'solver': 'saga', 'tol': 1e-05, 'warm_start': True}\n",
      "0.761 (+/-0.072) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'none', 'solver': 'saga', 'tol': 1e-05, 'warm_start': False}\n",
      "0.761 (+/-0.072) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'none', 'solver': 'saga', 'tol': 0.0001, 'warm_start': True}\n",
      "0.761 (+/-0.072) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'none', 'solver': 'saga', 'tol': 0.0001, 'warm_start': False}\n",
      "0.763 (+/-0.068) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'none', 'solver': 'saga', 'tol': 0.001, 'warm_start': True}\n",
      "0.763 (+/-0.068) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'none', 'solver': 'saga', 'tol': 0.001, 'warm_start': False}\n",
      "0.763 (+/-0.069) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'none', 'solver': 'saga', 'tol': 0.01, 'warm_start': True}\n",
      "0.763 (+/-0.069) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'none', 'solver': 'saga', 'tol': 0.01, 'warm_start': False}\n",
      "0.770 (+/-0.064) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'none', 'solver': 'saga', 'tol': 0.1, 'warm_start': True}\n",
      "0.771 (+/-0.084) for {'C': 0.01, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'none', 'solver': 'saga', 'tol': 0.1, 'warm_start': False}\n",
      "0.775 (+/-0.088) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': True}\n",
      "0.775 (+/-0.088) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': False}\n",
      "0.775 (+/-0.088) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': True}\n",
      "0.775 (+/-0.088) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': False}\n",
      "0.775 (+/-0.088) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': True}\n",
      "0.775 (+/-0.088) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': False}\n",
      "0.775 (+/-0.088) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': True}\n",
      "0.777 (+/-0.088) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': False}\n",
      "0.771 (+/-0.089) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': True}\n",
      "0.778 (+/-0.083) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': False}\n",
      "0.784 (+/-0.088) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l1', 'solver': 'saga', 'tol': 1e-05, 'warm_start': True}\n",
      "0.784 (+/-0.088) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l1', 'solver': 'saga', 'tol': 1e-05, 'warm_start': False}\n",
      "0.784 (+/-0.088) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.0001, 'warm_start': True}\n",
      "0.784 (+/-0.088) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.0001, 'warm_start': False}\n",
      "0.784 (+/-0.088) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.001, 'warm_start': True}\n",
      "0.784 (+/-0.088) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.001, 'warm_start': False}\n",
      "0.784 (+/-0.088) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.01, 'warm_start': True}\n",
      "0.781 (+/-0.087) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.01, 'warm_start': False}\n",
      "0.768 (+/-0.097) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.1, 'warm_start': True}\n",
      "0.774 (+/-0.086) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.1, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 1e-05, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 1e-05, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.0001, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.0001, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.001, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.001, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.01, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.01, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.1, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.1, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'none', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'none', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': False}\n",
      "0.796 (+/-0.080) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'none', 'solver': 'saga', 'tol': 1e-05, 'warm_start': True}\n",
      "0.796 (+/-0.080) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'none', 'solver': 'saga', 'tol': 1e-05, 'warm_start': False}\n",
      "0.796 (+/-0.080) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'none', 'solver': 'saga', 'tol': 0.0001, 'warm_start': True}\n",
      "0.796 (+/-0.080) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'none', 'solver': 'saga', 'tol': 0.0001, 'warm_start': False}\n",
      "0.796 (+/-0.080) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'none', 'solver': 'saga', 'tol': 0.001, 'warm_start': True}\n",
      "0.796 (+/-0.080) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'none', 'solver': 'saga', 'tol': 0.001, 'warm_start': False}\n",
      "0.794 (+/-0.069) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'none', 'solver': 'saga', 'tol': 0.01, 'warm_start': True}\n",
      "0.795 (+/-0.070) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'none', 'solver': 'saga', 'tol': 0.01, 'warm_start': False}\n",
      "0.780 (+/-0.077) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'none', 'solver': 'saga', 'tol': 0.1, 'warm_start': True}\n",
      "0.775 (+/-0.079) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'none', 'solver': 'saga', 'tol': 0.1, 'warm_start': False}\n",
      "0.775 (+/-0.088) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': True}\n",
      "0.775 (+/-0.088) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': False}\n",
      "0.775 (+/-0.088) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': True}\n",
      "0.775 (+/-0.088) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': False}\n",
      "0.775 (+/-0.088) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': True}\n",
      "0.775 (+/-0.088) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': False}\n",
      "0.775 (+/-0.088) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': True}\n",
      "0.775 (+/-0.088) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': False}\n",
      "0.774 (+/-0.090) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': True}\n",
      "0.772 (+/-0.091) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': False}\n",
      "0.784 (+/-0.088) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l1', 'solver': 'saga', 'tol': 1e-05, 'warm_start': True}\n",
      "0.784 (+/-0.088) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l1', 'solver': 'saga', 'tol': 1e-05, 'warm_start': False}\n",
      "0.784 (+/-0.088) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.0001, 'warm_start': True}\n",
      "0.784 (+/-0.088) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.0001, 'warm_start': False}\n",
      "0.784 (+/-0.088) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.001, 'warm_start': True}\n",
      "0.784 (+/-0.088) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.001, 'warm_start': False}\n",
      "0.782 (+/-0.086) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.01, 'warm_start': True}\n",
      "0.782 (+/-0.092) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.01, 'warm_start': False}\n",
      "0.784 (+/-0.091) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.1, 'warm_start': True}\n",
      "0.777 (+/-0.092) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.1, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 1e-05, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 1e-05, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.0001, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.0001, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.001, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.001, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.01, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.01, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.1, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.1, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'none', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'none', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': False}\n",
      "0.792 (+/-0.089) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'none', 'solver': 'saga', 'tol': 1e-05, 'warm_start': True}\n",
      "0.792 (+/-0.089) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'none', 'solver': 'saga', 'tol': 1e-05, 'warm_start': False}\n",
      "0.792 (+/-0.089) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'none', 'solver': 'saga', 'tol': 0.0001, 'warm_start': True}\n",
      "0.792 (+/-0.089) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'none', 'solver': 'saga', 'tol': 0.0001, 'warm_start': False}\n",
      "0.794 (+/-0.085) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'none', 'solver': 'saga', 'tol': 0.001, 'warm_start': True}\n",
      "0.794 (+/-0.085) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'none', 'solver': 'saga', 'tol': 0.001, 'warm_start': False}\n",
      "0.795 (+/-0.070) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'none', 'solver': 'saga', 'tol': 0.01, 'warm_start': True}\n",
      "0.794 (+/-0.069) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'none', 'solver': 'saga', 'tol': 0.01, 'warm_start': False}\n",
      "0.775 (+/-0.074) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'none', 'solver': 'saga', 'tol': 0.1, 'warm_start': True}\n",
      "0.766 (+/-0.086) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'none', 'solver': 'saga', 'tol': 0.1, 'warm_start': False}\n",
      "0.775 (+/-0.088) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': True}\n",
      "0.775 (+/-0.088) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': False}\n",
      "0.775 (+/-0.088) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': True}\n",
      "0.775 (+/-0.088) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': False}\n",
      "0.775 (+/-0.088) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': True}\n",
      "0.775 (+/-0.088) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': False}\n",
      "0.774 (+/-0.089) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': True}\n",
      "0.777 (+/-0.088) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': False}\n",
      "0.774 (+/-0.090) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': True}\n",
      "0.770 (+/-0.081) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': False}\n",
      "0.784 (+/-0.088) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l1', 'solver': 'saga', 'tol': 1e-05, 'warm_start': True}\n",
      "0.784 (+/-0.088) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l1', 'solver': 'saga', 'tol': 1e-05, 'warm_start': False}\n",
      "0.784 (+/-0.088) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.0001, 'warm_start': True}\n",
      "0.784 (+/-0.088) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.0001, 'warm_start': False}\n",
      "0.784 (+/-0.088) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.001, 'warm_start': True}\n",
      "0.784 (+/-0.088) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.001, 'warm_start': False}\n",
      "0.782 (+/-0.090) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.01, 'warm_start': True}\n",
      "0.778 (+/-0.088) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.01, 'warm_start': False}\n",
      "0.775 (+/-0.082) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.1, 'warm_start': True}\n",
      "0.774 (+/-0.084) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.1, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 1e-05, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 1e-05, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.0001, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.0001, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.001, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.001, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.01, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.01, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.1, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.1, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'none', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'none', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': False}\n",
      "0.791 (+/-0.087) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'none', 'solver': 'saga', 'tol': 1e-05, 'warm_start': True}\n",
      "0.791 (+/-0.087) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'none', 'solver': 'saga', 'tol': 1e-05, 'warm_start': False}\n",
      "0.791 (+/-0.087) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'none', 'solver': 'saga', 'tol': 0.0001, 'warm_start': True}\n",
      "0.791 (+/-0.087) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'none', 'solver': 'saga', 'tol': 0.0001, 'warm_start': False}\n",
      "0.794 (+/-0.085) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'none', 'solver': 'saga', 'tol': 0.001, 'warm_start': True}\n",
      "0.794 (+/-0.085) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'none', 'solver': 'saga', 'tol': 0.001, 'warm_start': False}\n",
      "0.795 (+/-0.070) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'none', 'solver': 'saga', 'tol': 0.01, 'warm_start': True}\n",
      "0.795 (+/-0.070) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'none', 'solver': 'saga', 'tol': 0.01, 'warm_start': False}\n",
      "0.780 (+/-0.080) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'none', 'solver': 'saga', 'tol': 0.1, 'warm_start': True}\n",
      "0.778 (+/-0.082) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'none', 'solver': 'saga', 'tol': 0.1, 'warm_start': False}\n",
      "0.775 (+/-0.088) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': True}\n",
      "0.775 (+/-0.088) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': False}\n",
      "0.775 (+/-0.088) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': True}\n",
      "0.775 (+/-0.088) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': False}\n",
      "0.775 (+/-0.088) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': True}\n",
      "0.775 (+/-0.088) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': False}\n",
      "0.774 (+/-0.089) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': True}\n",
      "0.774 (+/-0.089) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': False}\n",
      "0.777 (+/-0.085) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': True}\n",
      "0.772 (+/-0.090) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': False}\n",
      "0.784 (+/-0.088) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l1', 'solver': 'saga', 'tol': 1e-05, 'warm_start': True}\n",
      "0.784 (+/-0.088) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l1', 'solver': 'saga', 'tol': 1e-05, 'warm_start': False}\n",
      "0.784 (+/-0.088) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.0001, 'warm_start': True}\n",
      "0.784 (+/-0.088) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.0001, 'warm_start': False}\n",
      "0.784 (+/-0.088) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.001, 'warm_start': True}\n",
      "0.784 (+/-0.088) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.001, 'warm_start': False}\n",
      "0.784 (+/-0.088) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.01, 'warm_start': True}\n",
      "0.781 (+/-0.087) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.01, 'warm_start': False}\n",
      "0.774 (+/-0.091) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.1, 'warm_start': True}\n",
      "0.778 (+/-0.084) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.1, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 1e-05, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 1e-05, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.0001, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.0001, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.001, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.001, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.01, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.01, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.1, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.1, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'none', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'none', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': False}\n",
      "0.791 (+/-0.087) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'none', 'solver': 'saga', 'tol': 1e-05, 'warm_start': True}\n",
      "0.791 (+/-0.087) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'none', 'solver': 'saga', 'tol': 1e-05, 'warm_start': False}\n",
      "0.791 (+/-0.087) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'none', 'solver': 'saga', 'tol': 0.0001, 'warm_start': True}\n",
      "0.791 (+/-0.087) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'none', 'solver': 'saga', 'tol': 0.0001, 'warm_start': False}\n",
      "0.794 (+/-0.085) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'none', 'solver': 'saga', 'tol': 0.001, 'warm_start': True}\n",
      "0.794 (+/-0.085) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'none', 'solver': 'saga', 'tol': 0.001, 'warm_start': False}\n",
      "0.795 (+/-0.070) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'none', 'solver': 'saga', 'tol': 0.01, 'warm_start': True}\n",
      "0.794 (+/-0.069) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'none', 'solver': 'saga', 'tol': 0.01, 'warm_start': False}\n",
      "0.780 (+/-0.078) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'none', 'solver': 'saga', 'tol': 0.1, 'warm_start': True}\n",
      "0.775 (+/-0.083) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'none', 'solver': 'saga', 'tol': 0.1, 'warm_start': False}\n",
      "0.775 (+/-0.088) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': True}\n",
      "0.775 (+/-0.088) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': False}\n",
      "0.775 (+/-0.088) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': True}\n",
      "0.775 (+/-0.088) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': False}\n",
      "0.775 (+/-0.088) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': True}\n",
      "0.775 (+/-0.088) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': False}\n",
      "0.777 (+/-0.088) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': True}\n",
      "0.777 (+/-0.088) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': False}\n",
      "0.770 (+/-0.089) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': True}\n",
      "0.774 (+/-0.089) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': False}\n",
      "0.784 (+/-0.088) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l1', 'solver': 'saga', 'tol': 1e-05, 'warm_start': True}\n",
      "0.784 (+/-0.088) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l1', 'solver': 'saga', 'tol': 1e-05, 'warm_start': False}\n",
      "0.784 (+/-0.088) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.0001, 'warm_start': True}\n",
      "0.784 (+/-0.088) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.0001, 'warm_start': False}\n",
      "0.784 (+/-0.088) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.001, 'warm_start': True}\n",
      "0.784 (+/-0.088) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.001, 'warm_start': False}\n",
      "0.782 (+/-0.090) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.01, 'warm_start': True}\n",
      "0.784 (+/-0.088) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.01, 'warm_start': False}\n",
      "0.774 (+/-0.088) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.1, 'warm_start': True}\n",
      "0.772 (+/-0.090) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.1, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 1e-05, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 1e-05, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.0001, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.0001, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.001, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.001, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.01, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.01, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.1, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.1, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'none', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'none', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': False}\n",
      "0.791 (+/-0.087) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'none', 'solver': 'saga', 'tol': 1e-05, 'warm_start': True}\n",
      "0.791 (+/-0.087) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'none', 'solver': 'saga', 'tol': 1e-05, 'warm_start': False}\n",
      "0.791 (+/-0.087) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'none', 'solver': 'saga', 'tol': 0.0001, 'warm_start': True}\n",
      "0.791 (+/-0.087) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'none', 'solver': 'saga', 'tol': 0.0001, 'warm_start': False}\n",
      "0.794 (+/-0.085) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'none', 'solver': 'saga', 'tol': 0.001, 'warm_start': True}\n",
      "0.794 (+/-0.085) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'none', 'solver': 'saga', 'tol': 0.001, 'warm_start': False}\n",
      "0.795 (+/-0.070) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'none', 'solver': 'saga', 'tol': 0.01, 'warm_start': True}\n",
      "0.795 (+/-0.070) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'none', 'solver': 'saga', 'tol': 0.01, 'warm_start': False}\n",
      "0.773 (+/-0.075) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'none', 'solver': 'saga', 'tol': 0.1, 'warm_start': True}\n",
      "0.780 (+/-0.092) for {'C': 0.1, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'none', 'solver': 'saga', 'tol': 0.1, 'warm_start': False}\n",
      "0.756 (+/-0.075) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': True}\n",
      "0.756 (+/-0.075) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': False}\n",
      "0.756 (+/-0.075) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': True}\n",
      "0.756 (+/-0.075) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': False}\n",
      "0.756 (+/-0.075) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': True}\n",
      "0.757 (+/-0.078) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': False}\n",
      "0.761 (+/-0.082) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': True}\n",
      "0.756 (+/-0.075) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': False}\n",
      "0.750 (+/-0.064) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': True}\n",
      "0.760 (+/-0.077) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': False}\n",
      "0.756 (+/-0.075) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l1', 'solver': 'saga', 'tol': 1e-05, 'warm_start': True}\n",
      "0.756 (+/-0.075) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l1', 'solver': 'saga', 'tol': 1e-05, 'warm_start': False}\n",
      "0.756 (+/-0.075) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.0001, 'warm_start': True}\n",
      "0.756 (+/-0.075) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.0001, 'warm_start': False}\n",
      "0.757 (+/-0.078) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.001, 'warm_start': True}\n",
      "0.760 (+/-0.084) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.001, 'warm_start': False}\n",
      "0.758 (+/-0.076) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.01, 'warm_start': True}\n",
      "0.756 (+/-0.079) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.01, 'warm_start': False}\n",
      "0.761 (+/-0.078) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.1, 'warm_start': True}\n",
      "0.761 (+/-0.080) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.1, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 1e-05, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 1e-05, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.0001, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.0001, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.001, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.001, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.01, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.01, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.1, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.1, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'none', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'none', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': False}\n",
      "0.763 (+/-0.064) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'none', 'solver': 'saga', 'tol': 1e-05, 'warm_start': True}\n",
      "0.763 (+/-0.064) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'none', 'solver': 'saga', 'tol': 1e-05, 'warm_start': False}\n",
      "0.763 (+/-0.064) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'none', 'solver': 'saga', 'tol': 0.0001, 'warm_start': True}\n",
      "0.764 (+/-0.070) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'none', 'solver': 'saga', 'tol': 0.0001, 'warm_start': False}\n",
      "0.763 (+/-0.064) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'none', 'solver': 'saga', 'tol': 0.001, 'warm_start': True}\n",
      "0.763 (+/-0.064) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'none', 'solver': 'saga', 'tol': 0.001, 'warm_start': False}\n",
      "0.763 (+/-0.069) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'none', 'solver': 'saga', 'tol': 0.01, 'warm_start': True}\n",
      "0.763 (+/-0.069) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'none', 'solver': 'saga', 'tol': 0.01, 'warm_start': False}\n",
      "0.771 (+/-0.084) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'none', 'solver': 'saga', 'tol': 0.1, 'warm_start': True}\n",
      "0.771 (+/-0.057) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'none', 'solver': 'saga', 'tol': 0.1, 'warm_start': False}\n",
      "0.756 (+/-0.075) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': True}\n",
      "0.756 (+/-0.075) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': False}\n",
      "0.756 (+/-0.075) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': True}\n",
      "0.756 (+/-0.075) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': False}\n",
      "0.756 (+/-0.075) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': True}\n",
      "0.756 (+/-0.075) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': False}\n",
      "0.758 (+/-0.082) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': True}\n",
      "0.757 (+/-0.078) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': False}\n",
      "0.756 (+/-0.077) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': True}\n",
      "0.754 (+/-0.072) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': False}\n",
      "0.756 (+/-0.075) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l1', 'solver': 'saga', 'tol': 1e-05, 'warm_start': True}\n",
      "0.756 (+/-0.075) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l1', 'solver': 'saga', 'tol': 1e-05, 'warm_start': False}\n",
      "0.756 (+/-0.075) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.0001, 'warm_start': True}\n",
      "0.756 (+/-0.075) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.0001, 'warm_start': False}\n",
      "0.760 (+/-0.084) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.001, 'warm_start': True}\n",
      "0.758 (+/-0.081) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.001, 'warm_start': False}\n",
      "0.760 (+/-0.082) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.01, 'warm_start': True}\n",
      "0.760 (+/-0.080) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.01, 'warm_start': False}\n",
      "0.756 (+/-0.065) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.1, 'warm_start': True}\n",
      "0.756 (+/-0.072) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.1, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 1e-05, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 1e-05, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.0001, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.0001, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.001, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.001, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.01, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.01, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.1, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.1, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'none', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'none', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': False}\n",
      "0.764 (+/-0.073) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'none', 'solver': 'saga', 'tol': 1e-05, 'warm_start': True}\n",
      "0.764 (+/-0.073) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'none', 'solver': 'saga', 'tol': 1e-05, 'warm_start': False}\n",
      "0.764 (+/-0.073) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'none', 'solver': 'saga', 'tol': 0.0001, 'warm_start': True}\n",
      "0.764 (+/-0.073) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'none', 'solver': 'saga', 'tol': 0.0001, 'warm_start': False}\n",
      "0.763 (+/-0.068) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'none', 'solver': 'saga', 'tol': 0.001, 'warm_start': True}\n",
      "0.763 (+/-0.068) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'none', 'solver': 'saga', 'tol': 0.001, 'warm_start': False}\n",
      "0.763 (+/-0.069) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'none', 'solver': 'saga', 'tol': 0.01, 'warm_start': True}\n",
      "0.763 (+/-0.069) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'none', 'solver': 'saga', 'tol': 0.01, 'warm_start': False}\n",
      "0.765 (+/-0.047) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'none', 'solver': 'saga', 'tol': 0.1, 'warm_start': True}\n",
      "0.771 (+/-0.073) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'none', 'solver': 'saga', 'tol': 0.1, 'warm_start': False}\n",
      "0.756 (+/-0.075) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': True}\n",
      "0.756 (+/-0.075) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': False}\n",
      "0.756 (+/-0.075) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': True}\n",
      "0.756 (+/-0.075) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': False}\n",
      "0.756 (+/-0.075) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': True}\n",
      "0.757 (+/-0.078) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': False}\n",
      "0.758 (+/-0.082) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': True}\n",
      "0.757 (+/-0.078) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': False}\n",
      "0.754 (+/-0.072) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': True}\n",
      "0.760 (+/-0.079) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': False}\n",
      "0.756 (+/-0.075) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l1', 'solver': 'saga', 'tol': 1e-05, 'warm_start': True}\n",
      "0.756 (+/-0.075) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l1', 'solver': 'saga', 'tol': 1e-05, 'warm_start': False}\n",
      "0.756 (+/-0.075) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.0001, 'warm_start': True}\n",
      "0.756 (+/-0.075) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.0001, 'warm_start': False}\n",
      "0.758 (+/-0.081) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.001, 'warm_start': True}\n",
      "0.760 (+/-0.084) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.001, 'warm_start': False}\n",
      "0.758 (+/-0.080) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.01, 'warm_start': True}\n",
      "0.761 (+/-0.082) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.01, 'warm_start': False}\n",
      "0.758 (+/-0.073) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.1, 'warm_start': True}\n",
      "0.761 (+/-0.061) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.1, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 1e-05, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 1e-05, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.0001, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.0001, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.001, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.001, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.01, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.01, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.1, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.1, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'none', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'none', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': False}\n",
      "0.761 (+/-0.072) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'none', 'solver': 'saga', 'tol': 1e-05, 'warm_start': True}\n",
      "0.761 (+/-0.072) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'none', 'solver': 'saga', 'tol': 1e-05, 'warm_start': False}\n",
      "0.761 (+/-0.072) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'none', 'solver': 'saga', 'tol': 0.0001, 'warm_start': True}\n",
      "0.761 (+/-0.072) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'none', 'solver': 'saga', 'tol': 0.0001, 'warm_start': False}\n",
      "0.763 (+/-0.068) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'none', 'solver': 'saga', 'tol': 0.001, 'warm_start': True}\n",
      "0.763 (+/-0.068) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'none', 'solver': 'saga', 'tol': 0.001, 'warm_start': False}\n",
      "0.763 (+/-0.069) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'none', 'solver': 'saga', 'tol': 0.01, 'warm_start': True}\n",
      "0.763 (+/-0.069) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'none', 'solver': 'saga', 'tol': 0.01, 'warm_start': False}\n",
      "0.768 (+/-0.076) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'none', 'solver': 'saga', 'tol': 0.1, 'warm_start': True}\n",
      "0.768 (+/-0.070) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'none', 'solver': 'saga', 'tol': 0.1, 'warm_start': False}\n",
      "0.756 (+/-0.075) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': True}\n",
      "0.756 (+/-0.075) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': False}\n",
      "0.756 (+/-0.075) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': True}\n",
      "0.756 (+/-0.075) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': False}\n",
      "0.756 (+/-0.075) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': True}\n",
      "0.756 (+/-0.075) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': False}\n",
      "0.757 (+/-0.078) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': True}\n",
      "0.760 (+/-0.084) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': False}\n",
      "0.760 (+/-0.072) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': True}\n",
      "0.756 (+/-0.074) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': False}\n",
      "0.756 (+/-0.075) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l1', 'solver': 'saga', 'tol': 1e-05, 'warm_start': True}\n",
      "0.756 (+/-0.075) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l1', 'solver': 'saga', 'tol': 1e-05, 'warm_start': False}\n",
      "0.756 (+/-0.075) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.0001, 'warm_start': True}\n",
      "0.756 (+/-0.075) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.0001, 'warm_start': False}\n",
      "0.758 (+/-0.081) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.001, 'warm_start': True}\n",
      "0.757 (+/-0.078) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.001, 'warm_start': False}\n",
      "0.756 (+/-0.075) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.01, 'warm_start': True}\n",
      "0.758 (+/-0.082) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.01, 'warm_start': False}\n",
      "0.763 (+/-0.070) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.1, 'warm_start': True}\n",
      "0.761 (+/-0.069) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.1, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 1e-05, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 1e-05, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.0001, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.0001, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.001, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.001, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.01, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.01, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.1, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.1, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'none', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'none', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': False}\n",
      "0.761 (+/-0.072) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'none', 'solver': 'saga', 'tol': 1e-05, 'warm_start': True}\n",
      "0.761 (+/-0.072) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'none', 'solver': 'saga', 'tol': 1e-05, 'warm_start': False}\n",
      "0.761 (+/-0.072) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'none', 'solver': 'saga', 'tol': 0.0001, 'warm_start': True}\n",
      "0.761 (+/-0.072) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'none', 'solver': 'saga', 'tol': 0.0001, 'warm_start': False}\n",
      "0.763 (+/-0.068) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'none', 'solver': 'saga', 'tol': 0.001, 'warm_start': True}\n",
      "0.763 (+/-0.068) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'none', 'solver': 'saga', 'tol': 0.001, 'warm_start': False}\n",
      "0.763 (+/-0.069) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'none', 'solver': 'saga', 'tol': 0.01, 'warm_start': True}\n",
      "0.763 (+/-0.069) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'none', 'solver': 'saga', 'tol': 0.01, 'warm_start': False}\n",
      "0.774 (+/-0.071) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'none', 'solver': 'saga', 'tol': 0.1, 'warm_start': True}\n",
      "0.768 (+/-0.087) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'none', 'solver': 'saga', 'tol': 0.1, 'warm_start': False}\n",
      "0.756 (+/-0.075) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': True}\n",
      "0.756 (+/-0.075) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': False}\n",
      "0.756 (+/-0.075) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': True}\n",
      "0.756 (+/-0.075) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': False}\n",
      "0.756 (+/-0.075) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': True}\n",
      "0.756 (+/-0.075) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': False}\n",
      "0.757 (+/-0.079) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': True}\n",
      "0.756 (+/-0.070) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': False}\n",
      "0.764 (+/-0.070) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': True}\n",
      "0.758 (+/-0.078) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': False}\n",
      "0.756 (+/-0.075) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l1', 'solver': 'saga', 'tol': 1e-05, 'warm_start': True}\n",
      "0.756 (+/-0.075) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l1', 'solver': 'saga', 'tol': 1e-05, 'warm_start': False}\n",
      "0.756 (+/-0.075) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.0001, 'warm_start': True}\n",
      "0.756 (+/-0.075) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.0001, 'warm_start': False}\n",
      "0.758 (+/-0.081) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.001, 'warm_start': True}\n",
      "0.757 (+/-0.078) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.001, 'warm_start': False}\n",
      "0.758 (+/-0.086) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.01, 'warm_start': True}\n",
      "0.758 (+/-0.079) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.01, 'warm_start': False}\n",
      "0.764 (+/-0.071) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.1, 'warm_start': True}\n",
      "0.758 (+/-0.076) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.1, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 1e-05, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 1e-05, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.0001, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.0001, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.001, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.001, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.01, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.01, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.1, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.1, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'none', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'none', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': False}\n",
      "0.761 (+/-0.072) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'none', 'solver': 'saga', 'tol': 1e-05, 'warm_start': True}\n",
      "0.761 (+/-0.072) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'none', 'solver': 'saga', 'tol': 1e-05, 'warm_start': False}\n",
      "0.761 (+/-0.072) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'none', 'solver': 'saga', 'tol': 0.0001, 'warm_start': True}\n",
      "0.761 (+/-0.072) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'none', 'solver': 'saga', 'tol': 0.0001, 'warm_start': False}\n",
      "0.763 (+/-0.068) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'none', 'solver': 'saga', 'tol': 0.001, 'warm_start': True}\n",
      "0.763 (+/-0.068) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'none', 'solver': 'saga', 'tol': 0.001, 'warm_start': False}\n",
      "0.763 (+/-0.069) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'none', 'solver': 'saga', 'tol': 0.01, 'warm_start': True}\n",
      "0.763 (+/-0.069) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'none', 'solver': 'saga', 'tol': 0.01, 'warm_start': False}\n",
      "0.775 (+/-0.080) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'none', 'solver': 'saga', 'tol': 0.1, 'warm_start': True}\n",
      "0.770 (+/-0.067) for {'C': 0.1, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'none', 'solver': 'saga', 'tol': 0.1, 'warm_start': False}\n",
      "0.796 (+/-0.092) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': True}\n",
      "0.796 (+/-0.092) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': False}\n",
      "0.796 (+/-0.092) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': True}\n",
      "0.796 (+/-0.092) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': False}\n",
      "0.796 (+/-0.092) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': True}\n",
      "0.796 (+/-0.092) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': False}\n",
      "0.796 (+/-0.092) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': True}\n",
      "0.796 (+/-0.092) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': False}\n",
      "0.791 (+/-0.072) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': True}\n",
      "0.796 (+/-0.073) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': False}\n",
      "0.796 (+/-0.092) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l1', 'solver': 'saga', 'tol': 1e-05, 'warm_start': True}\n",
      "0.796 (+/-0.092) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l1', 'solver': 'saga', 'tol': 1e-05, 'warm_start': False}\n",
      "0.796 (+/-0.092) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.0001, 'warm_start': True}\n",
      "0.796 (+/-0.092) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.0001, 'warm_start': False}\n",
      "0.796 (+/-0.092) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.001, 'warm_start': True}\n",
      "0.796 (+/-0.092) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.001, 'warm_start': False}\n",
      "0.795 (+/-0.076) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.01, 'warm_start': True}\n",
      "0.795 (+/-0.076) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.01, 'warm_start': False}\n",
      "0.767 (+/-0.076) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.1, 'warm_start': True}\n",
      "0.782 (+/-0.085) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.1, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 1e-05, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 1e-05, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.0001, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.0001, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.001, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.001, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.01, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.01, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.1, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.1, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'none', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'none', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': False}\n",
      "0.796 (+/-0.080) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'none', 'solver': 'saga', 'tol': 1e-05, 'warm_start': True}\n",
      "0.796 (+/-0.080) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'none', 'solver': 'saga', 'tol': 1e-05, 'warm_start': False}\n",
      "0.796 (+/-0.080) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'none', 'solver': 'saga', 'tol': 0.0001, 'warm_start': True}\n",
      "0.796 (+/-0.080) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'none', 'solver': 'saga', 'tol': 0.0001, 'warm_start': False}\n",
      "0.796 (+/-0.080) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'none', 'solver': 'saga', 'tol': 0.001, 'warm_start': True}\n",
      "0.796 (+/-0.080) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'none', 'solver': 'saga', 'tol': 0.001, 'warm_start': False}\n",
      "0.795 (+/-0.070) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'none', 'solver': 'saga', 'tol': 0.01, 'warm_start': True}\n",
      "0.795 (+/-0.070) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'none', 'solver': 'saga', 'tol': 0.01, 'warm_start': False}\n",
      "0.774 (+/-0.081) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'none', 'solver': 'saga', 'tol': 0.1, 'warm_start': True}\n",
      "0.774 (+/-0.079) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'none', 'solver': 'saga', 'tol': 0.1, 'warm_start': False}\n",
      "0.796 (+/-0.092) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': True}\n",
      "0.796 (+/-0.092) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': False}\n",
      "0.796 (+/-0.092) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': True}\n",
      "0.796 (+/-0.092) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': False}\n",
      "0.796 (+/-0.092) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': True}\n",
      "0.796 (+/-0.092) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': False}\n",
      "0.796 (+/-0.092) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': True}\n",
      "0.796 (+/-0.083) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': False}\n",
      "0.789 (+/-0.066) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': True}\n",
      "0.796 (+/-0.078) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': False}\n",
      "0.796 (+/-0.092) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l1', 'solver': 'saga', 'tol': 1e-05, 'warm_start': True}\n",
      "0.796 (+/-0.092) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l1', 'solver': 'saga', 'tol': 1e-05, 'warm_start': False}\n",
      "0.796 (+/-0.092) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.0001, 'warm_start': True}\n",
      "0.796 (+/-0.092) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.0001, 'warm_start': False}\n",
      "0.796 (+/-0.092) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.001, 'warm_start': True}\n",
      "0.796 (+/-0.092) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.001, 'warm_start': False}\n",
      "0.795 (+/-0.076) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.01, 'warm_start': True}\n",
      "0.795 (+/-0.076) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.01, 'warm_start': False}\n",
      "0.773 (+/-0.087) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.1, 'warm_start': True}\n",
      "0.777 (+/-0.078) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.1, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 1e-05, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 1e-05, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.0001, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.0001, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.001, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.001, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.01, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.01, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.1, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.1, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'none', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'none', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': False}\n",
      "0.792 (+/-0.089) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'none', 'solver': 'saga', 'tol': 1e-05, 'warm_start': True}\n",
      "0.792 (+/-0.089) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'none', 'solver': 'saga', 'tol': 1e-05, 'warm_start': False}\n",
      "0.792 (+/-0.089) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'none', 'solver': 'saga', 'tol': 0.0001, 'warm_start': True}\n",
      "0.792 (+/-0.089) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'none', 'solver': 'saga', 'tol': 0.0001, 'warm_start': False}\n",
      "0.794 (+/-0.085) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'none', 'solver': 'saga', 'tol': 0.001, 'warm_start': True}\n",
      "0.794 (+/-0.085) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'none', 'solver': 'saga', 'tol': 0.001, 'warm_start': False}\n",
      "0.795 (+/-0.070) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'none', 'solver': 'saga', 'tol': 0.01, 'warm_start': True}\n",
      "0.794 (+/-0.069) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'none', 'solver': 'saga', 'tol': 0.01, 'warm_start': False}\n",
      "0.774 (+/-0.078) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'none', 'solver': 'saga', 'tol': 0.1, 'warm_start': True}\n",
      "0.777 (+/-0.084) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'none', 'solver': 'saga', 'tol': 0.1, 'warm_start': False}\n",
      "0.796 (+/-0.092) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': True}\n",
      "0.796 (+/-0.092) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': False}\n",
      "0.796 (+/-0.092) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': True}\n",
      "0.796 (+/-0.092) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': False}\n",
      "0.796 (+/-0.092) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': True}\n",
      "0.796 (+/-0.092) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': False}\n",
      "0.794 (+/-0.078) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': True}\n",
      "0.795 (+/-0.085) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': False}\n",
      "0.795 (+/-0.069) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': True}\n",
      "0.792 (+/-0.077) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': False}\n",
      "0.796 (+/-0.092) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l1', 'solver': 'saga', 'tol': 1e-05, 'warm_start': True}\n",
      "0.796 (+/-0.092) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l1', 'solver': 'saga', 'tol': 1e-05, 'warm_start': False}\n",
      "0.796 (+/-0.092) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.0001, 'warm_start': True}\n",
      "0.796 (+/-0.092) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.0001, 'warm_start': False}\n",
      "0.796 (+/-0.092) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.001, 'warm_start': True}\n",
      "0.796 (+/-0.092) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.001, 'warm_start': False}\n",
      "0.795 (+/-0.076) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.01, 'warm_start': True}\n",
      "0.795 (+/-0.076) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.01, 'warm_start': False}\n",
      "0.781 (+/-0.079) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.1, 'warm_start': True}\n",
      "0.782 (+/-0.076) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.1, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 1e-05, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 1e-05, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.0001, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.0001, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.001, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.001, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.01, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.01, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.1, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.1, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'none', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'none', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': False}\n",
      "0.791 (+/-0.087) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'none', 'solver': 'saga', 'tol': 1e-05, 'warm_start': True}\n",
      "0.791 (+/-0.087) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'none', 'solver': 'saga', 'tol': 1e-05, 'warm_start': False}\n",
      "0.791 (+/-0.087) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'none', 'solver': 'saga', 'tol': 0.0001, 'warm_start': True}\n",
      "0.791 (+/-0.087) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'none', 'solver': 'saga', 'tol': 0.0001, 'warm_start': False}\n",
      "0.794 (+/-0.085) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'none', 'solver': 'saga', 'tol': 0.001, 'warm_start': True}\n",
      "0.794 (+/-0.085) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'none', 'solver': 'saga', 'tol': 0.001, 'warm_start': False}\n",
      "0.795 (+/-0.070) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'none', 'solver': 'saga', 'tol': 0.01, 'warm_start': True}\n",
      "0.794 (+/-0.069) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'none', 'solver': 'saga', 'tol': 0.01, 'warm_start': False}\n",
      "0.775 (+/-0.077) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'none', 'solver': 'saga', 'tol': 0.1, 'warm_start': True}\n",
      "0.780 (+/-0.087) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'none', 'solver': 'saga', 'tol': 0.1, 'warm_start': False}\n",
      "0.796 (+/-0.092) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': True}\n",
      "0.796 (+/-0.092) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': False}\n",
      "0.796 (+/-0.092) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': True}\n",
      "0.796 (+/-0.092) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': False}\n",
      "0.796 (+/-0.092) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': True}\n",
      "0.796 (+/-0.092) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': False}\n",
      "0.792 (+/-0.071) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': True}\n",
      "0.795 (+/-0.085) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': False}\n",
      "0.795 (+/-0.075) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': True}\n",
      "0.792 (+/-0.070) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': False}\n",
      "0.796 (+/-0.092) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l1', 'solver': 'saga', 'tol': 1e-05, 'warm_start': True}\n",
      "0.796 (+/-0.092) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l1', 'solver': 'saga', 'tol': 1e-05, 'warm_start': False}\n",
      "0.796 (+/-0.092) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.0001, 'warm_start': True}\n",
      "0.796 (+/-0.092) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.0001, 'warm_start': False}\n",
      "0.796 (+/-0.092) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.001, 'warm_start': True}\n",
      "0.796 (+/-0.092) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.001, 'warm_start': False}\n",
      "0.795 (+/-0.076) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.01, 'warm_start': True}\n",
      "0.795 (+/-0.076) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.01, 'warm_start': False}\n",
      "0.778 (+/-0.072) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.1, 'warm_start': True}\n",
      "0.771 (+/-0.080) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.1, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 1e-05, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 1e-05, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.0001, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.0001, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.001, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.001, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.01, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.01, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.1, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.1, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'none', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'none', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': False}\n",
      "0.791 (+/-0.087) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'none', 'solver': 'saga', 'tol': 1e-05, 'warm_start': True}\n",
      "0.791 (+/-0.087) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'none', 'solver': 'saga', 'tol': 1e-05, 'warm_start': False}\n",
      "0.791 (+/-0.087) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'none', 'solver': 'saga', 'tol': 0.0001, 'warm_start': True}\n",
      "0.791 (+/-0.087) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'none', 'solver': 'saga', 'tol': 0.0001, 'warm_start': False}\n",
      "0.794 (+/-0.085) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'none', 'solver': 'saga', 'tol': 0.001, 'warm_start': True}\n",
      "0.794 (+/-0.085) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'none', 'solver': 'saga', 'tol': 0.001, 'warm_start': False}\n",
      "0.795 (+/-0.070) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'none', 'solver': 'saga', 'tol': 0.01, 'warm_start': True}\n",
      "0.795 (+/-0.070) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'none', 'solver': 'saga', 'tol': 0.01, 'warm_start': False}\n",
      "0.782 (+/-0.086) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'none', 'solver': 'saga', 'tol': 0.1, 'warm_start': True}\n",
      "0.777 (+/-0.081) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'none', 'solver': 'saga', 'tol': 0.1, 'warm_start': False}\n",
      "0.796 (+/-0.092) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': True}\n",
      "0.796 (+/-0.092) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': False}\n",
      "0.796 (+/-0.092) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': True}\n",
      "0.796 (+/-0.092) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': False}\n",
      "0.796 (+/-0.092) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': True}\n",
      "0.796 (+/-0.092) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': False}\n",
      "0.795 (+/-0.085) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': True}\n",
      "0.794 (+/-0.084) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': False}\n",
      "0.791 (+/-0.081) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': True}\n",
      "0.795 (+/-0.076) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': False}\n",
      "0.796 (+/-0.092) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l1', 'solver': 'saga', 'tol': 1e-05, 'warm_start': True}\n",
      "0.796 (+/-0.092) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l1', 'solver': 'saga', 'tol': 1e-05, 'warm_start': False}\n",
      "0.796 (+/-0.092) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.0001, 'warm_start': True}\n",
      "0.796 (+/-0.092) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.0001, 'warm_start': False}\n",
      "0.796 (+/-0.092) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.001, 'warm_start': True}\n",
      "0.796 (+/-0.092) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.001, 'warm_start': False}\n",
      "0.795 (+/-0.076) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.01, 'warm_start': True}\n",
      "0.795 (+/-0.076) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.01, 'warm_start': False}\n",
      "0.775 (+/-0.069) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.1, 'warm_start': True}\n",
      "0.774 (+/-0.075) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.1, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 1e-05, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 1e-05, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.0001, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.0001, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.001, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.001, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.01, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.01, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.1, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.1, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'none', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'none', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': False}\n",
      "0.791 (+/-0.087) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'none', 'solver': 'saga', 'tol': 1e-05, 'warm_start': True}\n",
      "0.791 (+/-0.087) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'none', 'solver': 'saga', 'tol': 1e-05, 'warm_start': False}\n",
      "0.791 (+/-0.087) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'none', 'solver': 'saga', 'tol': 0.0001, 'warm_start': True}\n",
      "0.791 (+/-0.087) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'none', 'solver': 'saga', 'tol': 0.0001, 'warm_start': False}\n",
      "0.794 (+/-0.085) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'none', 'solver': 'saga', 'tol': 0.001, 'warm_start': True}\n",
      "0.794 (+/-0.085) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'none', 'solver': 'saga', 'tol': 0.001, 'warm_start': False}\n",
      "0.795 (+/-0.070) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'none', 'solver': 'saga', 'tol': 0.01, 'warm_start': True}\n",
      "0.795 (+/-0.070) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'none', 'solver': 'saga', 'tol': 0.01, 'warm_start': False}\n",
      "0.778 (+/-0.074) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'none', 'solver': 'saga', 'tol': 0.1, 'warm_start': True}\n",
      "0.775 (+/-0.068) for {'C': 1.0, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'none', 'solver': 'saga', 'tol': 0.1, 'warm_start': False}\n",
      "0.767 (+/-0.065) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': True}\n",
      "0.767 (+/-0.065) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': False}\n",
      "0.767 (+/-0.065) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': True}\n",
      "0.767 (+/-0.065) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': False}\n",
      "0.767 (+/-0.065) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': True}\n",
      "0.770 (+/-0.067) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': False}\n",
      "0.770 (+/-0.071) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': True}\n",
      "0.768 (+/-0.070) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': False}\n",
      "0.767 (+/-0.076) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': True}\n",
      "0.768 (+/-0.073) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': False}\n",
      "0.763 (+/-0.068) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l1', 'solver': 'saga', 'tol': 1e-05, 'warm_start': True}\n",
      "0.763 (+/-0.068) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l1', 'solver': 'saga', 'tol': 1e-05, 'warm_start': False}\n",
      "0.763 (+/-0.068) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.0001, 'warm_start': True}\n",
      "0.763 (+/-0.068) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.0001, 'warm_start': False}\n",
      "0.764 (+/-0.070) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.001, 'warm_start': True}\n",
      "0.763 (+/-0.068) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.001, 'warm_start': False}\n",
      "0.758 (+/-0.066) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.01, 'warm_start': True}\n",
      "0.758 (+/-0.066) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.01, 'warm_start': False}\n",
      "0.771 (+/-0.061) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.1, 'warm_start': True}\n",
      "0.771 (+/-0.062) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.1, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 1e-05, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 1e-05, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.0001, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.0001, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.001, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.001, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.01, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.01, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.1, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.1, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'none', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'none', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': False}\n",
      "0.764 (+/-0.070) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'none', 'solver': 'saga', 'tol': 1e-05, 'warm_start': True}\n",
      "0.764 (+/-0.070) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'none', 'solver': 'saga', 'tol': 1e-05, 'warm_start': False}\n",
      "0.763 (+/-0.064) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'none', 'solver': 'saga', 'tol': 0.0001, 'warm_start': True}\n",
      "0.764 (+/-0.070) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'none', 'solver': 'saga', 'tol': 0.0001, 'warm_start': False}\n",
      "0.763 (+/-0.064) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'none', 'solver': 'saga', 'tol': 0.001, 'warm_start': True}\n",
      "0.763 (+/-0.064) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'none', 'solver': 'saga', 'tol': 0.001, 'warm_start': False}\n",
      "0.763 (+/-0.069) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'none', 'solver': 'saga', 'tol': 0.01, 'warm_start': True}\n",
      "0.763 (+/-0.069) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'none', 'solver': 'saga', 'tol': 0.01, 'warm_start': False}\n",
      "0.768 (+/-0.052) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'none', 'solver': 'saga', 'tol': 0.1, 'warm_start': True}\n",
      "0.772 (+/-0.068) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'none', 'solver': 'saga', 'tol': 0.1, 'warm_start': False}\n",
      "0.767 (+/-0.065) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': True}\n",
      "0.767 (+/-0.065) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': False}\n",
      "0.767 (+/-0.065) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': True}\n",
      "0.767 (+/-0.065) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': False}\n",
      "0.767 (+/-0.065) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': True}\n",
      "0.767 (+/-0.065) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': False}\n",
      "0.767 (+/-0.070) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': True}\n",
      "0.767 (+/-0.065) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': False}\n",
      "0.770 (+/-0.063) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': True}\n",
      "0.765 (+/-0.061) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': False}\n",
      "0.765 (+/-0.064) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l1', 'solver': 'saga', 'tol': 1e-05, 'warm_start': True}\n",
      "0.765 (+/-0.064) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l1', 'solver': 'saga', 'tol': 1e-05, 'warm_start': False}\n",
      "0.765 (+/-0.064) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.0001, 'warm_start': True}\n",
      "0.765 (+/-0.064) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.0001, 'warm_start': False}\n",
      "0.767 (+/-0.065) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.001, 'warm_start': True}\n",
      "0.768 (+/-0.066) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.001, 'warm_start': False}\n",
      "0.758 (+/-0.066) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.01, 'warm_start': True}\n",
      "0.758 (+/-0.066) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.01, 'warm_start': False}\n",
      "0.772 (+/-0.071) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.1, 'warm_start': True}\n",
      "0.773 (+/-0.079) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.1, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 1e-05, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 1e-05, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.0001, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.0001, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.001, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.001, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.01, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.01, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.1, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.1, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'none', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'none', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': False}\n",
      "0.764 (+/-0.073) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'none', 'solver': 'saga', 'tol': 1e-05, 'warm_start': True}\n",
      "0.764 (+/-0.073) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'none', 'solver': 'saga', 'tol': 1e-05, 'warm_start': False}\n",
      "0.764 (+/-0.073) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'none', 'solver': 'saga', 'tol': 0.0001, 'warm_start': True}\n",
      "0.764 (+/-0.073) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'none', 'solver': 'saga', 'tol': 0.0001, 'warm_start': False}\n",
      "0.763 (+/-0.068) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'none', 'solver': 'saga', 'tol': 0.001, 'warm_start': True}\n",
      "0.763 (+/-0.068) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'none', 'solver': 'saga', 'tol': 0.001, 'warm_start': False}\n",
      "0.763 (+/-0.069) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'none', 'solver': 'saga', 'tol': 0.01, 'warm_start': True}\n",
      "0.763 (+/-0.069) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'none', 'solver': 'saga', 'tol': 0.01, 'warm_start': False}\n",
      "0.774 (+/-0.080) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'none', 'solver': 'saga', 'tol': 0.1, 'warm_start': True}\n",
      "0.768 (+/-0.062) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'none', 'solver': 'saga', 'tol': 0.1, 'warm_start': False}\n",
      "0.767 (+/-0.065) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': True}\n",
      "0.767 (+/-0.065) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': False}\n",
      "0.767 (+/-0.065) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': True}\n",
      "0.767 (+/-0.065) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': False}\n",
      "0.765 (+/-0.065) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': True}\n",
      "0.767 (+/-0.065) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': False}\n",
      "0.770 (+/-0.071) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': True}\n",
      "0.765 (+/-0.065) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': False}\n",
      "0.767 (+/-0.062) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': True}\n",
      "0.765 (+/-0.062) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': False}\n",
      "0.767 (+/-0.065) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l1', 'solver': 'saga', 'tol': 1e-05, 'warm_start': True}\n",
      "0.767 (+/-0.065) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l1', 'solver': 'saga', 'tol': 1e-05, 'warm_start': False}\n",
      "0.767 (+/-0.065) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.0001, 'warm_start': True}\n",
      "0.767 (+/-0.065) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.0001, 'warm_start': False}\n",
      "0.767 (+/-0.065) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.001, 'warm_start': True}\n",
      "0.768 (+/-0.066) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.001, 'warm_start': False}\n",
      "0.758 (+/-0.066) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.01, 'warm_start': True}\n",
      "0.758 (+/-0.066) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.01, 'warm_start': False}\n",
      "0.771 (+/-0.062) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.1, 'warm_start': True}\n",
      "0.773 (+/-0.071) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.1, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 1e-05, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 1e-05, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.0001, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.0001, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.001, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.001, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.01, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.01, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.1, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.1, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'none', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'none', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': False}\n",
      "0.761 (+/-0.072) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'none', 'solver': 'saga', 'tol': 1e-05, 'warm_start': True}\n",
      "0.761 (+/-0.072) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'none', 'solver': 'saga', 'tol': 1e-05, 'warm_start': False}\n",
      "0.761 (+/-0.072) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'none', 'solver': 'saga', 'tol': 0.0001, 'warm_start': True}\n",
      "0.761 (+/-0.072) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'none', 'solver': 'saga', 'tol': 0.0001, 'warm_start': False}\n",
      "0.763 (+/-0.068) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'none', 'solver': 'saga', 'tol': 0.001, 'warm_start': True}\n",
      "0.763 (+/-0.068) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'none', 'solver': 'saga', 'tol': 0.001, 'warm_start': False}\n",
      "0.763 (+/-0.069) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'none', 'solver': 'saga', 'tol': 0.01, 'warm_start': True}\n",
      "0.763 (+/-0.069) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'none', 'solver': 'saga', 'tol': 0.01, 'warm_start': False}\n",
      "0.766 (+/-0.061) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'none', 'solver': 'saga', 'tol': 0.1, 'warm_start': True}\n",
      "0.767 (+/-0.060) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'none', 'solver': 'saga', 'tol': 0.1, 'warm_start': False}\n",
      "0.767 (+/-0.065) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': True}\n",
      "0.767 (+/-0.065) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': False}\n",
      "0.767 (+/-0.065) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': True}\n",
      "0.767 (+/-0.065) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': False}\n",
      "0.767 (+/-0.065) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': True}\n",
      "0.767 (+/-0.065) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': False}\n",
      "0.765 (+/-0.065) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': True}\n",
      "0.767 (+/-0.069) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': False}\n",
      "0.764 (+/-0.070) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': True}\n",
      "0.761 (+/-0.060) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': False}\n",
      "0.767 (+/-0.065) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l1', 'solver': 'saga', 'tol': 1e-05, 'warm_start': True}\n",
      "0.767 (+/-0.065) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l1', 'solver': 'saga', 'tol': 1e-05, 'warm_start': False}\n",
      "0.767 (+/-0.065) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.0001, 'warm_start': True}\n",
      "0.767 (+/-0.065) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.0001, 'warm_start': False}\n",
      "0.767 (+/-0.065) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.001, 'warm_start': True}\n",
      "0.767 (+/-0.065) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.001, 'warm_start': False}\n",
      "0.758 (+/-0.066) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.01, 'warm_start': True}\n",
      "0.758 (+/-0.066) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.01, 'warm_start': False}\n",
      "0.770 (+/-0.080) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.1, 'warm_start': True}\n",
      "0.765 (+/-0.060) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.1, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 1e-05, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 1e-05, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.0001, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.0001, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.001, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.001, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.01, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.01, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.1, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.1, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'none', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'none', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': False}\n",
      "0.761 (+/-0.072) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'none', 'solver': 'saga', 'tol': 1e-05, 'warm_start': True}\n",
      "0.761 (+/-0.072) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'none', 'solver': 'saga', 'tol': 1e-05, 'warm_start': False}\n",
      "0.761 (+/-0.072) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'none', 'solver': 'saga', 'tol': 0.0001, 'warm_start': True}\n",
      "0.761 (+/-0.072) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'none', 'solver': 'saga', 'tol': 0.0001, 'warm_start': False}\n",
      "0.764 (+/-0.073) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'none', 'solver': 'saga', 'tol': 0.001, 'warm_start': True}\n",
      "0.763 (+/-0.068) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'none', 'solver': 'saga', 'tol': 0.001, 'warm_start': False}\n",
      "0.763 (+/-0.069) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'none', 'solver': 'saga', 'tol': 0.01, 'warm_start': True}\n",
      "0.763 (+/-0.069) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'none', 'solver': 'saga', 'tol': 0.01, 'warm_start': False}\n",
      "0.770 (+/-0.064) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'none', 'solver': 'saga', 'tol': 0.1, 'warm_start': True}\n",
      "0.764 (+/-0.077) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'none', 'solver': 'saga', 'tol': 0.1, 'warm_start': False}\n",
      "0.767 (+/-0.065) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': True}\n",
      "0.767 (+/-0.065) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': False}\n",
      "0.767 (+/-0.065) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': True}\n",
      "0.767 (+/-0.065) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': False}\n",
      "0.768 (+/-0.066) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': True}\n",
      "0.765 (+/-0.065) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': False}\n",
      "0.768 (+/-0.070) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': True}\n",
      "0.768 (+/-0.066) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': False}\n",
      "0.767 (+/-0.062) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': True}\n",
      "0.770 (+/-0.075) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': False}\n",
      "0.767 (+/-0.065) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l1', 'solver': 'saga', 'tol': 1e-05, 'warm_start': True}\n",
      "0.767 (+/-0.065) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l1', 'solver': 'saga', 'tol': 1e-05, 'warm_start': False}\n",
      "0.767 (+/-0.065) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.0001, 'warm_start': True}\n",
      "0.767 (+/-0.065) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.0001, 'warm_start': False}\n",
      "0.768 (+/-0.066) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.001, 'warm_start': True}\n",
      "0.767 (+/-0.065) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.001, 'warm_start': False}\n",
      "0.758 (+/-0.066) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.01, 'warm_start': True}\n",
      "0.758 (+/-0.066) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.01, 'warm_start': False}\n",
      "0.771 (+/-0.061) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.1, 'warm_start': True}\n",
      "0.770 (+/-0.062) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.1, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 1e-05, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 1e-05, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.0001, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.0001, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.001, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.001, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.01, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.01, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.1, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.1, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'none', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'none', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': False}\n",
      "0.761 (+/-0.072) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'none', 'solver': 'saga', 'tol': 1e-05, 'warm_start': True}\n",
      "0.761 (+/-0.072) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'none', 'solver': 'saga', 'tol': 1e-05, 'warm_start': False}\n",
      "0.761 (+/-0.072) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'none', 'solver': 'saga', 'tol': 0.0001, 'warm_start': True}\n",
      "0.761 (+/-0.072) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'none', 'solver': 'saga', 'tol': 0.0001, 'warm_start': False}\n",
      "0.763 (+/-0.068) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'none', 'solver': 'saga', 'tol': 0.001, 'warm_start': True}\n",
      "0.763 (+/-0.068) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'none', 'solver': 'saga', 'tol': 0.001, 'warm_start': False}\n",
      "0.763 (+/-0.069) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'none', 'solver': 'saga', 'tol': 0.01, 'warm_start': True}\n",
      "0.763 (+/-0.069) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'none', 'solver': 'saga', 'tol': 0.01, 'warm_start': False}\n",
      "0.772 (+/-0.072) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'none', 'solver': 'saga', 'tol': 0.1, 'warm_start': True}\n",
      "0.770 (+/-0.075) for {'C': 1.0, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'none', 'solver': 'saga', 'tol': 0.1, 'warm_start': False}\n",
      "0.792 (+/-0.089) for {'C': 10, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': True}\n",
      "0.792 (+/-0.089) for {'C': 10, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': False}\n",
      "0.792 (+/-0.089) for {'C': 10, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': True}\n",
      "0.792 (+/-0.089) for {'C': 10, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': False}\n",
      "0.792 (+/-0.089) for {'C': 10, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': True}\n",
      "0.792 (+/-0.089) for {'C': 10, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': False}\n",
      "0.791 (+/-0.087) for {'C': 10, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': True}\n",
      "0.794 (+/-0.081) for {'C': 10, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': False}\n",
      "0.794 (+/-0.079) for {'C': 10, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': True}\n",
      "0.791 (+/-0.081) for {'C': 10, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': False}\n",
      "0.796 (+/-0.080) for {'C': 10, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l1', 'solver': 'saga', 'tol': 1e-05, 'warm_start': True}\n",
      "0.796 (+/-0.080) for {'C': 10, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l1', 'solver': 'saga', 'tol': 1e-05, 'warm_start': False}\n",
      "0.796 (+/-0.080) for {'C': 10, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.0001, 'warm_start': True}\n",
      "0.796 (+/-0.080) for {'C': 10, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.0001, 'warm_start': False}\n",
      "0.796 (+/-0.080) for {'C': 10, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.001, 'warm_start': True}\n",
      "0.796 (+/-0.080) for {'C': 10, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.001, 'warm_start': False}\n",
      "0.795 (+/-0.070) for {'C': 10, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.01, 'warm_start': True}\n",
      "0.795 (+/-0.070) for {'C': 10, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.01, 'warm_start': False}\n",
      "0.771 (+/-0.079) for {'C': 10, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.1, 'warm_start': True}\n",
      "0.770 (+/-0.086) for {'C': 10, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.1, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 1e-05, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 1e-05, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.0001, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.0001, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.001, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.001, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.01, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.01, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.1, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.1, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'none', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'none', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': False}\n",
      "0.796 (+/-0.080) for {'C': 10, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'none', 'solver': 'saga', 'tol': 1e-05, 'warm_start': True}\n",
      "0.796 (+/-0.080) for {'C': 10, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'none', 'solver': 'saga', 'tol': 1e-05, 'warm_start': False}\n",
      "0.796 (+/-0.080) for {'C': 10, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'none', 'solver': 'saga', 'tol': 0.0001, 'warm_start': True}\n",
      "0.796 (+/-0.080) for {'C': 10, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'none', 'solver': 'saga', 'tol': 0.0001, 'warm_start': False}\n",
      "0.796 (+/-0.080) for {'C': 10, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'none', 'solver': 'saga', 'tol': 0.001, 'warm_start': True}\n",
      "0.796 (+/-0.080) for {'C': 10, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'none', 'solver': 'saga', 'tol': 0.001, 'warm_start': False}\n",
      "0.794 (+/-0.069) for {'C': 10, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'none', 'solver': 'saga', 'tol': 0.01, 'warm_start': True}\n",
      "0.795 (+/-0.070) for {'C': 10, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'none', 'solver': 'saga', 'tol': 0.01, 'warm_start': False}\n",
      "0.774 (+/-0.091) for {'C': 10, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'none', 'solver': 'saga', 'tol': 0.1, 'warm_start': True}\n",
      "0.777 (+/-0.081) for {'C': 10, 'fit_intercept': True, 'max_iter': 100, 'penalty': 'none', 'solver': 'saga', 'tol': 0.1, 'warm_start': False}\n",
      "0.792 (+/-0.089) for {'C': 10, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': True}\n",
      "0.792 (+/-0.089) for {'C': 10, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': False}\n",
      "0.792 (+/-0.089) for {'C': 10, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': True}\n",
      "0.792 (+/-0.089) for {'C': 10, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': False}\n",
      "0.792 (+/-0.089) for {'C': 10, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': True}\n",
      "0.791 (+/-0.083) for {'C': 10, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': False}\n",
      "0.791 (+/-0.087) for {'C': 10, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': True}\n",
      "0.792 (+/-0.089) for {'C': 10, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': False}\n",
      "0.791 (+/-0.079) for {'C': 10, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': True}\n",
      "0.792 (+/-0.082) for {'C': 10, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': False}\n",
      "0.794 (+/-0.085) for {'C': 10, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l1', 'solver': 'saga', 'tol': 1e-05, 'warm_start': True}\n",
      "0.794 (+/-0.085) for {'C': 10, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l1', 'solver': 'saga', 'tol': 1e-05, 'warm_start': False}\n",
      "0.794 (+/-0.085) for {'C': 10, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.0001, 'warm_start': True}\n",
      "0.794 (+/-0.085) for {'C': 10, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.0001, 'warm_start': False}\n",
      "0.796 (+/-0.080) for {'C': 10, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.001, 'warm_start': True}\n",
      "0.796 (+/-0.080) for {'C': 10, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.001, 'warm_start': False}\n",
      "0.795 (+/-0.070) for {'C': 10, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.01, 'warm_start': True}\n",
      "0.795 (+/-0.070) for {'C': 10, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.01, 'warm_start': False}\n",
      "0.775 (+/-0.078) for {'C': 10, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.1, 'warm_start': True}\n",
      "0.771 (+/-0.082) for {'C': 10, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.1, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 1e-05, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 1e-05, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.0001, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.0001, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.001, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.001, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.01, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.01, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.1, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.1, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'none', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'none', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': False}\n",
      "0.792 (+/-0.089) for {'C': 10, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'none', 'solver': 'saga', 'tol': 1e-05, 'warm_start': True}\n",
      "0.792 (+/-0.089) for {'C': 10, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'none', 'solver': 'saga', 'tol': 1e-05, 'warm_start': False}\n",
      "0.792 (+/-0.089) for {'C': 10, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'none', 'solver': 'saga', 'tol': 0.0001, 'warm_start': True}\n",
      "0.792 (+/-0.089) for {'C': 10, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'none', 'solver': 'saga', 'tol': 0.0001, 'warm_start': False}\n",
      "0.794 (+/-0.085) for {'C': 10, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'none', 'solver': 'saga', 'tol': 0.001, 'warm_start': True}\n",
      "0.794 (+/-0.085) for {'C': 10, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'none', 'solver': 'saga', 'tol': 0.001, 'warm_start': False}\n",
      "0.795 (+/-0.070) for {'C': 10, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'none', 'solver': 'saga', 'tol': 0.01, 'warm_start': True}\n",
      "0.795 (+/-0.070) for {'C': 10, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'none', 'solver': 'saga', 'tol': 0.01, 'warm_start': False}\n",
      "0.778 (+/-0.074) for {'C': 10, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'none', 'solver': 'saga', 'tol': 0.1, 'warm_start': True}\n",
      "0.778 (+/-0.074) for {'C': 10, 'fit_intercept': True, 'max_iter': 500, 'penalty': 'none', 'solver': 'saga', 'tol': 0.1, 'warm_start': False}\n",
      "0.792 (+/-0.089) for {'C': 10, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': True}\n",
      "0.792 (+/-0.089) for {'C': 10, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': False}\n",
      "0.792 (+/-0.089) for {'C': 10, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': True}\n",
      "0.792 (+/-0.089) for {'C': 10, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': False}\n",
      "0.792 (+/-0.089) for {'C': 10, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': True}\n",
      "0.792 (+/-0.089) for {'C': 10, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': False}\n",
      "0.792 (+/-0.089) for {'C': 10, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': True}\n",
      "0.789 (+/-0.086) for {'C': 10, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': False}\n",
      "0.787 (+/-0.073) for {'C': 10, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': True}\n",
      "0.791 (+/-0.079) for {'C': 10, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': False}\n",
      "0.794 (+/-0.085) for {'C': 10, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l1', 'solver': 'saga', 'tol': 1e-05, 'warm_start': True}\n",
      "0.794 (+/-0.085) for {'C': 10, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l1', 'solver': 'saga', 'tol': 1e-05, 'warm_start': False}\n",
      "0.794 (+/-0.085) for {'C': 10, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.0001, 'warm_start': True}\n",
      "0.794 (+/-0.085) for {'C': 10, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.0001, 'warm_start': False}\n",
      "0.796 (+/-0.080) for {'C': 10, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.001, 'warm_start': True}\n",
      "0.796 (+/-0.080) for {'C': 10, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.001, 'warm_start': False}\n",
      "0.795 (+/-0.070) for {'C': 10, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.01, 'warm_start': True}\n",
      "0.795 (+/-0.070) for {'C': 10, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.01, 'warm_start': False}\n",
      "0.782 (+/-0.074) for {'C': 10, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.1, 'warm_start': True}\n",
      "0.771 (+/-0.074) for {'C': 10, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.1, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 1e-05, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 1e-05, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.0001, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.0001, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.001, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.001, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.01, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.01, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.1, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.1, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'none', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'none', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': False}\n",
      "0.791 (+/-0.087) for {'C': 10, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'none', 'solver': 'saga', 'tol': 1e-05, 'warm_start': True}\n",
      "0.791 (+/-0.087) for {'C': 10, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'none', 'solver': 'saga', 'tol': 1e-05, 'warm_start': False}\n",
      "0.791 (+/-0.087) for {'C': 10, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'none', 'solver': 'saga', 'tol': 0.0001, 'warm_start': True}\n",
      "0.791 (+/-0.087) for {'C': 10, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'none', 'solver': 'saga', 'tol': 0.0001, 'warm_start': False}\n",
      "0.794 (+/-0.085) for {'C': 10, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'none', 'solver': 'saga', 'tol': 0.001, 'warm_start': True}\n",
      "0.794 (+/-0.085) for {'C': 10, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'none', 'solver': 'saga', 'tol': 0.001, 'warm_start': False}\n",
      "0.795 (+/-0.070) for {'C': 10, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'none', 'solver': 'saga', 'tol': 0.01, 'warm_start': True}\n",
      "0.795 (+/-0.070) for {'C': 10, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'none', 'solver': 'saga', 'tol': 0.01, 'warm_start': False}\n",
      "0.771 (+/-0.079) for {'C': 10, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'none', 'solver': 'saga', 'tol': 0.1, 'warm_start': True}\n",
      "0.773 (+/-0.074) for {'C': 10, 'fit_intercept': True, 'max_iter': 1000, 'penalty': 'none', 'solver': 'saga', 'tol': 0.1, 'warm_start': False}\n",
      "0.792 (+/-0.089) for {'C': 10, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': True}\n",
      "0.792 (+/-0.089) for {'C': 10, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': False}\n",
      "0.792 (+/-0.089) for {'C': 10, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': True}\n",
      "0.792 (+/-0.089) for {'C': 10, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': False}\n",
      "0.792 (+/-0.089) for {'C': 10, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': True}\n",
      "0.791 (+/-0.083) for {'C': 10, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': False}\n",
      "0.789 (+/-0.086) for {'C': 10, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': True}\n",
      "0.791 (+/-0.087) for {'C': 10, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': False}\n",
      "0.794 (+/-0.087) for {'C': 10, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': True}\n",
      "0.798 (+/-0.077) for {'C': 10, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': False}\n",
      "0.792 (+/-0.089) for {'C': 10, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l1', 'solver': 'saga', 'tol': 1e-05, 'warm_start': True}\n",
      "0.792 (+/-0.089) for {'C': 10, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l1', 'solver': 'saga', 'tol': 1e-05, 'warm_start': False}\n",
      "0.794 (+/-0.085) for {'C': 10, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.0001, 'warm_start': True}\n",
      "0.794 (+/-0.085) for {'C': 10, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.0001, 'warm_start': False}\n",
      "0.796 (+/-0.080) for {'C': 10, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.001, 'warm_start': True}\n",
      "0.796 (+/-0.080) for {'C': 10, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.001, 'warm_start': False}\n",
      "0.795 (+/-0.070) for {'C': 10, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.01, 'warm_start': True}\n",
      "0.795 (+/-0.070) for {'C': 10, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.01, 'warm_start': False}\n",
      "0.773 (+/-0.078) for {'C': 10, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.1, 'warm_start': True}\n",
      "0.775 (+/-0.075) for {'C': 10, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.1, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 1e-05, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 1e-05, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.0001, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.0001, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.001, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.001, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.01, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.01, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.1, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.1, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'none', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'none', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': False}\n",
      "0.791 (+/-0.087) for {'C': 10, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'none', 'solver': 'saga', 'tol': 1e-05, 'warm_start': True}\n",
      "0.791 (+/-0.087) for {'C': 10, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'none', 'solver': 'saga', 'tol': 1e-05, 'warm_start': False}\n",
      "0.791 (+/-0.087) for {'C': 10, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'none', 'solver': 'saga', 'tol': 0.0001, 'warm_start': True}\n",
      "0.791 (+/-0.087) for {'C': 10, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'none', 'solver': 'saga', 'tol': 0.0001, 'warm_start': False}\n",
      "0.794 (+/-0.085) for {'C': 10, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'none', 'solver': 'saga', 'tol': 0.001, 'warm_start': True}\n",
      "0.794 (+/-0.085) for {'C': 10, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'none', 'solver': 'saga', 'tol': 0.001, 'warm_start': False}\n",
      "0.795 (+/-0.070) for {'C': 10, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'none', 'solver': 'saga', 'tol': 0.01, 'warm_start': True}\n",
      "0.795 (+/-0.070) for {'C': 10, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'none', 'solver': 'saga', 'tol': 0.01, 'warm_start': False}\n",
      "0.775 (+/-0.073) for {'C': 10, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'none', 'solver': 'saga', 'tol': 0.1, 'warm_start': True}\n",
      "0.771 (+/-0.075) for {'C': 10, 'fit_intercept': True, 'max_iter': 1500, 'penalty': 'none', 'solver': 'saga', 'tol': 0.1, 'warm_start': False}\n",
      "0.792 (+/-0.089) for {'C': 10, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': True}\n",
      "0.792 (+/-0.089) for {'C': 10, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': False}\n",
      "0.792 (+/-0.089) for {'C': 10, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': True}\n",
      "0.792 (+/-0.089) for {'C': 10, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': False}\n",
      "0.791 (+/-0.083) for {'C': 10, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': True}\n",
      "0.792 (+/-0.089) for {'C': 10, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': False}\n",
      "0.792 (+/-0.084) for {'C': 10, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': True}\n",
      "0.792 (+/-0.089) for {'C': 10, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': False}\n",
      "0.795 (+/-0.072) for {'C': 10, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': True}\n",
      "0.791 (+/-0.085) for {'C': 10, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': False}\n",
      "0.792 (+/-0.089) for {'C': 10, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l1', 'solver': 'saga', 'tol': 1e-05, 'warm_start': True}\n",
      "0.792 (+/-0.089) for {'C': 10, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l1', 'solver': 'saga', 'tol': 1e-05, 'warm_start': False}\n",
      "0.794 (+/-0.085) for {'C': 10, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.0001, 'warm_start': True}\n",
      "0.794 (+/-0.085) for {'C': 10, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.0001, 'warm_start': False}\n",
      "0.796 (+/-0.080) for {'C': 10, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.001, 'warm_start': True}\n",
      "0.796 (+/-0.080) for {'C': 10, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.001, 'warm_start': False}\n",
      "0.795 (+/-0.070) for {'C': 10, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.01, 'warm_start': True}\n",
      "0.795 (+/-0.070) for {'C': 10, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.01, 'warm_start': False}\n",
      "0.775 (+/-0.079) for {'C': 10, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.1, 'warm_start': True}\n",
      "0.777 (+/-0.086) for {'C': 10, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.1, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 1e-05, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 1e-05, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.0001, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.0001, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.001, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.001, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.01, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.01, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.1, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.1, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'none', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'none', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': False}\n",
      "0.791 (+/-0.087) for {'C': 10, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'none', 'solver': 'saga', 'tol': 1e-05, 'warm_start': True}\n",
      "0.791 (+/-0.087) for {'C': 10, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'none', 'solver': 'saga', 'tol': 1e-05, 'warm_start': False}\n",
      "0.791 (+/-0.087) for {'C': 10, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'none', 'solver': 'saga', 'tol': 0.0001, 'warm_start': True}\n",
      "0.791 (+/-0.087) for {'C': 10, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'none', 'solver': 'saga', 'tol': 0.0001, 'warm_start': False}\n",
      "0.794 (+/-0.085) for {'C': 10, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'none', 'solver': 'saga', 'tol': 0.001, 'warm_start': True}\n",
      "0.794 (+/-0.085) for {'C': 10, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'none', 'solver': 'saga', 'tol': 0.001, 'warm_start': False}\n",
      "0.795 (+/-0.070) for {'C': 10, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'none', 'solver': 'saga', 'tol': 0.01, 'warm_start': True}\n",
      "0.795 (+/-0.070) for {'C': 10, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'none', 'solver': 'saga', 'tol': 0.01, 'warm_start': False}\n",
      "0.774 (+/-0.081) for {'C': 10, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'none', 'solver': 'saga', 'tol': 0.1, 'warm_start': True}\n",
      "0.777 (+/-0.084) for {'C': 10, 'fit_intercept': True, 'max_iter': 2000, 'penalty': 'none', 'solver': 'saga', 'tol': 0.1, 'warm_start': False}\n",
      "0.763 (+/-0.072) for {'C': 10, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': True}\n",
      "0.763 (+/-0.072) for {'C': 10, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': False}\n",
      "0.763 (+/-0.072) for {'C': 10, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': True}\n",
      "0.763 (+/-0.072) for {'C': 10, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': False}\n",
      "0.763 (+/-0.072) for {'C': 10, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': True}\n",
      "0.763 (+/-0.072) for {'C': 10, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': False}\n",
      "0.764 (+/-0.078) for {'C': 10, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': True}\n",
      "0.764 (+/-0.078) for {'C': 10, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': False}\n",
      "0.765 (+/-0.081) for {'C': 10, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': True}\n",
      "0.764 (+/-0.082) for {'C': 10, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': False}\n",
      "0.763 (+/-0.064) for {'C': 10, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l1', 'solver': 'saga', 'tol': 1e-05, 'warm_start': True}\n",
      "0.763 (+/-0.064) for {'C': 10, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l1', 'solver': 'saga', 'tol': 1e-05, 'warm_start': False}\n",
      "0.763 (+/-0.064) for {'C': 10, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.0001, 'warm_start': True}\n",
      "0.763 (+/-0.064) for {'C': 10, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.0001, 'warm_start': False}\n",
      "0.763 (+/-0.064) for {'C': 10, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.001, 'warm_start': True}\n",
      "0.763 (+/-0.064) for {'C': 10, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.001, 'warm_start': False}\n",
      "0.763 (+/-0.069) for {'C': 10, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.01, 'warm_start': True}\n",
      "0.763 (+/-0.069) for {'C': 10, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.01, 'warm_start': False}\n",
      "0.770 (+/-0.060) for {'C': 10, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.1, 'warm_start': True}\n",
      "0.772 (+/-0.071) for {'C': 10, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.1, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 1e-05, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 1e-05, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.0001, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.0001, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.001, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.001, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.01, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.01, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.1, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.1, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'none', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'none', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': False}\n",
      "0.764 (+/-0.070) for {'C': 10, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'none', 'solver': 'saga', 'tol': 1e-05, 'warm_start': True}\n",
      "0.763 (+/-0.064) for {'C': 10, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'none', 'solver': 'saga', 'tol': 1e-05, 'warm_start': False}\n",
      "0.764 (+/-0.070) for {'C': 10, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'none', 'solver': 'saga', 'tol': 0.0001, 'warm_start': True}\n",
      "0.763 (+/-0.064) for {'C': 10, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'none', 'solver': 'saga', 'tol': 0.0001, 'warm_start': False}\n",
      "0.763 (+/-0.064) for {'C': 10, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'none', 'solver': 'saga', 'tol': 0.001, 'warm_start': True}\n",
      "0.763 (+/-0.064) for {'C': 10, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'none', 'solver': 'saga', 'tol': 0.001, 'warm_start': False}\n",
      "0.763 (+/-0.069) for {'C': 10, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'none', 'solver': 'saga', 'tol': 0.01, 'warm_start': True}\n",
      "0.763 (+/-0.069) for {'C': 10, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'none', 'solver': 'saga', 'tol': 0.01, 'warm_start': False}\n",
      "0.773 (+/-0.076) for {'C': 10, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'none', 'solver': 'saga', 'tol': 0.1, 'warm_start': True}\n",
      "0.772 (+/-0.062) for {'C': 10, 'fit_intercept': False, 'max_iter': 100, 'penalty': 'none', 'solver': 'saga', 'tol': 0.1, 'warm_start': False}\n",
      "0.763 (+/-0.072) for {'C': 10, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': True}\n",
      "0.763 (+/-0.072) for {'C': 10, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': False}\n",
      "0.763 (+/-0.072) for {'C': 10, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': True}\n",
      "0.763 (+/-0.072) for {'C': 10, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': False}\n",
      "0.763 (+/-0.072) for {'C': 10, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': True}\n",
      "0.763 (+/-0.072) for {'C': 10, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': False}\n",
      "0.764 (+/-0.078) for {'C': 10, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': True}\n",
      "0.764 (+/-0.078) for {'C': 10, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': False}\n",
      "0.767 (+/-0.069) for {'C': 10, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': True}\n",
      "0.768 (+/-0.068) for {'C': 10, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': False}\n",
      "0.764 (+/-0.073) for {'C': 10, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l1', 'solver': 'saga', 'tol': 1e-05, 'warm_start': True}\n",
      "0.764 (+/-0.073) for {'C': 10, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l1', 'solver': 'saga', 'tol': 1e-05, 'warm_start': False}\n",
      "0.764 (+/-0.073) for {'C': 10, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.0001, 'warm_start': True}\n",
      "0.764 (+/-0.073) for {'C': 10, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.0001, 'warm_start': False}\n",
      "0.763 (+/-0.068) for {'C': 10, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.001, 'warm_start': True}\n",
      "0.763 (+/-0.068) for {'C': 10, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.001, 'warm_start': False}\n",
      "0.763 (+/-0.069) for {'C': 10, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.01, 'warm_start': True}\n",
      "0.763 (+/-0.069) for {'C': 10, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.01, 'warm_start': False}\n",
      "0.774 (+/-0.064) for {'C': 10, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.1, 'warm_start': True}\n",
      "0.771 (+/-0.073) for {'C': 10, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.1, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 1e-05, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 1e-05, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.0001, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.0001, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.001, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.001, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.01, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.01, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.1, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.1, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'none', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'none', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': False}\n",
      "0.764 (+/-0.073) for {'C': 10, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'none', 'solver': 'saga', 'tol': 1e-05, 'warm_start': True}\n",
      "0.764 (+/-0.073) for {'C': 10, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'none', 'solver': 'saga', 'tol': 1e-05, 'warm_start': False}\n",
      "0.764 (+/-0.073) for {'C': 10, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'none', 'solver': 'saga', 'tol': 0.0001, 'warm_start': True}\n",
      "0.764 (+/-0.073) for {'C': 10, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'none', 'solver': 'saga', 'tol': 0.0001, 'warm_start': False}\n",
      "0.764 (+/-0.073) for {'C': 10, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'none', 'solver': 'saga', 'tol': 0.001, 'warm_start': True}\n",
      "0.764 (+/-0.073) for {'C': 10, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'none', 'solver': 'saga', 'tol': 0.001, 'warm_start': False}\n",
      "0.763 (+/-0.069) for {'C': 10, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'none', 'solver': 'saga', 'tol': 0.01, 'warm_start': True}\n",
      "0.763 (+/-0.069) for {'C': 10, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'none', 'solver': 'saga', 'tol': 0.01, 'warm_start': False}\n",
      "0.770 (+/-0.067) for {'C': 10, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'none', 'solver': 'saga', 'tol': 0.1, 'warm_start': True}\n",
      "0.770 (+/-0.060) for {'C': 10, 'fit_intercept': False, 'max_iter': 500, 'penalty': 'none', 'solver': 'saga', 'tol': 0.1, 'warm_start': False}\n",
      "0.763 (+/-0.072) for {'C': 10, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': True}\n",
      "0.763 (+/-0.072) for {'C': 10, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': False}\n",
      "0.763 (+/-0.072) for {'C': 10, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': True}\n",
      "0.763 (+/-0.072) for {'C': 10, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': False}\n",
      "0.763 (+/-0.072) for {'C': 10, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': True}\n",
      "0.763 (+/-0.072) for {'C': 10, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': False}\n",
      "0.765 (+/-0.080) for {'C': 10, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': True}\n",
      "0.765 (+/-0.080) for {'C': 10, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': False}\n",
      "0.770 (+/-0.069) for {'C': 10, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': True}\n",
      "0.761 (+/-0.059) for {'C': 10, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': False}\n",
      "0.763 (+/-0.072) for {'C': 10, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l1', 'solver': 'saga', 'tol': 1e-05, 'warm_start': True}\n",
      "0.763 (+/-0.072) for {'C': 10, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l1', 'solver': 'saga', 'tol': 1e-05, 'warm_start': False}\n",
      "0.763 (+/-0.072) for {'C': 10, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.0001, 'warm_start': True}\n",
      "0.763 (+/-0.072) for {'C': 10, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.0001, 'warm_start': False}\n",
      "0.763 (+/-0.068) for {'C': 10, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.001, 'warm_start': True}\n",
      "0.763 (+/-0.068) for {'C': 10, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.001, 'warm_start': False}\n",
      "0.763 (+/-0.069) for {'C': 10, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.01, 'warm_start': True}\n",
      "0.763 (+/-0.069) for {'C': 10, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.01, 'warm_start': False}\n",
      "0.763 (+/-0.042) for {'C': 10, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.1, 'warm_start': True}\n",
      "0.775 (+/-0.074) for {'C': 10, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.1, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 1e-05, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 1e-05, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.0001, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.0001, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.001, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.001, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.01, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.01, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.1, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.1, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'none', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'none', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': False}\n",
      "0.761 (+/-0.072) for {'C': 10, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'none', 'solver': 'saga', 'tol': 1e-05, 'warm_start': True}\n",
      "0.761 (+/-0.072) for {'C': 10, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'none', 'solver': 'saga', 'tol': 1e-05, 'warm_start': False}\n",
      "0.761 (+/-0.072) for {'C': 10, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'none', 'solver': 'saga', 'tol': 0.0001, 'warm_start': True}\n",
      "0.761 (+/-0.072) for {'C': 10, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'none', 'solver': 'saga', 'tol': 0.0001, 'warm_start': False}\n",
      "0.763 (+/-0.068) for {'C': 10, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'none', 'solver': 'saga', 'tol': 0.001, 'warm_start': True}\n",
      "0.763 (+/-0.068) for {'C': 10, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'none', 'solver': 'saga', 'tol': 0.001, 'warm_start': False}\n",
      "0.763 (+/-0.069) for {'C': 10, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'none', 'solver': 'saga', 'tol': 0.01, 'warm_start': True}\n",
      "0.763 (+/-0.069) for {'C': 10, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'none', 'solver': 'saga', 'tol': 0.01, 'warm_start': False}\n",
      "0.761 (+/-0.058) for {'C': 10, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'none', 'solver': 'saga', 'tol': 0.1, 'warm_start': True}\n",
      "0.771 (+/-0.086) for {'C': 10, 'fit_intercept': False, 'max_iter': 1000, 'penalty': 'none', 'solver': 'saga', 'tol': 0.1, 'warm_start': False}\n",
      "0.763 (+/-0.072) for {'C': 10, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': True}\n",
      "0.763 (+/-0.072) for {'C': 10, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': False}\n",
      "0.763 (+/-0.072) for {'C': 10, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': True}\n",
      "0.763 (+/-0.072) for {'C': 10, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': False}\n",
      "0.763 (+/-0.072) for {'C': 10, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': True}\n",
      "0.763 (+/-0.072) for {'C': 10, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': False}\n",
      "0.764 (+/-0.078) for {'C': 10, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': True}\n",
      "0.761 (+/-0.072) for {'C': 10, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': False}\n",
      "0.764 (+/-0.078) for {'C': 10, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': True}\n",
      "0.767 (+/-0.070) for {'C': 10, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': False}\n",
      "0.763 (+/-0.072) for {'C': 10, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l1', 'solver': 'saga', 'tol': 1e-05, 'warm_start': True}\n",
      "0.763 (+/-0.072) for {'C': 10, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l1', 'solver': 'saga', 'tol': 1e-05, 'warm_start': False}\n",
      "0.763 (+/-0.072) for {'C': 10, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.0001, 'warm_start': True}\n",
      "0.763 (+/-0.072) for {'C': 10, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.0001, 'warm_start': False}\n",
      "0.763 (+/-0.068) for {'C': 10, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.001, 'warm_start': True}\n",
      "0.763 (+/-0.068) for {'C': 10, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.001, 'warm_start': False}\n",
      "0.763 (+/-0.069) for {'C': 10, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.01, 'warm_start': True}\n",
      "0.763 (+/-0.069) for {'C': 10, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.01, 'warm_start': False}\n",
      "0.770 (+/-0.057) for {'C': 10, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.1, 'warm_start': True}\n",
      "0.763 (+/-0.074) for {'C': 10, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.1, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 1e-05, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 1e-05, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.0001, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.0001, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.001, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.001, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.01, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.01, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.1, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.1, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'none', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'none', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': False}\n",
      "0.761 (+/-0.072) for {'C': 10, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'none', 'solver': 'saga', 'tol': 1e-05, 'warm_start': True}\n",
      "0.761 (+/-0.072) for {'C': 10, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'none', 'solver': 'saga', 'tol': 1e-05, 'warm_start': False}\n",
      "0.761 (+/-0.072) for {'C': 10, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'none', 'solver': 'saga', 'tol': 0.0001, 'warm_start': True}\n",
      "0.761 (+/-0.072) for {'C': 10, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'none', 'solver': 'saga', 'tol': 0.0001, 'warm_start': False}\n",
      "0.763 (+/-0.068) for {'C': 10, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'none', 'solver': 'saga', 'tol': 0.001, 'warm_start': True}\n",
      "0.763 (+/-0.068) for {'C': 10, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'none', 'solver': 'saga', 'tol': 0.001, 'warm_start': False}\n",
      "0.763 (+/-0.069) for {'C': 10, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'none', 'solver': 'saga', 'tol': 0.01, 'warm_start': True}\n",
      "0.763 (+/-0.069) for {'C': 10, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'none', 'solver': 'saga', 'tol': 0.01, 'warm_start': False}\n",
      "0.771 (+/-0.066) for {'C': 10, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'none', 'solver': 'saga', 'tol': 0.1, 'warm_start': True}\n",
      "0.771 (+/-0.057) for {'C': 10, 'fit_intercept': False, 'max_iter': 1500, 'penalty': 'none', 'solver': 'saga', 'tol': 0.1, 'warm_start': False}\n",
      "0.763 (+/-0.072) for {'C': 10, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': True}\n",
      "0.763 (+/-0.072) for {'C': 10, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': False}\n",
      "0.763 (+/-0.072) for {'C': 10, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': True}\n",
      "0.763 (+/-0.072) for {'C': 10, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': False}\n",
      "0.763 (+/-0.072) for {'C': 10, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': True}\n",
      "0.763 (+/-0.072) for {'C': 10, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': False}\n",
      "0.763 (+/-0.072) for {'C': 10, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': True}\n",
      "0.765 (+/-0.080) for {'C': 10, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': False}\n",
      "0.770 (+/-0.085) for {'C': 10, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': True}\n",
      "0.763 (+/-0.072) for {'C': 10, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': False}\n",
      "0.763 (+/-0.072) for {'C': 10, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l1', 'solver': 'saga', 'tol': 1e-05, 'warm_start': True}\n",
      "0.763 (+/-0.072) for {'C': 10, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l1', 'solver': 'saga', 'tol': 1e-05, 'warm_start': False}\n",
      "0.763 (+/-0.072) for {'C': 10, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.0001, 'warm_start': True}\n",
      "0.763 (+/-0.072) for {'C': 10, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.0001, 'warm_start': False}\n",
      "0.763 (+/-0.068) for {'C': 10, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.001, 'warm_start': True}\n",
      "0.763 (+/-0.068) for {'C': 10, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.001, 'warm_start': False}\n",
      "0.763 (+/-0.069) for {'C': 10, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.01, 'warm_start': True}\n",
      "0.763 (+/-0.069) for {'C': 10, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.01, 'warm_start': False}\n",
      "0.775 (+/-0.077) for {'C': 10, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.1, 'warm_start': True}\n",
      "0.772 (+/-0.074) for {'C': 10, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'l1', 'solver': 'saga', 'tol': 0.1, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'elasticnet', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 1e-05, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 1e-05, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.0001, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.0001, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.001, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.001, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.01, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.01, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.1, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'elasticnet', 'solver': 'saga', 'tol': 0.1, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'none', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'none', 'solver': 'liblinear', 'tol': 1e-05, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.0001, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.001, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.01, 'warm_start': False}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': True}\n",
      "nan (+/-nan) for {'C': 10, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'none', 'solver': 'liblinear', 'tol': 0.1, 'warm_start': False}\n",
      "0.761 (+/-0.072) for {'C': 10, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'none', 'solver': 'saga', 'tol': 1e-05, 'warm_start': True}\n",
      "0.761 (+/-0.072) for {'C': 10, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'none', 'solver': 'saga', 'tol': 1e-05, 'warm_start': False}\n",
      "0.761 (+/-0.072) for {'C': 10, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'none', 'solver': 'saga', 'tol': 0.0001, 'warm_start': True}\n",
      "0.761 (+/-0.072) for {'C': 10, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'none', 'solver': 'saga', 'tol': 0.0001, 'warm_start': False}\n",
      "0.763 (+/-0.068) for {'C': 10, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'none', 'solver': 'saga', 'tol': 0.001, 'warm_start': True}\n",
      "0.763 (+/-0.068) for {'C': 10, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'none', 'solver': 'saga', 'tol': 0.001, 'warm_start': False}\n",
      "0.763 (+/-0.069) for {'C': 10, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'none', 'solver': 'saga', 'tol': 0.01, 'warm_start': True}\n",
      "0.763 (+/-0.069) for {'C': 10, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'none', 'solver': 'saga', 'tol': 0.01, 'warm_start': False}\n",
      "0.771 (+/-0.077) for {'C': 10, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'none', 'solver': 'saga', 'tol': 0.1, 'warm_start': True}\n",
      "0.777 (+/-0.068) for {'C': 10, 'fit_intercept': False, 'max_iter': 2000, 'penalty': 'none', 'solver': 'saga', 'tol': 0.1, 'warm_start': False}\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.85      0.85      0.85       114\n",
      "         1.0       0.73      0.73      0.73        64\n",
      "\n",
      "    accuracy                           0.81       178\n",
      "   macro avg       0.79      0.79      0.79       178\n",
      "weighted avg       0.81      0.81      0.81       178\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "tuned_parameters = [\n",
    "                    {'penalty': ['l2'],\n",
    "                     'C': [0.01,0.1,1.0,10], 'fit_intercept':[True,False], 'solver':['liblinear','newton-cg', 'lbfgs', 'sag', 'saga'],\n",
    "                     'max_iter':[100,500,1000,1500,2000],'warm_start':[True, False],'fit_intercept':[True, False],\n",
    "                     'tol':[0.00001,0.0001,0.001,0.01,0.1]},\n",
    "                    {'penalty': ['l1', 'elasticnet', 'none'],\n",
    "                     'C': [0.01,0.1,1.0,10], 'fit_intercept':[True,False], 'solver':[ 'liblinear', 'saga'],\n",
    "                     'max_iter':[100,500,1000,1500,2000],'warm_start':[True, False],'fit_intercept':[True, False],\n",
    "                     'tol':[0.00001,0.0001,0.001,0.01,0.1]}\n",
    "                    ]\n",
    "\n",
    "\n",
    "print()\n",
    "\n",
    "clf = GridSearchCV(\n",
    "    LogisticRegression(), tuned_parameters, scoring='accuracy',cv=10\n",
    ")\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best parameters set found on development set:\")\n",
    "print()\n",
    "print(clf.best_params_)\n",
    "print()\n",
    "print(\"Grid scores on development set:\")\n",
    "print()\n",
    "means = clf.cv_results_['mean_test_score']\n",
    "stds = clf.cv_results_['std_test_score']\n",
    "for mean, std, params in zip(means, stds, clf.cv_results_['params']):\n",
    "    print(\"%0.3f (+/-%0.03f) for %r\"\n",
    "          % (mean, std * 2, params))\n",
    "print()\n",
    "\n",
    "print(\"Detailed classification report:\")\n",
    "print()\n",
    "print(\"The model is trained on the full development set.\")\n",
    "print(\"The scores are computed on the full evaluation set.\")\n",
    "print()\n",
    "y_true, y_pred = y_test, clf.predict(X_test)\n",
    "print(classification_report(y_true, y_pred))\n",
    "print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1TE7sEruQ7qi"
   },
   "source": [
    "### Cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "AsSHb_h0QzXx",
    "outputId": "7c141151-ea42-4aaa-9f55-73d7d526da4c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.796879\n"
     ]
    }
   ],
   "source": [
    "clf = LogisticRegression(C= 10, fit_intercept= True, max_iter= 1500, penalty= 'l1', solver= 'liblinear', tol= 0.1, warm_start= False)\n",
    "score=cross_validate(clf, X, y, cv=10, scoring=\"accuracy\")[\"test_score\"].mean()\n",
    "print(f\"{score:.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wB4fhopYMZcQ"
   },
   "source": [
    "### Generating Predicion Result for submission in .csv format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JGN24RYr7nJN"
   },
   "outputs": [],
   "source": [
    "df2 = pd.read_csv(url2)\n",
    "clf = LogisticRegression(C= 10, fit_intercept= True, max_iter= 1500, penalty= 'l1', solver= 'liblinear', tol= 0.1, warm_start= False)\n",
    "clf.fit(X, y)\n",
    "pred=clf.predict(X_test2)\n",
    "pd.DataFrame({\"PassengerId\": df2[\"PassengerId\"], \"Survived\": pred}).to_csv(\"log_reg_submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1ZFkJ7pp7oi_"
   },
   "source": [
    "The generated results csv file need to be copied and pasted to another csv file in order to make a successful submisison due to an unknown formatting issue."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hw-roPvL3ylU"
   },
   "source": [
    "### Kaggle Submisison Score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bKuZWFFM3GIJ"
   },
   "source": [
    "![alt text](https://raw.githubusercontent.com/zyzhang1130/CE9010/master/Titanic/logistic_regression.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uefZVRzR5iw0"
   },
   "source": [
    "## K-nearest Neighbors Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 555
    },
    "colab_type": "code",
    "id": "WfA5vNQI5hvl",
    "outputId": "6dab9b5d-4552-46d0-b9c2-173ab70882cc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best parameters set found on development set:\n",
      "\n",
      "{'n_neighbors': 20, 'weights': 'uniform'}\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "0.709 (+/-0.149) for {'n_neighbors': 1, 'weights': 'uniform'}\n",
      "0.709 (+/-0.149) for {'n_neighbors': 1, 'weights': 'distance'}\n",
      "0.791 (+/-0.080) for {'n_neighbors': 10, 'weights': 'uniform'}\n",
      "0.758 (+/-0.098) for {'n_neighbors': 10, 'weights': 'distance'}\n",
      "0.799 (+/-0.106) for {'n_neighbors': 20, 'weights': 'uniform'}\n",
      "0.765 (+/-0.094) for {'n_neighbors': 20, 'weights': 'distance'}\n",
      "0.785 (+/-0.108) for {'n_neighbors': 30, 'weights': 'uniform'}\n",
      "0.767 (+/-0.100) for {'n_neighbors': 30, 'weights': 'distance'}\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.85      0.88      0.86       114\n",
      "         1.0       0.77      0.72      0.74        64\n",
      "\n",
      "    accuracy                           0.82       178\n",
      "   macro avg       0.81      0.80      0.80       178\n",
      "weighted avg       0.82      0.82      0.82       178\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score\n",
    "tuned_parameters = [{'n_neighbors': [1, 10, 20, 30],\n",
    "                     'weights': ['uniform', 'distance']}\n",
    "                    ]\n",
    "\n",
    "\n",
    "print()\n",
    "\n",
    "clf = GridSearchCV(\n",
    "    KNeighborsClassifier(), tuned_parameters, scoring='accuracy',cv=10\n",
    ")\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best parameters set found on development set:\")\n",
    "print()\n",
    "print(clf.best_params_)\n",
    "print()\n",
    "print(\"Grid scores on development set:\")\n",
    "print()\n",
    "means = clf.cv_results_['mean_test_score']\n",
    "stds = clf.cv_results_['std_test_score']\n",
    "for mean, std, params in zip(means, stds, clf.cv_results_['params']):\n",
    "    print(\"%0.3f (+/-%0.03f) for %r\"\n",
    "          % (mean, std * 2, params))\n",
    "print()\n",
    "\n",
    "print(\"Detailed classification report:\")\n",
    "print()\n",
    "print(\"The model is trained on the full development set.\")\n",
    "print(\"The scores are computed on the full evaluation set.\")\n",
    "print()\n",
    "y_true, y_pred = y_test, clf.predict(X_test)\n",
    "print(classification_report(y_true, y_pred))\n",
    "print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 607
    },
    "colab_type": "code",
    "id": "LCaz0cvb_4_3",
    "outputId": "4f69823e-3662-4560-dae2-633e403af112"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best parameters set found on development set:\n",
      "\n",
      "{'n_neighbors': 24, 'weights': 'distance'}\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "0.764 (+/-0.097) for {'n_neighbors': 15, 'weights': 'distance'}\n",
      "0.764 (+/-0.093) for {'n_neighbors': 16, 'weights': 'distance'}\n",
      "0.764 (+/-0.093) for {'n_neighbors': 17, 'weights': 'distance'}\n",
      "0.765 (+/-0.094) for {'n_neighbors': 18, 'weights': 'distance'}\n",
      "0.764 (+/-0.090) for {'n_neighbors': 19, 'weights': 'distance'}\n",
      "0.765 (+/-0.094) for {'n_neighbors': 20, 'weights': 'distance'}\n",
      "0.765 (+/-0.095) for {'n_neighbors': 21, 'weights': 'distance'}\n",
      "0.765 (+/-0.094) for {'n_neighbors': 22, 'weights': 'distance'}\n",
      "0.768 (+/-0.088) for {'n_neighbors': 23, 'weights': 'distance'}\n",
      "0.770 (+/-0.090) for {'n_neighbors': 24, 'weights': 'distance'}\n",
      "0.770 (+/-0.094) for {'n_neighbors': 25, 'weights': 'distance'}\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.84      0.89      0.86       114\n",
      "         1.0       0.78      0.70      0.74        64\n",
      "\n",
      "    accuracy                           0.82       178\n",
      "   macro avg       0.81      0.79      0.80       178\n",
      "weighted avg       0.82      0.82      0.82       178\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "tuned_parameters = [{'n_neighbors': [15,16,17,18,19,20,21,22,23,24,25],\n",
    "                     'weights': [ 'distance']}\n",
    "                    ]\n",
    "\n",
    "\n",
    "print()\n",
    "\n",
    "clf = GridSearchCV(\n",
    "    KNeighborsClassifier(), tuned_parameters, scoring='accuracy', cv=10\n",
    ")\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best parameters set found on development set:\")\n",
    "print()\n",
    "print(clf.best_params_)\n",
    "print()\n",
    "print(\"Grid scores on development set:\")\n",
    "print()\n",
    "means = clf.cv_results_['mean_test_score']\n",
    "stds = clf.cv_results_['std_test_score']\n",
    "for mean, std, params in zip(means, stds, clf.cv_results_['params']):\n",
    "    print(\"%0.3f (+/-%0.03f) for %r\"\n",
    "          % (mean, std * 2, params))\n",
    "print()\n",
    "\n",
    "print(\"Detailed classification report:\")\n",
    "print()\n",
    "print(\"The model is trained on the full development set.\")\n",
    "print(\"The scores are computed on the full evaluation set.\")\n",
    "print()\n",
    "y_true, y_pred = y_test, clf.predict(X_test)\n",
    "print(classification_report(y_true, y_pred))\n",
    "print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "S2Gy8Tnqfbd7"
   },
   "source": [
    "However, when we use this selected parameters, it did not produce a better result than when 'n_neighbors'=7. This is likely due to the fact that the training dataset size is rather limited and hence even cross-validation was applied, overfitting still occurred."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "a3KjeDsUTgVD"
   },
   "source": [
    "### Cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "sZFhpjKIRhHF",
    "outputId": "411d115d-01fd-4bc6-f34a-db8c7e5da56c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.774407\n"
     ]
    }
   ],
   "source": [
    "clf = KNeighborsClassifier(n_neighbors=7,weights='distance')\n",
    "score=cross_validate(clf, X, y, cv=10, scoring=\"accuracy\")[\"test_score\"].mean()\n",
    "print(f\"{score:.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xLlaxYE7McC6"
   },
   "source": [
    "### Generating Predicion Result for submission in .csv format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "niTqWzv8rEO3"
   },
   "outputs": [],
   "source": [
    "df2 = pd.read_csv(url2)\n",
    "clf = KNeighborsClassifier(n_neighbors=7,weights='distance')\n",
    "clf.fit(X, y)\n",
    "pred=clf.predict(X_test2)\n",
    "pd.DataFrame({\"PassengerId\": df2[\"PassengerId\"], \"Survived\": pred}).to_csv(\"knn_submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "taXxFO6w9IfZ"
   },
   "source": [
    "![alt text](https://raw.githubusercontent.com/zyzhang1130/CE9010/master/Titanic/knn.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Pol0BFqogOhr"
   },
   "source": [
    "## DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 641
    },
    "colab_type": "code",
    "id": "XdzlVQgEqXz2",
    "outputId": "31be2bd3-70b4-4957-e124-8aff273aefd1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best parameters set found on development set:\n",
      "\n",
      "{'max_depth': 7}\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "0.774 (+/-0.061) for {'max_depth': 4}\n",
      "0.803 (+/-0.087) for {'max_depth': 5}\n",
      "0.791 (+/-0.130) for {'max_depth': 6}\n",
      "0.805 (+/-0.114) for {'max_depth': 7}\n",
      "0.788 (+/-0.127) for {'max_depth': 8}\n",
      "0.791 (+/-0.111) for {'max_depth': 9}\n",
      "0.784 (+/-0.085) for {'max_depth': 10}\n",
      "0.795 (+/-0.103) for {'max_depth': 11}\n",
      "0.780 (+/-0.131) for {'max_depth': 12}\n",
      "0.782 (+/-0.121) for {'max_depth': 13}\n",
      "0.777 (+/-0.139) for {'max_depth': 14}\n",
      "0.773 (+/-0.112) for {'max_depth': 15}\n",
      "0.773 (+/-0.122) for {'max_depth': 16}\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.82      0.93      0.87       114\n",
      "         1.0       0.83      0.62      0.71        64\n",
      "\n",
      "    accuracy                           0.82       178\n",
      "   macro avg       0.82      0.78      0.79       178\n",
      "weighted avg       0.82      0.82      0.81       178\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "tuned_parameters = [{'max_depth': [4,5,6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16]}\n",
    "                    ]\n",
    "\n",
    "\n",
    "print()\n",
    "\n",
    "clf = GridSearchCV(\n",
    "    DecisionTreeClassifier(), tuned_parameters, scoring='accuracy', cv=10\n",
    ")\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best parameters set found on development set:\")\n",
    "print()\n",
    "print(clf.best_params_)\n",
    "print()\n",
    "print(\"Grid scores on development set:\")\n",
    "print()\n",
    "means = clf.cv_results_['mean_test_score']\n",
    "stds = clf.cv_results_['std_test_score']\n",
    "for mean, std, params in zip(means, stds, clf.cv_results_['params']):\n",
    "    print(\"%0.3f (+/-%0.03f) for %r\"\n",
    "          % (mean, std * 2, params))\n",
    "print()\n",
    "\n",
    "print(\"Detailed classification report:\")\n",
    "print()\n",
    "print(\"The model is trained on the full development set.\")\n",
    "print(\"The scores are computed on the full evaluation set.\")\n",
    "print()\n",
    "y_true, y_pred = y_test, clf.predict(X_test)\n",
    "print(classification_report(y_true, y_pred))\n",
    "print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "V8NSN6vITj05"
   },
   "source": [
    "### Cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "aVumKaLJRwMz",
    "outputId": "51292cfc-fbe8-4623-e8ea-cd1113b74105"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.794657\n"
     ]
    }
   ],
   "source": [
    "clf = DecisionTreeClassifier(max_depth=7)\n",
    "score=cross_validate(clf, X, y, cv=10, scoring=\"accuracy\")[\"test_score\"].mean()\n",
    "print(f\"{score:.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Uu-YBpJKMd-G"
   },
   "source": [
    "### Generating Predicion Result for submission in .csv format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "P7Nms3-NrRP_"
   },
   "outputs": [],
   "source": [
    "df2 = pd.read_csv(url2)\n",
    "clf = DecisionTreeClassifier(max_depth=7)\n",
    "clf.fit(X, y)\n",
    "pred=clf.predict(X_test2)\n",
    "pd.DataFrame({\"PassengerId\": df2[\"PassengerId\"], \"Survived\": pred}).to_csv(\"DecisionTree_submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wFUZiAwo4SSd"
   },
   "source": [
    "![alt text](https://raw.githubusercontent.com/zyzhang1130/CE9010/master/Titanic/DecisionTree.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SQbRksfjmHr1"
   },
   "source": [
    "## GaussianProcessClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 520
    },
    "colab_type": "code",
    "id": "Su4WWi9xmJPs",
    "outputId": "2699d75f-31d1-4db5-fdaf-e6c37b97406c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best parameters set found on development set:\n",
      "\n",
      "{'kernel': 1**2 * RBF(length_scale=0.8)}\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "0.794 (+/-0.078) for {'kernel': 1**2 * RBF(length_scale=0.8)}\n",
      "0.794 (+/-0.078) for {'kernel': 1**2 * RBF(length_scale=0.9)}\n",
      "0.794 (+/-0.078) for {'kernel': 1**2 * RBF(length_scale=1)}\n",
      "0.794 (+/-0.078) for {'kernel': 1**2 * RBF(length_scale=1.1)}\n",
      "0.794 (+/-0.078) for {'kernel': 1**2 * RBF(length_scale=1.2)}\n",
      "0.794 (+/-0.078) for {'kernel': 1**2 * RBF(length_scale=1.3)}\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.86      0.89      0.88       114\n",
      "         1.0       0.80      0.73      0.76        64\n",
      "\n",
      "    accuracy                           0.84       178\n",
      "   macro avg       0.83      0.81      0.82       178\n",
      "weighted avg       0.84      0.84      0.84       178\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "tuned_parameters = [{'kernel':[1.0 * RBF(0.8),1.0 * RBF(0.9),1.0 * RBF(1.0),1.0 * RBF(1.1),1.0 * RBF(1.2),1.0 * RBF(1.3)]}\n",
    "                    ]\n",
    "\n",
    "\n",
    "print()\n",
    "\n",
    "clf = GridSearchCV(\n",
    "    GaussianProcessClassifier(), tuned_parameters, scoring='accuracy', cv=10\n",
    ")\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best parameters set found on development set:\")\n",
    "print()\n",
    "print(clf.best_params_)\n",
    "print()\n",
    "print(\"Grid scores on development set:\")\n",
    "print()\n",
    "means = clf.cv_results_['mean_test_score']\n",
    "stds = clf.cv_results_['std_test_score']\n",
    "for mean, std, params in zip(means, stds, clf.cv_results_['params']):\n",
    "    print(\"%0.3f (+/-%0.03f) for %r\"\n",
    "          % (mean, std * 2, params))\n",
    "print()\n",
    "\n",
    "print(\"Detailed classification report:\")\n",
    "print()\n",
    "print(\"The model is trained on the full development set.\")\n",
    "print(\"The scores are computed on the full evaluation set.\")\n",
    "print()\n",
    "y_true, y_pred = y_test, clf.predict(X_test)\n",
    "print(classification_report(y_true, y_pred))\n",
    "print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BoScu4AUTlrt"
   },
   "source": [
    "### Cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "KdQJzZfzSDAY",
    "outputId": "4466d679-0b36-4a37-db52-550fcd3dff31"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.815943\n"
     ]
    }
   ],
   "source": [
    "clf = GaussianProcessClassifier(1**2 * RBF(length_scale=0.8))\n",
    "score=cross_validate(clf, X, y, cv=10, scoring=\"accuracy\")[\"test_score\"].mean()\n",
    "print(f\"{score:.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1Ga4dOPoMfsl"
   },
   "source": [
    "### Generating Predicion Result for submission in .csv format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "72RgBwcOrfS3"
   },
   "outputs": [],
   "source": [
    "df2 = pd.read_csv(url2)\n",
    "clf = GaussianProcessClassifier(1**2 * RBF(length_scale=0.8))\n",
    "clf.fit(X, y)\n",
    "pred=clf.predict(X_test2)\n",
    "pd.DataFrame({\"PassengerId\": df2[\"PassengerId\"], \"Survived\": pred}).to_csv(\"GaussianProcess_submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XYKCujeq-_MM"
   },
   "source": [
    "![alt text](https://raw.githubusercontent.com/zyzhang1130/CE9010/master/Titanic/GaussianProcess.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3vfJ-NUNtXHd"
   },
   "source": [
    "## BaggingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 971
    },
    "colab_type": "code",
    "id": "V2DMamqHnZa7",
    "outputId": "49b673a3-e3cb-4521-ee44-651b38bd19e4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best parameters set found on development set:\n",
      "\n",
      "{'bootstrap': True, 'bootstrap_features': True, 'n_estimators': 10, 'warm_start': False}\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "0.787 (+/-0.098) for {'bootstrap': True, 'bootstrap_features': True, 'n_estimators': 8, 'warm_start': False}\n",
      "0.778 (+/-0.114) for {'bootstrap': True, 'bootstrap_features': True, 'n_estimators': 9, 'warm_start': False}\n",
      "0.808 (+/-0.097) for {'bootstrap': True, 'bootstrap_features': True, 'n_estimators': 10, 'warm_start': False}\n",
      "0.788 (+/-0.130) for {'bootstrap': True, 'bootstrap_features': True, 'n_estimators': 11, 'warm_start': False}\n",
      "0.785 (+/-0.105) for {'bootstrap': True, 'bootstrap_features': True, 'n_estimators': 12, 'warm_start': False}\n",
      "0.785 (+/-0.101) for {'bootstrap': True, 'bootstrap_features': True, 'n_estimators': 13, 'warm_start': False}\n",
      "0.792 (+/-0.084) for {'bootstrap': True, 'bootstrap_features': True, 'n_estimators': 14, 'warm_start': False}\n",
      "0.795 (+/-0.119) for {'bootstrap': True, 'bootstrap_features': True, 'n_estimators': 15, 'warm_start': False}\n",
      "0.792 (+/-0.099) for {'bootstrap': True, 'bootstrap_features': False, 'n_estimators': 8, 'warm_start': False}\n",
      "0.781 (+/-0.125) for {'bootstrap': True, 'bootstrap_features': False, 'n_estimators': 9, 'warm_start': False}\n",
      "0.805 (+/-0.104) for {'bootstrap': True, 'bootstrap_features': False, 'n_estimators': 10, 'warm_start': False}\n",
      "0.784 (+/-0.119) for {'bootstrap': True, 'bootstrap_features': False, 'n_estimators': 11, 'warm_start': False}\n",
      "0.789 (+/-0.097) for {'bootstrap': True, 'bootstrap_features': False, 'n_estimators': 12, 'warm_start': False}\n",
      "0.795 (+/-0.105) for {'bootstrap': True, 'bootstrap_features': False, 'n_estimators': 13, 'warm_start': False}\n",
      "0.782 (+/-0.125) for {'bootstrap': True, 'bootstrap_features': False, 'n_estimators': 14, 'warm_start': False}\n",
      "0.791 (+/-0.125) for {'bootstrap': True, 'bootstrap_features': False, 'n_estimators': 15, 'warm_start': False}\n",
      "0.780 (+/-0.122) for {'bootstrap': False, 'bootstrap_features': True, 'n_estimators': 8, 'warm_start': False}\n",
      "0.771 (+/-0.112) for {'bootstrap': False, 'bootstrap_features': True, 'n_estimators': 9, 'warm_start': False}\n",
      "0.777 (+/-0.134) for {'bootstrap': False, 'bootstrap_features': True, 'n_estimators': 10, 'warm_start': False}\n",
      "0.788 (+/-0.128) for {'bootstrap': False, 'bootstrap_features': True, 'n_estimators': 11, 'warm_start': False}\n",
      "0.775 (+/-0.127) for {'bootstrap': False, 'bootstrap_features': True, 'n_estimators': 12, 'warm_start': False}\n",
      "0.772 (+/-0.139) for {'bootstrap': False, 'bootstrap_features': True, 'n_estimators': 13, 'warm_start': False}\n",
      "0.782 (+/-0.127) for {'bootstrap': False, 'bootstrap_features': True, 'n_estimators': 14, 'warm_start': False}\n",
      "0.796 (+/-0.114) for {'bootstrap': False, 'bootstrap_features': True, 'n_estimators': 15, 'warm_start': False}\n",
      "0.775 (+/-0.138) for {'bootstrap': False, 'bootstrap_features': False, 'n_estimators': 8, 'warm_start': False}\n",
      "0.765 (+/-0.131) for {'bootstrap': False, 'bootstrap_features': False, 'n_estimators': 9, 'warm_start': False}\n",
      "0.770 (+/-0.133) for {'bootstrap': False, 'bootstrap_features': False, 'n_estimators': 10, 'warm_start': False}\n",
      "0.775 (+/-0.130) for {'bootstrap': False, 'bootstrap_features': False, 'n_estimators': 11, 'warm_start': False}\n",
      "0.768 (+/-0.116) for {'bootstrap': False, 'bootstrap_features': False, 'n_estimators': 12, 'warm_start': False}\n",
      "0.768 (+/-0.127) for {'bootstrap': False, 'bootstrap_features': False, 'n_estimators': 13, 'warm_start': False}\n",
      "0.771 (+/-0.132) for {'bootstrap': False, 'bootstrap_features': False, 'n_estimators': 14, 'warm_start': False}\n",
      "0.765 (+/-0.129) for {'bootstrap': False, 'bootstrap_features': False, 'n_estimators': 15, 'warm_start': False}\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.76      0.93      0.84       114\n",
      "         1.0       0.79      0.48      0.60        64\n",
      "\n",
      "    accuracy                           0.77       178\n",
      "   macro avg       0.78      0.71      0.72       178\n",
      "weighted avg       0.77      0.77      0.75       178\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "tuned_parameters = [{ 'n_estimators':[8,9,10,11,12,13,14,15],'warm_start':[ False],'bootstrap':[True, False],'bootstrap_features':[True, False]}\n",
    "                    ]\n",
    "\n",
    "\n",
    "print()\n",
    "\n",
    "clf = GridSearchCV(\n",
    "    BaggingClassifier(), tuned_parameters, scoring='accuracy', cv=10\n",
    ")\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best parameters set found on development set:\")\n",
    "print()\n",
    "print(clf.best_params_)\n",
    "print()\n",
    "print(\"Grid scores on development set:\")\n",
    "print()\n",
    "means = clf.cv_results_['mean_test_score']\n",
    "stds = clf.cv_results_['std_test_score']\n",
    "for mean, std, params in zip(means, stds, clf.cv_results_['params']):\n",
    "    print(\"%0.3f (+/-%0.03f) for %r\"\n",
    "          % (mean, std * 2, params))\n",
    "print()\n",
    "\n",
    "print(\"Detailed classification report:\")\n",
    "print()\n",
    "print(\"The model is trained on the full development set.\")\n",
    "print(\"The scores are computed on the full evaluation set.\")\n",
    "print()\n",
    "y_true, y_pred = y_test, clf.predict(X_test)\n",
    "print(classification_report(y_true, y_pred))\n",
    "print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DSRD6nEsTpc4"
   },
   "source": [
    "### Cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "mfw7Na19STo4",
    "outputId": "1442ed15-c04e-4b7c-ed0b-e8c09c80164f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.792409\n"
     ]
    }
   ],
   "source": [
    "clf = BaggingClassifier(bootstrap= True, bootstrap_features= True, n_estimators= 10, warm_start= False)\n",
    "score=cross_validate(clf, X, y, cv=10, scoring=\"accuracy\")[\"test_score\"].mean()\n",
    "print(f\"{score:.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UAgozb_kMh0q"
   },
   "source": [
    "### Generating Predicion Result for submission in .csv format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZWkOTvYarzua"
   },
   "outputs": [],
   "source": [
    "df2 = pd.read_csv(url2)\n",
    "clf = BaggingClassifier(bootstrap= True, bootstrap_features= True, n_estimators= 10, warm_start= False)\n",
    "clf.fit(X, y)\n",
    "pred=clf.predict(X_test2)\n",
    "pd.DataFrame({\"PassengerId\": df2[\"PassengerId\"], \"Survived\": pred}).to_csv(\"Bagging_submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "c6ObMls2yae5"
   },
   "source": [
    "![alt text](https://raw.githubusercontent.com/zyzhang1130/CE9010/master/Titanic/bagging.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "aal4SmKxICmE"
   },
   "source": [
    "## MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "jtRR1NEswjXV",
    "outputId": "6d7a9b07-5389-4ddc-cff6-923f1d0948bb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best parameters set found on development set:\n",
      "\n",
      "{'alpha': 0.01, 'early_stopping': False, 'max_iter': 2000, 'solver': 'adam'}\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "0.791 (+/-0.091) for {'alpha': 0.0001, 'early_stopping': True, 'max_iter': 1000, 'solver': 'adam'}\n",
      "0.777 (+/-0.090) for {'alpha': 0.0001, 'early_stopping': True, 'max_iter': 1500, 'solver': 'adam'}\n",
      "0.767 (+/-0.089) for {'alpha': 0.0001, 'early_stopping': True, 'max_iter': 2000, 'solver': 'adam'}\n",
      "0.805 (+/-0.080) for {'alpha': 0.0001, 'early_stopping': False, 'max_iter': 1000, 'solver': 'adam'}\n",
      "0.796 (+/-0.090) for {'alpha': 0.0001, 'early_stopping': False, 'max_iter': 1500, 'solver': 'adam'}\n",
      "0.798 (+/-0.095) for {'alpha': 0.0001, 'early_stopping': False, 'max_iter': 2000, 'solver': 'adam'}\n",
      "0.774 (+/-0.089) for {'alpha': 0.001, 'early_stopping': True, 'max_iter': 1000, 'solver': 'adam'}\n",
      "0.770 (+/-0.087) for {'alpha': 0.001, 'early_stopping': True, 'max_iter': 1500, 'solver': 'adam'}\n",
      "0.787 (+/-0.115) for {'alpha': 0.001, 'early_stopping': True, 'max_iter': 2000, 'solver': 'adam'}\n",
      "0.808 (+/-0.091) for {'alpha': 0.001, 'early_stopping': False, 'max_iter': 1000, 'solver': 'adam'}\n",
      "0.802 (+/-0.089) for {'alpha': 0.001, 'early_stopping': False, 'max_iter': 1500, 'solver': 'adam'}\n",
      "0.796 (+/-0.082) for {'alpha': 0.001, 'early_stopping': False, 'max_iter': 2000, 'solver': 'adam'}\n",
      "0.759 (+/-0.115) for {'alpha': 0.01, 'early_stopping': True, 'max_iter': 1000, 'solver': 'adam'}\n",
      "0.778 (+/-0.113) for {'alpha': 0.01, 'early_stopping': True, 'max_iter': 1500, 'solver': 'adam'}\n",
      "0.774 (+/-0.100) for {'alpha': 0.01, 'early_stopping': True, 'max_iter': 2000, 'solver': 'adam'}\n",
      "0.802 (+/-0.078) for {'alpha': 0.01, 'early_stopping': False, 'max_iter': 1000, 'solver': 'adam'}\n",
      "0.802 (+/-0.092) for {'alpha': 0.01, 'early_stopping': False, 'max_iter': 1500, 'solver': 'adam'}\n",
      "0.812 (+/-0.083) for {'alpha': 0.01, 'early_stopping': False, 'max_iter': 2000, 'solver': 'adam'}\n",
      "0.765 (+/-0.099) for {'alpha': 0.1, 'early_stopping': True, 'max_iter': 1000, 'solver': 'adam'}\n",
      "0.782 (+/-0.083) for {'alpha': 0.1, 'early_stopping': True, 'max_iter': 1500, 'solver': 'adam'}\n",
      "0.763 (+/-0.075) for {'alpha': 0.1, 'early_stopping': True, 'max_iter': 2000, 'solver': 'adam'}\n",
      "0.810 (+/-0.085) for {'alpha': 0.1, 'early_stopping': False, 'max_iter': 1000, 'solver': 'adam'}\n",
      "0.803 (+/-0.083) for {'alpha': 0.1, 'early_stopping': False, 'max_iter': 1500, 'solver': 'adam'}\n",
      "0.803 (+/-0.092) for {'alpha': 0.1, 'early_stopping': False, 'max_iter': 2000, 'solver': 'adam'}\n",
      "0.777 (+/-0.122) for {'alpha': 1, 'early_stopping': True, 'max_iter': 1000, 'solver': 'adam'}\n",
      "0.756 (+/-0.093) for {'alpha': 1, 'early_stopping': True, 'max_iter': 1500, 'solver': 'adam'}\n",
      "0.778 (+/-0.066) for {'alpha': 1, 'early_stopping': True, 'max_iter': 2000, 'solver': 'adam'}\n",
      "0.798 (+/-0.075) for {'alpha': 1, 'early_stopping': False, 'max_iter': 1000, 'solver': 'adam'}\n",
      "0.795 (+/-0.074) for {'alpha': 1, 'early_stopping': False, 'max_iter': 1500, 'solver': 'adam'}\n",
      "0.796 (+/-0.080) for {'alpha': 1, 'early_stopping': False, 'max_iter': 2000, 'solver': 'adam'}\n",
      "0.600 (+/-0.133) for {'alpha': 0.0001, 'early_stopping': True, 'learning_rate': 'constant', 'max_iter': 1000, 'momentum': 0.1, 'solver': 'sgd'}\n",
      "0.524 (+/-0.269) for {'alpha': 0.0001, 'early_stopping': True, 'learning_rate': 'constant', 'max_iter': 1000, 'momentum': 0.3, 'solver': 'sgd'}\n",
      "0.585 (+/-0.221) for {'alpha': 0.0001, 'early_stopping': True, 'learning_rate': 'constant', 'max_iter': 1000, 'momentum': 0.5, 'solver': 'sgd'}\n",
      "0.673 (+/-0.086) for {'alpha': 0.0001, 'early_stopping': True, 'learning_rate': 'constant', 'max_iter': 1000, 'momentum': 0.7, 'solver': 'sgd'}\n",
      "0.735 (+/-0.078) for {'alpha': 0.0001, 'early_stopping': True, 'learning_rate': 'constant', 'max_iter': 1000, 'momentum': 0.9, 'solver': 'sgd'}\n",
      "0.547 (+/-0.256) for {'alpha': 0.0001, 'early_stopping': True, 'learning_rate': 'constant', 'max_iter': 1500, 'momentum': 0.1, 'solver': 'sgd'}\n",
      "0.580 (+/-0.188) for {'alpha': 0.0001, 'early_stopping': True, 'learning_rate': 'constant', 'max_iter': 1500, 'momentum': 0.3, 'solver': 'sgd'}\n",
      "0.573 (+/-0.226) for {'alpha': 0.0001, 'early_stopping': True, 'learning_rate': 'constant', 'max_iter': 1500, 'momentum': 0.5, 'solver': 'sgd'}\n",
      "0.590 (+/-0.241) for {'alpha': 0.0001, 'early_stopping': True, 'learning_rate': 'constant', 'max_iter': 1500, 'momentum': 0.7, 'solver': 'sgd'}\n",
      "0.694 (+/-0.217) for {'alpha': 0.0001, 'early_stopping': True, 'learning_rate': 'constant', 'max_iter': 1500, 'momentum': 0.9, 'solver': 'sgd'}\n",
      "0.535 (+/-0.307) for {'alpha': 0.0001, 'early_stopping': True, 'learning_rate': 'constant', 'max_iter': 2000, 'momentum': 0.1, 'solver': 'sgd'}\n",
      "0.593 (+/-0.212) for {'alpha': 0.0001, 'early_stopping': True, 'learning_rate': 'constant', 'max_iter': 2000, 'momentum': 0.3, 'solver': 'sgd'}\n",
      "0.497 (+/-0.216) for {'alpha': 0.0001, 'early_stopping': True, 'learning_rate': 'constant', 'max_iter': 2000, 'momentum': 0.5, 'solver': 'sgd'}\n",
      "0.606 (+/-0.237) for {'alpha': 0.0001, 'early_stopping': True, 'learning_rate': 'constant', 'max_iter': 2000, 'momentum': 0.7, 'solver': 'sgd'}\n",
      "0.701 (+/-0.126) for {'alpha': 0.0001, 'early_stopping': True, 'learning_rate': 'constant', 'max_iter': 2000, 'momentum': 0.9, 'solver': 'sgd'}\n",
      "0.469 (+/-0.197) for {'alpha': 0.0001, 'early_stopping': True, 'learning_rate': 'invscaling', 'max_iter': 1000, 'momentum': 0.1, 'solver': 'sgd'}\n",
      "0.463 (+/-0.160) for {'alpha': 0.0001, 'early_stopping': True, 'learning_rate': 'invscaling', 'max_iter': 1000, 'momentum': 0.3, 'solver': 'sgd'}\n",
      "0.486 (+/-0.223) for {'alpha': 0.0001, 'early_stopping': True, 'learning_rate': 'invscaling', 'max_iter': 1000, 'momentum': 0.5, 'solver': 'sgd'}\n",
      "0.573 (+/-0.218) for {'alpha': 0.0001, 'early_stopping': True, 'learning_rate': 'invscaling', 'max_iter': 1000, 'momentum': 0.7, 'solver': 'sgd'}\n",
      "0.483 (+/-0.200) for {'alpha': 0.0001, 'early_stopping': True, 'learning_rate': 'invscaling', 'max_iter': 1000, 'momentum': 0.9, 'solver': 'sgd'}\n",
      "0.525 (+/-0.256) for {'alpha': 0.0001, 'early_stopping': True, 'learning_rate': 'invscaling', 'max_iter': 1500, 'momentum': 0.1, 'solver': 'sgd'}\n",
      "0.497 (+/-0.297) for {'alpha': 0.0001, 'early_stopping': True, 'learning_rate': 'invscaling', 'max_iter': 1500, 'momentum': 0.3, 'solver': 'sgd'}\n",
      "0.531 (+/-0.285) for {'alpha': 0.0001, 'early_stopping': True, 'learning_rate': 'invscaling', 'max_iter': 1500, 'momentum': 0.5, 'solver': 'sgd'}\n",
      "0.476 (+/-0.225) for {'alpha': 0.0001, 'early_stopping': True, 'learning_rate': 'invscaling', 'max_iter': 1500, 'momentum': 0.7, 'solver': 'sgd'}\n",
      "0.546 (+/-0.255) for {'alpha': 0.0001, 'early_stopping': True, 'learning_rate': 'invscaling', 'max_iter': 1500, 'momentum': 0.9, 'solver': 'sgd'}\n",
      "0.506 (+/-0.260) for {'alpha': 0.0001, 'early_stopping': True, 'learning_rate': 'invscaling', 'max_iter': 2000, 'momentum': 0.1, 'solver': 'sgd'}\n",
      "0.497 (+/-0.296) for {'alpha': 0.0001, 'early_stopping': True, 'learning_rate': 'invscaling', 'max_iter': 2000, 'momentum': 0.3, 'solver': 'sgd'}\n",
      "0.516 (+/-0.225) for {'alpha': 0.0001, 'early_stopping': True, 'learning_rate': 'invscaling', 'max_iter': 2000, 'momentum': 0.5, 'solver': 'sgd'}\n",
      "0.489 (+/-0.179) for {'alpha': 0.0001, 'early_stopping': True, 'learning_rate': 'invscaling', 'max_iter': 2000, 'momentum': 0.7, 'solver': 'sgd'}\n",
      "0.518 (+/-0.217) for {'alpha': 0.0001, 'early_stopping': True, 'learning_rate': 'invscaling', 'max_iter': 2000, 'momentum': 0.9, 'solver': 'sgd'}\n",
      "0.598 (+/-0.187) for {'alpha': 0.0001, 'early_stopping': True, 'learning_rate': 'adaptive', 'max_iter': 1000, 'momentum': 0.1, 'solver': 'sgd'}\n",
      "0.548 (+/-0.273) for {'alpha': 0.0001, 'early_stopping': True, 'learning_rate': 'adaptive', 'max_iter': 1000, 'momentum': 0.3, 'solver': 'sgd'}\n",
      "0.605 (+/-0.147) for {'alpha': 0.0001, 'early_stopping': True, 'learning_rate': 'adaptive', 'max_iter': 1000, 'momentum': 0.5, 'solver': 'sgd'}\n",
      "0.565 (+/-0.231) for {'alpha': 0.0001, 'early_stopping': True, 'learning_rate': 'adaptive', 'max_iter': 1000, 'momentum': 0.7, 'solver': 'sgd'}\n",
      "0.716 (+/-0.138) for {'alpha': 0.0001, 'early_stopping': True, 'learning_rate': 'adaptive', 'max_iter': 1000, 'momentum': 0.9, 'solver': 'sgd'}\n",
      "0.521 (+/-0.261) for {'alpha': 0.0001, 'early_stopping': True, 'learning_rate': 'adaptive', 'max_iter': 1500, 'momentum': 0.1, 'solver': 'sgd'}\n",
      "0.524 (+/-0.316) for {'alpha': 0.0001, 'early_stopping': True, 'learning_rate': 'adaptive', 'max_iter': 1500, 'momentum': 0.3, 'solver': 'sgd'}\n",
      "0.599 (+/-0.255) for {'alpha': 0.0001, 'early_stopping': True, 'learning_rate': 'adaptive', 'max_iter': 1500, 'momentum': 0.5, 'solver': 'sgd'}\n",
      "0.566 (+/-0.258) for {'alpha': 0.0001, 'early_stopping': True, 'learning_rate': 'adaptive', 'max_iter': 1500, 'momentum': 0.7, 'solver': 'sgd'}\n",
      "0.739 (+/-0.089) for {'alpha': 0.0001, 'early_stopping': True, 'learning_rate': 'adaptive', 'max_iter': 1500, 'momentum': 0.9, 'solver': 'sgd'}\n",
      "0.573 (+/-0.283) for {'alpha': 0.0001, 'early_stopping': True, 'learning_rate': 'adaptive', 'max_iter': 2000, 'momentum': 0.1, 'solver': 'sgd'}\n",
      "0.532 (+/-0.130) for {'alpha': 0.0001, 'early_stopping': True, 'learning_rate': 'adaptive', 'max_iter': 2000, 'momentum': 0.3, 'solver': 'sgd'}\n",
      "0.607 (+/-0.228) for {'alpha': 0.0001, 'early_stopping': True, 'learning_rate': 'adaptive', 'max_iter': 2000, 'momentum': 0.5, 'solver': 'sgd'}\n",
      "0.606 (+/-0.198) for {'alpha': 0.0001, 'early_stopping': True, 'learning_rate': 'adaptive', 'max_iter': 2000, 'momentum': 0.7, 'solver': 'sgd'}\n",
      "0.723 (+/-0.164) for {'alpha': 0.0001, 'early_stopping': True, 'learning_rate': 'adaptive', 'max_iter': 2000, 'momentum': 0.9, 'solver': 'sgd'}\n",
      "0.791 (+/-0.074) for {'alpha': 0.0001, 'early_stopping': False, 'learning_rate': 'constant', 'max_iter': 1000, 'momentum': 0.1, 'solver': 'sgd'}\n",
      "0.777 (+/-0.074) for {'alpha': 0.0001, 'early_stopping': False, 'learning_rate': 'constant', 'max_iter': 1000, 'momentum': 0.3, 'solver': 'sgd'}\n",
      "0.781 (+/-0.076) for {'alpha': 0.0001, 'early_stopping': False, 'learning_rate': 'constant', 'max_iter': 1000, 'momentum': 0.5, 'solver': 'sgd'}\n",
      "0.789 (+/-0.084) for {'alpha': 0.0001, 'early_stopping': False, 'learning_rate': 'constant', 'max_iter': 1000, 'momentum': 0.7, 'solver': 'sgd'}\n",
      "0.787 (+/-0.083) for {'alpha': 0.0001, 'early_stopping': False, 'learning_rate': 'constant', 'max_iter': 1000, 'momentum': 0.9, 'solver': 'sgd'}\n",
      "0.778 (+/-0.077) for {'alpha': 0.0001, 'early_stopping': False, 'learning_rate': 'constant', 'max_iter': 1500, 'momentum': 0.1, 'solver': 'sgd'}\n",
      "0.778 (+/-0.093) for {'alpha': 0.0001, 'early_stopping': False, 'learning_rate': 'constant', 'max_iter': 1500, 'momentum': 0.3, 'solver': 'sgd'}\n",
      "0.778 (+/-0.084) for {'alpha': 0.0001, 'early_stopping': False, 'learning_rate': 'constant', 'max_iter': 1500, 'momentum': 0.5, 'solver': 'sgd'}\n",
      "0.787 (+/-0.088) for {'alpha': 0.0001, 'early_stopping': False, 'learning_rate': 'constant', 'max_iter': 1500, 'momentum': 0.7, 'solver': 'sgd'}\n",
      "0.791 (+/-0.077) for {'alpha': 0.0001, 'early_stopping': False, 'learning_rate': 'constant', 'max_iter': 1500, 'momentum': 0.9, 'solver': 'sgd'}\n",
      "0.780 (+/-0.088) for {'alpha': 0.0001, 'early_stopping': False, 'learning_rate': 'constant', 'max_iter': 2000, 'momentum': 0.1, 'solver': 'sgd'}\n",
      "0.781 (+/-0.092) for {'alpha': 0.0001, 'early_stopping': False, 'learning_rate': 'constant', 'max_iter': 2000, 'momentum': 0.3, 'solver': 'sgd'}\n",
      "0.777 (+/-0.071) for {'alpha': 0.0001, 'early_stopping': False, 'learning_rate': 'constant', 'max_iter': 2000, 'momentum': 0.5, 'solver': 'sgd'}\n",
      "0.785 (+/-0.074) for {'alpha': 0.0001, 'early_stopping': False, 'learning_rate': 'constant', 'max_iter': 2000, 'momentum': 0.7, 'solver': 'sgd'}\n",
      "0.788 (+/-0.084) for {'alpha': 0.0001, 'early_stopping': False, 'learning_rate': 'constant', 'max_iter': 2000, 'momentum': 0.9, 'solver': 'sgd'}\n",
      "0.548 (+/-0.275) for {'alpha': 0.0001, 'early_stopping': False, 'learning_rate': 'invscaling', 'max_iter': 1000, 'momentum': 0.1, 'solver': 'sgd'}\n",
      "0.427 (+/-0.232) for {'alpha': 0.0001, 'early_stopping': False, 'learning_rate': 'invscaling', 'max_iter': 1000, 'momentum': 0.3, 'solver': 'sgd'}\n",
      "0.510 (+/-0.213) for {'alpha': 0.0001, 'early_stopping': False, 'learning_rate': 'invscaling', 'max_iter': 1000, 'momentum': 0.5, 'solver': 'sgd'}\n",
      "0.584 (+/-0.195) for {'alpha': 0.0001, 'early_stopping': False, 'learning_rate': 'invscaling', 'max_iter': 1000, 'momentum': 0.7, 'solver': 'sgd'}\n",
      "0.475 (+/-0.253) for {'alpha': 0.0001, 'early_stopping': False, 'learning_rate': 'invscaling', 'max_iter': 1000, 'momentum': 0.9, 'solver': 'sgd'}\n",
      "0.569 (+/-0.270) for {'alpha': 0.0001, 'early_stopping': False, 'learning_rate': 'invscaling', 'max_iter': 1500, 'momentum': 0.1, 'solver': 'sgd'}\n",
      "0.431 (+/-0.213) for {'alpha': 0.0001, 'early_stopping': False, 'learning_rate': 'invscaling', 'max_iter': 1500, 'momentum': 0.3, 'solver': 'sgd'}\n",
      "0.489 (+/-0.241) for {'alpha': 0.0001, 'early_stopping': False, 'learning_rate': 'invscaling', 'max_iter': 1500, 'momentum': 0.5, 'solver': 'sgd'}\n",
      "0.520 (+/-0.248) for {'alpha': 0.0001, 'early_stopping': False, 'learning_rate': 'invscaling', 'max_iter': 1500, 'momentum': 0.7, 'solver': 'sgd'}\n",
      "0.523 (+/-0.272) for {'alpha': 0.0001, 'early_stopping': False, 'learning_rate': 'invscaling', 'max_iter': 1500, 'momentum': 0.9, 'solver': 'sgd'}\n",
      "0.457 (+/-0.224) for {'alpha': 0.0001, 'early_stopping': False, 'learning_rate': 'invscaling', 'max_iter': 2000, 'momentum': 0.1, 'solver': 'sgd'}\n",
      "0.460 (+/-0.296) for {'alpha': 0.0001, 'early_stopping': False, 'learning_rate': 'invscaling', 'max_iter': 2000, 'momentum': 0.3, 'solver': 'sgd'}\n",
      "0.503 (+/-0.277) for {'alpha': 0.0001, 'early_stopping': False, 'learning_rate': 'invscaling', 'max_iter': 2000, 'momentum': 0.5, 'solver': 'sgd'}\n",
      "0.601 (+/-0.187) for {'alpha': 0.0001, 'early_stopping': False, 'learning_rate': 'invscaling', 'max_iter': 2000, 'momentum': 0.7, 'solver': 'sgd'}\n",
      "0.534 (+/-0.249) for {'alpha': 0.0001, 'early_stopping': False, 'learning_rate': 'invscaling', 'max_iter': 2000, 'momentum': 0.9, 'solver': 'sgd'}\n",
      "0.785 (+/-0.106) for {'alpha': 0.0001, 'early_stopping': False, 'learning_rate': 'adaptive', 'max_iter': 1000, 'momentum': 0.1, 'solver': 'sgd'}\n",
      "0.781 (+/-0.066) for {'alpha': 0.0001, 'early_stopping': False, 'learning_rate': 'adaptive', 'max_iter': 1000, 'momentum': 0.3, 'solver': 'sgd'}\n",
      "0.791 (+/-0.083) for {'alpha': 0.0001, 'early_stopping': False, 'learning_rate': 'adaptive', 'max_iter': 1000, 'momentum': 0.5, 'solver': 'sgd'}\n",
      "0.781 (+/-0.070) for {'alpha': 0.0001, 'early_stopping': False, 'learning_rate': 'adaptive', 'max_iter': 1000, 'momentum': 0.7, 'solver': 'sgd'}\n",
      "0.789 (+/-0.079) for {'alpha': 0.0001, 'early_stopping': False, 'learning_rate': 'adaptive', 'max_iter': 1000, 'momentum': 0.9, 'solver': 'sgd'}\n",
      "0.782 (+/-0.081) for {'alpha': 0.0001, 'early_stopping': False, 'learning_rate': 'adaptive', 'max_iter': 1500, 'momentum': 0.1, 'solver': 'sgd'}\n",
      "0.774 (+/-0.076) for {'alpha': 0.0001, 'early_stopping': False, 'learning_rate': 'adaptive', 'max_iter': 1500, 'momentum': 0.3, 'solver': 'sgd'}\n",
      "0.794 (+/-0.084) for {'alpha': 0.0001, 'early_stopping': False, 'learning_rate': 'adaptive', 'max_iter': 1500, 'momentum': 0.5, 'solver': 'sgd'}\n",
      "0.782 (+/-0.090) for {'alpha': 0.0001, 'early_stopping': False, 'learning_rate': 'adaptive', 'max_iter': 1500, 'momentum': 0.7, 'solver': 'sgd'}\n",
      "0.792 (+/-0.075) for {'alpha': 0.0001, 'early_stopping': False, 'learning_rate': 'adaptive', 'max_iter': 1500, 'momentum': 0.9, 'solver': 'sgd'}\n",
      "0.785 (+/-0.099) for {'alpha': 0.0001, 'early_stopping': False, 'learning_rate': 'adaptive', 'max_iter': 2000, 'momentum': 0.1, 'solver': 'sgd'}\n",
      "0.780 (+/-0.080) for {'alpha': 0.0001, 'early_stopping': False, 'learning_rate': 'adaptive', 'max_iter': 2000, 'momentum': 0.3, 'solver': 'sgd'}\n",
      "0.775 (+/-0.067) for {'alpha': 0.0001, 'early_stopping': False, 'learning_rate': 'adaptive', 'max_iter': 2000, 'momentum': 0.5, 'solver': 'sgd'}\n",
      "0.781 (+/-0.070) for {'alpha': 0.0001, 'early_stopping': False, 'learning_rate': 'adaptive', 'max_iter': 2000, 'momentum': 0.7, 'solver': 'sgd'}\n",
      "0.784 (+/-0.080) for {'alpha': 0.0001, 'early_stopping': False, 'learning_rate': 'adaptive', 'max_iter': 2000, 'momentum': 0.9, 'solver': 'sgd'}\n",
      "0.525 (+/-0.239) for {'alpha': 0.001, 'early_stopping': True, 'learning_rate': 'constant', 'max_iter': 1000, 'momentum': 0.1, 'solver': 'sgd'}\n",
      "0.500 (+/-0.195) for {'alpha': 0.001, 'early_stopping': True, 'learning_rate': 'constant', 'max_iter': 1000, 'momentum': 0.3, 'solver': 'sgd'}\n",
      "0.521 (+/-0.318) for {'alpha': 0.001, 'early_stopping': True, 'learning_rate': 'constant', 'max_iter': 1000, 'momentum': 0.5, 'solver': 'sgd'}\n",
      "0.587 (+/-0.228) for {'alpha': 0.001, 'early_stopping': True, 'learning_rate': 'constant', 'max_iter': 1000, 'momentum': 0.7, 'solver': 'sgd'}\n",
      "0.646 (+/-0.297) for {'alpha': 0.001, 'early_stopping': True, 'learning_rate': 'constant', 'max_iter': 1000, 'momentum': 0.9, 'solver': 'sgd'}\n",
      "0.590 (+/-0.276) for {'alpha': 0.001, 'early_stopping': True, 'learning_rate': 'constant', 'max_iter': 1500, 'momentum': 0.1, 'solver': 'sgd'}\n",
      "0.546 (+/-0.254) for {'alpha': 0.001, 'early_stopping': True, 'learning_rate': 'constant', 'max_iter': 1500, 'momentum': 0.3, 'solver': 'sgd'}\n",
      "0.562 (+/-0.243) for {'alpha': 0.001, 'early_stopping': True, 'learning_rate': 'constant', 'max_iter': 1500, 'momentum': 0.5, 'solver': 'sgd'}\n",
      "0.566 (+/-0.244) for {'alpha': 0.001, 'early_stopping': True, 'learning_rate': 'constant', 'max_iter': 1500, 'momentum': 0.7, 'solver': 'sgd'}\n",
      "0.708 (+/-0.159) for {'alpha': 0.001, 'early_stopping': True, 'learning_rate': 'constant', 'max_iter': 1500, 'momentum': 0.9, 'solver': 'sgd'}\n",
      "0.496 (+/-0.232) for {'alpha': 0.001, 'early_stopping': True, 'learning_rate': 'constant', 'max_iter': 2000, 'momentum': 0.1, 'solver': 'sgd'}\n",
      "0.518 (+/-0.247) for {'alpha': 0.001, 'early_stopping': True, 'learning_rate': 'constant', 'max_iter': 2000, 'momentum': 0.3, 'solver': 'sgd'}\n",
      "0.537 (+/-0.248) for {'alpha': 0.001, 'early_stopping': True, 'learning_rate': 'constant', 'max_iter': 2000, 'momentum': 0.5, 'solver': 'sgd'}\n",
      "0.587 (+/-0.219) for {'alpha': 0.001, 'early_stopping': True, 'learning_rate': 'constant', 'max_iter': 2000, 'momentum': 0.7, 'solver': 'sgd'}\n",
      "0.654 (+/-0.075) for {'alpha': 0.001, 'early_stopping': True, 'learning_rate': 'constant', 'max_iter': 2000, 'momentum': 0.9, 'solver': 'sgd'}\n",
      "0.542 (+/-0.253) for {'alpha': 0.001, 'early_stopping': True, 'learning_rate': 'invscaling', 'max_iter': 1000, 'momentum': 0.1, 'solver': 'sgd'}\n",
      "0.486 (+/-0.221) for {'alpha': 0.001, 'early_stopping': True, 'learning_rate': 'invscaling', 'max_iter': 1000, 'momentum': 0.3, 'solver': 'sgd'}\n",
      "0.555 (+/-0.290) for {'alpha': 0.001, 'early_stopping': True, 'learning_rate': 'invscaling', 'max_iter': 1000, 'momentum': 0.5, 'solver': 'sgd'}\n",
      "0.499 (+/-0.281) for {'alpha': 0.001, 'early_stopping': True, 'learning_rate': 'invscaling', 'max_iter': 1000, 'momentum': 0.7, 'solver': 'sgd'}\n",
      "0.541 (+/-0.243) for {'alpha': 0.001, 'early_stopping': True, 'learning_rate': 'invscaling', 'max_iter': 1000, 'momentum': 0.9, 'solver': 'sgd'}\n",
      "0.470 (+/-0.232) for {'alpha': 0.001, 'early_stopping': True, 'learning_rate': 'invscaling', 'max_iter': 1500, 'momentum': 0.1, 'solver': 'sgd'}\n",
      "0.462 (+/-0.282) for {'alpha': 0.001, 'early_stopping': True, 'learning_rate': 'invscaling', 'max_iter': 1500, 'momentum': 0.3, 'solver': 'sgd'}\n",
      "0.531 (+/-0.329) for {'alpha': 0.001, 'early_stopping': True, 'learning_rate': 'invscaling', 'max_iter': 1500, 'momentum': 0.5, 'solver': 'sgd'}\n",
      "0.502 (+/-0.316) for {'alpha': 0.001, 'early_stopping': True, 'learning_rate': 'invscaling', 'max_iter': 1500, 'momentum': 0.7, 'solver': 'sgd'}\n",
      "0.417 (+/-0.258) for {'alpha': 0.001, 'early_stopping': True, 'learning_rate': 'invscaling', 'max_iter': 1500, 'momentum': 0.9, 'solver': 'sgd'}\n",
      "0.483 (+/-0.199) for {'alpha': 0.001, 'early_stopping': True, 'learning_rate': 'invscaling', 'max_iter': 2000, 'momentum': 0.1, 'solver': 'sgd'}\n",
      "0.555 (+/-0.306) for {'alpha': 0.001, 'early_stopping': True, 'learning_rate': 'invscaling', 'max_iter': 2000, 'momentum': 0.3, 'solver': 'sgd'}\n",
      "0.428 (+/-0.216) for {'alpha': 0.001, 'early_stopping': True, 'learning_rate': 'invscaling', 'max_iter': 2000, 'momentum': 0.5, 'solver': 'sgd'}\n",
      "0.509 (+/-0.235) for {'alpha': 0.001, 'early_stopping': True, 'learning_rate': 'invscaling', 'max_iter': 2000, 'momentum': 0.7, 'solver': 'sgd'}\n",
      "0.496 (+/-0.324) for {'alpha': 0.001, 'early_stopping': True, 'learning_rate': 'invscaling', 'max_iter': 2000, 'momentum': 0.9, 'solver': 'sgd'}\n",
      "0.521 (+/-0.268) for {'alpha': 0.001, 'early_stopping': True, 'learning_rate': 'adaptive', 'max_iter': 1000, 'momentum': 0.1, 'solver': 'sgd'}\n",
      "0.509 (+/-0.240) for {'alpha': 0.001, 'early_stopping': True, 'learning_rate': 'adaptive', 'max_iter': 1000, 'momentum': 0.3, 'solver': 'sgd'}\n",
      "0.601 (+/-0.120) for {'alpha': 0.001, 'early_stopping': True, 'learning_rate': 'adaptive', 'max_iter': 1000, 'momentum': 0.5, 'solver': 'sgd'}\n",
      "0.624 (+/-0.261) for {'alpha': 0.001, 'early_stopping': True, 'learning_rate': 'adaptive', 'max_iter': 1000, 'momentum': 0.7, 'solver': 'sgd'}\n",
      "0.707 (+/-0.177) for {'alpha': 0.001, 'early_stopping': True, 'learning_rate': 'adaptive', 'max_iter': 1000, 'momentum': 0.9, 'solver': 'sgd'}\n",
      "0.566 (+/-0.252) for {'alpha': 0.001, 'early_stopping': True, 'learning_rate': 'adaptive', 'max_iter': 1500, 'momentum': 0.1, 'solver': 'sgd'}\n",
      "0.579 (+/-0.197) for {'alpha': 0.001, 'early_stopping': True, 'learning_rate': 'adaptive', 'max_iter': 1500, 'momentum': 0.3, 'solver': 'sgd'}\n",
      "0.537 (+/-0.254) for {'alpha': 0.001, 'early_stopping': True, 'learning_rate': 'adaptive', 'max_iter': 1500, 'momentum': 0.5, 'solver': 'sgd'}\n",
      "0.601 (+/-0.186) for {'alpha': 0.001, 'early_stopping': True, 'learning_rate': 'adaptive', 'max_iter': 1500, 'momentum': 0.7, 'solver': 'sgd'}\n",
      "0.732 (+/-0.154) for {'alpha': 0.001, 'early_stopping': True, 'learning_rate': 'adaptive', 'max_iter': 1500, 'momentum': 0.9, 'solver': 'sgd'}\n",
      "0.480 (+/-0.215) for {'alpha': 0.001, 'early_stopping': True, 'learning_rate': 'adaptive', 'max_iter': 2000, 'momentum': 0.1, 'solver': 'sgd'}\n",
      "0.549 (+/-0.290) for {'alpha': 0.001, 'early_stopping': True, 'learning_rate': 'adaptive', 'max_iter': 2000, 'momentum': 0.3, 'solver': 'sgd'}\n",
      "0.557 (+/-0.240) for {'alpha': 0.001, 'early_stopping': True, 'learning_rate': 'adaptive', 'max_iter': 2000, 'momentum': 0.5, 'solver': 'sgd'}\n",
      "0.671 (+/-0.127) for {'alpha': 0.001, 'early_stopping': True, 'learning_rate': 'adaptive', 'max_iter': 2000, 'momentum': 0.7, 'solver': 'sgd'}\n",
      "0.681 (+/-0.118) for {'alpha': 0.001, 'early_stopping': True, 'learning_rate': 'adaptive', 'max_iter': 2000, 'momentum': 0.9, 'solver': 'sgd'}\n",
      "0.798 (+/-0.102) for {'alpha': 0.001, 'early_stopping': False, 'learning_rate': 'constant', 'max_iter': 1000, 'momentum': 0.1, 'solver': 'sgd'}\n",
      "0.781 (+/-0.082) for {'alpha': 0.001, 'early_stopping': False, 'learning_rate': 'constant', 'max_iter': 1000, 'momentum': 0.3, 'solver': 'sgd'}\n",
      "0.788 (+/-0.075) for {'alpha': 0.001, 'early_stopping': False, 'learning_rate': 'constant', 'max_iter': 1000, 'momentum': 0.5, 'solver': 'sgd'}\n",
      "0.782 (+/-0.068) for {'alpha': 0.001, 'early_stopping': False, 'learning_rate': 'constant', 'max_iter': 1000, 'momentum': 0.7, 'solver': 'sgd'}\n",
      "0.794 (+/-0.086) for {'alpha': 0.001, 'early_stopping': False, 'learning_rate': 'constant', 'max_iter': 1000, 'momentum': 0.9, 'solver': 'sgd'}\n",
      "0.784 (+/-0.078) for {'alpha': 0.001, 'early_stopping': False, 'learning_rate': 'constant', 'max_iter': 1500, 'momentum': 0.1, 'solver': 'sgd'}\n",
      "0.775 (+/-0.093) for {'alpha': 0.001, 'early_stopping': False, 'learning_rate': 'constant', 'max_iter': 1500, 'momentum': 0.3, 'solver': 'sgd'}\n",
      "0.773 (+/-0.064) for {'alpha': 0.001, 'early_stopping': False, 'learning_rate': 'constant', 'max_iter': 1500, 'momentum': 0.5, 'solver': 'sgd'}\n",
      "0.791 (+/-0.087) for {'alpha': 0.001, 'early_stopping': False, 'learning_rate': 'constant', 'max_iter': 1500, 'momentum': 0.7, 'solver': 'sgd'}\n",
      "0.789 (+/-0.081) for {'alpha': 0.001, 'early_stopping': False, 'learning_rate': 'constant', 'max_iter': 1500, 'momentum': 0.9, 'solver': 'sgd'}\n",
      "0.789 (+/-0.104) for {'alpha': 0.001, 'early_stopping': False, 'learning_rate': 'constant', 'max_iter': 2000, 'momentum': 0.1, 'solver': 'sgd'}\n",
      "0.774 (+/-0.088) for {'alpha': 0.001, 'early_stopping': False, 'learning_rate': 'constant', 'max_iter': 2000, 'momentum': 0.3, 'solver': 'sgd'}\n",
      "0.777 (+/-0.065) for {'alpha': 0.001, 'early_stopping': False, 'learning_rate': 'constant', 'max_iter': 2000, 'momentum': 0.5, 'solver': 'sgd'}\n",
      "0.789 (+/-0.060) for {'alpha': 0.001, 'early_stopping': False, 'learning_rate': 'constant', 'max_iter': 2000, 'momentum': 0.7, 'solver': 'sgd'}\n",
      "0.789 (+/-0.074) for {'alpha': 0.001, 'early_stopping': False, 'learning_rate': 'constant', 'max_iter': 2000, 'momentum': 0.9, 'solver': 'sgd'}\n",
      "0.431 (+/-0.217) for {'alpha': 0.001, 'early_stopping': False, 'learning_rate': 'invscaling', 'max_iter': 1000, 'momentum': 0.1, 'solver': 'sgd'}\n",
      "0.508 (+/-0.308) for {'alpha': 0.001, 'early_stopping': False, 'learning_rate': 'invscaling', 'max_iter': 1000, 'momentum': 0.3, 'solver': 'sgd'}\n",
      "0.543 (+/-0.376) for {'alpha': 0.001, 'early_stopping': False, 'learning_rate': 'invscaling', 'max_iter': 1000, 'momentum': 0.5, 'solver': 'sgd'}\n",
      "0.500 (+/-0.253) for {'alpha': 0.001, 'early_stopping': False, 'learning_rate': 'invscaling', 'max_iter': 1000, 'momentum': 0.7, 'solver': 'sgd'}\n",
      "0.521 (+/-0.291) for {'alpha': 0.001, 'early_stopping': False, 'learning_rate': 'invscaling', 'max_iter': 1000, 'momentum': 0.9, 'solver': 'sgd'}\n",
      "0.535 (+/-0.232) for {'alpha': 0.001, 'early_stopping': False, 'learning_rate': 'invscaling', 'max_iter': 1500, 'momentum': 0.1, 'solver': 'sgd'}\n",
      "0.397 (+/-0.259) for {'alpha': 0.001, 'early_stopping': False, 'learning_rate': 'invscaling', 'max_iter': 1500, 'momentum': 0.3, 'solver': 'sgd'}\n",
      "0.428 (+/-0.246) for {'alpha': 0.001, 'early_stopping': False, 'learning_rate': 'invscaling', 'max_iter': 1500, 'momentum': 0.5, 'solver': 'sgd'}\n",
      "0.490 (+/-0.286) for {'alpha': 0.001, 'early_stopping': False, 'learning_rate': 'invscaling', 'max_iter': 1500, 'momentum': 0.7, 'solver': 'sgd'}\n",
      "0.528 (+/-0.147) for {'alpha': 0.001, 'early_stopping': False, 'learning_rate': 'invscaling', 'max_iter': 1500, 'momentum': 0.9, 'solver': 'sgd'}\n",
      "0.484 (+/-0.280) for {'alpha': 0.001, 'early_stopping': False, 'learning_rate': 'invscaling', 'max_iter': 2000, 'momentum': 0.1, 'solver': 'sgd'}\n",
      "0.469 (+/-0.227) for {'alpha': 0.001, 'early_stopping': False, 'learning_rate': 'invscaling', 'max_iter': 2000, 'momentum': 0.3, 'solver': 'sgd'}\n",
      "0.525 (+/-0.204) for {'alpha': 0.001, 'early_stopping': False, 'learning_rate': 'invscaling', 'max_iter': 2000, 'momentum': 0.5, 'solver': 'sgd'}\n",
      "0.400 (+/-0.257) for {'alpha': 0.001, 'early_stopping': False, 'learning_rate': 'invscaling', 'max_iter': 2000, 'momentum': 0.7, 'solver': 'sgd'}\n",
      "0.494 (+/-0.251) for {'alpha': 0.001, 'early_stopping': False, 'learning_rate': 'invscaling', 'max_iter': 2000, 'momentum': 0.9, 'solver': 'sgd'}\n",
      "0.785 (+/-0.092) for {'alpha': 0.001, 'early_stopping': False, 'learning_rate': 'adaptive', 'max_iter': 1000, 'momentum': 0.1, 'solver': 'sgd'}\n",
      "0.781 (+/-0.096) for {'alpha': 0.001, 'early_stopping': False, 'learning_rate': 'adaptive', 'max_iter': 1000, 'momentum': 0.3, 'solver': 'sgd'}\n",
      "0.781 (+/-0.084) for {'alpha': 0.001, 'early_stopping': False, 'learning_rate': 'adaptive', 'max_iter': 1000, 'momentum': 0.5, 'solver': 'sgd'}\n",
      "0.787 (+/-0.081) for {'alpha': 0.001, 'early_stopping': False, 'learning_rate': 'adaptive', 'max_iter': 1000, 'momentum': 0.7, 'solver': 'sgd'}\n",
      "0.792 (+/-0.083) for {'alpha': 0.001, 'early_stopping': False, 'learning_rate': 'adaptive', 'max_iter': 1000, 'momentum': 0.9, 'solver': 'sgd'}\n",
      "0.782 (+/-0.093) for {'alpha': 0.001, 'early_stopping': False, 'learning_rate': 'adaptive', 'max_iter': 1500, 'momentum': 0.1, 'solver': 'sgd'}\n",
      "0.787 (+/-0.087) for {'alpha': 0.001, 'early_stopping': False, 'learning_rate': 'adaptive', 'max_iter': 1500, 'momentum': 0.3, 'solver': 'sgd'}\n",
      "0.788 (+/-0.090) for {'alpha': 0.001, 'early_stopping': False, 'learning_rate': 'adaptive', 'max_iter': 1500, 'momentum': 0.5, 'solver': 'sgd'}\n",
      "0.778 (+/-0.088) for {'alpha': 0.001, 'early_stopping': False, 'learning_rate': 'adaptive', 'max_iter': 1500, 'momentum': 0.7, 'solver': 'sgd'}\n",
      "0.792 (+/-0.081) for {'alpha': 0.001, 'early_stopping': False, 'learning_rate': 'adaptive', 'max_iter': 1500, 'momentum': 0.9, 'solver': 'sgd'}\n",
      "0.775 (+/-0.099) for {'alpha': 0.001, 'early_stopping': False, 'learning_rate': 'adaptive', 'max_iter': 2000, 'momentum': 0.1, 'solver': 'sgd'}\n",
      "0.785 (+/-0.098) for {'alpha': 0.001, 'early_stopping': False, 'learning_rate': 'adaptive', 'max_iter': 2000, 'momentum': 0.3, 'solver': 'sgd'}\n",
      "0.789 (+/-0.101) for {'alpha': 0.001, 'early_stopping': False, 'learning_rate': 'adaptive', 'max_iter': 2000, 'momentum': 0.5, 'solver': 'sgd'}\n",
      "0.784 (+/-0.073) for {'alpha': 0.001, 'early_stopping': False, 'learning_rate': 'adaptive', 'max_iter': 2000, 'momentum': 0.7, 'solver': 'sgd'}\n",
      "0.787 (+/-0.072) for {'alpha': 0.001, 'early_stopping': False, 'learning_rate': 'adaptive', 'max_iter': 2000, 'momentum': 0.9, 'solver': 'sgd'}\n",
      "0.563 (+/-0.255) for {'alpha': 0.01, 'early_stopping': True, 'learning_rate': 'constant', 'max_iter': 1000, 'momentum': 0.1, 'solver': 'sgd'}\n",
      "0.556 (+/-0.221) for {'alpha': 0.01, 'early_stopping': True, 'learning_rate': 'constant', 'max_iter': 1000, 'momentum': 0.3, 'solver': 'sgd'}\n",
      "0.554 (+/-0.230) for {'alpha': 0.01, 'early_stopping': True, 'learning_rate': 'constant', 'max_iter': 1000, 'momentum': 0.5, 'solver': 'sgd'}\n",
      "0.576 (+/-0.206) for {'alpha': 0.01, 'early_stopping': True, 'learning_rate': 'constant', 'max_iter': 1000, 'momentum': 0.7, 'solver': 'sgd'}\n",
      "0.661 (+/-0.265) for {'alpha': 0.01, 'early_stopping': True, 'learning_rate': 'constant', 'max_iter': 1000, 'momentum': 0.9, 'solver': 'sgd'}\n",
      "0.503 (+/-0.256) for {'alpha': 0.01, 'early_stopping': True, 'learning_rate': 'constant', 'max_iter': 1500, 'momentum': 0.1, 'solver': 'sgd'}\n",
      "0.534 (+/-0.324) for {'alpha': 0.01, 'early_stopping': True, 'learning_rate': 'constant', 'max_iter': 1500, 'momentum': 0.3, 'solver': 'sgd'}\n",
      "0.562 (+/-0.240) for {'alpha': 0.01, 'early_stopping': True, 'learning_rate': 'constant', 'max_iter': 1500, 'momentum': 0.5, 'solver': 'sgd'}\n",
      "0.611 (+/-0.313) for {'alpha': 0.01, 'early_stopping': True, 'learning_rate': 'constant', 'max_iter': 1500, 'momentum': 0.7, 'solver': 'sgd'}\n",
      "0.706 (+/-0.098) for {'alpha': 0.01, 'early_stopping': True, 'learning_rate': 'constant', 'max_iter': 1500, 'momentum': 0.9, 'solver': 'sgd'}\n",
      "0.541 (+/-0.247) for {'alpha': 0.01, 'early_stopping': True, 'learning_rate': 'constant', 'max_iter': 2000, 'momentum': 0.1, 'solver': 'sgd'}\n",
      "0.553 (+/-0.352) for {'alpha': 0.01, 'early_stopping': True, 'learning_rate': 'constant', 'max_iter': 2000, 'momentum': 0.3, 'solver': 'sgd'}\n",
      "0.534 (+/-0.335) for {'alpha': 0.01, 'early_stopping': True, 'learning_rate': 'constant', 'max_iter': 2000, 'momentum': 0.5, 'solver': 'sgd'}\n",
      "0.599 (+/-0.274) for {'alpha': 0.01, 'early_stopping': True, 'learning_rate': 'constant', 'max_iter': 2000, 'momentum': 0.7, 'solver': 'sgd'}\n",
      "0.675 (+/-0.189) for {'alpha': 0.01, 'early_stopping': True, 'learning_rate': 'constant', 'max_iter': 2000, 'momentum': 0.9, 'solver': 'sgd'}\n",
      "0.505 (+/-0.296) for {'alpha': 0.01, 'early_stopping': True, 'learning_rate': 'invscaling', 'max_iter': 1000, 'momentum': 0.1, 'solver': 'sgd'}\n",
      "0.534 (+/-0.185) for {'alpha': 0.01, 'early_stopping': True, 'learning_rate': 'invscaling', 'max_iter': 1000, 'momentum': 0.3, 'solver': 'sgd'}\n",
      "0.505 (+/-0.296) for {'alpha': 0.01, 'early_stopping': True, 'learning_rate': 'invscaling', 'max_iter': 1000, 'momentum': 0.5, 'solver': 'sgd'}\n",
      "0.440 (+/-0.237) for {'alpha': 0.01, 'early_stopping': True, 'learning_rate': 'invscaling', 'max_iter': 1000, 'momentum': 0.7, 'solver': 'sgd'}\n",
      "0.467 (+/-0.301) for {'alpha': 0.01, 'early_stopping': True, 'learning_rate': 'invscaling', 'max_iter': 1000, 'momentum': 0.9, 'solver': 'sgd'}\n",
      "0.521 (+/-0.253) for {'alpha': 0.01, 'early_stopping': True, 'learning_rate': 'invscaling', 'max_iter': 1500, 'momentum': 0.1, 'solver': 'sgd'}\n",
      "0.473 (+/-0.267) for {'alpha': 0.01, 'early_stopping': True, 'learning_rate': 'invscaling', 'max_iter': 1500, 'momentum': 0.3, 'solver': 'sgd'}\n",
      "0.522 (+/-0.265) for {'alpha': 0.01, 'early_stopping': True, 'learning_rate': 'invscaling', 'max_iter': 1500, 'momentum': 0.5, 'solver': 'sgd'}\n",
      "0.509 (+/-0.224) for {'alpha': 0.01, 'early_stopping': True, 'learning_rate': 'invscaling', 'max_iter': 1500, 'momentum': 0.7, 'solver': 'sgd'}\n",
      "0.474 (+/-0.192) for {'alpha': 0.01, 'early_stopping': True, 'learning_rate': 'invscaling', 'max_iter': 1500, 'momentum': 0.9, 'solver': 'sgd'}\n",
      "0.459 (+/-0.270) for {'alpha': 0.01, 'early_stopping': True, 'learning_rate': 'invscaling', 'max_iter': 2000, 'momentum': 0.1, 'solver': 'sgd'}\n",
      "0.460 (+/-0.200) for {'alpha': 0.01, 'early_stopping': True, 'learning_rate': 'invscaling', 'max_iter': 2000, 'momentum': 0.3, 'solver': 'sgd'}\n",
      "0.540 (+/-0.338) for {'alpha': 0.01, 'early_stopping': True, 'learning_rate': 'invscaling', 'max_iter': 2000, 'momentum': 0.5, 'solver': 'sgd'}\n",
      "0.475 (+/-0.294) for {'alpha': 0.01, 'early_stopping': True, 'learning_rate': 'invscaling', 'max_iter': 2000, 'momentum': 0.7, 'solver': 'sgd'}\n",
      "0.514 (+/-0.256) for {'alpha': 0.01, 'early_stopping': True, 'learning_rate': 'invscaling', 'max_iter': 2000, 'momentum': 0.9, 'solver': 'sgd'}\n",
      "0.546 (+/-0.232) for {'alpha': 0.01, 'early_stopping': True, 'learning_rate': 'adaptive', 'max_iter': 1000, 'momentum': 0.1, 'solver': 'sgd'}\n",
      "0.635 (+/-0.128) for {'alpha': 0.01, 'early_stopping': True, 'learning_rate': 'adaptive', 'max_iter': 1000, 'momentum': 0.3, 'solver': 'sgd'}\n",
      "0.558 (+/-0.230) for {'alpha': 0.01, 'early_stopping': True, 'learning_rate': 'adaptive', 'max_iter': 1000, 'momentum': 0.5, 'solver': 'sgd'}\n",
      "0.604 (+/-0.115) for {'alpha': 0.01, 'early_stopping': True, 'learning_rate': 'adaptive', 'max_iter': 1000, 'momentum': 0.7, 'solver': 'sgd'}\n",
      "0.719 (+/-0.083) for {'alpha': 0.01, 'early_stopping': True, 'learning_rate': 'adaptive', 'max_iter': 1000, 'momentum': 0.9, 'solver': 'sgd'}\n",
      "0.571 (+/-0.323) for {'alpha': 0.01, 'early_stopping': True, 'learning_rate': 'adaptive', 'max_iter': 1500, 'momentum': 0.1, 'solver': 'sgd'}\n",
      "0.534 (+/-0.184) for {'alpha': 0.01, 'early_stopping': True, 'learning_rate': 'adaptive', 'max_iter': 1500, 'momentum': 0.3, 'solver': 'sgd'}\n",
      "0.624 (+/-0.288) for {'alpha': 0.01, 'early_stopping': True, 'learning_rate': 'adaptive', 'max_iter': 1500, 'momentum': 0.5, 'solver': 'sgd'}\n",
      "0.563 (+/-0.275) for {'alpha': 0.01, 'early_stopping': True, 'learning_rate': 'adaptive', 'max_iter': 1500, 'momentum': 0.7, 'solver': 'sgd'}\n",
      "0.703 (+/-0.146) for {'alpha': 0.01, 'early_stopping': True, 'learning_rate': 'adaptive', 'max_iter': 1500, 'momentum': 0.9, 'solver': 'sgd'}\n",
      "0.528 (+/-0.214) for {'alpha': 0.01, 'early_stopping': True, 'learning_rate': 'adaptive', 'max_iter': 2000, 'momentum': 0.1, 'solver': 'sgd'}\n",
      "0.566 (+/-0.258) for {'alpha': 0.01, 'early_stopping': True, 'learning_rate': 'adaptive', 'max_iter': 2000, 'momentum': 0.3, 'solver': 'sgd'}\n",
      "0.549 (+/-0.230) for {'alpha': 0.01, 'early_stopping': True, 'learning_rate': 'adaptive', 'max_iter': 2000, 'momentum': 0.5, 'solver': 'sgd'}\n",
      "0.590 (+/-0.210) for {'alpha': 0.01, 'early_stopping': True, 'learning_rate': 'adaptive', 'max_iter': 2000, 'momentum': 0.7, 'solver': 'sgd'}\n",
      "0.743 (+/-0.116) for {'alpha': 0.01, 'early_stopping': True, 'learning_rate': 'adaptive', 'max_iter': 2000, 'momentum': 0.9, 'solver': 'sgd'}\n",
      "0.777 (+/-0.087) for {'alpha': 0.01, 'early_stopping': False, 'learning_rate': 'constant', 'max_iter': 1000, 'momentum': 0.1, 'solver': 'sgd'}\n",
      "0.785 (+/-0.075) for {'alpha': 0.01, 'early_stopping': False, 'learning_rate': 'constant', 'max_iter': 1000, 'momentum': 0.3, 'solver': 'sgd'}\n",
      "0.787 (+/-0.079) for {'alpha': 0.01, 'early_stopping': False, 'learning_rate': 'constant', 'max_iter': 1000, 'momentum': 0.5, 'solver': 'sgd'}\n",
      "0.794 (+/-0.074) for {'alpha': 0.01, 'early_stopping': False, 'learning_rate': 'constant', 'max_iter': 1000, 'momentum': 0.7, 'solver': 'sgd'}\n",
      "0.795 (+/-0.073) for {'alpha': 0.01, 'early_stopping': False, 'learning_rate': 'constant', 'max_iter': 1000, 'momentum': 0.9, 'solver': 'sgd'}\n",
      "0.774 (+/-0.083) for {'alpha': 0.01, 'early_stopping': False, 'learning_rate': 'constant', 'max_iter': 1500, 'momentum': 0.1, 'solver': 'sgd'}\n",
      "0.782 (+/-0.098) for {'alpha': 0.01, 'early_stopping': False, 'learning_rate': 'constant', 'max_iter': 1500, 'momentum': 0.3, 'solver': 'sgd'}\n",
      "0.788 (+/-0.068) for {'alpha': 0.01, 'early_stopping': False, 'learning_rate': 'constant', 'max_iter': 1500, 'momentum': 0.5, 'solver': 'sgd'}\n",
      "0.778 (+/-0.083) for {'alpha': 0.01, 'early_stopping': False, 'learning_rate': 'constant', 'max_iter': 1500, 'momentum': 0.7, 'solver': 'sgd'}\n",
      "0.787 (+/-0.084) for {'alpha': 0.01, 'early_stopping': False, 'learning_rate': 'constant', 'max_iter': 1500, 'momentum': 0.9, 'solver': 'sgd'}\n",
      "0.771 (+/-0.091) for {'alpha': 0.01, 'early_stopping': False, 'learning_rate': 'constant', 'max_iter': 2000, 'momentum': 0.1, 'solver': 'sgd'}\n",
      "0.782 (+/-0.086) for {'alpha': 0.01, 'early_stopping': False, 'learning_rate': 'constant', 'max_iter': 2000, 'momentum': 0.3, 'solver': 'sgd'}\n",
      "0.782 (+/-0.068) for {'alpha': 0.01, 'early_stopping': False, 'learning_rate': 'constant', 'max_iter': 2000, 'momentum': 0.5, 'solver': 'sgd'}\n",
      "0.784 (+/-0.085) for {'alpha': 0.01, 'early_stopping': False, 'learning_rate': 'constant', 'max_iter': 2000, 'momentum': 0.7, 'solver': 'sgd'}\n",
      "0.788 (+/-0.082) for {'alpha': 0.01, 'early_stopping': False, 'learning_rate': 'constant', 'max_iter': 2000, 'momentum': 0.9, 'solver': 'sgd'}\n",
      "0.530 (+/-0.317) for {'alpha': 0.01, 'early_stopping': False, 'learning_rate': 'invscaling', 'max_iter': 1000, 'momentum': 0.1, 'solver': 'sgd'}\n",
      "0.497 (+/-0.220) for {'alpha': 0.01, 'early_stopping': False, 'learning_rate': 'invscaling', 'max_iter': 1000, 'momentum': 0.3, 'solver': 'sgd'}\n",
      "0.490 (+/-0.359) for {'alpha': 0.01, 'early_stopping': False, 'learning_rate': 'invscaling', 'max_iter': 1000, 'momentum': 0.5, 'solver': 'sgd'}\n",
      "0.524 (+/-0.236) for {'alpha': 0.01, 'early_stopping': False, 'learning_rate': 'invscaling', 'max_iter': 1000, 'momentum': 0.7, 'solver': 'sgd'}\n",
      "0.476 (+/-0.236) for {'alpha': 0.01, 'early_stopping': False, 'learning_rate': 'invscaling', 'max_iter': 1000, 'momentum': 0.9, 'solver': 'sgd'}\n",
      "0.556 (+/-0.255) for {'alpha': 0.01, 'early_stopping': False, 'learning_rate': 'invscaling', 'max_iter': 1500, 'momentum': 0.1, 'solver': 'sgd'}\n",
      "0.521 (+/-0.223) for {'alpha': 0.01, 'early_stopping': False, 'learning_rate': 'invscaling', 'max_iter': 1500, 'momentum': 0.3, 'solver': 'sgd'}\n",
      "0.445 (+/-0.217) for {'alpha': 0.01, 'early_stopping': False, 'learning_rate': 'invscaling', 'max_iter': 1500, 'momentum': 0.5, 'solver': 'sgd'}\n",
      "0.510 (+/-0.213) for {'alpha': 0.01, 'early_stopping': False, 'learning_rate': 'invscaling', 'max_iter': 1500, 'momentum': 0.7, 'solver': 'sgd'}\n",
      "0.514 (+/-0.273) for {'alpha': 0.01, 'early_stopping': False, 'learning_rate': 'invscaling', 'max_iter': 1500, 'momentum': 0.9, 'solver': 'sgd'}\n",
      "0.476 (+/-0.238) for {'alpha': 0.01, 'early_stopping': False, 'learning_rate': 'invscaling', 'max_iter': 2000, 'momentum': 0.1, 'solver': 'sgd'}\n",
      "0.518 (+/-0.245) for {'alpha': 0.01, 'early_stopping': False, 'learning_rate': 'invscaling', 'max_iter': 2000, 'momentum': 0.3, 'solver': 'sgd'}\n",
      "0.491 (+/-0.254) for {'alpha': 0.01, 'early_stopping': False, 'learning_rate': 'invscaling', 'max_iter': 2000, 'momentum': 0.5, 'solver': 'sgd'}\n",
      "0.479 (+/-0.230) for {'alpha': 0.01, 'early_stopping': False, 'learning_rate': 'invscaling', 'max_iter': 2000, 'momentum': 0.7, 'solver': 'sgd'}\n",
      "0.547 (+/-0.252) for {'alpha': 0.01, 'early_stopping': False, 'learning_rate': 'invscaling', 'max_iter': 2000, 'momentum': 0.9, 'solver': 'sgd'}\n",
      "0.772 (+/-0.048) for {'alpha': 0.01, 'early_stopping': False, 'learning_rate': 'adaptive', 'max_iter': 1000, 'momentum': 0.1, 'solver': 'sgd'}\n",
      "0.789 (+/-0.105) for {'alpha': 0.01, 'early_stopping': False, 'learning_rate': 'adaptive', 'max_iter': 1000, 'momentum': 0.3, 'solver': 'sgd'}\n",
      "0.789 (+/-0.080) for {'alpha': 0.01, 'early_stopping': False, 'learning_rate': 'adaptive', 'max_iter': 1000, 'momentum': 0.5, 'solver': 'sgd'}\n",
      "0.787 (+/-0.065) for {'alpha': 0.01, 'early_stopping': False, 'learning_rate': 'adaptive', 'max_iter': 1000, 'momentum': 0.7, 'solver': 'sgd'}\n",
      "0.787 (+/-0.071) for {'alpha': 0.01, 'early_stopping': False, 'learning_rate': 'adaptive', 'max_iter': 1000, 'momentum': 0.9, 'solver': 'sgd'}\n",
      "0.779 (+/-0.073) for {'alpha': 0.01, 'early_stopping': False, 'learning_rate': 'adaptive', 'max_iter': 1500, 'momentum': 0.1, 'solver': 'sgd'}\n",
      "0.782 (+/-0.099) for {'alpha': 0.01, 'early_stopping': False, 'learning_rate': 'adaptive', 'max_iter': 1500, 'momentum': 0.3, 'solver': 'sgd'}\n",
      "0.775 (+/-0.081) for {'alpha': 0.01, 'early_stopping': False, 'learning_rate': 'adaptive', 'max_iter': 1500, 'momentum': 0.5, 'solver': 'sgd'}\n",
      "0.780 (+/-0.069) for {'alpha': 0.01, 'early_stopping': False, 'learning_rate': 'adaptive', 'max_iter': 1500, 'momentum': 0.7, 'solver': 'sgd'}\n",
      "0.789 (+/-0.084) for {'alpha': 0.01, 'early_stopping': False, 'learning_rate': 'adaptive', 'max_iter': 1500, 'momentum': 0.9, 'solver': 'sgd'}\n",
      "0.787 (+/-0.110) for {'alpha': 0.01, 'early_stopping': False, 'learning_rate': 'adaptive', 'max_iter': 2000, 'momentum': 0.1, 'solver': 'sgd'}\n",
      "0.789 (+/-0.105) for {'alpha': 0.01, 'early_stopping': False, 'learning_rate': 'adaptive', 'max_iter': 2000, 'momentum': 0.3, 'solver': 'sgd'}\n",
      "0.792 (+/-0.101) for {'alpha': 0.01, 'early_stopping': False, 'learning_rate': 'adaptive', 'max_iter': 2000, 'momentum': 0.5, 'solver': 'sgd'}\n",
      "0.794 (+/-0.078) for {'alpha': 0.01, 'early_stopping': False, 'learning_rate': 'adaptive', 'max_iter': 2000, 'momentum': 0.7, 'solver': 'sgd'}\n",
      "0.782 (+/-0.073) for {'alpha': 0.01, 'early_stopping': False, 'learning_rate': 'adaptive', 'max_iter': 2000, 'momentum': 0.9, 'solver': 'sgd'}\n",
      "0.524 (+/-0.278) for {'alpha': 0.1, 'early_stopping': True, 'learning_rate': 'constant', 'max_iter': 1000, 'momentum': 0.1, 'solver': 'sgd'}\n",
      "0.580 (+/-0.106) for {'alpha': 0.1, 'early_stopping': True, 'learning_rate': 'constant', 'max_iter': 1000, 'momentum': 0.3, 'solver': 'sgd'}\n",
      "0.527 (+/-0.285) for {'alpha': 0.1, 'early_stopping': True, 'learning_rate': 'constant', 'max_iter': 1000, 'momentum': 0.5, 'solver': 'sgd'}\n",
      "0.546 (+/-0.328) for {'alpha': 0.1, 'early_stopping': True, 'learning_rate': 'constant', 'max_iter': 1000, 'momentum': 0.7, 'solver': 'sgd'}\n",
      "0.678 (+/-0.214) for {'alpha': 0.1, 'early_stopping': True, 'learning_rate': 'constant', 'max_iter': 1000, 'momentum': 0.9, 'solver': 'sgd'}\n",
      "0.525 (+/-0.280) for {'alpha': 0.1, 'early_stopping': True, 'learning_rate': 'constant', 'max_iter': 1500, 'momentum': 0.1, 'solver': 'sgd'}\n",
      "0.525 (+/-0.307) for {'alpha': 0.1, 'early_stopping': True, 'learning_rate': 'constant', 'max_iter': 1500, 'momentum': 0.3, 'solver': 'sgd'}\n",
      "0.550 (+/-0.301) for {'alpha': 0.1, 'early_stopping': True, 'learning_rate': 'constant', 'max_iter': 1500, 'momentum': 0.5, 'solver': 'sgd'}\n",
      "0.605 (+/-0.315) for {'alpha': 0.1, 'early_stopping': True, 'learning_rate': 'constant', 'max_iter': 1500, 'momentum': 0.7, 'solver': 'sgd'}\n",
      "0.693 (+/-0.148) for {'alpha': 0.1, 'early_stopping': True, 'learning_rate': 'constant', 'max_iter': 1500, 'momentum': 0.9, 'solver': 'sgd'}\n",
      "0.485 (+/-0.227) for {'alpha': 0.1, 'early_stopping': True, 'learning_rate': 'constant', 'max_iter': 2000, 'momentum': 0.1, 'solver': 'sgd'}\n",
      "0.556 (+/-0.202) for {'alpha': 0.1, 'early_stopping': True, 'learning_rate': 'constant', 'max_iter': 2000, 'momentum': 0.3, 'solver': 'sgd'}\n",
      "0.449 (+/-0.166) for {'alpha': 0.1, 'early_stopping': True, 'learning_rate': 'constant', 'max_iter': 2000, 'momentum': 0.5, 'solver': 'sgd'}\n",
      "0.580 (+/-0.269) for {'alpha': 0.1, 'early_stopping': True, 'learning_rate': 'constant', 'max_iter': 2000, 'momentum': 0.7, 'solver': 'sgd'}\n",
      "0.670 (+/-0.103) for {'alpha': 0.1, 'early_stopping': True, 'learning_rate': 'constant', 'max_iter': 2000, 'momentum': 0.9, 'solver': 'sgd'}\n",
      "0.454 (+/-0.217) for {'alpha': 0.1, 'early_stopping': True, 'learning_rate': 'invscaling', 'max_iter': 1000, 'momentum': 0.1, 'solver': 'sgd'}\n",
      "0.557 (+/-0.247) for {'alpha': 0.1, 'early_stopping': True, 'learning_rate': 'invscaling', 'max_iter': 1000, 'momentum': 0.3, 'solver': 'sgd'}\n",
      "0.537 (+/-0.237) for {'alpha': 0.1, 'early_stopping': True, 'learning_rate': 'invscaling', 'max_iter': 1000, 'momentum': 0.5, 'solver': 'sgd'}\n",
      "0.481 (+/-0.244) for {'alpha': 0.1, 'early_stopping': True, 'learning_rate': 'invscaling', 'max_iter': 1000, 'momentum': 0.7, 'solver': 'sgd'}\n",
      "0.521 (+/-0.216) for {'alpha': 0.1, 'early_stopping': True, 'learning_rate': 'invscaling', 'max_iter': 1000, 'momentum': 0.9, 'solver': 'sgd'}\n",
      "0.408 (+/-0.282) for {'alpha': 0.1, 'early_stopping': True, 'learning_rate': 'invscaling', 'max_iter': 1500, 'momentum': 0.1, 'solver': 'sgd'}\n",
      "0.488 (+/-0.302) for {'alpha': 0.1, 'early_stopping': True, 'learning_rate': 'invscaling', 'max_iter': 1500, 'momentum': 0.3, 'solver': 'sgd'}\n",
      "0.563 (+/-0.344) for {'alpha': 0.1, 'early_stopping': True, 'learning_rate': 'invscaling', 'max_iter': 1500, 'momentum': 0.5, 'solver': 'sgd'}\n",
      "0.563 (+/-0.222) for {'alpha': 0.1, 'early_stopping': True, 'learning_rate': 'invscaling', 'max_iter': 1500, 'momentum': 0.7, 'solver': 'sgd'}\n",
      "0.506 (+/-0.328) for {'alpha': 0.1, 'early_stopping': True, 'learning_rate': 'invscaling', 'max_iter': 1500, 'momentum': 0.9, 'solver': 'sgd'}\n",
      "0.502 (+/-0.303) for {'alpha': 0.1, 'early_stopping': True, 'learning_rate': 'invscaling', 'max_iter': 2000, 'momentum': 0.1, 'solver': 'sgd'}\n",
      "0.452 (+/-0.136) for {'alpha': 0.1, 'early_stopping': True, 'learning_rate': 'invscaling', 'max_iter': 2000, 'momentum': 0.3, 'solver': 'sgd'}\n",
      "0.467 (+/-0.206) for {'alpha': 0.1, 'early_stopping': True, 'learning_rate': 'invscaling', 'max_iter': 2000, 'momentum': 0.5, 'solver': 'sgd'}\n",
      "0.537 (+/-0.263) for {'alpha': 0.1, 'early_stopping': True, 'learning_rate': 'invscaling', 'max_iter': 2000, 'momentum': 0.7, 'solver': 'sgd'}\n",
      "0.557 (+/-0.255) for {'alpha': 0.1, 'early_stopping': True, 'learning_rate': 'invscaling', 'max_iter': 2000, 'momentum': 0.9, 'solver': 'sgd'}\n",
      "0.472 (+/-0.223) for {'alpha': 0.1, 'early_stopping': True, 'learning_rate': 'adaptive', 'max_iter': 1000, 'momentum': 0.1, 'solver': 'sgd'}\n",
      "0.534 (+/-0.294) for {'alpha': 0.1, 'early_stopping': True, 'learning_rate': 'adaptive', 'max_iter': 1000, 'momentum': 0.3, 'solver': 'sgd'}\n",
      "0.508 (+/-0.254) for {'alpha': 0.1, 'early_stopping': True, 'learning_rate': 'adaptive', 'max_iter': 1000, 'momentum': 0.5, 'solver': 'sgd'}\n",
      "0.631 (+/-0.203) for {'alpha': 0.1, 'early_stopping': True, 'learning_rate': 'adaptive', 'max_iter': 1000, 'momentum': 0.7, 'solver': 'sgd'}\n",
      "0.666 (+/-0.135) for {'alpha': 0.1, 'early_stopping': True, 'learning_rate': 'adaptive', 'max_iter': 1000, 'momentum': 0.9, 'solver': 'sgd'}\n",
      "0.397 (+/-0.132) for {'alpha': 0.1, 'early_stopping': True, 'learning_rate': 'adaptive', 'max_iter': 1500, 'momentum': 0.1, 'solver': 'sgd'}\n",
      "0.507 (+/-0.229) for {'alpha': 0.1, 'early_stopping': True, 'learning_rate': 'adaptive', 'max_iter': 1500, 'momentum': 0.3, 'solver': 'sgd'}\n",
      "0.572 (+/-0.296) for {'alpha': 0.1, 'early_stopping': True, 'learning_rate': 'adaptive', 'max_iter': 1500, 'momentum': 0.5, 'solver': 'sgd'}\n",
      "0.657 (+/-0.279) for {'alpha': 0.1, 'early_stopping': True, 'learning_rate': 'adaptive', 'max_iter': 1500, 'momentum': 0.7, 'solver': 'sgd'}\n",
      "0.686 (+/-0.148) for {'alpha': 0.1, 'early_stopping': True, 'learning_rate': 'adaptive', 'max_iter': 1500, 'momentum': 0.9, 'solver': 'sgd'}\n",
      "0.522 (+/-0.272) for {'alpha': 0.1, 'early_stopping': True, 'learning_rate': 'adaptive', 'max_iter': 2000, 'momentum': 0.1, 'solver': 'sgd'}\n",
      "0.594 (+/-0.201) for {'alpha': 0.1, 'early_stopping': True, 'learning_rate': 'adaptive', 'max_iter': 2000, 'momentum': 0.3, 'solver': 'sgd'}\n",
      "0.602 (+/-0.195) for {'alpha': 0.1, 'early_stopping': True, 'learning_rate': 'adaptive', 'max_iter': 2000, 'momentum': 0.5, 'solver': 'sgd'}\n",
      "0.642 (+/-0.224) for {'alpha': 0.1, 'early_stopping': True, 'learning_rate': 'adaptive', 'max_iter': 2000, 'momentum': 0.7, 'solver': 'sgd'}\n",
      "0.726 (+/-0.105) for {'alpha': 0.1, 'early_stopping': True, 'learning_rate': 'adaptive', 'max_iter': 2000, 'momentum': 0.9, 'solver': 'sgd'}\n",
      "0.764 (+/-0.087) for {'alpha': 0.1, 'early_stopping': False, 'learning_rate': 'constant', 'max_iter': 1000, 'momentum': 0.1, 'solver': 'sgd'}\n",
      "0.782 (+/-0.080) for {'alpha': 0.1, 'early_stopping': False, 'learning_rate': 'constant', 'max_iter': 1000, 'momentum': 0.3, 'solver': 'sgd'}\n",
      "0.780 (+/-0.071) for {'alpha': 0.1, 'early_stopping': False, 'learning_rate': 'constant', 'max_iter': 1000, 'momentum': 0.5, 'solver': 'sgd'}\n",
      "0.787 (+/-0.082) for {'alpha': 0.1, 'early_stopping': False, 'learning_rate': 'constant', 'max_iter': 1000, 'momentum': 0.7, 'solver': 'sgd'}\n",
      "0.792 (+/-0.085) for {'alpha': 0.1, 'early_stopping': False, 'learning_rate': 'constant', 'max_iter': 1000, 'momentum': 0.9, 'solver': 'sgd'}\n",
      "0.757 (+/-0.105) for {'alpha': 0.1, 'early_stopping': False, 'learning_rate': 'constant', 'max_iter': 1500, 'momentum': 0.1, 'solver': 'sgd'}\n",
      "0.784 (+/-0.066) for {'alpha': 0.1, 'early_stopping': False, 'learning_rate': 'constant', 'max_iter': 1500, 'momentum': 0.3, 'solver': 'sgd'}\n",
      "0.792 (+/-0.082) for {'alpha': 0.1, 'early_stopping': False, 'learning_rate': 'constant', 'max_iter': 1500, 'momentum': 0.5, 'solver': 'sgd'}\n",
      "0.789 (+/-0.061) for {'alpha': 0.1, 'early_stopping': False, 'learning_rate': 'constant', 'max_iter': 1500, 'momentum': 0.7, 'solver': 'sgd'}\n",
      "0.789 (+/-0.074) for {'alpha': 0.1, 'early_stopping': False, 'learning_rate': 'constant', 'max_iter': 1500, 'momentum': 0.9, 'solver': 'sgd'}\n",
      "0.788 (+/-0.086) for {'alpha': 0.1, 'early_stopping': False, 'learning_rate': 'constant', 'max_iter': 2000, 'momentum': 0.1, 'solver': 'sgd'}\n",
      "0.784 (+/-0.100) for {'alpha': 0.1, 'early_stopping': False, 'learning_rate': 'constant', 'max_iter': 2000, 'momentum': 0.3, 'solver': 'sgd'}\n",
      "0.785 (+/-0.076) for {'alpha': 0.1, 'early_stopping': False, 'learning_rate': 'constant', 'max_iter': 2000, 'momentum': 0.5, 'solver': 'sgd'}\n",
      "0.792 (+/-0.078) for {'alpha': 0.1, 'early_stopping': False, 'learning_rate': 'constant', 'max_iter': 2000, 'momentum': 0.7, 'solver': 'sgd'}\n",
      "0.795 (+/-0.077) for {'alpha': 0.1, 'early_stopping': False, 'learning_rate': 'constant', 'max_iter': 2000, 'momentum': 0.9, 'solver': 'sgd'}\n",
      "0.548 (+/-0.225) for {'alpha': 0.1, 'early_stopping': False, 'learning_rate': 'invscaling', 'max_iter': 1000, 'momentum': 0.1, 'solver': 'sgd'}\n",
      "0.541 (+/-0.200) for {'alpha': 0.1, 'early_stopping': False, 'learning_rate': 'invscaling', 'max_iter': 1000, 'momentum': 0.3, 'solver': 'sgd'}\n",
      "0.545 (+/-0.295) for {'alpha': 0.1, 'early_stopping': False, 'learning_rate': 'invscaling', 'max_iter': 1000, 'momentum': 0.5, 'solver': 'sgd'}\n",
      "0.520 (+/-0.245) for {'alpha': 0.1, 'early_stopping': False, 'learning_rate': 'invscaling', 'max_iter': 1000, 'momentum': 0.7, 'solver': 'sgd'}\n",
      "0.569 (+/-0.289) for {'alpha': 0.1, 'early_stopping': False, 'learning_rate': 'invscaling', 'max_iter': 1000, 'momentum': 0.9, 'solver': 'sgd'}\n",
      "0.477 (+/-0.245) for {'alpha': 0.1, 'early_stopping': False, 'learning_rate': 'invscaling', 'max_iter': 1500, 'momentum': 0.1, 'solver': 'sgd'}\n",
      "0.433 (+/-0.211) for {'alpha': 0.1, 'early_stopping': False, 'learning_rate': 'invscaling', 'max_iter': 1500, 'momentum': 0.3, 'solver': 'sgd'}\n",
      "0.527 (+/-0.340) for {'alpha': 0.1, 'early_stopping': False, 'learning_rate': 'invscaling', 'max_iter': 1500, 'momentum': 0.5, 'solver': 'sgd'}\n",
      "0.463 (+/-0.233) for {'alpha': 0.1, 'early_stopping': False, 'learning_rate': 'invscaling', 'max_iter': 1500, 'momentum': 0.7, 'solver': 'sgd'}\n",
      "0.490 (+/-0.228) for {'alpha': 0.1, 'early_stopping': False, 'learning_rate': 'invscaling', 'max_iter': 1500, 'momentum': 0.9, 'solver': 'sgd'}\n",
      "0.531 (+/-0.234) for {'alpha': 0.1, 'early_stopping': False, 'learning_rate': 'invscaling', 'max_iter': 2000, 'momentum': 0.1, 'solver': 'sgd'}\n",
      "0.518 (+/-0.218) for {'alpha': 0.1, 'early_stopping': False, 'learning_rate': 'invscaling', 'max_iter': 2000, 'momentum': 0.3, 'solver': 'sgd'}\n",
      "0.528 (+/-0.244) for {'alpha': 0.1, 'early_stopping': False, 'learning_rate': 'invscaling', 'max_iter': 2000, 'momentum': 0.5, 'solver': 'sgd'}\n",
      "0.507 (+/-0.266) for {'alpha': 0.1, 'early_stopping': False, 'learning_rate': 'invscaling', 'max_iter': 2000, 'momentum': 0.7, 'solver': 'sgd'}\n",
      "0.490 (+/-0.233) for {'alpha': 0.1, 'early_stopping': False, 'learning_rate': 'invscaling', 'max_iter': 2000, 'momentum': 0.9, 'solver': 'sgd'}\n",
      "0.781 (+/-0.112) for {'alpha': 0.1, 'early_stopping': False, 'learning_rate': 'adaptive', 'max_iter': 1000, 'momentum': 0.1, 'solver': 'sgd'}\n",
      "0.772 (+/-0.093) for {'alpha': 0.1, 'early_stopping': False, 'learning_rate': 'adaptive', 'max_iter': 1000, 'momentum': 0.3, 'solver': 'sgd'}\n",
      "0.775 (+/-0.073) for {'alpha': 0.1, 'early_stopping': False, 'learning_rate': 'adaptive', 'max_iter': 1000, 'momentum': 0.5, 'solver': 'sgd'}\n",
      "0.784 (+/-0.078) for {'alpha': 0.1, 'early_stopping': False, 'learning_rate': 'adaptive', 'max_iter': 1000, 'momentum': 0.7, 'solver': 'sgd'}\n",
      "0.788 (+/-0.083) for {'alpha': 0.1, 'early_stopping': False, 'learning_rate': 'adaptive', 'max_iter': 1000, 'momentum': 0.9, 'solver': 'sgd'}\n",
      "0.770 (+/-0.106) for {'alpha': 0.1, 'early_stopping': False, 'learning_rate': 'adaptive', 'max_iter': 1500, 'momentum': 0.1, 'solver': 'sgd'}\n",
      "0.774 (+/-0.072) for {'alpha': 0.1, 'early_stopping': False, 'learning_rate': 'adaptive', 'max_iter': 1500, 'momentum': 0.3, 'solver': 'sgd'}\n",
      "0.789 (+/-0.082) for {'alpha': 0.1, 'early_stopping': False, 'learning_rate': 'adaptive', 'max_iter': 1500, 'momentum': 0.5, 'solver': 'sgd'}\n",
      "0.787 (+/-0.071) for {'alpha': 0.1, 'early_stopping': False, 'learning_rate': 'adaptive', 'max_iter': 1500, 'momentum': 0.7, 'solver': 'sgd'}\n",
      "0.784 (+/-0.084) for {'alpha': 0.1, 'early_stopping': False, 'learning_rate': 'adaptive', 'max_iter': 1500, 'momentum': 0.9, 'solver': 'sgd'}\n",
      "0.777 (+/-0.082) for {'alpha': 0.1, 'early_stopping': False, 'learning_rate': 'adaptive', 'max_iter': 2000, 'momentum': 0.1, 'solver': 'sgd'}\n",
      "0.801 (+/-0.102) for {'alpha': 0.1, 'early_stopping': False, 'learning_rate': 'adaptive', 'max_iter': 2000, 'momentum': 0.3, 'solver': 'sgd'}\n",
      "0.780 (+/-0.086) for {'alpha': 0.1, 'early_stopping': False, 'learning_rate': 'adaptive', 'max_iter': 2000, 'momentum': 0.5, 'solver': 'sgd'}\n",
      "0.792 (+/-0.072) for {'alpha': 0.1, 'early_stopping': False, 'learning_rate': 'adaptive', 'max_iter': 2000, 'momentum': 0.7, 'solver': 'sgd'}\n",
      "0.782 (+/-0.077) for {'alpha': 0.1, 'early_stopping': False, 'learning_rate': 'adaptive', 'max_iter': 2000, 'momentum': 0.9, 'solver': 'sgd'}\n",
      "0.524 (+/-0.240) for {'alpha': 1, 'early_stopping': True, 'learning_rate': 'constant', 'max_iter': 1000, 'momentum': 0.1, 'solver': 'sgd'}\n",
      "0.493 (+/-0.233) for {'alpha': 1, 'early_stopping': True, 'learning_rate': 'constant', 'max_iter': 1000, 'momentum': 0.3, 'solver': 'sgd'}\n",
      "0.486 (+/-0.278) for {'alpha': 1, 'early_stopping': True, 'learning_rate': 'constant', 'max_iter': 1000, 'momentum': 0.5, 'solver': 'sgd'}\n",
      "0.569 (+/-0.243) for {'alpha': 1, 'early_stopping': True, 'learning_rate': 'constant', 'max_iter': 1000, 'momentum': 0.7, 'solver': 'sgd'}\n",
      "0.711 (+/-0.091) for {'alpha': 1, 'early_stopping': True, 'learning_rate': 'constant', 'max_iter': 1000, 'momentum': 0.9, 'solver': 'sgd'}\n",
      "0.550 (+/-0.166) for {'alpha': 1, 'early_stopping': True, 'learning_rate': 'constant', 'max_iter': 1500, 'momentum': 0.1, 'solver': 'sgd'}\n",
      "0.529 (+/-0.312) for {'alpha': 1, 'early_stopping': True, 'learning_rate': 'constant', 'max_iter': 1500, 'momentum': 0.3, 'solver': 'sgd'}\n",
      "0.612 (+/-0.082) for {'alpha': 1, 'early_stopping': True, 'learning_rate': 'constant', 'max_iter': 1500, 'momentum': 0.5, 'solver': 'sgd'}\n",
      "0.633 (+/-0.121) for {'alpha': 1, 'early_stopping': True, 'learning_rate': 'constant', 'max_iter': 1500, 'momentum': 0.7, 'solver': 'sgd'}\n",
      "0.713 (+/-0.086) for {'alpha': 1, 'early_stopping': True, 'learning_rate': 'constant', 'max_iter': 1500, 'momentum': 0.9, 'solver': 'sgd'}\n",
      "0.504 (+/-0.225) for {'alpha': 1, 'early_stopping': True, 'learning_rate': 'constant', 'max_iter': 2000, 'momentum': 0.1, 'solver': 'sgd'}\n",
      "0.566 (+/-0.266) for {'alpha': 1, 'early_stopping': True, 'learning_rate': 'constant', 'max_iter': 2000, 'momentum': 0.3, 'solver': 'sgd'}\n",
      "0.560 (+/-0.246) for {'alpha': 1, 'early_stopping': True, 'learning_rate': 'constant', 'max_iter': 2000, 'momentum': 0.5, 'solver': 'sgd'}\n",
      "0.538 (+/-0.317) for {'alpha': 1, 'early_stopping': True, 'learning_rate': 'constant', 'max_iter': 2000, 'momentum': 0.7, 'solver': 'sgd'}\n",
      "0.701 (+/-0.139) for {'alpha': 1, 'early_stopping': True, 'learning_rate': 'constant', 'max_iter': 2000, 'momentum': 0.9, 'solver': 'sgd'}\n",
      "0.546 (+/-0.234) for {'alpha': 1, 'early_stopping': True, 'learning_rate': 'invscaling', 'max_iter': 1000, 'momentum': 0.1, 'solver': 'sgd'}\n",
      "0.510 (+/-0.211) for {'alpha': 1, 'early_stopping': True, 'learning_rate': 'invscaling', 'max_iter': 1000, 'momentum': 0.3, 'solver': 'sgd'}\n",
      "0.507 (+/-0.244) for {'alpha': 1, 'early_stopping': True, 'learning_rate': 'invscaling', 'max_iter': 1000, 'momentum': 0.5, 'solver': 'sgd'}\n",
      "0.525 (+/-0.217) for {'alpha': 1, 'early_stopping': True, 'learning_rate': 'invscaling', 'max_iter': 1000, 'momentum': 0.7, 'solver': 'sgd'}\n",
      "0.532 (+/-0.264) for {'alpha': 1, 'early_stopping': True, 'learning_rate': 'invscaling', 'max_iter': 1000, 'momentum': 0.9, 'solver': 'sgd'}\n",
      "0.531 (+/-0.255) for {'alpha': 1, 'early_stopping': True, 'learning_rate': 'invscaling', 'max_iter': 1500, 'momentum': 0.1, 'solver': 'sgd'}\n",
      "0.458 (+/-0.314) for {'alpha': 1, 'early_stopping': True, 'learning_rate': 'invscaling', 'max_iter': 1500, 'momentum': 0.3, 'solver': 'sgd'}\n",
      "0.479 (+/-0.249) for {'alpha': 1, 'early_stopping': True, 'learning_rate': 'invscaling', 'max_iter': 1500, 'momentum': 0.5, 'solver': 'sgd'}\n",
      "0.489 (+/-0.195) for {'alpha': 1, 'early_stopping': True, 'learning_rate': 'invscaling', 'max_iter': 1500, 'momentum': 0.7, 'solver': 'sgd'}\n",
      "0.525 (+/-0.276) for {'alpha': 1, 'early_stopping': True, 'learning_rate': 'invscaling', 'max_iter': 1500, 'momentum': 0.9, 'solver': 'sgd'}\n",
      "0.519 (+/-0.281) for {'alpha': 1, 'early_stopping': True, 'learning_rate': 'invscaling', 'max_iter': 2000, 'momentum': 0.1, 'solver': 'sgd'}\n",
      "0.594 (+/-0.198) for {'alpha': 1, 'early_stopping': True, 'learning_rate': 'invscaling', 'max_iter': 2000, 'momentum': 0.3, 'solver': 'sgd'}\n",
      "0.517 (+/-0.283) for {'alpha': 1, 'early_stopping': True, 'learning_rate': 'invscaling', 'max_iter': 2000, 'momentum': 0.5, 'solver': 'sgd'}\n",
      "0.489 (+/-0.201) for {'alpha': 1, 'early_stopping': True, 'learning_rate': 'invscaling', 'max_iter': 2000, 'momentum': 0.7, 'solver': 'sgd'}\n",
      "0.466 (+/-0.251) for {'alpha': 1, 'early_stopping': True, 'learning_rate': 'invscaling', 'max_iter': 2000, 'momentum': 0.9, 'solver': 'sgd'}\n",
      "0.575 (+/-0.285) for {'alpha': 1, 'early_stopping': True, 'learning_rate': 'adaptive', 'max_iter': 1000, 'momentum': 0.1, 'solver': 'sgd'}\n",
      "0.552 (+/-0.216) for {'alpha': 1, 'early_stopping': True, 'learning_rate': 'adaptive', 'max_iter': 1000, 'momentum': 0.3, 'solver': 'sgd'}\n",
      "0.521 (+/-0.306) for {'alpha': 1, 'early_stopping': True, 'learning_rate': 'adaptive', 'max_iter': 1000, 'momentum': 0.5, 'solver': 'sgd'}\n",
      "0.613 (+/-0.274) for {'alpha': 1, 'early_stopping': True, 'learning_rate': 'adaptive', 'max_iter': 1000, 'momentum': 0.7, 'solver': 'sgd'}\n",
      "0.678 (+/-0.237) for {'alpha': 1, 'early_stopping': True, 'learning_rate': 'adaptive', 'max_iter': 1000, 'momentum': 0.9, 'solver': 'sgd'}\n",
      "0.577 (+/-0.166) for {'alpha': 1, 'early_stopping': True, 'learning_rate': 'adaptive', 'max_iter': 1500, 'momentum': 0.1, 'solver': 'sgd'}\n",
      "0.534 (+/-0.246) for {'alpha': 1, 'early_stopping': True, 'learning_rate': 'adaptive', 'max_iter': 1500, 'momentum': 0.3, 'solver': 'sgd'}\n",
      "0.511 (+/-0.291) for {'alpha': 1, 'early_stopping': True, 'learning_rate': 'adaptive', 'max_iter': 1500, 'momentum': 0.5, 'solver': 'sgd'}\n",
      "0.651 (+/-0.138) for {'alpha': 1, 'early_stopping': True, 'learning_rate': 'adaptive', 'max_iter': 1500, 'momentum': 0.7, 'solver': 'sgd'}\n",
      "0.692 (+/-0.140) for {'alpha': 1, 'early_stopping': True, 'learning_rate': 'adaptive', 'max_iter': 1500, 'momentum': 0.9, 'solver': 'sgd'}\n",
      "0.569 (+/-0.266) for {'alpha': 1, 'early_stopping': True, 'learning_rate': 'adaptive', 'max_iter': 2000, 'momentum': 0.1, 'solver': 'sgd'}\n",
      "0.586 (+/-0.116) for {'alpha': 1, 'early_stopping': True, 'learning_rate': 'adaptive', 'max_iter': 2000, 'momentum': 0.3, 'solver': 'sgd'}\n",
      "0.632 (+/-0.189) for {'alpha': 1, 'early_stopping': True, 'learning_rate': 'adaptive', 'max_iter': 2000, 'momentum': 0.5, 'solver': 'sgd'}\n",
      "0.573 (+/-0.308) for {'alpha': 1, 'early_stopping': True, 'learning_rate': 'adaptive', 'max_iter': 2000, 'momentum': 0.7, 'solver': 'sgd'}\n",
      "0.676 (+/-0.152) for {'alpha': 1, 'early_stopping': True, 'learning_rate': 'adaptive', 'max_iter': 2000, 'momentum': 0.9, 'solver': 'sgd'}\n",
      "0.770 (+/-0.083) for {'alpha': 1, 'early_stopping': False, 'learning_rate': 'constant', 'max_iter': 1000, 'momentum': 0.1, 'solver': 'sgd'}\n",
      "0.789 (+/-0.104) for {'alpha': 1, 'early_stopping': False, 'learning_rate': 'constant', 'max_iter': 1000, 'momentum': 0.3, 'solver': 'sgd'}\n",
      "0.792 (+/-0.083) for {'alpha': 1, 'early_stopping': False, 'learning_rate': 'constant', 'max_iter': 1000, 'momentum': 0.5, 'solver': 'sgd'}\n",
      "0.788 (+/-0.076) for {'alpha': 1, 'early_stopping': False, 'learning_rate': 'constant', 'max_iter': 1000, 'momentum': 0.7, 'solver': 'sgd'}\n",
      "0.791 (+/-0.081) for {'alpha': 1, 'early_stopping': False, 'learning_rate': 'constant', 'max_iter': 1000, 'momentum': 0.9, 'solver': 'sgd'}\n",
      "0.782 (+/-0.110) for {'alpha': 1, 'early_stopping': False, 'learning_rate': 'constant', 'max_iter': 1500, 'momentum': 0.1, 'solver': 'sgd'}\n",
      "0.785 (+/-0.086) for {'alpha': 1, 'early_stopping': False, 'learning_rate': 'constant', 'max_iter': 1500, 'momentum': 0.3, 'solver': 'sgd'}\n",
      "0.787 (+/-0.085) for {'alpha': 1, 'early_stopping': False, 'learning_rate': 'constant', 'max_iter': 1500, 'momentum': 0.5, 'solver': 'sgd'}\n",
      "0.785 (+/-0.057) for {'alpha': 1, 'early_stopping': False, 'learning_rate': 'constant', 'max_iter': 1500, 'momentum': 0.7, 'solver': 'sgd'}\n",
      "0.791 (+/-0.072) for {'alpha': 1, 'early_stopping': False, 'learning_rate': 'constant', 'max_iter': 1500, 'momentum': 0.9, 'solver': 'sgd'}\n",
      "0.778 (+/-0.098) for {'alpha': 1, 'early_stopping': False, 'learning_rate': 'constant', 'max_iter': 2000, 'momentum': 0.1, 'solver': 'sgd'}\n",
      "0.801 (+/-0.093) for {'alpha': 1, 'early_stopping': False, 'learning_rate': 'constant', 'max_iter': 2000, 'momentum': 0.3, 'solver': 'sgd'}\n",
      "0.794 (+/-0.081) for {'alpha': 1, 'early_stopping': False, 'learning_rate': 'constant', 'max_iter': 2000, 'momentum': 0.5, 'solver': 'sgd'}\n",
      "0.789 (+/-0.083) for {'alpha': 1, 'early_stopping': False, 'learning_rate': 'constant', 'max_iter': 2000, 'momentum': 0.7, 'solver': 'sgd'}\n",
      "0.795 (+/-0.076) for {'alpha': 1, 'early_stopping': False, 'learning_rate': 'constant', 'max_iter': 2000, 'momentum': 0.9, 'solver': 'sgd'}\n",
      "0.482 (+/-0.247) for {'alpha': 1, 'early_stopping': False, 'learning_rate': 'invscaling', 'max_iter': 1000, 'momentum': 0.1, 'solver': 'sgd'}\n",
      "0.575 (+/-0.300) for {'alpha': 1, 'early_stopping': False, 'learning_rate': 'invscaling', 'max_iter': 1000, 'momentum': 0.3, 'solver': 'sgd'}\n",
      "0.503 (+/-0.253) for {'alpha': 1, 'early_stopping': False, 'learning_rate': 'invscaling', 'max_iter': 1000, 'momentum': 0.5, 'solver': 'sgd'}\n",
      "0.575 (+/-0.240) for {'alpha': 1, 'early_stopping': False, 'learning_rate': 'invscaling', 'max_iter': 1000, 'momentum': 0.7, 'solver': 'sgd'}\n",
      "0.563 (+/-0.220) for {'alpha': 1, 'early_stopping': False, 'learning_rate': 'invscaling', 'max_iter': 1000, 'momentum': 0.9, 'solver': 'sgd'}\n",
      "0.491 (+/-0.301) for {'alpha': 1, 'early_stopping': False, 'learning_rate': 'invscaling', 'max_iter': 1500, 'momentum': 0.1, 'solver': 'sgd'}\n",
      "0.483 (+/-0.246) for {'alpha': 1, 'early_stopping': False, 'learning_rate': 'invscaling', 'max_iter': 1500, 'momentum': 0.3, 'solver': 'sgd'}\n",
      "0.487 (+/-0.181) for {'alpha': 1, 'early_stopping': False, 'learning_rate': 'invscaling', 'max_iter': 1500, 'momentum': 0.5, 'solver': 'sgd'}\n",
      "0.524 (+/-0.276) for {'alpha': 1, 'early_stopping': False, 'learning_rate': 'invscaling', 'max_iter': 1500, 'momentum': 0.7, 'solver': 'sgd'}\n",
      "0.458 (+/-0.270) for {'alpha': 1, 'early_stopping': False, 'learning_rate': 'invscaling', 'max_iter': 1500, 'momentum': 0.9, 'solver': 'sgd'}\n",
      "0.479 (+/-0.200) for {'alpha': 1, 'early_stopping': False, 'learning_rate': 'invscaling', 'max_iter': 2000, 'momentum': 0.1, 'solver': 'sgd'}\n",
      "0.501 (+/-0.294) for {'alpha': 1, 'early_stopping': False, 'learning_rate': 'invscaling', 'max_iter': 2000, 'momentum': 0.3, 'solver': 'sgd'}\n",
      "0.516 (+/-0.203) for {'alpha': 1, 'early_stopping': False, 'learning_rate': 'invscaling', 'max_iter': 2000, 'momentum': 0.5, 'solver': 'sgd'}\n",
      "0.552 (+/-0.312) for {'alpha': 1, 'early_stopping': False, 'learning_rate': 'invscaling', 'max_iter': 2000, 'momentum': 0.7, 'solver': 'sgd'}\n",
      "0.548 (+/-0.310) for {'alpha': 1, 'early_stopping': False, 'learning_rate': 'invscaling', 'max_iter': 2000, 'momentum': 0.9, 'solver': 'sgd'}\n",
      "0.798 (+/-0.104) for {'alpha': 1, 'early_stopping': False, 'learning_rate': 'adaptive', 'max_iter': 1000, 'momentum': 0.1, 'solver': 'sgd'}\n",
      "0.792 (+/-0.091) for {'alpha': 1, 'early_stopping': False, 'learning_rate': 'adaptive', 'max_iter': 1000, 'momentum': 0.3, 'solver': 'sgd'}\n",
      "0.777 (+/-0.086) for {'alpha': 1, 'early_stopping': False, 'learning_rate': 'adaptive', 'max_iter': 1000, 'momentum': 0.5, 'solver': 'sgd'}\n",
      "0.788 (+/-0.088) for {'alpha': 1, 'early_stopping': False, 'learning_rate': 'adaptive', 'max_iter': 1000, 'momentum': 0.7, 'solver': 'sgd'}\n",
      "0.794 (+/-0.077) for {'alpha': 1, 'early_stopping': False, 'learning_rate': 'adaptive', 'max_iter': 1000, 'momentum': 0.9, 'solver': 'sgd'}\n",
      "0.786 (+/-0.072) for {'alpha': 1, 'early_stopping': False, 'learning_rate': 'adaptive', 'max_iter': 1500, 'momentum': 0.1, 'solver': 'sgd'}\n",
      "0.785 (+/-0.082) for {'alpha': 1, 'early_stopping': False, 'learning_rate': 'adaptive', 'max_iter': 1500, 'momentum': 0.3, 'solver': 'sgd'}\n",
      "0.789 (+/-0.098) for {'alpha': 1, 'early_stopping': False, 'learning_rate': 'adaptive', 'max_iter': 1500, 'momentum': 0.5, 'solver': 'sgd'}\n",
      "0.788 (+/-0.076) for {'alpha': 1, 'early_stopping': False, 'learning_rate': 'adaptive', 'max_iter': 1500, 'momentum': 0.7, 'solver': 'sgd'}\n",
      "0.789 (+/-0.074) for {'alpha': 1, 'early_stopping': False, 'learning_rate': 'adaptive', 'max_iter': 1500, 'momentum': 0.9, 'solver': 'sgd'}\n",
      "0.784 (+/-0.114) for {'alpha': 1, 'early_stopping': False, 'learning_rate': 'adaptive', 'max_iter': 2000, 'momentum': 0.1, 'solver': 'sgd'}\n",
      "0.784 (+/-0.069) for {'alpha': 1, 'early_stopping': False, 'learning_rate': 'adaptive', 'max_iter': 2000, 'momentum': 0.3, 'solver': 'sgd'}\n",
      "0.787 (+/-0.079) for {'alpha': 1, 'early_stopping': False, 'learning_rate': 'adaptive', 'max_iter': 2000, 'momentum': 0.5, 'solver': 'sgd'}\n",
      "0.782 (+/-0.099) for {'alpha': 1, 'early_stopping': False, 'learning_rate': 'adaptive', 'max_iter': 2000, 'momentum': 0.7, 'solver': 'sgd'}\n",
      "0.788 (+/-0.068) for {'alpha': 1, 'early_stopping': False, 'learning_rate': 'adaptive', 'max_iter': 2000, 'momentum': 0.9, 'solver': 'sgd'}\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.89      0.90      0.90       114\n",
      "         1.0       0.82      0.80      0.81        64\n",
      "\n",
      "    accuracy                           0.87       178\n",
      "   macro avg       0.86      0.85      0.85       178\n",
      "weighted avg       0.86      0.87      0.86       178\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "tuned_parameters = [{ 'alpha':[0.0001,0.001,0.01,0.1,1], 'max_iter':[1000,1500,2000],\n",
    "      'solver':['adam'], 'early_stopping':[True, False]},\n",
    "                    { 'alpha':[0.0001,0.001,0.01,0.1,1],\n",
    "'max_iter':[1000,1500,2000],'momentum':[0.1,0.3,0.5,0.7,0.9],\n",
    "                     'solver':['sgd'], 'early_stopping':[True, False],'learning_rate':['constant','invscaling','adaptive']},\n",
    "                    ]\n",
    "\n",
    "\n",
    "print()\n",
    "\n",
    "clf = GridSearchCV(\n",
    "    MLPClassifier(), tuned_parameters, scoring='accuracy', cv=10\n",
    ")\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best parameters set found on development set:\")\n",
    "print()\n",
    "print(clf.best_params_)\n",
    "print()\n",
    "print(\"Grid scores on development set:\")\n",
    "print()\n",
    "means = clf.cv_results_['mean_test_score']\n",
    "stds = clf.cv_results_['std_test_score']\n",
    "for mean, std, params in zip(means, stds, clf.cv_results_['params']):\n",
    "    print(\"%0.3f (+/-%0.03f) for %r\"\n",
    "          % (mean, std * 2, params))\n",
    "print()\n",
    "\n",
    "print(\"Detailed classification report:\")\n",
    "print()\n",
    "print(\"The model is trained on the full development set.\")\n",
    "print(\"The scores are computed on the full evaluation set.\")\n",
    "print()\n",
    "y_true, y_pred = y_test, clf.predict(X_test)\n",
    "print(classification_report(y_true, y_pred))\n",
    "print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XFGkbUewTrHN"
   },
   "source": [
    "### Cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "c4aD0u-YSbcp",
    "outputId": "f570647c-e9ff-4f62-9571-a62fba266d3e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.801348\n"
     ]
    }
   ],
   "source": [
    "clf = MLPClassifier(alpha= 0.01, early_stopping= False, max_iter= 2000, solver='adam')\n",
    "score=cross_validate(clf, X, y, cv=10, scoring=\"accuracy\")[\"test_score\"].mean()\n",
    "print(f\"{score:.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1oY7OpOMMjbA"
   },
   "source": [
    "### Generating Predicion Result for submission in .csv format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZjT-qeiMr91u"
   },
   "outputs": [],
   "source": [
    "df2 = pd.read_csv(url2)\n",
    "clf = MLPClassifier(alpha= 0.01, early_stopping= False, max_iter= 2000, solver='adam')\n",
    "clf.fit(X, y)\n",
    "pred=clf.predict(X_test2)\n",
    "pd.DataFrame({\"PassengerId\": df2[\"PassengerId\"], \"Survived\": pred}).to_csv(\"MLP_submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GZ-lxD2aAHX6"
   },
   "source": [
    "![alt text](https://raw.githubusercontent.com/zyzhang1130/CE9010/master/Titanic/mlp.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nZyDLaUo7BjQ"
   },
   "source": [
    "## Gradient Boosting Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "3WR9I_zx7Gx2",
    "outputId": "12a551e2-e05e-4c3b-a57e-d11a782699e1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best parameters set found on development set:\n",
      "\n",
      "{'learning_rate': 0.1, 'loss': 'exponential', 'max_depth': 4, 'warm_start': True}\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "0.610 (+/-0.011) for {'learning_rate': 0.001, 'loss': 'deviance', 'max_depth': 1, 'warm_start': True}\n",
      "0.610 (+/-0.011) for {'learning_rate': 0.001, 'loss': 'deviance', 'max_depth': 1, 'warm_start': False}\n",
      "0.610 (+/-0.011) for {'learning_rate': 0.001, 'loss': 'deviance', 'max_depth': 2, 'warm_start': True}\n",
      "0.610 (+/-0.011) for {'learning_rate': 0.001, 'loss': 'deviance', 'max_depth': 2, 'warm_start': False}\n",
      "0.610 (+/-0.011) for {'learning_rate': 0.001, 'loss': 'deviance', 'max_depth': 3, 'warm_start': True}\n",
      "0.610 (+/-0.011) for {'learning_rate': 0.001, 'loss': 'deviance', 'max_depth': 3, 'warm_start': False}\n",
      "0.610 (+/-0.011) for {'learning_rate': 0.001, 'loss': 'deviance', 'max_depth': 4, 'warm_start': True}\n",
      "0.610 (+/-0.011) for {'learning_rate': 0.001, 'loss': 'deviance', 'max_depth': 4, 'warm_start': False}\n",
      "0.610 (+/-0.011) for {'learning_rate': 0.001, 'loss': 'deviance', 'max_depth': 5, 'warm_start': True}\n",
      "0.610 (+/-0.011) for {'learning_rate': 0.001, 'loss': 'deviance', 'max_depth': 5, 'warm_start': False}\n",
      "0.610 (+/-0.011) for {'learning_rate': 0.001, 'loss': 'deviance', 'max_depth': 6, 'warm_start': True}\n",
      "0.610 (+/-0.011) for {'learning_rate': 0.001, 'loss': 'deviance', 'max_depth': 6, 'warm_start': False}\n",
      "0.610 (+/-0.011) for {'learning_rate': 0.001, 'loss': 'deviance', 'max_depth': 7, 'warm_start': True}\n",
      "0.610 (+/-0.011) for {'learning_rate': 0.001, 'loss': 'deviance', 'max_depth': 7, 'warm_start': False}\n",
      "0.610 (+/-0.011) for {'learning_rate': 0.001, 'loss': 'deviance', 'max_depth': 8, 'warm_start': True}\n",
      "0.610 (+/-0.011) for {'learning_rate': 0.001, 'loss': 'deviance', 'max_depth': 8, 'warm_start': False}\n",
      "0.610 (+/-0.011) for {'learning_rate': 0.001, 'loss': 'deviance', 'max_depth': 9, 'warm_start': True}\n",
      "0.610 (+/-0.011) for {'learning_rate': 0.001, 'loss': 'deviance', 'max_depth': 9, 'warm_start': False}\n",
      "0.610 (+/-0.011) for {'learning_rate': 0.001, 'loss': 'exponential', 'max_depth': 1, 'warm_start': True}\n",
      "0.610 (+/-0.011) for {'learning_rate': 0.001, 'loss': 'exponential', 'max_depth': 1, 'warm_start': False}\n",
      "0.610 (+/-0.011) for {'learning_rate': 0.001, 'loss': 'exponential', 'max_depth': 2, 'warm_start': True}\n",
      "0.610 (+/-0.011) for {'learning_rate': 0.001, 'loss': 'exponential', 'max_depth': 2, 'warm_start': False}\n",
      "0.610 (+/-0.011) for {'learning_rate': 0.001, 'loss': 'exponential', 'max_depth': 3, 'warm_start': True}\n",
      "0.610 (+/-0.011) for {'learning_rate': 0.001, 'loss': 'exponential', 'max_depth': 3, 'warm_start': False}\n",
      "0.610 (+/-0.011) for {'learning_rate': 0.001, 'loss': 'exponential', 'max_depth': 4, 'warm_start': True}\n",
      "0.610 (+/-0.011) for {'learning_rate': 0.001, 'loss': 'exponential', 'max_depth': 4, 'warm_start': False}\n",
      "0.610 (+/-0.011) for {'learning_rate': 0.001, 'loss': 'exponential', 'max_depth': 5, 'warm_start': True}\n",
      "0.610 (+/-0.011) for {'learning_rate': 0.001, 'loss': 'exponential', 'max_depth': 5, 'warm_start': False}\n",
      "0.610 (+/-0.011) for {'learning_rate': 0.001, 'loss': 'exponential', 'max_depth': 6, 'warm_start': True}\n",
      "0.610 (+/-0.011) for {'learning_rate': 0.001, 'loss': 'exponential', 'max_depth': 6, 'warm_start': False}\n",
      "0.610 (+/-0.011) for {'learning_rate': 0.001, 'loss': 'exponential', 'max_depth': 7, 'warm_start': True}\n",
      "0.610 (+/-0.011) for {'learning_rate': 0.001, 'loss': 'exponential', 'max_depth': 7, 'warm_start': False}\n",
      "0.610 (+/-0.011) for {'learning_rate': 0.001, 'loss': 'exponential', 'max_depth': 8, 'warm_start': True}\n",
      "0.610 (+/-0.011) for {'learning_rate': 0.001, 'loss': 'exponential', 'max_depth': 8, 'warm_start': False}\n",
      "0.610 (+/-0.011) for {'learning_rate': 0.001, 'loss': 'exponential', 'max_depth': 9, 'warm_start': True}\n",
      "0.610 (+/-0.011) for {'learning_rate': 0.001, 'loss': 'exponential', 'max_depth': 9, 'warm_start': False}\n",
      "0.784 (+/-0.090) for {'learning_rate': 0.01, 'loss': 'deviance', 'max_depth': 1, 'warm_start': True}\n",
      "0.784 (+/-0.090) for {'learning_rate': 0.01, 'loss': 'deviance', 'max_depth': 1, 'warm_start': False}\n",
      "0.780 (+/-0.082) for {'learning_rate': 0.01, 'loss': 'deviance', 'max_depth': 2, 'warm_start': True}\n",
      "0.780 (+/-0.082) for {'learning_rate': 0.01, 'loss': 'deviance', 'max_depth': 2, 'warm_start': False}\n",
      "0.802 (+/-0.094) for {'learning_rate': 0.01, 'loss': 'deviance', 'max_depth': 3, 'warm_start': True}\n",
      "0.802 (+/-0.094) for {'learning_rate': 0.01, 'loss': 'deviance', 'max_depth': 3, 'warm_start': False}\n",
      "0.812 (+/-0.091) for {'learning_rate': 0.01, 'loss': 'deviance', 'max_depth': 4, 'warm_start': True}\n",
      "0.812 (+/-0.091) for {'learning_rate': 0.01, 'loss': 'deviance', 'max_depth': 4, 'warm_start': False}\n",
      "0.816 (+/-0.089) for {'learning_rate': 0.01, 'loss': 'deviance', 'max_depth': 5, 'warm_start': True}\n",
      "0.815 (+/-0.092) for {'learning_rate': 0.01, 'loss': 'deviance', 'max_depth': 5, 'warm_start': False}\n",
      "0.816 (+/-0.084) for {'learning_rate': 0.01, 'loss': 'deviance', 'max_depth': 6, 'warm_start': True}\n",
      "0.815 (+/-0.086) for {'learning_rate': 0.01, 'loss': 'deviance', 'max_depth': 6, 'warm_start': False}\n",
      "0.813 (+/-0.083) for {'learning_rate': 0.01, 'loss': 'deviance', 'max_depth': 7, 'warm_start': True}\n",
      "0.812 (+/-0.086) for {'learning_rate': 0.01, 'loss': 'deviance', 'max_depth': 7, 'warm_start': False}\n",
      "0.816 (+/-0.099) for {'learning_rate': 0.01, 'loss': 'deviance', 'max_depth': 8, 'warm_start': True}\n",
      "0.816 (+/-0.102) for {'learning_rate': 0.01, 'loss': 'deviance', 'max_depth': 8, 'warm_start': False}\n",
      "0.799 (+/-0.119) for {'learning_rate': 0.01, 'loss': 'deviance', 'max_depth': 9, 'warm_start': True}\n",
      "0.798 (+/-0.111) for {'learning_rate': 0.01, 'loss': 'deviance', 'max_depth': 9, 'warm_start': False}\n",
      "0.784 (+/-0.090) for {'learning_rate': 0.01, 'loss': 'exponential', 'max_depth': 1, 'warm_start': True}\n",
      "0.784 (+/-0.090) for {'learning_rate': 0.01, 'loss': 'exponential', 'max_depth': 1, 'warm_start': False}\n",
      "0.780 (+/-0.082) for {'learning_rate': 0.01, 'loss': 'exponential', 'max_depth': 2, 'warm_start': True}\n",
      "0.780 (+/-0.082) for {'learning_rate': 0.01, 'loss': 'exponential', 'max_depth': 2, 'warm_start': False}\n",
      "0.801 (+/-0.096) for {'learning_rate': 0.01, 'loss': 'exponential', 'max_depth': 3, 'warm_start': True}\n",
      "0.801 (+/-0.096) for {'learning_rate': 0.01, 'loss': 'exponential', 'max_depth': 3, 'warm_start': False}\n",
      "0.809 (+/-0.095) for {'learning_rate': 0.01, 'loss': 'exponential', 'max_depth': 4, 'warm_start': True}\n",
      "0.809 (+/-0.095) for {'learning_rate': 0.01, 'loss': 'exponential', 'max_depth': 4, 'warm_start': False}\n",
      "0.811 (+/-0.089) for {'learning_rate': 0.01, 'loss': 'exponential', 'max_depth': 5, 'warm_start': True}\n",
      "0.811 (+/-0.089) for {'learning_rate': 0.01, 'loss': 'exponential', 'max_depth': 5, 'warm_start': False}\n",
      "0.815 (+/-0.092) for {'learning_rate': 0.01, 'loss': 'exponential', 'max_depth': 6, 'warm_start': True}\n",
      "0.817 (+/-0.087) for {'learning_rate': 0.01, 'loss': 'exponential', 'max_depth': 6, 'warm_start': False}\n",
      "0.813 (+/-0.084) for {'learning_rate': 0.01, 'loss': 'exponential', 'max_depth': 7, 'warm_start': True}\n",
      "0.815 (+/-0.083) for {'learning_rate': 0.01, 'loss': 'exponential', 'max_depth': 7, 'warm_start': False}\n",
      "0.815 (+/-0.092) for {'learning_rate': 0.01, 'loss': 'exponential', 'max_depth': 8, 'warm_start': True}\n",
      "0.816 (+/-0.093) for {'learning_rate': 0.01, 'loss': 'exponential', 'max_depth': 8, 'warm_start': False}\n",
      "0.801 (+/-0.106) for {'learning_rate': 0.01, 'loss': 'exponential', 'max_depth': 9, 'warm_start': True}\n",
      "0.802 (+/-0.107) for {'learning_rate': 0.01, 'loss': 'exponential', 'max_depth': 9, 'warm_start': False}\n",
      "0.802 (+/-0.097) for {'learning_rate': 0.1, 'loss': 'deviance', 'max_depth': 1, 'warm_start': True}\n",
      "0.802 (+/-0.097) for {'learning_rate': 0.1, 'loss': 'deviance', 'max_depth': 1, 'warm_start': False}\n",
      "0.819 (+/-0.094) for {'learning_rate': 0.1, 'loss': 'deviance', 'max_depth': 2, 'warm_start': True}\n",
      "0.819 (+/-0.094) for {'learning_rate': 0.1, 'loss': 'deviance', 'max_depth': 2, 'warm_start': False}\n",
      "0.827 (+/-0.082) for {'learning_rate': 0.1, 'loss': 'deviance', 'max_depth': 3, 'warm_start': True}\n",
      "0.827 (+/-0.082) for {'learning_rate': 0.1, 'loss': 'deviance', 'max_depth': 3, 'warm_start': False}\n",
      "0.827 (+/-0.085) for {'learning_rate': 0.1, 'loss': 'deviance', 'max_depth': 4, 'warm_start': True}\n",
      "0.829 (+/-0.083) for {'learning_rate': 0.1, 'loss': 'deviance', 'max_depth': 4, 'warm_start': False}\n",
      "0.816 (+/-0.072) for {'learning_rate': 0.1, 'loss': 'deviance', 'max_depth': 5, 'warm_start': True}\n",
      "0.817 (+/-0.070) for {'learning_rate': 0.1, 'loss': 'deviance', 'max_depth': 5, 'warm_start': False}\n",
      "0.801 (+/-0.100) for {'learning_rate': 0.1, 'loss': 'deviance', 'max_depth': 6, 'warm_start': True}\n",
      "0.803 (+/-0.092) for {'learning_rate': 0.1, 'loss': 'deviance', 'max_depth': 6, 'warm_start': False}\n",
      "0.794 (+/-0.096) for {'learning_rate': 0.1, 'loss': 'deviance', 'max_depth': 7, 'warm_start': True}\n",
      "0.801 (+/-0.095) for {'learning_rate': 0.1, 'loss': 'deviance', 'max_depth': 7, 'warm_start': False}\n",
      "0.801 (+/-0.116) for {'learning_rate': 0.1, 'loss': 'deviance', 'max_depth': 8, 'warm_start': True}\n",
      "0.796 (+/-0.119) for {'learning_rate': 0.1, 'loss': 'deviance', 'max_depth': 8, 'warm_start': False}\n",
      "0.798 (+/-0.129) for {'learning_rate': 0.1, 'loss': 'deviance', 'max_depth': 9, 'warm_start': True}\n",
      "0.795 (+/-0.124) for {'learning_rate': 0.1, 'loss': 'deviance', 'max_depth': 9, 'warm_start': False}\n",
      "0.791 (+/-0.091) for {'learning_rate': 0.1, 'loss': 'exponential', 'max_depth': 1, 'warm_start': True}\n",
      "0.791 (+/-0.091) for {'learning_rate': 0.1, 'loss': 'exponential', 'max_depth': 1, 'warm_start': False}\n",
      "0.809 (+/-0.112) for {'learning_rate': 0.1, 'loss': 'exponential', 'max_depth': 2, 'warm_start': True}\n",
      "0.809 (+/-0.112) for {'learning_rate': 0.1, 'loss': 'exponential', 'max_depth': 2, 'warm_start': False}\n",
      "0.829 (+/-0.082) for {'learning_rate': 0.1, 'loss': 'exponential', 'max_depth': 3, 'warm_start': True}\n",
      "0.829 (+/-0.082) for {'learning_rate': 0.1, 'loss': 'exponential', 'max_depth': 3, 'warm_start': False}\n",
      "0.830 (+/-0.090) for {'learning_rate': 0.1, 'loss': 'exponential', 'max_depth': 4, 'warm_start': True}\n",
      "0.830 (+/-0.090) for {'learning_rate': 0.1, 'loss': 'exponential', 'max_depth': 4, 'warm_start': False}\n",
      "0.812 (+/-0.086) for {'learning_rate': 0.1, 'loss': 'exponential', 'max_depth': 5, 'warm_start': True}\n",
      "0.813 (+/-0.084) for {'learning_rate': 0.1, 'loss': 'exponential', 'max_depth': 5, 'warm_start': False}\n",
      "0.806 (+/-0.087) for {'learning_rate': 0.1, 'loss': 'exponential', 'max_depth': 6, 'warm_start': True}\n",
      "0.799 (+/-0.098) for {'learning_rate': 0.1, 'loss': 'exponential', 'max_depth': 6, 'warm_start': False}\n",
      "0.798 (+/-0.092) for {'learning_rate': 0.1, 'loss': 'exponential', 'max_depth': 7, 'warm_start': True}\n",
      "0.803 (+/-0.111) for {'learning_rate': 0.1, 'loss': 'exponential', 'max_depth': 7, 'warm_start': False}\n",
      "0.794 (+/-0.103) for {'learning_rate': 0.1, 'loss': 'exponential', 'max_depth': 8, 'warm_start': True}\n",
      "0.791 (+/-0.094) for {'learning_rate': 0.1, 'loss': 'exponential', 'max_depth': 8, 'warm_start': False}\n",
      "0.784 (+/-0.120) for {'learning_rate': 0.1, 'loss': 'exponential', 'max_depth': 9, 'warm_start': True}\n",
      "0.805 (+/-0.114) for {'learning_rate': 0.1, 'loss': 'exponential', 'max_depth': 9, 'warm_start': False}\n",
      "0.810 (+/-0.094) for {'learning_rate': 1, 'loss': 'deviance', 'max_depth': 1, 'warm_start': True}\n",
      "0.810 (+/-0.094) for {'learning_rate': 1, 'loss': 'deviance', 'max_depth': 1, 'warm_start': False}\n",
      "0.799 (+/-0.102) for {'learning_rate': 1, 'loss': 'deviance', 'max_depth': 2, 'warm_start': True}\n",
      "0.799 (+/-0.102) for {'learning_rate': 1, 'loss': 'deviance', 'max_depth': 2, 'warm_start': False}\n",
      "0.786 (+/-0.114) for {'learning_rate': 1, 'loss': 'deviance', 'max_depth': 3, 'warm_start': True}\n",
      "0.791 (+/-0.113) for {'learning_rate': 1, 'loss': 'deviance', 'max_depth': 3, 'warm_start': False}\n",
      "0.775 (+/-0.137) for {'learning_rate': 1, 'loss': 'deviance', 'max_depth': 4, 'warm_start': True}\n",
      "0.778 (+/-0.134) for {'learning_rate': 1, 'loss': 'deviance', 'max_depth': 4, 'warm_start': False}\n",
      "0.784 (+/-0.133) for {'learning_rate': 1, 'loss': 'deviance', 'max_depth': 5, 'warm_start': True}\n",
      "0.785 (+/-0.130) for {'learning_rate': 1, 'loss': 'deviance', 'max_depth': 5, 'warm_start': False}\n",
      "0.784 (+/-0.113) for {'learning_rate': 1, 'loss': 'deviance', 'max_depth': 6, 'warm_start': True}\n",
      "0.792 (+/-0.132) for {'learning_rate': 1, 'loss': 'deviance', 'max_depth': 6, 'warm_start': False}\n",
      "0.796 (+/-0.095) for {'learning_rate': 1, 'loss': 'deviance', 'max_depth': 7, 'warm_start': True}\n",
      "0.801 (+/-0.104) for {'learning_rate': 1, 'loss': 'deviance', 'max_depth': 7, 'warm_start': False}\n",
      "0.793 (+/-0.112) for {'learning_rate': 1, 'loss': 'deviance', 'max_depth': 8, 'warm_start': True}\n",
      "0.789 (+/-0.109) for {'learning_rate': 1, 'loss': 'deviance', 'max_depth': 8, 'warm_start': False}\n",
      "0.791 (+/-0.107) for {'learning_rate': 1, 'loss': 'deviance', 'max_depth': 9, 'warm_start': True}\n",
      "0.784 (+/-0.114) for {'learning_rate': 1, 'loss': 'deviance', 'max_depth': 9, 'warm_start': False}\n",
      "0.813 (+/-0.104) for {'learning_rate': 1, 'loss': 'exponential', 'max_depth': 1, 'warm_start': True}\n",
      "0.813 (+/-0.104) for {'learning_rate': 1, 'loss': 'exponential', 'max_depth': 1, 'warm_start': False}\n",
      "0.799 (+/-0.110) for {'learning_rate': 1, 'loss': 'exponential', 'max_depth': 2, 'warm_start': True}\n",
      "0.799 (+/-0.110) for {'learning_rate': 1, 'loss': 'exponential', 'max_depth': 2, 'warm_start': False}\n",
      "0.784 (+/-0.138) for {'learning_rate': 1, 'loss': 'exponential', 'max_depth': 3, 'warm_start': True}\n",
      "0.785 (+/-0.137) for {'learning_rate': 1, 'loss': 'exponential', 'max_depth': 3, 'warm_start': False}\n",
      "0.782 (+/-0.123) for {'learning_rate': 1, 'loss': 'exponential', 'max_depth': 4, 'warm_start': True}\n",
      "0.785 (+/-0.131) for {'learning_rate': 1, 'loss': 'exponential', 'max_depth': 4, 'warm_start': False}\n",
      "0.794 (+/-0.113) for {'learning_rate': 1, 'loss': 'exponential', 'max_depth': 5, 'warm_start': True}\n",
      "0.789 (+/-0.093) for {'learning_rate': 1, 'loss': 'exponential', 'max_depth': 5, 'warm_start': False}\n",
      "0.791 (+/-0.132) for {'learning_rate': 1, 'loss': 'exponential', 'max_depth': 6, 'warm_start': True}\n",
      "0.787 (+/-0.135) for {'learning_rate': 1, 'loss': 'exponential', 'max_depth': 6, 'warm_start': False}\n",
      "0.792 (+/-0.123) for {'learning_rate': 1, 'loss': 'exponential', 'max_depth': 7, 'warm_start': True}\n",
      "0.793 (+/-0.135) for {'learning_rate': 1, 'loss': 'exponential', 'max_depth': 7, 'warm_start': False}\n",
      "0.796 (+/-0.145) for {'learning_rate': 1, 'loss': 'exponential', 'max_depth': 8, 'warm_start': True}\n",
      "0.795 (+/-0.135) for {'learning_rate': 1, 'loss': 'exponential', 'max_depth': 8, 'warm_start': False}\n",
      "0.792 (+/-0.128) for {'learning_rate': 1, 'loss': 'exponential', 'max_depth': 9, 'warm_start': True}\n",
      "0.785 (+/-0.124) for {'learning_rate': 1, 'loss': 'exponential', 'max_depth': 9, 'warm_start': False}\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.79      0.92      0.85       114\n",
      "         1.0       0.80      0.56      0.66        64\n",
      "\n",
      "    accuracy                           0.79       178\n",
      "   macro avg       0.79      0.74      0.76       178\n",
      "weighted avg       0.79      0.79      0.78       178\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "tuned_parameters = [{ 'loss':['deviance', 'exponential'], 'learning_rate':[0.001,0.01,0.1,1],\n",
    "      'warm_start':[True, False], 'max_depth':[1,2,3,4,5,6,7,8,9]}\n",
    "                    ]\n",
    "\n",
    "\n",
    "print()\n",
    "\n",
    "clf = GridSearchCV(\n",
    "    GradientBoostingClassifier(), tuned_parameters, scoring='accuracy', cv=10\n",
    ")\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best parameters set found on development set:\")\n",
    "print()\n",
    "print(clf.best_params_)\n",
    "print()\n",
    "print(\"Grid scores on development set:\")\n",
    "print()\n",
    "means = clf.cv_results_['mean_test_score']\n",
    "stds = clf.cv_results_['std_test_score']\n",
    "for mean, std, params in zip(means, stds, clf.cv_results_['params']):\n",
    "    print(\"%0.3f (+/-%0.03f) for %r\"\n",
    "          % (mean, std * 2, params))\n",
    "print()\n",
    "\n",
    "print(\"Detailed classification report:\")\n",
    "print()\n",
    "print(\"The model is trained on the full development set.\")\n",
    "print(\"The scores are computed on the full evaluation set.\")\n",
    "print()\n",
    "y_true, y_pred = y_test, clf.predict(X_test)\n",
    "print(classification_report(y_true, y_pred))\n",
    "print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Gvmd32XZTtLO"
   },
   "source": [
    "### Cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "FuoHmzHoSkd-",
    "outputId": "1d24d2ce-be96-482e-f293-8e0cf4416d99"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.819363\n"
     ]
    }
   ],
   "source": [
    "clf = GradientBoostingClassifier(learning_rate= 0.1, loss= 'exponential', max_depth= 4, warm_start= True)\n",
    "score=cross_validate(clf, X, y, cv=10, scoring=\"accuracy\")[\"test_score\"].mean()\n",
    "print(f\"{score:.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qmae7Z2yMlKP"
   },
   "source": [
    "### Generating Predicion Result for submission in .csv format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mmcGazd6sYDa"
   },
   "outputs": [],
   "source": [
    "df2 = pd.read_csv(url2)\n",
    "clf = GradientBoostingClassifier(learning_rate= 0.1, loss= 'exponential', max_depth= 4, warm_start= True)\n",
    "clf.fit(X, y)\n",
    "pred=clf.predict(X_test2)\n",
    "pd.DataFrame({\"PassengerId\": df2[\"PassengerId\"], \"Survived\": pred}).to_csv(\"GradientBoosting_submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "F3O08TBpA9FA"
   },
   "source": [
    "![alt text](https://raw.githubusercontent.com/zyzhang1130/CE9010/master/Titanic/GradientBoosting.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "u1qhZ7fOmbvB"
   },
   "source": [
    "## AdaBoost Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "E64nFMZ_moMm",
    "outputId": "c6497be2-2148-4fa9-b0e1-9caa32657f73"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best parameters set found on development set:\n",
      "\n",
      "{'algorithm': 'SAMME', 'base_estimator': DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
      "                       max_depth=7, max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                       random_state=None, splitter='best'), 'learning_rate': 0.2, 'n_estimators': 200}\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "0.778 (+/-0.108) for {'algorithm': 'SAMME.R', 'base_estimator': DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
      "                       max_depth=7, max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                       random_state=None, splitter='best'), 'learning_rate': 0.2, 'n_estimators': 50}\n",
      "0.794 (+/-0.118) for {'algorithm': 'SAMME.R', 'base_estimator': DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
      "                       max_depth=7, max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                       random_state=None, splitter='best'), 'learning_rate': 0.2, 'n_estimators': 60}\n",
      "0.787 (+/-0.099) for {'algorithm': 'SAMME.R', 'base_estimator': DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
      "                       max_depth=7, max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                       random_state=None, splitter='best'), 'learning_rate': 0.2, 'n_estimators': 70}\n",
      "0.781 (+/-0.121) for {'algorithm': 'SAMME.R', 'base_estimator': DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
      "                       max_depth=7, max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                       random_state=None, splitter='best'), 'learning_rate': 0.2, 'n_estimators': 80}\n",
      "0.791 (+/-0.120) for {'algorithm': 'SAMME.R', 'base_estimator': DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
      "                       max_depth=7, max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                       random_state=None, splitter='best'), 'learning_rate': 0.2, 'n_estimators': 90}\n",
      "0.789 (+/-0.128) for {'algorithm': 'SAMME.R', 'base_estimator': DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
      "                       max_depth=7, max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                       random_state=None, splitter='best'), 'learning_rate': 0.2, 'n_estimators': 100}\n",
      "0.789 (+/-0.101) for {'algorithm': 'SAMME.R', 'base_estimator': DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
      "                       max_depth=7, max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                       random_state=None, splitter='best'), 'learning_rate': 0.2, 'n_estimators': 120}\n",
      "0.791 (+/-0.126) for {'algorithm': 'SAMME.R', 'base_estimator': DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
      "                       max_depth=7, max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                       random_state=None, splitter='best'), 'learning_rate': 0.2, 'n_estimators': 140}\n",
      "0.792 (+/-0.111) for {'algorithm': 'SAMME.R', 'base_estimator': DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
      "                       max_depth=7, max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                       random_state=None, splitter='best'), 'learning_rate': 0.2, 'n_estimators': 160}\n",
      "0.791 (+/-0.093) for {'algorithm': 'SAMME.R', 'base_estimator': DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
      "                       max_depth=7, max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                       random_state=None, splitter='best'), 'learning_rate': 0.2, 'n_estimators': 180}\n",
      "0.789 (+/-0.111) for {'algorithm': 'SAMME.R', 'base_estimator': DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
      "                       max_depth=7, max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                       random_state=None, splitter='best'), 'learning_rate': 0.2, 'n_estimators': 200}\n",
      "0.781 (+/-0.117) for {'algorithm': 'SAMME.R', 'base_estimator': DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
      "                       max_depth=7, max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                       random_state=None, splitter='best'), 'learning_rate': 0.4, 'n_estimators': 50}\n",
      "0.785 (+/-0.118) for {'algorithm': 'SAMME.R', 'base_estimator': DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
      "                       max_depth=7, max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                       random_state=None, splitter='best'), 'learning_rate': 0.4, 'n_estimators': 60}\n",
      "0.784 (+/-0.129) for {'algorithm': 'SAMME.R', 'base_estimator': DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
      "                       max_depth=7, max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                       random_state=None, splitter='best'), 'learning_rate': 0.4, 'n_estimators': 70}\n",
      "0.791 (+/-0.141) for {'algorithm': 'SAMME.R', 'base_estimator': DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
      "                       max_depth=7, max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                       random_state=None, splitter='best'), 'learning_rate': 0.4, 'n_estimators': 80}\n",
      "0.791 (+/-0.102) for {'algorithm': 'SAMME.R', 'base_estimator': DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
      "                       max_depth=7, max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                       random_state=None, splitter='best'), 'learning_rate': 0.4, 'n_estimators': 90}\n",
      "0.780 (+/-0.122) for {'algorithm': 'SAMME.R', 'base_estimator': DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
      "                       max_depth=7, max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                       random_state=None, splitter='best'), 'learning_rate': 0.4, 'n_estimators': 100}\n",
      "0.779 (+/-0.121) for {'algorithm': 'SAMME.R', 'base_estimator': DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
      "                       max_depth=7, max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                       random_state=None, splitter='best'), 'learning_rate': 0.4, 'n_estimators': 120}\n",
      "0.788 (+/-0.113) for {'algorithm': 'SAMME.R', 'base_estimator': DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
      "                       max_depth=7, max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                       random_state=None, splitter='best'), 'learning_rate': 0.4, 'n_estimators': 140}\n",
      "0.774 (+/-0.123) for {'algorithm': 'SAMME.R', 'base_estimator': DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
      "                       max_depth=7, max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                       random_state=None, splitter='best'), 'learning_rate': 0.4, 'n_estimators': 160}\n",
      "0.789 (+/-0.108) for {'algorithm': 'SAMME.R', 'base_estimator': DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
      "                       max_depth=7, max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                       random_state=None, splitter='best'), 'learning_rate': 0.4, 'n_estimators': 180}\n",
      "0.785 (+/-0.128) for {'algorithm': 'SAMME.R', 'base_estimator': DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
      "                       max_depth=7, max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                       random_state=None, splitter='best'), 'learning_rate': 0.4, 'n_estimators': 200}\n",
      "0.777 (+/-0.106) for {'algorithm': 'SAMME.R', 'base_estimator': DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
      "                       max_depth=7, max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                       random_state=None, splitter='best'), 'learning_rate': 0.6, 'n_estimators': 50}\n",
      "0.782 (+/-0.099) for {'algorithm': 'SAMME.R', 'base_estimator': DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
      "                       max_depth=7, max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                       random_state=None, splitter='best'), 'learning_rate': 0.6, 'n_estimators': 60}\n",
      "0.792 (+/-0.114) for {'algorithm': 'SAMME.R', 'base_estimator': DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
      "                       max_depth=7, max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                       random_state=None, splitter='best'), 'learning_rate': 0.6, 'n_estimators': 70}\n",
      "0.788 (+/-0.120) for {'algorithm': 'SAMME.R', 'base_estimator': DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
      "                       max_depth=7, max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                       random_state=None, splitter='best'), 'learning_rate': 0.6, 'n_estimators': 80}\n",
      "0.791 (+/-0.121) for {'algorithm': 'SAMME.R', 'base_estimator': DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
      "                       max_depth=7, max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                       random_state=None, splitter='best'), 'learning_rate': 0.6, 'n_estimators': 90}\n",
      "0.801 (+/-0.113) for {'algorithm': 'SAMME.R', 'base_estimator': DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
      "                       max_depth=7, max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                       random_state=None, splitter='best'), 'learning_rate': 0.6, 'n_estimators': 100}\n",
      "0.792 (+/-0.097) for {'algorithm': 'SAMME.R', 'base_estimator': DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
      "                       max_depth=7, max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                       random_state=None, splitter='best'), 'learning_rate': 0.6, 'n_estimators': 120}\n",
      "0.782 (+/-0.111) for {'algorithm': 'SAMME.R', 'base_estimator': DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
      "                       max_depth=7, max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                       random_state=None, splitter='best'), 'learning_rate': 0.6, 'n_estimators': 140}\n",
      "0.803 (+/-0.104) for {'algorithm': 'SAMME.R', 'base_estimator': DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
      "                       max_depth=7, max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                       random_state=None, splitter='best'), 'learning_rate': 0.6, 'n_estimators': 160}\n",
      "0.791 (+/-0.099) for {'algorithm': 'SAMME.R', 'base_estimator': DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
      "                       max_depth=7, max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                       random_state=None, splitter='best'), 'learning_rate': 0.6, 'n_estimators': 180}\n",
      "0.784 (+/-0.103) for {'algorithm': 'SAMME.R', 'base_estimator': DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
      "                       max_depth=7, max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                       random_state=None, splitter='best'), 'learning_rate': 0.6, 'n_estimators': 200}\n",
      "0.785 (+/-0.106) for {'algorithm': 'SAMME.R', 'base_estimator': DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
      "                       max_depth=7, max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                       random_state=None, splitter='best'), 'learning_rate': 0.8, 'n_estimators': 50}\n",
      "0.793 (+/-0.110) for {'algorithm': 'SAMME.R', 'base_estimator': DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
      "                       max_depth=7, max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                       random_state=None, splitter='best'), 'learning_rate': 0.8, 'n_estimators': 60}\n",
      "0.778 (+/-0.122) for {'algorithm': 'SAMME.R', 'base_estimator': DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
      "                       max_depth=7, max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                       random_state=None, splitter='best'), 'learning_rate': 0.8, 'n_estimators': 70}\n",
      "0.784 (+/-0.101) for {'algorithm': 'SAMME.R', 'base_estimator': DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
      "                       max_depth=7, max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                       random_state=None, splitter='best'), 'learning_rate': 0.8, 'n_estimators': 80}\n",
      "0.778 (+/-0.141) for {'algorithm': 'SAMME.R', 'base_estimator': DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
      "                       max_depth=7, max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                       random_state=None, splitter='best'), 'learning_rate': 0.8, 'n_estimators': 90}\n",
      "0.788 (+/-0.130) for {'algorithm': 'SAMME.R', 'base_estimator': DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
      "                       max_depth=7, max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                       random_state=None, splitter='best'), 'learning_rate': 0.8, 'n_estimators': 100}\n",
      "0.794 (+/-0.119) for {'algorithm': 'SAMME.R', 'base_estimator': DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
      "                       max_depth=7, max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                       random_state=None, splitter='best'), 'learning_rate': 0.8, 'n_estimators': 120}\n",
      "0.792 (+/-0.098) for {'algorithm': 'SAMME.R', 'base_estimator': DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
      "                       max_depth=7, max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                       random_state=None, splitter='best'), 'learning_rate': 0.8, 'n_estimators': 140}\n",
      "0.805 (+/-0.118) for {'algorithm': 'SAMME.R', 'base_estimator': DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
      "                       max_depth=7, max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                       random_state=None, splitter='best'), 'learning_rate': 0.8, 'n_estimators': 160}\n",
      "0.792 (+/-0.107) for {'algorithm': 'SAMME.R', 'base_estimator': DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
      "                       max_depth=7, max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                       random_state=None, splitter='best'), 'learning_rate': 0.8, 'n_estimators': 180}\n",
      "0.785 (+/-0.117) for {'algorithm': 'SAMME.R', 'base_estimator': DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
      "                       max_depth=7, max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                       random_state=None, splitter='best'), 'learning_rate': 0.8, 'n_estimators': 200}\n",
      "0.782 (+/-0.121) for {'algorithm': 'SAMME.R', 'base_estimator': DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
      "                       max_depth=7, max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                       random_state=None, splitter='best'), 'learning_rate': 1.0, 'n_estimators': 50}\n",
      "0.777 (+/-0.115) for {'algorithm': 'SAMME.R', 'base_estimator': DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
      "                       max_depth=7, max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                       random_state=None, splitter='best'), 'learning_rate': 1.0, 'n_estimators': 60}\n",
      "0.802 (+/-0.107) for {'algorithm': 'SAMME.R', 'base_estimator': DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
      "                       max_depth=7, max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                       random_state=None, splitter='best'), 'learning_rate': 1.0, 'n_estimators': 70}\n",
      "0.795 (+/-0.106) for {'algorithm': 'SAMME.R', 'base_estimator': DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
      "                       max_depth=7, max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                       random_state=None, splitter='best'), 'learning_rate': 1.0, 'n_estimators': 80}\n",
      "0.787 (+/-0.106) for {'algorithm': 'SAMME.R', 'base_estimator': DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
      "                       max_depth=7, max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                       random_state=None, splitter='best'), 'learning_rate': 1.0, 'n_estimators': 90}\n",
      "0.786 (+/-0.094) for {'algorithm': 'SAMME.R', 'base_estimator': DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
      "                       max_depth=7, max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                       random_state=None, splitter='best'), 'learning_rate': 1.0, 'n_estimators': 100}\n",
      "0.792 (+/-0.134) for {'algorithm': 'SAMME.R', 'base_estimator': DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
      "                       max_depth=7, max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                       random_state=None, splitter='best'), 'learning_rate': 1.0, 'n_estimators': 120}\n",
      "0.795 (+/-0.129) for {'algorithm': 'SAMME.R', 'base_estimator': DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
      "                       max_depth=7, max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                       random_state=None, splitter='best'), 'learning_rate': 1.0, 'n_estimators': 140}\n",
      "0.788 (+/-0.110) for {'algorithm': 'SAMME.R', 'base_estimator': DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
      "                       max_depth=7, max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                       random_state=None, splitter='best'), 'learning_rate': 1.0, 'n_estimators': 160}\n",
      "0.788 (+/-0.136) for {'algorithm': 'SAMME.R', 'base_estimator': DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
      "                       max_depth=7, max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                       random_state=None, splitter='best'), 'learning_rate': 1.0, 'n_estimators': 180}\n",
      "0.798 (+/-0.112) for {'algorithm': 'SAMME.R', 'base_estimator': DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
      "                       max_depth=7, max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                       random_state=None, splitter='best'), 'learning_rate': 1.0, 'n_estimators': 200}\n",
      "0.771 (+/-0.139) for {'algorithm': 'SAMME.R', 'base_estimator': DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
      "                       max_depth=7, max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                       random_state=None, splitter='best'), 'learning_rate': 1.2, 'n_estimators': 50}\n",
      "0.778 (+/-0.110) for {'algorithm': 'SAMME.R', 'base_estimator': DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
      "                       max_depth=7, max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                       random_state=None, splitter='best'), 'learning_rate': 1.2, 'n_estimators': 60}\n",
      "0.771 (+/-0.095) for {'algorithm': 'SAMME.R', 'base_estimator': DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
      "                       max_depth=7, max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                       random_state=None, splitter='best'), 'learning_rate': 1.2, 'n_estimators': 70}\n",
      "0.777 (+/-0.126) for {'algorithm': 'SAMME.R', 'base_estimator': DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
      "                       max_depth=7, max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                       random_state=None, splitter='best'), 'learning_rate': 1.2, 'n_estimators': 80}\n",
      "0.789 (+/-0.124) for {'algorithm': 'SAMME.R', 'base_estimator': DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
      "                       max_depth=7, max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                       random_state=None, splitter='best'), 'learning_rate': 1.2, 'n_estimators': 90}\n",
      "0.789 (+/-0.128) for {'algorithm': 'SAMME.R', 'base_estimator': DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
      "                       max_depth=7, max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                       random_state=None, splitter='best'), 'learning_rate': 1.2, 'n_estimators': 100}\n",
      "0.799 (+/-0.111) for {'algorithm': 'SAMME.R', 'base_estimator': DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
      "                       max_depth=7, max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                       random_state=None, splitter='best'), 'learning_rate': 1.2, 'n_estimators': 120}\n",
      "0.798 (+/-0.101) for {'algorithm': 'SAMME.R', 'base_estimator': DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
      "                       max_depth=7, max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                       random_state=None, splitter='best'), 'learning_rate': 1.2, 'n_estimators': 140}\n",
      "0.785 (+/-0.099) for {'algorithm': 'SAMME.R', 'base_estimator': DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
      "                       max_depth=7, max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                       random_state=None, splitter='best'), 'learning_rate': 1.2, 'n_estimators': 160}\n",
      "0.794 (+/-0.112) for {'algorithm': 'SAMME.R', 'base_estimator': DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
      "                       max_depth=7, max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                       random_state=None, splitter='best'), 'learning_rate': 1.2, 'n_estimators': 180}\n",
      "0.788 (+/-0.103) for {'algorithm': 'SAMME.R', 'base_estimator': DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
      "                       max_depth=7, max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                       random_state=None, splitter='best'), 'learning_rate': 1.2, 'n_estimators': 200}\n",
      "0.779 (+/-0.124) for {'algorithm': 'SAMME.R', 'base_estimator': DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
      "                       max_depth=7, max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                       random_state=None, splitter='best'), 'learning_rate': 1.4, 'n_estimators': 50}\n",
      "0.789 (+/-0.104) for {'algorithm': 'SAMME.R', 'base_estimator': DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
      "                       max_depth=7, max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                       random_state=None, splitter='best'), 'learning_rate': 1.4, 'n_estimators': 60}\n",
      "0.782 (+/-0.123) for {'algorithm': 'SAMME.R', 'base_estimator': DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
      "                       max_depth=7, max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                       random_state=None, splitter='best'), 'learning_rate': 1.4, 'n_estimators': 70}\n",
      "0.785 (+/-0.089) for {'algorithm': 'SAMME.R', 'base_estimator': DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
      "                       max_depth=7, max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                       random_state=None, splitter='best'), 'learning_rate': 1.4, 'n_estimators': 80}\n",
      "0.781 (+/-0.121) for {'algorithm': 'SAMME.R', 'base_estimator': DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
      "                       max_depth=7, max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                       random_state=None, splitter='best'), 'learning_rate': 1.4, 'n_estimators': 90}\n",
      "0.788 (+/-0.131) for {'algorithm': 'SAMME.R', 'base_estimator': DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
      "                       max_depth=7, max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                       random_state=None, splitter='best'), 'learning_rate': 1.4, 'n_estimators': 100}\n",
      "0.777 (+/-0.139) for {'algorithm': 'SAMME.R', 'base_estimator': DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
      "                       max_depth=7, max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                       random_state=None, splitter='best'), 'learning_rate': 1.4, 'n_estimators': 120}\n",
      "0.789 (+/-0.113) for {'algorithm': 'SAMME.R', 'base_estimator': DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
      "                       max_depth=7, max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                       random_state=None, splitter='best'), 'learning_rate': 1.4, 'n_estimators': 140}\n",
      "0.789 (+/-0.115) for {'algorithm': 'SAMME.R', 'base_estimator': DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
      "                       max_depth=7, max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                       random_state=None, splitter='best'), 'learning_rate': 1.4, 'n_estimators': 160}\n",
      "0.774 (+/-0.119) for {'algorithm': 'SAMME.R', 'base_estimator': DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
      "                       max_depth=7, max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                       random_state=None, splitter='best'), 'learning_rate': 1.4, 'n_estimators': 180}\n",
      "0.785 (+/-0.129) for {'algorithm': 'SAMME.R', 'base_estimator': DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
      "                       max_depth=7, max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                       random_state=None, splitter='best'), 'learning_rate': 1.4, 'n_estimators': 200}\n",
      "0.808 (+/-0.088) for {'algorithm': 'SAMME', 'base_estimator': DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
      "                       max_depth=7, max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                       random_state=None, splitter='best'), 'learning_rate': 0.2, 'n_estimators': 50}\n",
      "0.815 (+/-0.089) for {'algorithm': 'SAMME', 'base_estimator': DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
      "                       max_depth=7, max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                       random_state=None, splitter='best'), 'learning_rate': 0.2, 'n_estimators': 60}\n",
      "0.815 (+/-0.085) for {'algorithm': 'SAMME', 'base_estimator': DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
      "                       max_depth=7, max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                       random_state=None, splitter='best'), 'learning_rate': 0.2, 'n_estimators': 70}\n",
      "0.816 (+/-0.076) for {'algorithm': 'SAMME', 'base_estimator': DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
      "                       max_depth=7, max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                       random_state=None, splitter='best'), 'learning_rate': 0.2, 'n_estimators': 80}\n",
      "0.813 (+/-0.083) for {'algorithm': 'SAMME', 'base_estimator': DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
      "                       max_depth=7, max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                       random_state=None, splitter='best'), 'learning_rate': 0.2, 'n_estimators': 90}\n",
      "0.812 (+/-0.106) for {'algorithm': 'SAMME', 'base_estimator': DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
      "                       max_depth=7, max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                       random_state=None, splitter='best'), 'learning_rate': 0.2, 'n_estimators': 100}\n",
      "0.806 (+/-0.090) for {'algorithm': 'SAMME', 'base_estimator': DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
      "                       max_depth=7, max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                       random_state=None, splitter='best'), 'learning_rate': 0.2, 'n_estimators': 120}\n",
      "0.815 (+/-0.090) for {'algorithm': 'SAMME', 'base_estimator': DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
      "                       max_depth=7, max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                       random_state=None, splitter='best'), 'learning_rate': 0.2, 'n_estimators': 140}\n",
      "0.812 (+/-0.105) for {'algorithm': 'SAMME', 'base_estimator': DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
      "                       max_depth=7, max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                       random_state=None, splitter='best'), 'learning_rate': 0.2, 'n_estimators': 160}\n",
      "0.805 (+/-0.097) for {'algorithm': 'SAMME', 'base_estimator': DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
      "                       max_depth=7, max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                       random_state=None, splitter='best'), 'learning_rate': 0.2, 'n_estimators': 180}\n",
      "0.816 (+/-0.084) for {'algorithm': 'SAMME', 'base_estimator': DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
      "                       max_depth=7, max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                       random_state=None, splitter='best'), 'learning_rate': 0.2, 'n_estimators': 200}\n",
      "0.811 (+/-0.088) for {'algorithm': 'SAMME', 'base_estimator': DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
      "                       max_depth=7, max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                       random_state=None, splitter='best'), 'learning_rate': 0.4, 'n_estimators': 50}\n",
      "0.810 (+/-0.082) for {'algorithm': 'SAMME', 'base_estimator': DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
      "                       max_depth=7, max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                       random_state=None, splitter='best'), 'learning_rate': 0.4, 'n_estimators': 60}\n",
      "0.809 (+/-0.097) for {'algorithm': 'SAMME', 'base_estimator': DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
      "                       max_depth=7, max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                       random_state=None, splitter='best'), 'learning_rate': 0.4, 'n_estimators': 70}\n",
      "0.812 (+/-0.083) for {'algorithm': 'SAMME', 'base_estimator': DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
      "                       max_depth=7, max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                       random_state=None, splitter='best'), 'learning_rate': 0.4, 'n_estimators': 80}\n",
      "0.801 (+/-0.118) for {'algorithm': 'SAMME', 'base_estimator': DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
      "                       max_depth=7, max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                       random_state=None, splitter='best'), 'learning_rate': 0.4, 'n_estimators': 90}\n",
      "0.808 (+/-0.096) for {'algorithm': 'SAMME', 'base_estimator': DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
      "                       max_depth=7, max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                       random_state=None, splitter='best'), 'learning_rate': 0.4, 'n_estimators': 100}\n",
      "0.795 (+/-0.109) for {'algorithm': 'SAMME', 'base_estimator': DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
      "                       max_depth=7, max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                       random_state=None, splitter='best'), 'learning_rate': 0.4, 'n_estimators': 120}\n",
      "0.798 (+/-0.102) for {'algorithm': 'SAMME', 'base_estimator': DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
      "                       max_depth=7, max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                       random_state=None, splitter='best'), 'learning_rate': 0.4, 'n_estimators': 140}\n",
      "0.803 (+/-0.102) for {'algorithm': 'SAMME', 'base_estimator': DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
      "                       max_depth=7, max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                       random_state=None, splitter='best'), 'learning_rate': 0.4, 'n_estimators': 160}\n",
      "0.803 (+/-0.112) for {'algorithm': 'SAMME', 'base_estimator': DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
      "                       max_depth=7, max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                       random_state=None, splitter='best'), 'learning_rate': 0.4, 'n_estimators': 180}\n",
      "0.799 (+/-0.119) for {'algorithm': 'SAMME', 'base_estimator': DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
      "                       max_depth=7, max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                       random_state=None, splitter='best'), 'learning_rate': 0.4, 'n_estimators': 200}\n",
      "0.795 (+/-0.102) for {'algorithm': 'SAMME', 'base_estimator': DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
      "                       max_depth=7, max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                       random_state=None, splitter='best'), 'learning_rate': 0.6, 'n_estimators': 50}\n",
      "0.799 (+/-0.094) for {'algorithm': 'SAMME', 'base_estimator': DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
      "                       max_depth=7, max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                       random_state=None, splitter='best'), 'learning_rate': 0.6, 'n_estimators': 60}\n",
      "0.796 (+/-0.120) for {'algorithm': 'SAMME', 'base_estimator': DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
      "                       max_depth=7, max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                       random_state=None, splitter='best'), 'learning_rate': 0.6, 'n_estimators': 70}\n",
      "0.799 (+/-0.105) for {'algorithm': 'SAMME', 'base_estimator': DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
      "                       max_depth=7, max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                       random_state=None, splitter='best'), 'learning_rate': 0.6, 'n_estimators': 80}\n",
      "0.796 (+/-0.093) for {'algorithm': 'SAMME', 'base_estimator': DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
      "                       max_depth=7, max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                       random_state=None, splitter='best'), 'learning_rate': 0.6, 'n_estimators': 90}\n",
      "0.791 (+/-0.105) for {'algorithm': 'SAMME', 'base_estimator': DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
      "                       max_depth=7, max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                       random_state=None, splitter='best'), 'learning_rate': 0.6, 'n_estimators': 100}\n",
      "0.795 (+/-0.110) for {'algorithm': 'SAMME', 'base_estimator': DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
      "                       max_depth=7, max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                       random_state=None, splitter='best'), 'learning_rate': 0.6, 'n_estimators': 120}\n",
      "0.802 (+/-0.130) for {'algorithm': 'SAMME', 'base_estimator': DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
      "                       max_depth=7, max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                       random_state=None, splitter='best'), 'learning_rate': 0.6, 'n_estimators': 140}\n",
      "0.796 (+/-0.100) for {'algorithm': 'SAMME', 'base_estimator': DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
      "                       max_depth=7, max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                       random_state=None, splitter='best'), 'learning_rate': 0.6, 'n_estimators': 160}\n",
      "0.791 (+/-0.087) for {'algorithm': 'SAMME', 'base_estimator': DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
      "                       max_depth=7, max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                       random_state=None, splitter='best'), 'learning_rate': 0.6, 'n_estimators': 180}\n",
      "0.787 (+/-0.115) for {'algorithm': 'SAMME', 'base_estimator': DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
      "                       max_depth=7, max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                       random_state=None, splitter='best'), 'learning_rate': 0.6, 'n_estimators': 200}\n",
      "0.794 (+/-0.112) for {'algorithm': 'SAMME', 'base_estimator': DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
      "                       max_depth=7, max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                       random_state=None, splitter='best'), 'learning_rate': 0.8, 'n_estimators': 50}\n",
      "0.796 (+/-0.112) for {'algorithm': 'SAMME', 'base_estimator': DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
      "                       max_depth=7, max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                       random_state=None, splitter='best'), 'learning_rate': 0.8, 'n_estimators': 60}\n",
      "0.808 (+/-0.106) for {'algorithm': 'SAMME', 'base_estimator': DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
      "                       max_depth=7, max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                       random_state=None, splitter='best'), 'learning_rate': 0.8, 'n_estimators': 70}\n",
      "0.803 (+/-0.110) for {'algorithm': 'SAMME', 'base_estimator': DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
      "                       max_depth=7, max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                       random_state=None, splitter='best'), 'learning_rate': 0.8, 'n_estimators': 80}\n",
      "0.803 (+/-0.108) for {'algorithm': 'SAMME', 'base_estimator': DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
      "                       max_depth=7, max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                       random_state=None, splitter='best'), 'learning_rate': 0.8, 'n_estimators': 90}\n",
      "0.788 (+/-0.119) for {'algorithm': 'SAMME', 'base_estimator': DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
      "                       max_depth=7, max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                       random_state=None, splitter='best'), 'learning_rate': 0.8, 'n_estimators': 100}\n",
      "0.789 (+/-0.112) for {'algorithm': 'SAMME', 'base_estimator': DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
      "                       max_depth=7, max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                       random_state=None, splitter='best'), 'learning_rate': 0.8, 'n_estimators': 120}\n",
      "0.794 (+/-0.116) for {'algorithm': 'SAMME', 'base_estimator': DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
      "                       max_depth=7, max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                       random_state=None, splitter='best'), 'learning_rate': 0.8, 'n_estimators': 140}\n",
      "0.794 (+/-0.116) for {'algorithm': 'SAMME', 'base_estimator': DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
      "                       max_depth=7, max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                       random_state=None, splitter='best'), 'learning_rate': 0.8, 'n_estimators': 160}\n",
      "0.794 (+/-0.108) for {'algorithm': 'SAMME', 'base_estimator': DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
      "                       max_depth=7, max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                       random_state=None, splitter='best'), 'learning_rate': 0.8, 'n_estimators': 180}\n",
      "0.785 (+/-0.114) for {'algorithm': 'SAMME', 'base_estimator': DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
      "                       max_depth=7, max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                       random_state=None, splitter='best'), 'learning_rate': 0.8, 'n_estimators': 200}\n",
      "0.785 (+/-0.124) for {'algorithm': 'SAMME', 'base_estimator': DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
      "                       max_depth=7, max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                       random_state=None, splitter='best'), 'learning_rate': 1.0, 'n_estimators': 50}\n",
      "0.794 (+/-0.130) for {'algorithm': 'SAMME', 'base_estimator': DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
      "                       max_depth=7, max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                       random_state=None, splitter='best'), 'learning_rate': 1.0, 'n_estimators': 60}\n",
      "0.795 (+/-0.132) for {'algorithm': 'SAMME', 'base_estimator': DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
      "                       max_depth=7, max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                       random_state=None, splitter='best'), 'learning_rate': 1.0, 'n_estimators': 70}\n",
      "0.789 (+/-0.120) for {'algorithm': 'SAMME', 'base_estimator': DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
      "                       max_depth=7, max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                       random_state=None, splitter='best'), 'learning_rate': 1.0, 'n_estimators': 80}\n",
      "0.788 (+/-0.124) for {'algorithm': 'SAMME', 'base_estimator': DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
      "                       max_depth=7, max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                       random_state=None, splitter='best'), 'learning_rate': 1.0, 'n_estimators': 90}\n",
      "0.782 (+/-0.100) for {'algorithm': 'SAMME', 'base_estimator': DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
      "                       max_depth=7, max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                       random_state=None, splitter='best'), 'learning_rate': 1.0, 'n_estimators': 100}\n",
      "0.795 (+/-0.125) for {'algorithm': 'SAMME', 'base_estimator': DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
      "                       max_depth=7, max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                       random_state=None, splitter='best'), 'learning_rate': 1.0, 'n_estimators': 120}\n",
      "0.796 (+/-0.110) for {'algorithm': 'SAMME', 'base_estimator': DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
      "                       max_depth=7, max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                       random_state=None, splitter='best'), 'learning_rate': 1.0, 'n_estimators': 140}\n",
      "0.799 (+/-0.126) for {'algorithm': 'SAMME', 'base_estimator': DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
      "                       max_depth=7, max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                       random_state=None, splitter='best'), 'learning_rate': 1.0, 'n_estimators': 160}\n",
      "0.799 (+/-0.121) for {'algorithm': 'SAMME', 'base_estimator': DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
      "                       max_depth=7, max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                       random_state=None, splitter='best'), 'learning_rate': 1.0, 'n_estimators': 180}\n",
      "0.794 (+/-0.117) for {'algorithm': 'SAMME', 'base_estimator': DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
      "                       max_depth=7, max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                       random_state=None, splitter='best'), 'learning_rate': 1.0, 'n_estimators': 200}\n",
      "0.775 (+/-0.112) for {'algorithm': 'SAMME', 'base_estimator': DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
      "                       max_depth=7, max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                       random_state=None, splitter='best'), 'learning_rate': 1.2, 'n_estimators': 50}\n",
      "0.778 (+/-0.138) for {'algorithm': 'SAMME', 'base_estimator': DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
      "                       max_depth=7, max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                       random_state=None, splitter='best'), 'learning_rate': 1.2, 'n_estimators': 60}\n",
      "0.789 (+/-0.132) for {'algorithm': 'SAMME', 'base_estimator': DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
      "                       max_depth=7, max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                       random_state=None, splitter='best'), 'learning_rate': 1.2, 'n_estimators': 70}\n",
      "0.789 (+/-0.128) for {'algorithm': 'SAMME', 'base_estimator': DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
      "                       max_depth=7, max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                       random_state=None, splitter='best'), 'learning_rate': 1.2, 'n_estimators': 80}\n",
      "0.789 (+/-0.140) for {'algorithm': 'SAMME', 'base_estimator': DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
      "                       max_depth=7, max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                       random_state=None, splitter='best'), 'learning_rate': 1.2, 'n_estimators': 90}\n",
      "0.788 (+/-0.127) for {'algorithm': 'SAMME', 'base_estimator': DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
      "                       max_depth=7, max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                       random_state=None, splitter='best'), 'learning_rate': 1.2, 'n_estimators': 100}\n",
      "0.787 (+/-0.134) for {'algorithm': 'SAMME', 'base_estimator': DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
      "                       max_depth=7, max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                       random_state=None, splitter='best'), 'learning_rate': 1.2, 'n_estimators': 120}\n",
      "0.787 (+/-0.115) for {'algorithm': 'SAMME', 'base_estimator': DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
      "                       max_depth=7, max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                       random_state=None, splitter='best'), 'learning_rate': 1.2, 'n_estimators': 140}\n",
      "0.795 (+/-0.114) for {'algorithm': 'SAMME', 'base_estimator': DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
      "                       max_depth=7, max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                       random_state=None, splitter='best'), 'learning_rate': 1.2, 'n_estimators': 160}\n",
      "0.787 (+/-0.141) for {'algorithm': 'SAMME', 'base_estimator': DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
      "                       max_depth=7, max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                       random_state=None, splitter='best'), 'learning_rate': 1.2, 'n_estimators': 180}\n",
      "0.801 (+/-0.127) for {'algorithm': 'SAMME', 'base_estimator': DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
      "                       max_depth=7, max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                       random_state=None, splitter='best'), 'learning_rate': 1.2, 'n_estimators': 200}\n",
      "0.784 (+/-0.173) for {'algorithm': 'SAMME', 'base_estimator': DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
      "                       max_depth=7, max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                       random_state=None, splitter='best'), 'learning_rate': 1.4, 'n_estimators': 50}\n",
      "0.777 (+/-0.160) for {'algorithm': 'SAMME', 'base_estimator': DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
      "                       max_depth=7, max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                       random_state=None, splitter='best'), 'learning_rate': 1.4, 'n_estimators': 60}\n",
      "0.787 (+/-0.130) for {'algorithm': 'SAMME', 'base_estimator': DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
      "                       max_depth=7, max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                       random_state=None, splitter='best'), 'learning_rate': 1.4, 'n_estimators': 70}\n",
      "0.784 (+/-0.134) for {'algorithm': 'SAMME', 'base_estimator': DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
      "                       max_depth=7, max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                       random_state=None, splitter='best'), 'learning_rate': 1.4, 'n_estimators': 80}\n",
      "0.789 (+/-0.132) for {'algorithm': 'SAMME', 'base_estimator': DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
      "                       max_depth=7, max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                       random_state=None, splitter='best'), 'learning_rate': 1.4, 'n_estimators': 90}\n",
      "0.791 (+/-0.135) for {'algorithm': 'SAMME', 'base_estimator': DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
      "                       max_depth=7, max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                       random_state=None, splitter='best'), 'learning_rate': 1.4, 'n_estimators': 100}\n",
      "0.788 (+/-0.153) for {'algorithm': 'SAMME', 'base_estimator': DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
      "                       max_depth=7, max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                       random_state=None, splitter='best'), 'learning_rate': 1.4, 'n_estimators': 120}\n",
      "0.777 (+/-0.154) for {'algorithm': 'SAMME', 'base_estimator': DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
      "                       max_depth=7, max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                       random_state=None, splitter='best'), 'learning_rate': 1.4, 'n_estimators': 140}\n",
      "0.788 (+/-0.132) for {'algorithm': 'SAMME', 'base_estimator': DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
      "                       max_depth=7, max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                       random_state=None, splitter='best'), 'learning_rate': 1.4, 'n_estimators': 160}\n",
      "0.789 (+/-0.126) for {'algorithm': 'SAMME', 'base_estimator': DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
      "                       max_depth=7, max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                       random_state=None, splitter='best'), 'learning_rate': 1.4, 'n_estimators': 180}\n",
      "0.784 (+/-0.140) for {'algorithm': 'SAMME', 'base_estimator': DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
      "                       max_depth=7, max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                       random_state=None, splitter='best'), 'learning_rate': 1.4, 'n_estimators': 200}\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.77      0.84      0.80       114\n",
      "         1.0       0.66      0.55      0.60        64\n",
      "\n",
      "    accuracy                           0.74       178\n",
      "   macro avg       0.71      0.69      0.70       178\n",
      "weighted avg       0.73      0.74      0.73       178\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "tuned_parameters = [{'base_estimator':[DecisionTreeClassifier(max_depth=7)], 'n_estimators':[50,60,70,80,90,100,120,140,160,180,200], 'algorithm':['SAMME.R', 'SAMME'],\n",
    "  'learning_rate':[0.2,0.4,0.6,0.8,1.0,1.2,1.4]}\n",
    "                    ]\n",
    "\n",
    "\n",
    "print()\n",
    "\n",
    "clf = GridSearchCV(\n",
    "    AdaBoostClassifier(), tuned_parameters, scoring='accuracy', cv=10\n",
    ")\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best parameters set found on development set:\")\n",
    "print()\n",
    "print(clf.best_params_)\n",
    "print()\n",
    "print(\"Grid scores on development set:\")\n",
    "print()\n",
    "means = clf.cv_results_['mean_test_score']\n",
    "stds = clf.cv_results_['std_test_score']\n",
    "for mean, std, params in zip(means, stds, clf.cv_results_['params']):\n",
    "    print(\"%0.3f (+/-%0.03f) for %r\"\n",
    "          % (mean, std * 2, params))\n",
    "print()\n",
    "\n",
    "print(\"Detailed classification report:\")\n",
    "print()\n",
    "print(\"The model is trained on the full development set.\")\n",
    "print(\"The scores are computed on the full evaluation set.\")\n",
    "print()\n",
    "y_true, y_pred = y_test, clf.predict(X_test)\n",
    "print(classification_report(y_true, y_pred))\n",
    "print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lCjoq8YYTusT"
   },
   "source": [
    "### Cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "Ijz_7UUrSrCG",
    "outputId": "deb0e386-fe04-48f5-db18-3d93e4549537"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.818215\n"
     ]
    }
   ],
   "source": [
    "clf = AdaBoostClassifier(algorithm= 'SAMME', base_estimator= DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
    "                       max_depth=7, max_features=None, max_leaf_nodes=None,\n",
    "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "                       min_samples_leaf=1, min_samples_split=2,\n",
    "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
    "                       random_state=None, splitter='best'), learning_rate= 0.2, n_estimators= 200)\n",
    "score=cross_validate(clf, X, y, cv=10, scoring=\"accuracy\")[\"test_score\"].mean()\n",
    "print(f\"{score:.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "S8lrQloLMnIc"
   },
   "source": [
    "### Generating Predicion Result for submission in .csv format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_9pVnNQtsu1Q"
   },
   "outputs": [],
   "source": [
    "df2 = pd.read_csv(url2)\n",
    "clf = AdaBoostClassifier(algorithm= 'SAMME', base_estimator= DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
    "                       max_depth=7, max_features=None, max_leaf_nodes=None,\n",
    "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "                       min_samples_leaf=1, min_samples_split=2,\n",
    "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
    "                       random_state=None, splitter='best'), learning_rate= 0.2, n_estimators= 200)\n",
    "clf.fit(X, y)\n",
    "pred=clf.predict(X_test2)\n",
    "pd.DataFrame({\"PassengerId\": df2[\"PassengerId\"], \"Survived\": pred}).to_csv(\"AdaBoost_submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TwVI2KfcuV2d"
   },
   "source": [
    "![alt text](https://raw.githubusercontent.com/zyzhang1130/CE9010/master/Titanic/ada.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Fj6LyIK_DpUh"
   },
   "source": [
    "## RandomForest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "QPOkzPgqDoSa",
    "outputId": "6d19972f-a069-40cb-9ad8-7ba0c06159d7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best parameters set found on development set:\n",
      "\n",
      "{'bootstrap': True, 'criterion': 'gini', 'min_samples_split': 8, 'n_estimators': 180, 'warm_start': False}\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "0.796 (+/-0.124) for {'bootstrap': True, 'criterion': 'gini', 'min_samples_split': 2, 'n_estimators': 60, 'warm_start': True}\n",
      "0.787 (+/-0.104) for {'bootstrap': True, 'criterion': 'gini', 'min_samples_split': 2, 'n_estimators': 60, 'warm_start': False}\n",
      "0.796 (+/-0.124) for {'bootstrap': True, 'criterion': 'gini', 'min_samples_split': 2, 'n_estimators': 70, 'warm_start': True}\n",
      "0.799 (+/-0.116) for {'bootstrap': True, 'criterion': 'gini', 'min_samples_split': 2, 'n_estimators': 70, 'warm_start': False}\n",
      "0.799 (+/-0.113) for {'bootstrap': True, 'criterion': 'gini', 'min_samples_split': 2, 'n_estimators': 80, 'warm_start': True}\n",
      "0.789 (+/-0.125) for {'bootstrap': True, 'criterion': 'gini', 'min_samples_split': 2, 'n_estimators': 80, 'warm_start': False}\n",
      "0.787 (+/-0.117) for {'bootstrap': True, 'criterion': 'gini', 'min_samples_split': 2, 'n_estimators': 90, 'warm_start': True}\n",
      "0.791 (+/-0.111) for {'bootstrap': True, 'criterion': 'gini', 'min_samples_split': 2, 'n_estimators': 90, 'warm_start': False}\n",
      "0.794 (+/-0.127) for {'bootstrap': True, 'criterion': 'gini', 'min_samples_split': 2, 'n_estimators': 100, 'warm_start': True}\n",
      "0.799 (+/-0.122) for {'bootstrap': True, 'criterion': 'gini', 'min_samples_split': 2, 'n_estimators': 100, 'warm_start': False}\n",
      "0.799 (+/-0.125) for {'bootstrap': True, 'criterion': 'gini', 'min_samples_split': 2, 'n_estimators': 120, 'warm_start': True}\n",
      "0.792 (+/-0.112) for {'bootstrap': True, 'criterion': 'gini', 'min_samples_split': 2, 'n_estimators': 120, 'warm_start': False}\n",
      "0.789 (+/-0.120) for {'bootstrap': True, 'criterion': 'gini', 'min_samples_split': 2, 'n_estimators': 140, 'warm_start': True}\n",
      "0.798 (+/-0.117) for {'bootstrap': True, 'criterion': 'gini', 'min_samples_split': 2, 'n_estimators': 140, 'warm_start': False}\n",
      "0.792 (+/-0.117) for {'bootstrap': True, 'criterion': 'gini', 'min_samples_split': 2, 'n_estimators': 160, 'warm_start': True}\n",
      "0.794 (+/-0.126) for {'bootstrap': True, 'criterion': 'gini', 'min_samples_split': 2, 'n_estimators': 160, 'warm_start': False}\n",
      "0.795 (+/-0.130) for {'bootstrap': True, 'criterion': 'gini', 'min_samples_split': 2, 'n_estimators': 180, 'warm_start': True}\n",
      "0.794 (+/-0.121) for {'bootstrap': True, 'criterion': 'gini', 'min_samples_split': 2, 'n_estimators': 180, 'warm_start': False}\n",
      "0.792 (+/-0.119) for {'bootstrap': True, 'criterion': 'gini', 'min_samples_split': 2, 'n_estimators': 200, 'warm_start': True}\n",
      "0.798 (+/-0.119) for {'bootstrap': True, 'criterion': 'gini', 'min_samples_split': 2, 'n_estimators': 200, 'warm_start': False}\n",
      "0.808 (+/-0.099) for {'bootstrap': True, 'criterion': 'gini', 'min_samples_split': 3, 'n_estimators': 60, 'warm_start': True}\n",
      "0.806 (+/-0.105) for {'bootstrap': True, 'criterion': 'gini', 'min_samples_split': 3, 'n_estimators': 60, 'warm_start': False}\n",
      "0.805 (+/-0.105) for {'bootstrap': True, 'criterion': 'gini', 'min_samples_split': 3, 'n_estimators': 70, 'warm_start': True}\n",
      "0.808 (+/-0.096) for {'bootstrap': True, 'criterion': 'gini', 'min_samples_split': 3, 'n_estimators': 70, 'warm_start': False}\n",
      "0.802 (+/-0.111) for {'bootstrap': True, 'criterion': 'gini', 'min_samples_split': 3, 'n_estimators': 80, 'warm_start': True}\n",
      "0.809 (+/-0.109) for {'bootstrap': True, 'criterion': 'gini', 'min_samples_split': 3, 'n_estimators': 80, 'warm_start': False}\n",
      "0.810 (+/-0.094) for {'bootstrap': True, 'criterion': 'gini', 'min_samples_split': 3, 'n_estimators': 90, 'warm_start': True}\n",
      "0.803 (+/-0.104) for {'bootstrap': True, 'criterion': 'gini', 'min_samples_split': 3, 'n_estimators': 90, 'warm_start': False}\n",
      "0.808 (+/-0.103) for {'bootstrap': True, 'criterion': 'gini', 'min_samples_split': 3, 'n_estimators': 100, 'warm_start': True}\n",
      "0.812 (+/-0.090) for {'bootstrap': True, 'criterion': 'gini', 'min_samples_split': 3, 'n_estimators': 100, 'warm_start': False}\n",
      "0.806 (+/-0.102) for {'bootstrap': True, 'criterion': 'gini', 'min_samples_split': 3, 'n_estimators': 120, 'warm_start': True}\n",
      "0.803 (+/-0.112) for {'bootstrap': True, 'criterion': 'gini', 'min_samples_split': 3, 'n_estimators': 120, 'warm_start': False}\n",
      "0.808 (+/-0.107) for {'bootstrap': True, 'criterion': 'gini', 'min_samples_split': 3, 'n_estimators': 140, 'warm_start': True}\n",
      "0.811 (+/-0.105) for {'bootstrap': True, 'criterion': 'gini', 'min_samples_split': 3, 'n_estimators': 140, 'warm_start': False}\n",
      "0.808 (+/-0.116) for {'bootstrap': True, 'criterion': 'gini', 'min_samples_split': 3, 'n_estimators': 160, 'warm_start': True}\n",
      "0.808 (+/-0.099) for {'bootstrap': True, 'criterion': 'gini', 'min_samples_split': 3, 'n_estimators': 160, 'warm_start': False}\n",
      "0.803 (+/-0.117) for {'bootstrap': True, 'criterion': 'gini', 'min_samples_split': 3, 'n_estimators': 180, 'warm_start': True}\n",
      "0.809 (+/-0.102) for {'bootstrap': True, 'criterion': 'gini', 'min_samples_split': 3, 'n_estimators': 180, 'warm_start': False}\n",
      "0.815 (+/-0.095) for {'bootstrap': True, 'criterion': 'gini', 'min_samples_split': 3, 'n_estimators': 200, 'warm_start': True}\n",
      "0.808 (+/-0.095) for {'bootstrap': True, 'criterion': 'gini', 'min_samples_split': 3, 'n_estimators': 200, 'warm_start': False}\n",
      "0.806 (+/-0.101) for {'bootstrap': True, 'criterion': 'gini', 'min_samples_split': 4, 'n_estimators': 60, 'warm_start': True}\n",
      "0.812 (+/-0.100) for {'bootstrap': True, 'criterion': 'gini', 'min_samples_split': 4, 'n_estimators': 60, 'warm_start': False}\n",
      "0.819 (+/-0.096) for {'bootstrap': True, 'criterion': 'gini', 'min_samples_split': 4, 'n_estimators': 70, 'warm_start': True}\n",
      "0.816 (+/-0.104) for {'bootstrap': True, 'criterion': 'gini', 'min_samples_split': 4, 'n_estimators': 70, 'warm_start': False}\n",
      "0.815 (+/-0.097) for {'bootstrap': True, 'criterion': 'gini', 'min_samples_split': 4, 'n_estimators': 80, 'warm_start': True}\n",
      "0.813 (+/-0.096) for {'bootstrap': True, 'criterion': 'gini', 'min_samples_split': 4, 'n_estimators': 80, 'warm_start': False}\n",
      "0.823 (+/-0.086) for {'bootstrap': True, 'criterion': 'gini', 'min_samples_split': 4, 'n_estimators': 90, 'warm_start': True}\n",
      "0.823 (+/-0.103) for {'bootstrap': True, 'criterion': 'gini', 'min_samples_split': 4, 'n_estimators': 90, 'warm_start': False}\n",
      "0.820 (+/-0.095) for {'bootstrap': True, 'criterion': 'gini', 'min_samples_split': 4, 'n_estimators': 100, 'warm_start': True}\n",
      "0.820 (+/-0.100) for {'bootstrap': True, 'criterion': 'gini', 'min_samples_split': 4, 'n_estimators': 100, 'warm_start': False}\n",
      "0.817 (+/-0.092) for {'bootstrap': True, 'criterion': 'gini', 'min_samples_split': 4, 'n_estimators': 120, 'warm_start': True}\n",
      "0.823 (+/-0.104) for {'bootstrap': True, 'criterion': 'gini', 'min_samples_split': 4, 'n_estimators': 120, 'warm_start': False}\n",
      "0.823 (+/-0.108) for {'bootstrap': True, 'criterion': 'gini', 'min_samples_split': 4, 'n_estimators': 140, 'warm_start': True}\n",
      "0.822 (+/-0.109) for {'bootstrap': True, 'criterion': 'gini', 'min_samples_split': 4, 'n_estimators': 140, 'warm_start': False}\n",
      "0.820 (+/-0.094) for {'bootstrap': True, 'criterion': 'gini', 'min_samples_split': 4, 'n_estimators': 160, 'warm_start': True}\n",
      "0.823 (+/-0.093) for {'bootstrap': True, 'criterion': 'gini', 'min_samples_split': 4, 'n_estimators': 160, 'warm_start': False}\n",
      "0.823 (+/-0.105) for {'bootstrap': True, 'criterion': 'gini', 'min_samples_split': 4, 'n_estimators': 180, 'warm_start': True}\n",
      "0.812 (+/-0.092) for {'bootstrap': True, 'criterion': 'gini', 'min_samples_split': 4, 'n_estimators': 180, 'warm_start': False}\n",
      "0.818 (+/-0.105) for {'bootstrap': True, 'criterion': 'gini', 'min_samples_split': 4, 'n_estimators': 200, 'warm_start': True}\n",
      "0.816 (+/-0.105) for {'bootstrap': True, 'criterion': 'gini', 'min_samples_split': 4, 'n_estimators': 200, 'warm_start': False}\n",
      "0.823 (+/-0.099) for {'bootstrap': True, 'criterion': 'gini', 'min_samples_split': 5, 'n_estimators': 60, 'warm_start': True}\n",
      "0.819 (+/-0.093) for {'bootstrap': True, 'criterion': 'gini', 'min_samples_split': 5, 'n_estimators': 60, 'warm_start': False}\n",
      "0.822 (+/-0.094) for {'bootstrap': True, 'criterion': 'gini', 'min_samples_split': 5, 'n_estimators': 70, 'warm_start': True}\n",
      "0.818 (+/-0.098) for {'bootstrap': True, 'criterion': 'gini', 'min_samples_split': 5, 'n_estimators': 70, 'warm_start': False}\n",
      "0.815 (+/-0.095) for {'bootstrap': True, 'criterion': 'gini', 'min_samples_split': 5, 'n_estimators': 80, 'warm_start': True}\n",
      "0.820 (+/-0.088) for {'bootstrap': True, 'criterion': 'gini', 'min_samples_split': 5, 'n_estimators': 80, 'warm_start': False}\n",
      "0.827 (+/-0.096) for {'bootstrap': True, 'criterion': 'gini', 'min_samples_split': 5, 'n_estimators': 90, 'warm_start': True}\n",
      "0.823 (+/-0.101) for {'bootstrap': True, 'criterion': 'gini', 'min_samples_split': 5, 'n_estimators': 90, 'warm_start': False}\n",
      "0.823 (+/-0.104) for {'bootstrap': True, 'criterion': 'gini', 'min_samples_split': 5, 'n_estimators': 100, 'warm_start': True}\n",
      "0.823 (+/-0.091) for {'bootstrap': True, 'criterion': 'gini', 'min_samples_split': 5, 'n_estimators': 100, 'warm_start': False}\n",
      "0.823 (+/-0.091) for {'bootstrap': True, 'criterion': 'gini', 'min_samples_split': 5, 'n_estimators': 120, 'warm_start': True}\n",
      "0.822 (+/-0.093) for {'bootstrap': True, 'criterion': 'gini', 'min_samples_split': 5, 'n_estimators': 120, 'warm_start': False}\n",
      "0.823 (+/-0.099) for {'bootstrap': True, 'criterion': 'gini', 'min_samples_split': 5, 'n_estimators': 140, 'warm_start': True}\n",
      "0.827 (+/-0.102) for {'bootstrap': True, 'criterion': 'gini', 'min_samples_split': 5, 'n_estimators': 140, 'warm_start': False}\n",
      "0.823 (+/-0.102) for {'bootstrap': True, 'criterion': 'gini', 'min_samples_split': 5, 'n_estimators': 160, 'warm_start': True}\n",
      "0.826 (+/-0.102) for {'bootstrap': True, 'criterion': 'gini', 'min_samples_split': 5, 'n_estimators': 160, 'warm_start': False}\n",
      "0.827 (+/-0.097) for {'bootstrap': True, 'criterion': 'gini', 'min_samples_split': 5, 'n_estimators': 180, 'warm_start': True}\n",
      "0.823 (+/-0.099) for {'bootstrap': True, 'criterion': 'gini', 'min_samples_split': 5, 'n_estimators': 180, 'warm_start': False}\n",
      "0.822 (+/-0.102) for {'bootstrap': True, 'criterion': 'gini', 'min_samples_split': 5, 'n_estimators': 200, 'warm_start': True}\n",
      "0.826 (+/-0.092) for {'bootstrap': True, 'criterion': 'gini', 'min_samples_split': 5, 'n_estimators': 200, 'warm_start': False}\n",
      "0.823 (+/-0.093) for {'bootstrap': True, 'criterion': 'gini', 'min_samples_split': 6, 'n_estimators': 60, 'warm_start': True}\n",
      "0.813 (+/-0.091) for {'bootstrap': True, 'criterion': 'gini', 'min_samples_split': 6, 'n_estimators': 60, 'warm_start': False}\n",
      "0.816 (+/-0.112) for {'bootstrap': True, 'criterion': 'gini', 'min_samples_split': 6, 'n_estimators': 70, 'warm_start': True}\n",
      "0.822 (+/-0.105) for {'bootstrap': True, 'criterion': 'gini', 'min_samples_split': 6, 'n_estimators': 70, 'warm_start': False}\n",
      "0.825 (+/-0.095) for {'bootstrap': True, 'criterion': 'gini', 'min_samples_split': 6, 'n_estimators': 80, 'warm_start': True}\n",
      "0.822 (+/-0.098) for {'bootstrap': True, 'criterion': 'gini', 'min_samples_split': 6, 'n_estimators': 80, 'warm_start': False}\n",
      "0.820 (+/-0.092) for {'bootstrap': True, 'criterion': 'gini', 'min_samples_split': 6, 'n_estimators': 90, 'warm_start': True}\n",
      "0.822 (+/-0.093) for {'bootstrap': True, 'criterion': 'gini', 'min_samples_split': 6, 'n_estimators': 90, 'warm_start': False}\n",
      "0.823 (+/-0.094) for {'bootstrap': True, 'criterion': 'gini', 'min_samples_split': 6, 'n_estimators': 100, 'warm_start': True}\n",
      "0.822 (+/-0.103) for {'bootstrap': True, 'criterion': 'gini', 'min_samples_split': 6, 'n_estimators': 100, 'warm_start': False}\n",
      "0.830 (+/-0.099) for {'bootstrap': True, 'criterion': 'gini', 'min_samples_split': 6, 'n_estimators': 120, 'warm_start': True}\n",
      "0.822 (+/-0.084) for {'bootstrap': True, 'criterion': 'gini', 'min_samples_split': 6, 'n_estimators': 120, 'warm_start': False}\n",
      "0.824 (+/-0.102) for {'bootstrap': True, 'criterion': 'gini', 'min_samples_split': 6, 'n_estimators': 140, 'warm_start': True}\n",
      "0.824 (+/-0.097) for {'bootstrap': True, 'criterion': 'gini', 'min_samples_split': 6, 'n_estimators': 140, 'warm_start': False}\n",
      "0.832 (+/-0.098) for {'bootstrap': True, 'criterion': 'gini', 'min_samples_split': 6, 'n_estimators': 160, 'warm_start': True}\n",
      "0.829 (+/-0.100) for {'bootstrap': True, 'criterion': 'gini', 'min_samples_split': 6, 'n_estimators': 160, 'warm_start': False}\n",
      "0.824 (+/-0.094) for {'bootstrap': True, 'criterion': 'gini', 'min_samples_split': 6, 'n_estimators': 180, 'warm_start': True}\n",
      "0.824 (+/-0.087) for {'bootstrap': True, 'criterion': 'gini', 'min_samples_split': 6, 'n_estimators': 180, 'warm_start': False}\n",
      "0.823 (+/-0.095) for {'bootstrap': True, 'criterion': 'gini', 'min_samples_split': 6, 'n_estimators': 200, 'warm_start': True}\n",
      "0.827 (+/-0.104) for {'bootstrap': True, 'criterion': 'gini', 'min_samples_split': 6, 'n_estimators': 200, 'warm_start': False}\n",
      "0.820 (+/-0.092) for {'bootstrap': True, 'criterion': 'gini', 'min_samples_split': 7, 'n_estimators': 60, 'warm_start': True}\n",
      "0.822 (+/-0.085) for {'bootstrap': True, 'criterion': 'gini', 'min_samples_split': 7, 'n_estimators': 60, 'warm_start': False}\n",
      "0.820 (+/-0.095) for {'bootstrap': True, 'criterion': 'gini', 'min_samples_split': 7, 'n_estimators': 70, 'warm_start': True}\n",
      "0.825 (+/-0.091) for {'bootstrap': True, 'criterion': 'gini', 'min_samples_split': 7, 'n_estimators': 70, 'warm_start': False}\n",
      "0.823 (+/-0.099) for {'bootstrap': True, 'criterion': 'gini', 'min_samples_split': 7, 'n_estimators': 80, 'warm_start': True}\n",
      "0.823 (+/-0.086) for {'bootstrap': True, 'criterion': 'gini', 'min_samples_split': 7, 'n_estimators': 80, 'warm_start': False}\n",
      "0.826 (+/-0.090) for {'bootstrap': True, 'criterion': 'gini', 'min_samples_split': 7, 'n_estimators': 90, 'warm_start': True}\n",
      "0.823 (+/-0.089) for {'bootstrap': True, 'criterion': 'gini', 'min_samples_split': 7, 'n_estimators': 90, 'warm_start': False}\n",
      "0.827 (+/-0.090) for {'bootstrap': True, 'criterion': 'gini', 'min_samples_split': 7, 'n_estimators': 100, 'warm_start': True}\n",
      "0.827 (+/-0.090) for {'bootstrap': True, 'criterion': 'gini', 'min_samples_split': 7, 'n_estimators': 100, 'warm_start': False}\n",
      "0.829 (+/-0.094) for {'bootstrap': True, 'criterion': 'gini', 'min_samples_split': 7, 'n_estimators': 120, 'warm_start': True}\n",
      "0.827 (+/-0.093) for {'bootstrap': True, 'criterion': 'gini', 'min_samples_split': 7, 'n_estimators': 120, 'warm_start': False}\n",
      "0.826 (+/-0.078) for {'bootstrap': True, 'criterion': 'gini', 'min_samples_split': 7, 'n_estimators': 140, 'warm_start': True}\n",
      "0.825 (+/-0.094) for {'bootstrap': True, 'criterion': 'gini', 'min_samples_split': 7, 'n_estimators': 140, 'warm_start': False}\n",
      "0.830 (+/-0.093) for {'bootstrap': True, 'criterion': 'gini', 'min_samples_split': 7, 'n_estimators': 160, 'warm_start': True}\n",
      "0.820 (+/-0.101) for {'bootstrap': True, 'criterion': 'gini', 'min_samples_split': 7, 'n_estimators': 160, 'warm_start': False}\n",
      "0.832 (+/-0.092) for {'bootstrap': True, 'criterion': 'gini', 'min_samples_split': 7, 'n_estimators': 180, 'warm_start': True}\n",
      "0.824 (+/-0.094) for {'bootstrap': True, 'criterion': 'gini', 'min_samples_split': 7, 'n_estimators': 180, 'warm_start': False}\n",
      "0.825 (+/-0.097) for {'bootstrap': True, 'criterion': 'gini', 'min_samples_split': 7, 'n_estimators': 200, 'warm_start': True}\n",
      "0.825 (+/-0.096) for {'bootstrap': True, 'criterion': 'gini', 'min_samples_split': 7, 'n_estimators': 200, 'warm_start': False}\n",
      "0.822 (+/-0.083) for {'bootstrap': True, 'criterion': 'gini', 'min_samples_split': 8, 'n_estimators': 60, 'warm_start': True}\n",
      "0.815 (+/-0.094) for {'bootstrap': True, 'criterion': 'gini', 'min_samples_split': 8, 'n_estimators': 60, 'warm_start': False}\n",
      "0.827 (+/-0.095) for {'bootstrap': True, 'criterion': 'gini', 'min_samples_split': 8, 'n_estimators': 70, 'warm_start': True}\n",
      "0.826 (+/-0.104) for {'bootstrap': True, 'criterion': 'gini', 'min_samples_split': 8, 'n_estimators': 70, 'warm_start': False}\n",
      "0.820 (+/-0.092) for {'bootstrap': True, 'criterion': 'gini', 'min_samples_split': 8, 'n_estimators': 80, 'warm_start': True}\n",
      "0.822 (+/-0.095) for {'bootstrap': True, 'criterion': 'gini', 'min_samples_split': 8, 'n_estimators': 80, 'warm_start': False}\n",
      "0.820 (+/-0.094) for {'bootstrap': True, 'criterion': 'gini', 'min_samples_split': 8, 'n_estimators': 90, 'warm_start': True}\n",
      "0.816 (+/-0.086) for {'bootstrap': True, 'criterion': 'gini', 'min_samples_split': 8, 'n_estimators': 90, 'warm_start': False}\n",
      "0.817 (+/-0.081) for {'bootstrap': True, 'criterion': 'gini', 'min_samples_split': 8, 'n_estimators': 100, 'warm_start': True}\n",
      "0.827 (+/-0.092) for {'bootstrap': True, 'criterion': 'gini', 'min_samples_split': 8, 'n_estimators': 100, 'warm_start': False}\n",
      "0.826 (+/-0.100) for {'bootstrap': True, 'criterion': 'gini', 'min_samples_split': 8, 'n_estimators': 120, 'warm_start': True}\n",
      "0.823 (+/-0.089) for {'bootstrap': True, 'criterion': 'gini', 'min_samples_split': 8, 'n_estimators': 120, 'warm_start': False}\n",
      "0.826 (+/-0.098) for {'bootstrap': True, 'criterion': 'gini', 'min_samples_split': 8, 'n_estimators': 140, 'warm_start': True}\n",
      "0.827 (+/-0.100) for {'bootstrap': True, 'criterion': 'gini', 'min_samples_split': 8, 'n_estimators': 140, 'warm_start': False}\n",
      "0.826 (+/-0.093) for {'bootstrap': True, 'criterion': 'gini', 'min_samples_split': 8, 'n_estimators': 160, 'warm_start': True}\n",
      "0.825 (+/-0.088) for {'bootstrap': True, 'criterion': 'gini', 'min_samples_split': 8, 'n_estimators': 160, 'warm_start': False}\n",
      "0.826 (+/-0.095) for {'bootstrap': True, 'criterion': 'gini', 'min_samples_split': 8, 'n_estimators': 180, 'warm_start': True}\n",
      "0.836 (+/-0.080) for {'bootstrap': True, 'criterion': 'gini', 'min_samples_split': 8, 'n_estimators': 180, 'warm_start': False}\n",
      "0.825 (+/-0.089) for {'bootstrap': True, 'criterion': 'gini', 'min_samples_split': 8, 'n_estimators': 200, 'warm_start': True}\n",
      "0.829 (+/-0.085) for {'bootstrap': True, 'criterion': 'gini', 'min_samples_split': 8, 'n_estimators': 200, 'warm_start': False}\n",
      "0.819 (+/-0.095) for {'bootstrap': True, 'criterion': 'gini', 'min_samples_split': 9, 'n_estimators': 60, 'warm_start': True}\n",
      "0.819 (+/-0.097) for {'bootstrap': True, 'criterion': 'gini', 'min_samples_split': 9, 'n_estimators': 60, 'warm_start': False}\n",
      "0.816 (+/-0.090) for {'bootstrap': True, 'criterion': 'gini', 'min_samples_split': 9, 'n_estimators': 70, 'warm_start': True}\n",
      "0.815 (+/-0.101) for {'bootstrap': True, 'criterion': 'gini', 'min_samples_split': 9, 'n_estimators': 70, 'warm_start': False}\n",
      "0.815 (+/-0.097) for {'bootstrap': True, 'criterion': 'gini', 'min_samples_split': 9, 'n_estimators': 80, 'warm_start': True}\n",
      "0.830 (+/-0.084) for {'bootstrap': True, 'criterion': 'gini', 'min_samples_split': 9, 'n_estimators': 80, 'warm_start': False}\n",
      "0.822 (+/-0.083) for {'bootstrap': True, 'criterion': 'gini', 'min_samples_split': 9, 'n_estimators': 90, 'warm_start': True}\n",
      "0.823 (+/-0.092) for {'bootstrap': True, 'criterion': 'gini', 'min_samples_split': 9, 'n_estimators': 90, 'warm_start': False}\n",
      "0.817 (+/-0.105) for {'bootstrap': True, 'criterion': 'gini', 'min_samples_split': 9, 'n_estimators': 100, 'warm_start': True}\n",
      "0.829 (+/-0.092) for {'bootstrap': True, 'criterion': 'gini', 'min_samples_split': 9, 'n_estimators': 100, 'warm_start': False}\n",
      "0.820 (+/-0.100) for {'bootstrap': True, 'criterion': 'gini', 'min_samples_split': 9, 'n_estimators': 120, 'warm_start': True}\n",
      "0.826 (+/-0.083) for {'bootstrap': True, 'criterion': 'gini', 'min_samples_split': 9, 'n_estimators': 120, 'warm_start': False}\n",
      "0.819 (+/-0.078) for {'bootstrap': True, 'criterion': 'gini', 'min_samples_split': 9, 'n_estimators': 140, 'warm_start': True}\n",
      "0.820 (+/-0.091) for {'bootstrap': True, 'criterion': 'gini', 'min_samples_split': 9, 'n_estimators': 140, 'warm_start': False}\n",
      "0.822 (+/-0.092) for {'bootstrap': True, 'criterion': 'gini', 'min_samples_split': 9, 'n_estimators': 160, 'warm_start': True}\n",
      "0.823 (+/-0.087) for {'bootstrap': True, 'criterion': 'gini', 'min_samples_split': 9, 'n_estimators': 160, 'warm_start': False}\n",
      "0.830 (+/-0.090) for {'bootstrap': True, 'criterion': 'gini', 'min_samples_split': 9, 'n_estimators': 180, 'warm_start': True}\n",
      "0.822 (+/-0.097) for {'bootstrap': True, 'criterion': 'gini', 'min_samples_split': 9, 'n_estimators': 180, 'warm_start': False}\n",
      "0.825 (+/-0.098) for {'bootstrap': True, 'criterion': 'gini', 'min_samples_split': 9, 'n_estimators': 200, 'warm_start': True}\n",
      "0.822 (+/-0.098) for {'bootstrap': True, 'criterion': 'gini', 'min_samples_split': 9, 'n_estimators': 200, 'warm_start': False}\n",
      "0.794 (+/-0.118) for {'bootstrap': True, 'criterion': 'entropy', 'min_samples_split': 2, 'n_estimators': 60, 'warm_start': True}\n",
      "0.788 (+/-0.130) for {'bootstrap': True, 'criterion': 'entropy', 'min_samples_split': 2, 'n_estimators': 60, 'warm_start': False}\n",
      "0.794 (+/-0.121) for {'bootstrap': True, 'criterion': 'entropy', 'min_samples_split': 2, 'n_estimators': 70, 'warm_start': True}\n",
      "0.794 (+/-0.131) for {'bootstrap': True, 'criterion': 'entropy', 'min_samples_split': 2, 'n_estimators': 70, 'warm_start': False}\n",
      "0.789 (+/-0.118) for {'bootstrap': True, 'criterion': 'entropy', 'min_samples_split': 2, 'n_estimators': 80, 'warm_start': True}\n",
      "0.787 (+/-0.112) for {'bootstrap': True, 'criterion': 'entropy', 'min_samples_split': 2, 'n_estimators': 80, 'warm_start': False}\n",
      "0.794 (+/-0.116) for {'bootstrap': True, 'criterion': 'entropy', 'min_samples_split': 2, 'n_estimators': 90, 'warm_start': True}\n",
      "0.798 (+/-0.118) for {'bootstrap': True, 'criterion': 'entropy', 'min_samples_split': 2, 'n_estimators': 90, 'warm_start': False}\n",
      "0.795 (+/-0.111) for {'bootstrap': True, 'criterion': 'entropy', 'min_samples_split': 2, 'n_estimators': 100, 'warm_start': True}\n",
      "0.798 (+/-0.107) for {'bootstrap': True, 'criterion': 'entropy', 'min_samples_split': 2, 'n_estimators': 100, 'warm_start': False}\n",
      "0.791 (+/-0.117) for {'bootstrap': True, 'criterion': 'entropy', 'min_samples_split': 2, 'n_estimators': 120, 'warm_start': True}\n",
      "0.792 (+/-0.114) for {'bootstrap': True, 'criterion': 'entropy', 'min_samples_split': 2, 'n_estimators': 120, 'warm_start': False}\n",
      "0.794 (+/-0.130) for {'bootstrap': True, 'criterion': 'entropy', 'min_samples_split': 2, 'n_estimators': 140, 'warm_start': True}\n",
      "0.794 (+/-0.114) for {'bootstrap': True, 'criterion': 'entropy', 'min_samples_split': 2, 'n_estimators': 140, 'warm_start': False}\n",
      "0.789 (+/-0.121) for {'bootstrap': True, 'criterion': 'entropy', 'min_samples_split': 2, 'n_estimators': 160, 'warm_start': True}\n",
      "0.792 (+/-0.121) for {'bootstrap': True, 'criterion': 'entropy', 'min_samples_split': 2, 'n_estimators': 160, 'warm_start': False}\n",
      "0.792 (+/-0.133) for {'bootstrap': True, 'criterion': 'entropy', 'min_samples_split': 2, 'n_estimators': 180, 'warm_start': True}\n",
      "0.791 (+/-0.115) for {'bootstrap': True, 'criterion': 'entropy', 'min_samples_split': 2, 'n_estimators': 180, 'warm_start': False}\n",
      "0.792 (+/-0.129) for {'bootstrap': True, 'criterion': 'entropy', 'min_samples_split': 2, 'n_estimators': 200, 'warm_start': True}\n",
      "0.796 (+/-0.119) for {'bootstrap': True, 'criterion': 'entropy', 'min_samples_split': 2, 'n_estimators': 200, 'warm_start': False}\n",
      "0.809 (+/-0.102) for {'bootstrap': True, 'criterion': 'entropy', 'min_samples_split': 3, 'n_estimators': 60, 'warm_start': True}\n",
      "0.808 (+/-0.111) for {'bootstrap': True, 'criterion': 'entropy', 'min_samples_split': 3, 'n_estimators': 60, 'warm_start': False}\n",
      "0.809 (+/-0.098) for {'bootstrap': True, 'criterion': 'entropy', 'min_samples_split': 3, 'n_estimators': 70, 'warm_start': True}\n",
      "0.809 (+/-0.100) for {'bootstrap': True, 'criterion': 'entropy', 'min_samples_split': 3, 'n_estimators': 70, 'warm_start': False}\n",
      "0.803 (+/-0.112) for {'bootstrap': True, 'criterion': 'entropy', 'min_samples_split': 3, 'n_estimators': 80, 'warm_start': True}\n",
      "0.813 (+/-0.095) for {'bootstrap': True, 'criterion': 'entropy', 'min_samples_split': 3, 'n_estimators': 80, 'warm_start': False}\n",
      "0.798 (+/-0.116) for {'bootstrap': True, 'criterion': 'entropy', 'min_samples_split': 3, 'n_estimators': 90, 'warm_start': True}\n",
      "0.802 (+/-0.099) for {'bootstrap': True, 'criterion': 'entropy', 'min_samples_split': 3, 'n_estimators': 90, 'warm_start': False}\n",
      "0.820 (+/-0.104) for {'bootstrap': True, 'criterion': 'entropy', 'min_samples_split': 3, 'n_estimators': 100, 'warm_start': True}\n",
      "0.809 (+/-0.107) for {'bootstrap': True, 'criterion': 'entropy', 'min_samples_split': 3, 'n_estimators': 100, 'warm_start': False}\n",
      "0.808 (+/-0.106) for {'bootstrap': True, 'criterion': 'entropy', 'min_samples_split': 3, 'n_estimators': 120, 'warm_start': True}\n",
      "0.798 (+/-0.106) for {'bootstrap': True, 'criterion': 'entropy', 'min_samples_split': 3, 'n_estimators': 120, 'warm_start': False}\n",
      "0.801 (+/-0.117) for {'bootstrap': True, 'criterion': 'entropy', 'min_samples_split': 3, 'n_estimators': 140, 'warm_start': True}\n",
      "0.806 (+/-0.103) for {'bootstrap': True, 'criterion': 'entropy', 'min_samples_split': 3, 'n_estimators': 140, 'warm_start': False}\n",
      "0.806 (+/-0.096) for {'bootstrap': True, 'criterion': 'entropy', 'min_samples_split': 3, 'n_estimators': 160, 'warm_start': True}\n",
      "0.803 (+/-0.108) for {'bootstrap': True, 'criterion': 'entropy', 'min_samples_split': 3, 'n_estimators': 160, 'warm_start': False}\n",
      "0.810 (+/-0.107) for {'bootstrap': True, 'criterion': 'entropy', 'min_samples_split': 3, 'n_estimators': 180, 'warm_start': True}\n",
      "0.810 (+/-0.095) for {'bootstrap': True, 'criterion': 'entropy', 'min_samples_split': 3, 'n_estimators': 180, 'warm_start': False}\n",
      "0.810 (+/-0.101) for {'bootstrap': True, 'criterion': 'entropy', 'min_samples_split': 3, 'n_estimators': 200, 'warm_start': True}\n",
      "0.802 (+/-0.110) for {'bootstrap': True, 'criterion': 'entropy', 'min_samples_split': 3, 'n_estimators': 200, 'warm_start': False}\n",
      "0.822 (+/-0.086) for {'bootstrap': True, 'criterion': 'entropy', 'min_samples_split': 4, 'n_estimators': 60, 'warm_start': True}\n",
      "0.809 (+/-0.100) for {'bootstrap': True, 'criterion': 'entropy', 'min_samples_split': 4, 'n_estimators': 60, 'warm_start': False}\n",
      "0.822 (+/-0.076) for {'bootstrap': True, 'criterion': 'entropy', 'min_samples_split': 4, 'n_estimators': 70, 'warm_start': True}\n",
      "0.818 (+/-0.112) for {'bootstrap': True, 'criterion': 'entropy', 'min_samples_split': 4, 'n_estimators': 70, 'warm_start': False}\n",
      "0.813 (+/-0.097) for {'bootstrap': True, 'criterion': 'entropy', 'min_samples_split': 4, 'n_estimators': 80, 'warm_start': True}\n",
      "0.820 (+/-0.093) for {'bootstrap': True, 'criterion': 'entropy', 'min_samples_split': 4, 'n_estimators': 80, 'warm_start': False}\n",
      "0.820 (+/-0.105) for {'bootstrap': True, 'criterion': 'entropy', 'min_samples_split': 4, 'n_estimators': 90, 'warm_start': True}\n",
      "0.823 (+/-0.083) for {'bootstrap': True, 'criterion': 'entropy', 'min_samples_split': 4, 'n_estimators': 90, 'warm_start': False}\n",
      "0.816 (+/-0.095) for {'bootstrap': True, 'criterion': 'entropy', 'min_samples_split': 4, 'n_estimators': 100, 'warm_start': True}\n",
      "0.822 (+/-0.102) for {'bootstrap': True, 'criterion': 'entropy', 'min_samples_split': 4, 'n_estimators': 100, 'warm_start': False}\n",
      "0.816 (+/-0.098) for {'bootstrap': True, 'criterion': 'entropy', 'min_samples_split': 4, 'n_estimators': 120, 'warm_start': True}\n",
      "0.815 (+/-0.095) for {'bootstrap': True, 'criterion': 'entropy', 'min_samples_split': 4, 'n_estimators': 120, 'warm_start': False}\n",
      "0.822 (+/-0.099) for {'bootstrap': True, 'criterion': 'entropy', 'min_samples_split': 4, 'n_estimators': 140, 'warm_start': True}\n",
      "0.817 (+/-0.094) for {'bootstrap': True, 'criterion': 'entropy', 'min_samples_split': 4, 'n_estimators': 140, 'warm_start': False}\n",
      "0.823 (+/-0.098) for {'bootstrap': True, 'criterion': 'entropy', 'min_samples_split': 4, 'n_estimators': 160, 'warm_start': True}\n",
      "0.819 (+/-0.093) for {'bootstrap': True, 'criterion': 'entropy', 'min_samples_split': 4, 'n_estimators': 160, 'warm_start': False}\n",
      "0.823 (+/-0.089) for {'bootstrap': True, 'criterion': 'entropy', 'min_samples_split': 4, 'n_estimators': 180, 'warm_start': True}\n",
      "0.820 (+/-0.102) for {'bootstrap': True, 'criterion': 'entropy', 'min_samples_split': 4, 'n_estimators': 180, 'warm_start': False}\n",
      "0.823 (+/-0.099) for {'bootstrap': True, 'criterion': 'entropy', 'min_samples_split': 4, 'n_estimators': 200, 'warm_start': True}\n",
      "0.816 (+/-0.100) for {'bootstrap': True, 'criterion': 'entropy', 'min_samples_split': 4, 'n_estimators': 200, 'warm_start': False}\n",
      "0.819 (+/-0.103) for {'bootstrap': True, 'criterion': 'entropy', 'min_samples_split': 5, 'n_estimators': 60, 'warm_start': True}\n",
      "0.824 (+/-0.107) for {'bootstrap': True, 'criterion': 'entropy', 'min_samples_split': 5, 'n_estimators': 60, 'warm_start': False}\n",
      "0.824 (+/-0.110) for {'bootstrap': True, 'criterion': 'entropy', 'min_samples_split': 5, 'n_estimators': 70, 'warm_start': True}\n",
      "0.819 (+/-0.104) for {'bootstrap': True, 'criterion': 'entropy', 'min_samples_split': 5, 'n_estimators': 70, 'warm_start': False}\n",
      "0.816 (+/-0.094) for {'bootstrap': True, 'criterion': 'entropy', 'min_samples_split': 5, 'n_estimators': 80, 'warm_start': True}\n",
      "0.825 (+/-0.103) for {'bootstrap': True, 'criterion': 'entropy', 'min_samples_split': 5, 'n_estimators': 80, 'warm_start': False}\n",
      "0.826 (+/-0.099) for {'bootstrap': True, 'criterion': 'entropy', 'min_samples_split': 5, 'n_estimators': 90, 'warm_start': True}\n",
      "0.827 (+/-0.102) for {'bootstrap': True, 'criterion': 'entropy', 'min_samples_split': 5, 'n_estimators': 90, 'warm_start': False}\n",
      "0.820 (+/-0.092) for {'bootstrap': True, 'criterion': 'entropy', 'min_samples_split': 5, 'n_estimators': 100, 'warm_start': True}\n",
      "0.822 (+/-0.081) for {'bootstrap': True, 'criterion': 'entropy', 'min_samples_split': 5, 'n_estimators': 100, 'warm_start': False}\n",
      "0.816 (+/-0.105) for {'bootstrap': True, 'criterion': 'entropy', 'min_samples_split': 5, 'n_estimators': 120, 'warm_start': True}\n",
      "0.823 (+/-0.100) for {'bootstrap': True, 'criterion': 'entropy', 'min_samples_split': 5, 'n_estimators': 120, 'warm_start': False}\n",
      "0.819 (+/-0.105) for {'bootstrap': True, 'criterion': 'entropy', 'min_samples_split': 5, 'n_estimators': 140, 'warm_start': True}\n",
      "0.826 (+/-0.106) for {'bootstrap': True, 'criterion': 'entropy', 'min_samples_split': 5, 'n_estimators': 140, 'warm_start': False}\n",
      "0.826 (+/-0.090) for {'bootstrap': True, 'criterion': 'entropy', 'min_samples_split': 5, 'n_estimators': 160, 'warm_start': True}\n",
      "0.826 (+/-0.104) for {'bootstrap': True, 'criterion': 'entropy', 'min_samples_split': 5, 'n_estimators': 160, 'warm_start': False}\n",
      "0.827 (+/-0.102) for {'bootstrap': True, 'criterion': 'entropy', 'min_samples_split': 5, 'n_estimators': 180, 'warm_start': True}\n",
      "0.825 (+/-0.098) for {'bootstrap': True, 'criterion': 'entropy', 'min_samples_split': 5, 'n_estimators': 180, 'warm_start': False}\n",
      "0.824 (+/-0.086) for {'bootstrap': True, 'criterion': 'entropy', 'min_samples_split': 5, 'n_estimators': 200, 'warm_start': True}\n",
      "0.820 (+/-0.103) for {'bootstrap': True, 'criterion': 'entropy', 'min_samples_split': 5, 'n_estimators': 200, 'warm_start': False}\n",
      "0.824 (+/-0.091) for {'bootstrap': True, 'criterion': 'entropy', 'min_samples_split': 6, 'n_estimators': 60, 'warm_start': True}\n",
      "0.819 (+/-0.080) for {'bootstrap': True, 'criterion': 'entropy', 'min_samples_split': 6, 'n_estimators': 60, 'warm_start': False}\n",
      "0.829 (+/-0.100) for {'bootstrap': True, 'criterion': 'entropy', 'min_samples_split': 6, 'n_estimators': 70, 'warm_start': True}\n",
      "0.832 (+/-0.071) for {'bootstrap': True, 'criterion': 'entropy', 'min_samples_split': 6, 'n_estimators': 70, 'warm_start': False}\n",
      "0.817 (+/-0.101) for {'bootstrap': True, 'criterion': 'entropy', 'min_samples_split': 6, 'n_estimators': 80, 'warm_start': True}\n",
      "0.822 (+/-0.098) for {'bootstrap': True, 'criterion': 'entropy', 'min_samples_split': 6, 'n_estimators': 80, 'warm_start': False}\n",
      "0.834 (+/-0.110) for {'bootstrap': True, 'criterion': 'entropy', 'min_samples_split': 6, 'n_estimators': 90, 'warm_start': True}\n",
      "0.823 (+/-0.094) for {'bootstrap': True, 'criterion': 'entropy', 'min_samples_split': 6, 'n_estimators': 90, 'warm_start': False}\n",
      "0.829 (+/-0.101) for {'bootstrap': True, 'criterion': 'entropy', 'min_samples_split': 6, 'n_estimators': 100, 'warm_start': True}\n",
      "0.826 (+/-0.096) for {'bootstrap': True, 'criterion': 'entropy', 'min_samples_split': 6, 'n_estimators': 100, 'warm_start': False}\n",
      "0.826 (+/-0.094) for {'bootstrap': True, 'criterion': 'entropy', 'min_samples_split': 6, 'n_estimators': 120, 'warm_start': True}\n",
      "0.819 (+/-0.110) for {'bootstrap': True, 'criterion': 'entropy', 'min_samples_split': 6, 'n_estimators': 120, 'warm_start': False}\n",
      "0.819 (+/-0.098) for {'bootstrap': True, 'criterion': 'entropy', 'min_samples_split': 6, 'n_estimators': 140, 'warm_start': True}\n",
      "0.832 (+/-0.090) for {'bootstrap': True, 'criterion': 'entropy', 'min_samples_split': 6, 'n_estimators': 140, 'warm_start': False}\n",
      "0.830 (+/-0.091) for {'bootstrap': True, 'criterion': 'entropy', 'min_samples_split': 6, 'n_estimators': 160, 'warm_start': True}\n",
      "0.826 (+/-0.084) for {'bootstrap': True, 'criterion': 'entropy', 'min_samples_split': 6, 'n_estimators': 160, 'warm_start': False}\n",
      "0.826 (+/-0.089) for {'bootstrap': True, 'criterion': 'entropy', 'min_samples_split': 6, 'n_estimators': 180, 'warm_start': True}\n",
      "0.827 (+/-0.089) for {'bootstrap': True, 'criterion': 'entropy', 'min_samples_split': 6, 'n_estimators': 180, 'warm_start': False}\n",
      "0.827 (+/-0.092) for {'bootstrap': True, 'criterion': 'entropy', 'min_samples_split': 6, 'n_estimators': 200, 'warm_start': True}\n",
      "0.825 (+/-0.103) for {'bootstrap': True, 'criterion': 'entropy', 'min_samples_split': 6, 'n_estimators': 200, 'warm_start': False}\n",
      "0.825 (+/-0.088) for {'bootstrap': True, 'criterion': 'entropy', 'min_samples_split': 7, 'n_estimators': 60, 'warm_start': True}\n",
      "0.822 (+/-0.095) for {'bootstrap': True, 'criterion': 'entropy', 'min_samples_split': 7, 'n_estimators': 60, 'warm_start': False}\n",
      "0.829 (+/-0.098) for {'bootstrap': True, 'criterion': 'entropy', 'min_samples_split': 7, 'n_estimators': 70, 'warm_start': True}\n",
      "0.820 (+/-0.087) for {'bootstrap': True, 'criterion': 'entropy', 'min_samples_split': 7, 'n_estimators': 70, 'warm_start': False}\n",
      "0.833 (+/-0.084) for {'bootstrap': True, 'criterion': 'entropy', 'min_samples_split': 7, 'n_estimators': 80, 'warm_start': True}\n",
      "0.822 (+/-0.087) for {'bootstrap': True, 'criterion': 'entropy', 'min_samples_split': 7, 'n_estimators': 80, 'warm_start': False}\n",
      "0.822 (+/-0.072) for {'bootstrap': True, 'criterion': 'entropy', 'min_samples_split': 7, 'n_estimators': 90, 'warm_start': True}\n",
      "0.823 (+/-0.103) for {'bootstrap': True, 'criterion': 'entropy', 'min_samples_split': 7, 'n_estimators': 90, 'warm_start': False}\n",
      "0.819 (+/-0.097) for {'bootstrap': True, 'criterion': 'entropy', 'min_samples_split': 7, 'n_estimators': 100, 'warm_start': True}\n",
      "0.830 (+/-0.089) for {'bootstrap': True, 'criterion': 'entropy', 'min_samples_split': 7, 'n_estimators': 100, 'warm_start': False}\n",
      "0.829 (+/-0.094) for {'bootstrap': True, 'criterion': 'entropy', 'min_samples_split': 7, 'n_estimators': 120, 'warm_start': True}\n",
      "0.830 (+/-0.079) for {'bootstrap': True, 'criterion': 'entropy', 'min_samples_split': 7, 'n_estimators': 120, 'warm_start': False}\n",
      "0.826 (+/-0.096) for {'bootstrap': True, 'criterion': 'entropy', 'min_samples_split': 7, 'n_estimators': 140, 'warm_start': True}\n",
      "0.830 (+/-0.082) for {'bootstrap': True, 'criterion': 'entropy', 'min_samples_split': 7, 'n_estimators': 140, 'warm_start': False}\n",
      "0.829 (+/-0.091) for {'bootstrap': True, 'criterion': 'entropy', 'min_samples_split': 7, 'n_estimators': 160, 'warm_start': True}\n",
      "0.826 (+/-0.098) for {'bootstrap': True, 'criterion': 'entropy', 'min_samples_split': 7, 'n_estimators': 160, 'warm_start': False}\n",
      "0.830 (+/-0.105) for {'bootstrap': True, 'criterion': 'entropy', 'min_samples_split': 7, 'n_estimators': 180, 'warm_start': True}\n",
      "0.827 (+/-0.096) for {'bootstrap': True, 'criterion': 'entropy', 'min_samples_split': 7, 'n_estimators': 180, 'warm_start': False}\n",
      "0.823 (+/-0.104) for {'bootstrap': True, 'criterion': 'entropy', 'min_samples_split': 7, 'n_estimators': 200, 'warm_start': True}\n",
      "0.829 (+/-0.088) for {'bootstrap': True, 'criterion': 'entropy', 'min_samples_split': 7, 'n_estimators': 200, 'warm_start': False}\n",
      "0.812 (+/-0.093) for {'bootstrap': True, 'criterion': 'entropy', 'min_samples_split': 8, 'n_estimators': 60, 'warm_start': True}\n",
      "0.818 (+/-0.078) for {'bootstrap': True, 'criterion': 'entropy', 'min_samples_split': 8, 'n_estimators': 60, 'warm_start': False}\n",
      "0.827 (+/-0.086) for {'bootstrap': True, 'criterion': 'entropy', 'min_samples_split': 8, 'n_estimators': 70, 'warm_start': True}\n",
      "0.818 (+/-0.100) for {'bootstrap': True, 'criterion': 'entropy', 'min_samples_split': 8, 'n_estimators': 70, 'warm_start': False}\n",
      "0.822 (+/-0.097) for {'bootstrap': True, 'criterion': 'entropy', 'min_samples_split': 8, 'n_estimators': 80, 'warm_start': True}\n",
      "0.826 (+/-0.089) for {'bootstrap': True, 'criterion': 'entropy', 'min_samples_split': 8, 'n_estimators': 80, 'warm_start': False}\n",
      "0.819 (+/-0.088) for {'bootstrap': True, 'criterion': 'entropy', 'min_samples_split': 8, 'n_estimators': 90, 'warm_start': True}\n",
      "0.820 (+/-0.090) for {'bootstrap': True, 'criterion': 'entropy', 'min_samples_split': 8, 'n_estimators': 90, 'warm_start': False}\n",
      "0.827 (+/-0.078) for {'bootstrap': True, 'criterion': 'entropy', 'min_samples_split': 8, 'n_estimators': 100, 'warm_start': True}\n",
      "0.822 (+/-0.097) for {'bootstrap': True, 'criterion': 'entropy', 'min_samples_split': 8, 'n_estimators': 100, 'warm_start': False}\n",
      "0.829 (+/-0.082) for {'bootstrap': True, 'criterion': 'entropy', 'min_samples_split': 8, 'n_estimators': 120, 'warm_start': True}\n",
      "0.824 (+/-0.097) for {'bootstrap': True, 'criterion': 'entropy', 'min_samples_split': 8, 'n_estimators': 120, 'warm_start': False}\n",
      "0.825 (+/-0.082) for {'bootstrap': True, 'criterion': 'entropy', 'min_samples_split': 8, 'n_estimators': 140, 'warm_start': True}\n",
      "0.825 (+/-0.089) for {'bootstrap': True, 'criterion': 'entropy', 'min_samples_split': 8, 'n_estimators': 140, 'warm_start': False}\n",
      "0.825 (+/-0.089) for {'bootstrap': True, 'criterion': 'entropy', 'min_samples_split': 8, 'n_estimators': 160, 'warm_start': True}\n",
      "0.826 (+/-0.102) for {'bootstrap': True, 'criterion': 'entropy', 'min_samples_split': 8, 'n_estimators': 160, 'warm_start': False}\n",
      "0.830 (+/-0.088) for {'bootstrap': True, 'criterion': 'entropy', 'min_samples_split': 8, 'n_estimators': 180, 'warm_start': True}\n",
      "0.827 (+/-0.085) for {'bootstrap': True, 'criterion': 'entropy', 'min_samples_split': 8, 'n_estimators': 180, 'warm_start': False}\n",
      "0.825 (+/-0.089) for {'bootstrap': True, 'criterion': 'entropy', 'min_samples_split': 8, 'n_estimators': 200, 'warm_start': True}\n",
      "0.826 (+/-0.090) for {'bootstrap': True, 'criterion': 'entropy', 'min_samples_split': 8, 'n_estimators': 200, 'warm_start': False}\n",
      "0.820 (+/-0.096) for {'bootstrap': True, 'criterion': 'entropy', 'min_samples_split': 9, 'n_estimators': 60, 'warm_start': True}\n",
      "0.827 (+/-0.102) for {'bootstrap': True, 'criterion': 'entropy', 'min_samples_split': 9, 'n_estimators': 60, 'warm_start': False}\n",
      "0.832 (+/-0.081) for {'bootstrap': True, 'criterion': 'entropy', 'min_samples_split': 9, 'n_estimators': 70, 'warm_start': True}\n",
      "0.826 (+/-0.100) for {'bootstrap': True, 'criterion': 'entropy', 'min_samples_split': 9, 'n_estimators': 70, 'warm_start': False}\n",
      "0.825 (+/-0.076) for {'bootstrap': True, 'criterion': 'entropy', 'min_samples_split': 9, 'n_estimators': 80, 'warm_start': True}\n",
      "0.830 (+/-0.097) for {'bootstrap': True, 'criterion': 'entropy', 'min_samples_split': 9, 'n_estimators': 80, 'warm_start': False}\n",
      "0.820 (+/-0.086) for {'bootstrap': True, 'criterion': 'entropy', 'min_samples_split': 9, 'n_estimators': 90, 'warm_start': True}\n",
      "0.817 (+/-0.106) for {'bootstrap': True, 'criterion': 'entropy', 'min_samples_split': 9, 'n_estimators': 90, 'warm_start': False}\n",
      "0.819 (+/-0.077) for {'bootstrap': True, 'criterion': 'entropy', 'min_samples_split': 9, 'n_estimators': 100, 'warm_start': True}\n",
      "0.822 (+/-0.083) for {'bootstrap': True, 'criterion': 'entropy', 'min_samples_split': 9, 'n_estimators': 100, 'warm_start': False}\n",
      "0.832 (+/-0.092) for {'bootstrap': True, 'criterion': 'entropy', 'min_samples_split': 9, 'n_estimators': 120, 'warm_start': True}\n",
      "0.830 (+/-0.082) for {'bootstrap': True, 'criterion': 'entropy', 'min_samples_split': 9, 'n_estimators': 120, 'warm_start': False}\n",
      "0.825 (+/-0.096) for {'bootstrap': True, 'criterion': 'entropy', 'min_samples_split': 9, 'n_estimators': 140, 'warm_start': True}\n",
      "0.833 (+/-0.087) for {'bootstrap': True, 'criterion': 'entropy', 'min_samples_split': 9, 'n_estimators': 140, 'warm_start': False}\n",
      "0.830 (+/-0.091) for {'bootstrap': True, 'criterion': 'entropy', 'min_samples_split': 9, 'n_estimators': 160, 'warm_start': True}\n",
      "0.820 (+/-0.105) for {'bootstrap': True, 'criterion': 'entropy', 'min_samples_split': 9, 'n_estimators': 160, 'warm_start': False}\n",
      "0.822 (+/-0.089) for {'bootstrap': True, 'criterion': 'entropy', 'min_samples_split': 9, 'n_estimators': 180, 'warm_start': True}\n",
      "0.825 (+/-0.096) for {'bootstrap': True, 'criterion': 'entropy', 'min_samples_split': 9, 'n_estimators': 180, 'warm_start': False}\n",
      "0.826 (+/-0.090) for {'bootstrap': True, 'criterion': 'entropy', 'min_samples_split': 9, 'n_estimators': 200, 'warm_start': True}\n",
      "0.827 (+/-0.092) for {'bootstrap': True, 'criterion': 'entropy', 'min_samples_split': 9, 'n_estimators': 200, 'warm_start': False}\n",
      "0.778 (+/-0.140) for {'bootstrap': False, 'criterion': 'gini', 'min_samples_split': 2, 'n_estimators': 60, 'warm_start': True}\n",
      "0.777 (+/-0.138) for {'bootstrap': False, 'criterion': 'gini', 'min_samples_split': 2, 'n_estimators': 60, 'warm_start': False}\n",
      "0.777 (+/-0.130) for {'bootstrap': False, 'criterion': 'gini', 'min_samples_split': 2, 'n_estimators': 70, 'warm_start': True}\n",
      "0.775 (+/-0.145) for {'bootstrap': False, 'criterion': 'gini', 'min_samples_split': 2, 'n_estimators': 70, 'warm_start': False}\n",
      "0.778 (+/-0.125) for {'bootstrap': False, 'criterion': 'gini', 'min_samples_split': 2, 'n_estimators': 80, 'warm_start': True}\n",
      "0.775 (+/-0.152) for {'bootstrap': False, 'criterion': 'gini', 'min_samples_split': 2, 'n_estimators': 80, 'warm_start': False}\n",
      "0.775 (+/-0.127) for {'bootstrap': False, 'criterion': 'gini', 'min_samples_split': 2, 'n_estimators': 90, 'warm_start': True}\n",
      "0.780 (+/-0.122) for {'bootstrap': False, 'criterion': 'gini', 'min_samples_split': 2, 'n_estimators': 90, 'warm_start': False}\n",
      "0.778 (+/-0.122) for {'bootstrap': False, 'criterion': 'gini', 'min_samples_split': 2, 'n_estimators': 100, 'warm_start': True}\n",
      "0.784 (+/-0.129) for {'bootstrap': False, 'criterion': 'gini', 'min_samples_split': 2, 'n_estimators': 100, 'warm_start': False}\n",
      "0.777 (+/-0.135) for {'bootstrap': False, 'criterion': 'gini', 'min_samples_split': 2, 'n_estimators': 120, 'warm_start': True}\n",
      "0.778 (+/-0.131) for {'bootstrap': False, 'criterion': 'gini', 'min_samples_split': 2, 'n_estimators': 120, 'warm_start': False}\n",
      "0.768 (+/-0.144) for {'bootstrap': False, 'criterion': 'gini', 'min_samples_split': 2, 'n_estimators': 140, 'warm_start': True}\n",
      "0.775 (+/-0.117) for {'bootstrap': False, 'criterion': 'gini', 'min_samples_split': 2, 'n_estimators': 140, 'warm_start': False}\n",
      "0.782 (+/-0.125) for {'bootstrap': False, 'criterion': 'gini', 'min_samples_split': 2, 'n_estimators': 160, 'warm_start': True}\n",
      "0.778 (+/-0.126) for {'bootstrap': False, 'criterion': 'gini', 'min_samples_split': 2, 'n_estimators': 160, 'warm_start': False}\n",
      "0.768 (+/-0.138) for {'bootstrap': False, 'criterion': 'gini', 'min_samples_split': 2, 'n_estimators': 180, 'warm_start': True}\n",
      "0.777 (+/-0.124) for {'bootstrap': False, 'criterion': 'gini', 'min_samples_split': 2, 'n_estimators': 180, 'warm_start': False}\n",
      "0.775 (+/-0.133) for {'bootstrap': False, 'criterion': 'gini', 'min_samples_split': 2, 'n_estimators': 200, 'warm_start': True}\n",
      "0.778 (+/-0.109) for {'bootstrap': False, 'criterion': 'gini', 'min_samples_split': 2, 'n_estimators': 200, 'warm_start': False}\n",
      "0.794 (+/-0.108) for {'bootstrap': False, 'criterion': 'gini', 'min_samples_split': 3, 'n_estimators': 60, 'warm_start': True}\n",
      "0.788 (+/-0.130) for {'bootstrap': False, 'criterion': 'gini', 'min_samples_split': 3, 'n_estimators': 60, 'warm_start': False}\n",
      "0.787 (+/-0.118) for {'bootstrap': False, 'criterion': 'gini', 'min_samples_split': 3, 'n_estimators': 70, 'warm_start': True}\n",
      "0.782 (+/-0.115) for {'bootstrap': False, 'criterion': 'gini', 'min_samples_split': 3, 'n_estimators': 70, 'warm_start': False}\n",
      "0.787 (+/-0.118) for {'bootstrap': False, 'criterion': 'gini', 'min_samples_split': 3, 'n_estimators': 80, 'warm_start': True}\n",
      "0.784 (+/-0.129) for {'bootstrap': False, 'criterion': 'gini', 'min_samples_split': 3, 'n_estimators': 80, 'warm_start': False}\n",
      "0.794 (+/-0.114) for {'bootstrap': False, 'criterion': 'gini', 'min_samples_split': 3, 'n_estimators': 90, 'warm_start': True}\n",
      "0.787 (+/-0.122) for {'bootstrap': False, 'criterion': 'gini', 'min_samples_split': 3, 'n_estimators': 90, 'warm_start': False}\n",
      "0.791 (+/-0.119) for {'bootstrap': False, 'criterion': 'gini', 'min_samples_split': 3, 'n_estimators': 100, 'warm_start': True}\n",
      "0.785 (+/-0.112) for {'bootstrap': False, 'criterion': 'gini', 'min_samples_split': 3, 'n_estimators': 100, 'warm_start': False}\n",
      "0.787 (+/-0.121) for {'bootstrap': False, 'criterion': 'gini', 'min_samples_split': 3, 'n_estimators': 120, 'warm_start': True}\n",
      "0.787 (+/-0.112) for {'bootstrap': False, 'criterion': 'gini', 'min_samples_split': 3, 'n_estimators': 120, 'warm_start': False}\n",
      "0.781 (+/-0.125) for {'bootstrap': False, 'criterion': 'gini', 'min_samples_split': 3, 'n_estimators': 140, 'warm_start': True}\n",
      "0.791 (+/-0.114) for {'bootstrap': False, 'criterion': 'gini', 'min_samples_split': 3, 'n_estimators': 140, 'warm_start': False}\n",
      "0.791 (+/-0.120) for {'bootstrap': False, 'criterion': 'gini', 'min_samples_split': 3, 'n_estimators': 160, 'warm_start': True}\n",
      "0.792 (+/-0.110) for {'bootstrap': False, 'criterion': 'gini', 'min_samples_split': 3, 'n_estimators': 160, 'warm_start': False}\n",
      "0.788 (+/-0.130) for {'bootstrap': False, 'criterion': 'gini', 'min_samples_split': 3, 'n_estimators': 180, 'warm_start': True}\n",
      "0.791 (+/-0.109) for {'bootstrap': False, 'criterion': 'gini', 'min_samples_split': 3, 'n_estimators': 180, 'warm_start': False}\n",
      "0.791 (+/-0.121) for {'bootstrap': False, 'criterion': 'gini', 'min_samples_split': 3, 'n_estimators': 200, 'warm_start': True}\n",
      "0.785 (+/-0.125) for {'bootstrap': False, 'criterion': 'gini', 'min_samples_split': 3, 'n_estimators': 200, 'warm_start': False}\n",
      "0.789 (+/-0.101) for {'bootstrap': False, 'criterion': 'gini', 'min_samples_split': 4, 'n_estimators': 60, 'warm_start': True}\n",
      "0.791 (+/-0.112) for {'bootstrap': False, 'criterion': 'gini', 'min_samples_split': 4, 'n_estimators': 60, 'warm_start': False}\n",
      "0.796 (+/-0.115) for {'bootstrap': False, 'criterion': 'gini', 'min_samples_split': 4, 'n_estimators': 70, 'warm_start': True}\n",
      "0.795 (+/-0.109) for {'bootstrap': False, 'criterion': 'gini', 'min_samples_split': 4, 'n_estimators': 70, 'warm_start': False}\n",
      "0.789 (+/-0.112) for {'bootstrap': False, 'criterion': 'gini', 'min_samples_split': 4, 'n_estimators': 80, 'warm_start': True}\n",
      "0.799 (+/-0.109) for {'bootstrap': False, 'criterion': 'gini', 'min_samples_split': 4, 'n_estimators': 80, 'warm_start': False}\n",
      "0.794 (+/-0.104) for {'bootstrap': False, 'criterion': 'gini', 'min_samples_split': 4, 'n_estimators': 90, 'warm_start': True}\n",
      "0.787 (+/-0.122) for {'bootstrap': False, 'criterion': 'gini', 'min_samples_split': 4, 'n_estimators': 90, 'warm_start': False}\n",
      "0.792 (+/-0.121) for {'bootstrap': False, 'criterion': 'gini', 'min_samples_split': 4, 'n_estimators': 100, 'warm_start': True}\n",
      "0.796 (+/-0.098) for {'bootstrap': False, 'criterion': 'gini', 'min_samples_split': 4, 'n_estimators': 100, 'warm_start': False}\n",
      "0.801 (+/-0.108) for {'bootstrap': False, 'criterion': 'gini', 'min_samples_split': 4, 'n_estimators': 120, 'warm_start': True}\n",
      "0.791 (+/-0.119) for {'bootstrap': False, 'criterion': 'gini', 'min_samples_split': 4, 'n_estimators': 120, 'warm_start': False}\n",
      "0.801 (+/-0.103) for {'bootstrap': False, 'criterion': 'gini', 'min_samples_split': 4, 'n_estimators': 140, 'warm_start': True}\n",
      "0.796 (+/-0.106) for {'bootstrap': False, 'criterion': 'gini', 'min_samples_split': 4, 'n_estimators': 140, 'warm_start': False}\n",
      "0.796 (+/-0.113) for {'bootstrap': False, 'criterion': 'gini', 'min_samples_split': 4, 'n_estimators': 160, 'warm_start': True}\n",
      "0.794 (+/-0.119) for {'bootstrap': False, 'criterion': 'gini', 'min_samples_split': 4, 'n_estimators': 160, 'warm_start': False}\n",
      "0.791 (+/-0.117) for {'bootstrap': False, 'criterion': 'gini', 'min_samples_split': 4, 'n_estimators': 180, 'warm_start': True}\n",
      "0.796 (+/-0.106) for {'bootstrap': False, 'criterion': 'gini', 'min_samples_split': 4, 'n_estimators': 180, 'warm_start': False}\n",
      "0.789 (+/-0.121) for {'bootstrap': False, 'criterion': 'gini', 'min_samples_split': 4, 'n_estimators': 200, 'warm_start': True}\n",
      "0.792 (+/-0.110) for {'bootstrap': False, 'criterion': 'gini', 'min_samples_split': 4, 'n_estimators': 200, 'warm_start': False}\n",
      "0.805 (+/-0.087) for {'bootstrap': False, 'criterion': 'gini', 'min_samples_split': 5, 'n_estimators': 60, 'warm_start': True}\n",
      "0.806 (+/-0.098) for {'bootstrap': False, 'criterion': 'gini', 'min_samples_split': 5, 'n_estimators': 60, 'warm_start': False}\n",
      "0.809 (+/-0.096) for {'bootstrap': False, 'criterion': 'gini', 'min_samples_split': 5, 'n_estimators': 70, 'warm_start': True}\n",
      "0.809 (+/-0.085) for {'bootstrap': False, 'criterion': 'gini', 'min_samples_split': 5, 'n_estimators': 70, 'warm_start': False}\n",
      "0.813 (+/-0.092) for {'bootstrap': False, 'criterion': 'gini', 'min_samples_split': 5, 'n_estimators': 80, 'warm_start': True}\n",
      "0.805 (+/-0.110) for {'bootstrap': False, 'criterion': 'gini', 'min_samples_split': 5, 'n_estimators': 80, 'warm_start': False}\n",
      "0.812 (+/-0.088) for {'bootstrap': False, 'criterion': 'gini', 'min_samples_split': 5, 'n_estimators': 90, 'warm_start': True}\n",
      "0.812 (+/-0.097) for {'bootstrap': False, 'criterion': 'gini', 'min_samples_split': 5, 'n_estimators': 90, 'warm_start': False}\n",
      "0.806 (+/-0.094) for {'bootstrap': False, 'criterion': 'gini', 'min_samples_split': 5, 'n_estimators': 100, 'warm_start': True}\n",
      "0.812 (+/-0.100) for {'bootstrap': False, 'criterion': 'gini', 'min_samples_split': 5, 'n_estimators': 100, 'warm_start': False}\n",
      "0.816 (+/-0.102) for {'bootstrap': False, 'criterion': 'gini', 'min_samples_split': 5, 'n_estimators': 120, 'warm_start': True}\n",
      "0.808 (+/-0.105) for {'bootstrap': False, 'criterion': 'gini', 'min_samples_split': 5, 'n_estimators': 120, 'warm_start': False}\n",
      "0.806 (+/-0.103) for {'bootstrap': False, 'criterion': 'gini', 'min_samples_split': 5, 'n_estimators': 140, 'warm_start': True}\n",
      "0.810 (+/-0.082) for {'bootstrap': False, 'criterion': 'gini', 'min_samples_split': 5, 'n_estimators': 140, 'warm_start': False}\n",
      "0.809 (+/-0.097) for {'bootstrap': False, 'criterion': 'gini', 'min_samples_split': 5, 'n_estimators': 160, 'warm_start': True}\n",
      "0.811 (+/-0.098) for {'bootstrap': False, 'criterion': 'gini', 'min_samples_split': 5, 'n_estimators': 160, 'warm_start': False}\n",
      "0.809 (+/-0.085) for {'bootstrap': False, 'criterion': 'gini', 'min_samples_split': 5, 'n_estimators': 180, 'warm_start': True}\n",
      "0.812 (+/-0.083) for {'bootstrap': False, 'criterion': 'gini', 'min_samples_split': 5, 'n_estimators': 180, 'warm_start': False}\n",
      "0.809 (+/-0.096) for {'bootstrap': False, 'criterion': 'gini', 'min_samples_split': 5, 'n_estimators': 200, 'warm_start': True}\n",
      "0.810 (+/-0.093) for {'bootstrap': False, 'criterion': 'gini', 'min_samples_split': 5, 'n_estimators': 200, 'warm_start': False}\n",
      "0.813 (+/-0.088) for {'bootstrap': False, 'criterion': 'gini', 'min_samples_split': 6, 'n_estimators': 60, 'warm_start': True}\n",
      "0.812 (+/-0.085) for {'bootstrap': False, 'criterion': 'gini', 'min_samples_split': 6, 'n_estimators': 60, 'warm_start': False}\n",
      "0.812 (+/-0.100) for {'bootstrap': False, 'criterion': 'gini', 'min_samples_split': 6, 'n_estimators': 70, 'warm_start': True}\n",
      "0.816 (+/-0.085) for {'bootstrap': False, 'criterion': 'gini', 'min_samples_split': 6, 'n_estimators': 70, 'warm_start': False}\n",
      "0.812 (+/-0.090) for {'bootstrap': False, 'criterion': 'gini', 'min_samples_split': 6, 'n_estimators': 80, 'warm_start': True}\n",
      "0.818 (+/-0.095) for {'bootstrap': False, 'criterion': 'gini', 'min_samples_split': 6, 'n_estimators': 80, 'warm_start': False}\n",
      "0.812 (+/-0.089) for {'bootstrap': False, 'criterion': 'gini', 'min_samples_split': 6, 'n_estimators': 90, 'warm_start': True}\n",
      "0.817 (+/-0.086) for {'bootstrap': False, 'criterion': 'gini', 'min_samples_split': 6, 'n_estimators': 90, 'warm_start': False}\n",
      "0.815 (+/-0.089) for {'bootstrap': False, 'criterion': 'gini', 'min_samples_split': 6, 'n_estimators': 100, 'warm_start': True}\n",
      "0.813 (+/-0.102) for {'bootstrap': False, 'criterion': 'gini', 'min_samples_split': 6, 'n_estimators': 100, 'warm_start': False}\n",
      "0.815 (+/-0.082) for {'bootstrap': False, 'criterion': 'gini', 'min_samples_split': 6, 'n_estimators': 120, 'warm_start': True}\n",
      "0.819 (+/-0.079) for {'bootstrap': False, 'criterion': 'gini', 'min_samples_split': 6, 'n_estimators': 120, 'warm_start': False}\n",
      "0.813 (+/-0.086) for {'bootstrap': False, 'criterion': 'gini', 'min_samples_split': 6, 'n_estimators': 140, 'warm_start': True}\n",
      "0.815 (+/-0.094) for {'bootstrap': False, 'criterion': 'gini', 'min_samples_split': 6, 'n_estimators': 140, 'warm_start': False}\n",
      "0.815 (+/-0.090) for {'bootstrap': False, 'criterion': 'gini', 'min_samples_split': 6, 'n_estimators': 160, 'warm_start': True}\n",
      "0.815 (+/-0.093) for {'bootstrap': False, 'criterion': 'gini', 'min_samples_split': 6, 'n_estimators': 160, 'warm_start': False}\n",
      "0.813 (+/-0.109) for {'bootstrap': False, 'criterion': 'gini', 'min_samples_split': 6, 'n_estimators': 180, 'warm_start': True}\n",
      "0.823 (+/-0.090) for {'bootstrap': False, 'criterion': 'gini', 'min_samples_split': 6, 'n_estimators': 180, 'warm_start': False}\n",
      "0.816 (+/-0.091) for {'bootstrap': False, 'criterion': 'gini', 'min_samples_split': 6, 'n_estimators': 200, 'warm_start': True}\n",
      "0.822 (+/-0.084) for {'bootstrap': False, 'criterion': 'gini', 'min_samples_split': 6, 'n_estimators': 200, 'warm_start': False}\n",
      "0.815 (+/-0.089) for {'bootstrap': False, 'criterion': 'gini', 'min_samples_split': 7, 'n_estimators': 60, 'warm_start': True}\n",
      "0.813 (+/-0.095) for {'bootstrap': False, 'criterion': 'gini', 'min_samples_split': 7, 'n_estimators': 60, 'warm_start': False}\n",
      "0.812 (+/-0.099) for {'bootstrap': False, 'criterion': 'gini', 'min_samples_split': 7, 'n_estimators': 70, 'warm_start': True}\n",
      "0.816 (+/-0.085) for {'bootstrap': False, 'criterion': 'gini', 'min_samples_split': 7, 'n_estimators': 70, 'warm_start': False}\n",
      "0.823 (+/-0.076) for {'bootstrap': False, 'criterion': 'gini', 'min_samples_split': 7, 'n_estimators': 80, 'warm_start': True}\n",
      "0.815 (+/-0.097) for {'bootstrap': False, 'criterion': 'gini', 'min_samples_split': 7, 'n_estimators': 80, 'warm_start': False}\n",
      "0.823 (+/-0.079) for {'bootstrap': False, 'criterion': 'gini', 'min_samples_split': 7, 'n_estimators': 90, 'warm_start': True}\n",
      "0.816 (+/-0.099) for {'bootstrap': False, 'criterion': 'gini', 'min_samples_split': 7, 'n_estimators': 90, 'warm_start': False}\n",
      "0.819 (+/-0.088) for {'bootstrap': False, 'criterion': 'gini', 'min_samples_split': 7, 'n_estimators': 100, 'warm_start': True}\n",
      "0.820 (+/-0.101) for {'bootstrap': False, 'criterion': 'gini', 'min_samples_split': 7, 'n_estimators': 100, 'warm_start': False}\n",
      "0.819 (+/-0.097) for {'bootstrap': False, 'criterion': 'gini', 'min_samples_split': 7, 'n_estimators': 120, 'warm_start': True}\n",
      "0.819 (+/-0.084) for {'bootstrap': False, 'criterion': 'gini', 'min_samples_split': 7, 'n_estimators': 120, 'warm_start': False}\n",
      "0.822 (+/-0.094) for {'bootstrap': False, 'criterion': 'gini', 'min_samples_split': 7, 'n_estimators': 140, 'warm_start': True}\n",
      "0.819 (+/-0.098) for {'bootstrap': False, 'criterion': 'gini', 'min_samples_split': 7, 'n_estimators': 140, 'warm_start': False}\n",
      "0.816 (+/-0.104) for {'bootstrap': False, 'criterion': 'gini', 'min_samples_split': 7, 'n_estimators': 160, 'warm_start': True}\n",
      "0.815 (+/-0.097) for {'bootstrap': False, 'criterion': 'gini', 'min_samples_split': 7, 'n_estimators': 160, 'warm_start': False}\n",
      "0.819 (+/-0.093) for {'bootstrap': False, 'criterion': 'gini', 'min_samples_split': 7, 'n_estimators': 180, 'warm_start': True}\n",
      "0.820 (+/-0.084) for {'bootstrap': False, 'criterion': 'gini', 'min_samples_split': 7, 'n_estimators': 180, 'warm_start': False}\n",
      "0.822 (+/-0.094) for {'bootstrap': False, 'criterion': 'gini', 'min_samples_split': 7, 'n_estimators': 200, 'warm_start': True}\n",
      "0.820 (+/-0.088) for {'bootstrap': False, 'criterion': 'gini', 'min_samples_split': 7, 'n_estimators': 200, 'warm_start': False}\n",
      "0.825 (+/-0.085) for {'bootstrap': False, 'criterion': 'gini', 'min_samples_split': 8, 'n_estimators': 60, 'warm_start': True}\n",
      "0.820 (+/-0.098) for {'bootstrap': False, 'criterion': 'gini', 'min_samples_split': 8, 'n_estimators': 60, 'warm_start': False}\n",
      "0.820 (+/-0.091) for {'bootstrap': False, 'criterion': 'gini', 'min_samples_split': 8, 'n_estimators': 70, 'warm_start': True}\n",
      "0.824 (+/-0.083) for {'bootstrap': False, 'criterion': 'gini', 'min_samples_split': 8, 'n_estimators': 70, 'warm_start': False}\n",
      "0.822 (+/-0.086) for {'bootstrap': False, 'criterion': 'gini', 'min_samples_split': 8, 'n_estimators': 80, 'warm_start': True}\n",
      "0.810 (+/-0.077) for {'bootstrap': False, 'criterion': 'gini', 'min_samples_split': 8, 'n_estimators': 80, 'warm_start': False}\n",
      "0.820 (+/-0.089) for {'bootstrap': False, 'criterion': 'gini', 'min_samples_split': 8, 'n_estimators': 90, 'warm_start': True}\n",
      "0.825 (+/-0.087) for {'bootstrap': False, 'criterion': 'gini', 'min_samples_split': 8, 'n_estimators': 90, 'warm_start': False}\n",
      "0.813 (+/-0.097) for {'bootstrap': False, 'criterion': 'gini', 'min_samples_split': 8, 'n_estimators': 100, 'warm_start': True}\n",
      "0.813 (+/-0.092) for {'bootstrap': False, 'criterion': 'gini', 'min_samples_split': 8, 'n_estimators': 100, 'warm_start': False}\n",
      "0.822 (+/-0.093) for {'bootstrap': False, 'criterion': 'gini', 'min_samples_split': 8, 'n_estimators': 120, 'warm_start': True}\n",
      "0.816 (+/-0.086) for {'bootstrap': False, 'criterion': 'gini', 'min_samples_split': 8, 'n_estimators': 120, 'warm_start': False}\n",
      "0.818 (+/-0.093) for {'bootstrap': False, 'criterion': 'gini', 'min_samples_split': 8, 'n_estimators': 140, 'warm_start': True}\n",
      "0.822 (+/-0.097) for {'bootstrap': False, 'criterion': 'gini', 'min_samples_split': 8, 'n_estimators': 140, 'warm_start': False}\n",
      "0.823 (+/-0.083) for {'bootstrap': False, 'criterion': 'gini', 'min_samples_split': 8, 'n_estimators': 160, 'warm_start': True}\n",
      "0.822 (+/-0.088) for {'bootstrap': False, 'criterion': 'gini', 'min_samples_split': 8, 'n_estimators': 160, 'warm_start': False}\n",
      "0.826 (+/-0.080) for {'bootstrap': False, 'criterion': 'gini', 'min_samples_split': 8, 'n_estimators': 180, 'warm_start': True}\n",
      "0.823 (+/-0.085) for {'bootstrap': False, 'criterion': 'gini', 'min_samples_split': 8, 'n_estimators': 180, 'warm_start': False}\n",
      "0.819 (+/-0.086) for {'bootstrap': False, 'criterion': 'gini', 'min_samples_split': 8, 'n_estimators': 200, 'warm_start': True}\n",
      "0.820 (+/-0.085) for {'bootstrap': False, 'criterion': 'gini', 'min_samples_split': 8, 'n_estimators': 200, 'warm_start': False}\n",
      "0.819 (+/-0.092) for {'bootstrap': False, 'criterion': 'gini', 'min_samples_split': 9, 'n_estimators': 60, 'warm_start': True}\n",
      "0.819 (+/-0.090) for {'bootstrap': False, 'criterion': 'gini', 'min_samples_split': 9, 'n_estimators': 60, 'warm_start': False}\n",
      "0.825 (+/-0.102) for {'bootstrap': False, 'criterion': 'gini', 'min_samples_split': 9, 'n_estimators': 70, 'warm_start': True}\n",
      "0.826 (+/-0.085) for {'bootstrap': False, 'criterion': 'gini', 'min_samples_split': 9, 'n_estimators': 70, 'warm_start': False}\n",
      "0.819 (+/-0.085) for {'bootstrap': False, 'criterion': 'gini', 'min_samples_split': 9, 'n_estimators': 80, 'warm_start': True}\n",
      "0.825 (+/-0.087) for {'bootstrap': False, 'criterion': 'gini', 'min_samples_split': 9, 'n_estimators': 80, 'warm_start': False}\n",
      "0.826 (+/-0.081) for {'bootstrap': False, 'criterion': 'gini', 'min_samples_split': 9, 'n_estimators': 90, 'warm_start': True}\n",
      "0.818 (+/-0.089) for {'bootstrap': False, 'criterion': 'gini', 'min_samples_split': 9, 'n_estimators': 90, 'warm_start': False}\n",
      "0.819 (+/-0.089) for {'bootstrap': False, 'criterion': 'gini', 'min_samples_split': 9, 'n_estimators': 100, 'warm_start': True}\n",
      "0.822 (+/-0.086) for {'bootstrap': False, 'criterion': 'gini', 'min_samples_split': 9, 'n_estimators': 100, 'warm_start': False}\n",
      "0.819 (+/-0.086) for {'bootstrap': False, 'criterion': 'gini', 'min_samples_split': 9, 'n_estimators': 120, 'warm_start': True}\n",
      "0.819 (+/-0.095) for {'bootstrap': False, 'criterion': 'gini', 'min_samples_split': 9, 'n_estimators': 120, 'warm_start': False}\n",
      "0.818 (+/-0.092) for {'bootstrap': False, 'criterion': 'gini', 'min_samples_split': 9, 'n_estimators': 140, 'warm_start': True}\n",
      "0.820 (+/-0.084) for {'bootstrap': False, 'criterion': 'gini', 'min_samples_split': 9, 'n_estimators': 140, 'warm_start': False}\n",
      "0.819 (+/-0.091) for {'bootstrap': False, 'criterion': 'gini', 'min_samples_split': 9, 'n_estimators': 160, 'warm_start': True}\n",
      "0.823 (+/-0.083) for {'bootstrap': False, 'criterion': 'gini', 'min_samples_split': 9, 'n_estimators': 160, 'warm_start': False}\n",
      "0.825 (+/-0.082) for {'bootstrap': False, 'criterion': 'gini', 'min_samples_split': 9, 'n_estimators': 180, 'warm_start': True}\n",
      "0.823 (+/-0.086) for {'bootstrap': False, 'criterion': 'gini', 'min_samples_split': 9, 'n_estimators': 180, 'warm_start': False}\n",
      "0.826 (+/-0.083) for {'bootstrap': False, 'criterion': 'gini', 'min_samples_split': 9, 'n_estimators': 200, 'warm_start': True}\n",
      "0.825 (+/-0.084) for {'bootstrap': False, 'criterion': 'gini', 'min_samples_split': 9, 'n_estimators': 200, 'warm_start': False}\n",
      "0.781 (+/-0.111) for {'bootstrap': False, 'criterion': 'entropy', 'min_samples_split': 2, 'n_estimators': 60, 'warm_start': True}\n",
      "0.785 (+/-0.134) for {'bootstrap': False, 'criterion': 'entropy', 'min_samples_split': 2, 'n_estimators': 60, 'warm_start': False}\n",
      "0.787 (+/-0.120) for {'bootstrap': False, 'criterion': 'entropy', 'min_samples_split': 2, 'n_estimators': 70, 'warm_start': True}\n",
      "0.781 (+/-0.119) for {'bootstrap': False, 'criterion': 'entropy', 'min_samples_split': 2, 'n_estimators': 70, 'warm_start': False}\n",
      "0.777 (+/-0.132) for {'bootstrap': False, 'criterion': 'entropy', 'min_samples_split': 2, 'n_estimators': 80, 'warm_start': True}\n",
      "0.775 (+/-0.120) for {'bootstrap': False, 'criterion': 'entropy', 'min_samples_split': 2, 'n_estimators': 80, 'warm_start': False}\n",
      "0.785 (+/-0.114) for {'bootstrap': False, 'criterion': 'entropy', 'min_samples_split': 2, 'n_estimators': 90, 'warm_start': True}\n",
      "0.787 (+/-0.110) for {'bootstrap': False, 'criterion': 'entropy', 'min_samples_split': 2, 'n_estimators': 90, 'warm_start': False}\n",
      "0.782 (+/-0.121) for {'bootstrap': False, 'criterion': 'entropy', 'min_samples_split': 2, 'n_estimators': 100, 'warm_start': True}\n",
      "0.782 (+/-0.120) for {'bootstrap': False, 'criterion': 'entropy', 'min_samples_split': 2, 'n_estimators': 100, 'warm_start': False}\n",
      "0.771 (+/-0.144) for {'bootstrap': False, 'criterion': 'entropy', 'min_samples_split': 2, 'n_estimators': 120, 'warm_start': True}\n",
      "0.773 (+/-0.140) for {'bootstrap': False, 'criterion': 'entropy', 'min_samples_split': 2, 'n_estimators': 120, 'warm_start': False}\n",
      "0.782 (+/-0.114) for {'bootstrap': False, 'criterion': 'entropy', 'min_samples_split': 2, 'n_estimators': 140, 'warm_start': True}\n",
      "0.784 (+/-0.120) for {'bootstrap': False, 'criterion': 'entropy', 'min_samples_split': 2, 'n_estimators': 140, 'warm_start': False}\n",
      "0.782 (+/-0.130) for {'bootstrap': False, 'criterion': 'entropy', 'min_samples_split': 2, 'n_estimators': 160, 'warm_start': True}\n",
      "0.778 (+/-0.127) for {'bootstrap': False, 'criterion': 'entropy', 'min_samples_split': 2, 'n_estimators': 160, 'warm_start': False}\n",
      "0.782 (+/-0.129) for {'bootstrap': False, 'criterion': 'entropy', 'min_samples_split': 2, 'n_estimators': 180, 'warm_start': True}\n",
      "0.785 (+/-0.123) for {'bootstrap': False, 'criterion': 'entropy', 'min_samples_split': 2, 'n_estimators': 180, 'warm_start': False}\n",
      "0.781 (+/-0.132) for {'bootstrap': False, 'criterion': 'entropy', 'min_samples_split': 2, 'n_estimators': 200, 'warm_start': True}\n",
      "0.781 (+/-0.125) for {'bootstrap': False, 'criterion': 'entropy', 'min_samples_split': 2, 'n_estimators': 200, 'warm_start': False}\n",
      "0.791 (+/-0.108) for {'bootstrap': False, 'criterion': 'entropy', 'min_samples_split': 3, 'n_estimators': 60, 'warm_start': True}\n",
      "0.789 (+/-0.122) for {'bootstrap': False, 'criterion': 'entropy', 'min_samples_split': 3, 'n_estimators': 60, 'warm_start': False}\n",
      "0.789 (+/-0.111) for {'bootstrap': False, 'criterion': 'entropy', 'min_samples_split': 3, 'n_estimators': 70, 'warm_start': True}\n",
      "0.794 (+/-0.103) for {'bootstrap': False, 'criterion': 'entropy', 'min_samples_split': 3, 'n_estimators': 70, 'warm_start': False}\n",
      "0.794 (+/-0.107) for {'bootstrap': False, 'criterion': 'entropy', 'min_samples_split': 3, 'n_estimators': 80, 'warm_start': True}\n",
      "0.789 (+/-0.108) for {'bootstrap': False, 'criterion': 'entropy', 'min_samples_split': 3, 'n_estimators': 80, 'warm_start': False}\n",
      "0.794 (+/-0.108) for {'bootstrap': False, 'criterion': 'entropy', 'min_samples_split': 3, 'n_estimators': 90, 'warm_start': True}\n",
      "0.788 (+/-0.116) for {'bootstrap': False, 'criterion': 'entropy', 'min_samples_split': 3, 'n_estimators': 90, 'warm_start': False}\n",
      "0.792 (+/-0.121) for {'bootstrap': False, 'criterion': 'entropy', 'min_samples_split': 3, 'n_estimators': 100, 'warm_start': True}\n",
      "0.792 (+/-0.098) for {'bootstrap': False, 'criterion': 'entropy', 'min_samples_split': 3, 'n_estimators': 100, 'warm_start': False}\n",
      "0.791 (+/-0.115) for {'bootstrap': False, 'criterion': 'entropy', 'min_samples_split': 3, 'n_estimators': 120, 'warm_start': True}\n",
      "0.782 (+/-0.131) for {'bootstrap': False, 'criterion': 'entropy', 'min_samples_split': 3, 'n_estimators': 120, 'warm_start': False}\n",
      "0.787 (+/-0.121) for {'bootstrap': False, 'criterion': 'entropy', 'min_samples_split': 3, 'n_estimators': 140, 'warm_start': True}\n",
      "0.794 (+/-0.111) for {'bootstrap': False, 'criterion': 'entropy', 'min_samples_split': 3, 'n_estimators': 140, 'warm_start': False}\n",
      "0.788 (+/-0.121) for {'bootstrap': False, 'criterion': 'entropy', 'min_samples_split': 3, 'n_estimators': 160, 'warm_start': True}\n",
      "0.788 (+/-0.129) for {'bootstrap': False, 'criterion': 'entropy', 'min_samples_split': 3, 'n_estimators': 160, 'warm_start': False}\n",
      "0.792 (+/-0.107) for {'bootstrap': False, 'criterion': 'entropy', 'min_samples_split': 3, 'n_estimators': 180, 'warm_start': True}\n",
      "0.792 (+/-0.115) for {'bootstrap': False, 'criterion': 'entropy', 'min_samples_split': 3, 'n_estimators': 180, 'warm_start': False}\n",
      "0.788 (+/-0.117) for {'bootstrap': False, 'criterion': 'entropy', 'min_samples_split': 3, 'n_estimators': 200, 'warm_start': True}\n",
      "0.788 (+/-0.125) for {'bootstrap': False, 'criterion': 'entropy', 'min_samples_split': 3, 'n_estimators': 200, 'warm_start': False}\n",
      "0.785 (+/-0.119) for {'bootstrap': False, 'criterion': 'entropy', 'min_samples_split': 4, 'n_estimators': 60, 'warm_start': True}\n",
      "0.798 (+/-0.118) for {'bootstrap': False, 'criterion': 'entropy', 'min_samples_split': 4, 'n_estimators': 60, 'warm_start': False}\n",
      "0.791 (+/-0.112) for {'bootstrap': False, 'criterion': 'entropy', 'min_samples_split': 4, 'n_estimators': 70, 'warm_start': True}\n",
      "0.802 (+/-0.106) for {'bootstrap': False, 'criterion': 'entropy', 'min_samples_split': 4, 'n_estimators': 70, 'warm_start': False}\n",
      "0.792 (+/-0.121) for {'bootstrap': False, 'criterion': 'entropy', 'min_samples_split': 4, 'n_estimators': 80, 'warm_start': True}\n",
      "0.792 (+/-0.099) for {'bootstrap': False, 'criterion': 'entropy', 'min_samples_split': 4, 'n_estimators': 80, 'warm_start': False}\n",
      "0.789 (+/-0.112) for {'bootstrap': False, 'criterion': 'entropy', 'min_samples_split': 4, 'n_estimators': 90, 'warm_start': True}\n",
      "0.801 (+/-0.108) for {'bootstrap': False, 'criterion': 'entropy', 'min_samples_split': 4, 'n_estimators': 90, 'warm_start': False}\n",
      "0.798 (+/-0.107) for {'bootstrap': False, 'criterion': 'entropy', 'min_samples_split': 4, 'n_estimators': 100, 'warm_start': True}\n",
      "0.798 (+/-0.109) for {'bootstrap': False, 'criterion': 'entropy', 'min_samples_split': 4, 'n_estimators': 100, 'warm_start': False}\n",
      "0.791 (+/-0.125) for {'bootstrap': False, 'criterion': 'entropy', 'min_samples_split': 4, 'n_estimators': 120, 'warm_start': True}\n",
      "0.791 (+/-0.103) for {'bootstrap': False, 'criterion': 'entropy', 'min_samples_split': 4, 'n_estimators': 120, 'warm_start': False}\n",
      "0.796 (+/-0.100) for {'bootstrap': False, 'criterion': 'entropy', 'min_samples_split': 4, 'n_estimators': 140, 'warm_start': True}\n",
      "0.799 (+/-0.115) for {'bootstrap': False, 'criterion': 'entropy', 'min_samples_split': 4, 'n_estimators': 140, 'warm_start': False}\n",
      "0.801 (+/-0.102) for {'bootstrap': False, 'criterion': 'entropy', 'min_samples_split': 4, 'n_estimators': 160, 'warm_start': True}\n",
      "0.795 (+/-0.123) for {'bootstrap': False, 'criterion': 'entropy', 'min_samples_split': 4, 'n_estimators': 160, 'warm_start': False}\n",
      "0.802 (+/-0.105) for {'bootstrap': False, 'criterion': 'entropy', 'min_samples_split': 4, 'n_estimators': 180, 'warm_start': True}\n",
      "0.789 (+/-0.127) for {'bootstrap': False, 'criterion': 'entropy', 'min_samples_split': 4, 'n_estimators': 180, 'warm_start': False}\n",
      "0.801 (+/-0.113) for {'bootstrap': False, 'criterion': 'entropy', 'min_samples_split': 4, 'n_estimators': 200, 'warm_start': True}\n",
      "0.795 (+/-0.104) for {'bootstrap': False, 'criterion': 'entropy', 'min_samples_split': 4, 'n_estimators': 200, 'warm_start': False}\n",
      "0.808 (+/-0.104) for {'bootstrap': False, 'criterion': 'entropy', 'min_samples_split': 5, 'n_estimators': 60, 'warm_start': True}\n",
      "0.808 (+/-0.090) for {'bootstrap': False, 'criterion': 'entropy', 'min_samples_split': 5, 'n_estimators': 60, 'warm_start': False}\n",
      "0.802 (+/-0.105) for {'bootstrap': False, 'criterion': 'entropy', 'min_samples_split': 5, 'n_estimators': 70, 'warm_start': True}\n",
      "0.809 (+/-0.093) for {'bootstrap': False, 'criterion': 'entropy', 'min_samples_split': 5, 'n_estimators': 70, 'warm_start': False}\n",
      "0.813 (+/-0.093) for {'bootstrap': False, 'criterion': 'entropy', 'min_samples_split': 5, 'n_estimators': 80, 'warm_start': True}\n",
      "0.809 (+/-0.108) for {'bootstrap': False, 'criterion': 'entropy', 'min_samples_split': 5, 'n_estimators': 80, 'warm_start': False}\n",
      "0.808 (+/-0.091) for {'bootstrap': False, 'criterion': 'entropy', 'min_samples_split': 5, 'n_estimators': 90, 'warm_start': True}\n",
      "0.808 (+/-0.098) for {'bootstrap': False, 'criterion': 'entropy', 'min_samples_split': 5, 'n_estimators': 90, 'warm_start': False}\n",
      "0.812 (+/-0.097) for {'bootstrap': False, 'criterion': 'entropy', 'min_samples_split': 5, 'n_estimators': 100, 'warm_start': True}\n",
      "0.809 (+/-0.111) for {'bootstrap': False, 'criterion': 'entropy', 'min_samples_split': 5, 'n_estimators': 100, 'warm_start': False}\n",
      "0.812 (+/-0.098) for {'bootstrap': False, 'criterion': 'entropy', 'min_samples_split': 5, 'n_estimators': 120, 'warm_start': True}\n",
      "0.810 (+/-0.101) for {'bootstrap': False, 'criterion': 'entropy', 'min_samples_split': 5, 'n_estimators': 120, 'warm_start': False}\n",
      "0.812 (+/-0.097) for {'bootstrap': False, 'criterion': 'entropy', 'min_samples_split': 5, 'n_estimators': 140, 'warm_start': True}\n",
      "0.810 (+/-0.094) for {'bootstrap': False, 'criterion': 'entropy', 'min_samples_split': 5, 'n_estimators': 140, 'warm_start': False}\n",
      "0.811 (+/-0.112) for {'bootstrap': False, 'criterion': 'entropy', 'min_samples_split': 5, 'n_estimators': 160, 'warm_start': True}\n",
      "0.809 (+/-0.092) for {'bootstrap': False, 'criterion': 'entropy', 'min_samples_split': 5, 'n_estimators': 160, 'warm_start': False}\n",
      "0.809 (+/-0.106) for {'bootstrap': False, 'criterion': 'entropy', 'min_samples_split': 5, 'n_estimators': 180, 'warm_start': True}\n",
      "0.809 (+/-0.106) for {'bootstrap': False, 'criterion': 'entropy', 'min_samples_split': 5, 'n_estimators': 180, 'warm_start': False}\n",
      "0.806 (+/-0.101) for {'bootstrap': False, 'criterion': 'entropy', 'min_samples_split': 5, 'n_estimators': 200, 'warm_start': True}\n",
      "0.815 (+/-0.089) for {'bootstrap': False, 'criterion': 'entropy', 'min_samples_split': 5, 'n_estimators': 200, 'warm_start': False}\n",
      "0.812 (+/-0.108) for {'bootstrap': False, 'criterion': 'entropy', 'min_samples_split': 6, 'n_estimators': 60, 'warm_start': True}\n",
      "0.812 (+/-0.096) for {'bootstrap': False, 'criterion': 'entropy', 'min_samples_split': 6, 'n_estimators': 60, 'warm_start': False}\n",
      "0.812 (+/-0.097) for {'bootstrap': False, 'criterion': 'entropy', 'min_samples_split': 6, 'n_estimators': 70, 'warm_start': True}\n",
      "0.822 (+/-0.092) for {'bootstrap': False, 'criterion': 'entropy', 'min_samples_split': 6, 'n_estimators': 70, 'warm_start': False}\n",
      "0.815 (+/-0.089) for {'bootstrap': False, 'criterion': 'entropy', 'min_samples_split': 6, 'n_estimators': 80, 'warm_start': True}\n",
      "0.820 (+/-0.101) for {'bootstrap': False, 'criterion': 'entropy', 'min_samples_split': 6, 'n_estimators': 80, 'warm_start': False}\n",
      "0.813 (+/-0.091) for {'bootstrap': False, 'criterion': 'entropy', 'min_samples_split': 6, 'n_estimators': 90, 'warm_start': True}\n",
      "0.813 (+/-0.094) for {'bootstrap': False, 'criterion': 'entropy', 'min_samples_split': 6, 'n_estimators': 90, 'warm_start': False}\n",
      "0.823 (+/-0.088) for {'bootstrap': False, 'criterion': 'entropy', 'min_samples_split': 6, 'n_estimators': 100, 'warm_start': True}\n",
      "0.820 (+/-0.090) for {'bootstrap': False, 'criterion': 'entropy', 'min_samples_split': 6, 'n_estimators': 100, 'warm_start': False}\n",
      "0.812 (+/-0.084) for {'bootstrap': False, 'criterion': 'entropy', 'min_samples_split': 6, 'n_estimators': 120, 'warm_start': True}\n",
      "0.815 (+/-0.096) for {'bootstrap': False, 'criterion': 'entropy', 'min_samples_split': 6, 'n_estimators': 120, 'warm_start': False}\n",
      "0.813 (+/-0.099) for {'bootstrap': False, 'criterion': 'entropy', 'min_samples_split': 6, 'n_estimators': 140, 'warm_start': True}\n",
      "0.815 (+/-0.098) for {'bootstrap': False, 'criterion': 'entropy', 'min_samples_split': 6, 'n_estimators': 140, 'warm_start': False}\n",
      "0.816 (+/-0.091) for {'bootstrap': False, 'criterion': 'entropy', 'min_samples_split': 6, 'n_estimators': 160, 'warm_start': True}\n",
      "0.810 (+/-0.110) for {'bootstrap': False, 'criterion': 'entropy', 'min_samples_split': 6, 'n_estimators': 160, 'warm_start': False}\n",
      "0.815 (+/-0.095) for {'bootstrap': False, 'criterion': 'entropy', 'min_samples_split': 6, 'n_estimators': 180, 'warm_start': True}\n",
      "0.813 (+/-0.087) for {'bootstrap': False, 'criterion': 'entropy', 'min_samples_split': 6, 'n_estimators': 180, 'warm_start': False}\n",
      "0.806 (+/-0.105) for {'bootstrap': False, 'criterion': 'entropy', 'min_samples_split': 6, 'n_estimators': 200, 'warm_start': True}\n",
      "0.812 (+/-0.095) for {'bootstrap': False, 'criterion': 'entropy', 'min_samples_split': 6, 'n_estimators': 200, 'warm_start': False}\n",
      "0.815 (+/-0.096) for {'bootstrap': False, 'criterion': 'entropy', 'min_samples_split': 7, 'n_estimators': 60, 'warm_start': True}\n",
      "0.823 (+/-0.091) for {'bootstrap': False, 'criterion': 'entropy', 'min_samples_split': 7, 'n_estimators': 60, 'warm_start': False}\n",
      "0.812 (+/-0.104) for {'bootstrap': False, 'criterion': 'entropy', 'min_samples_split': 7, 'n_estimators': 70, 'warm_start': True}\n",
      "0.813 (+/-0.107) for {'bootstrap': False, 'criterion': 'entropy', 'min_samples_split': 7, 'n_estimators': 70, 'warm_start': False}\n",
      "0.820 (+/-0.093) for {'bootstrap': False, 'criterion': 'entropy', 'min_samples_split': 7, 'n_estimators': 80, 'warm_start': True}\n",
      "0.813 (+/-0.097) for {'bootstrap': False, 'criterion': 'entropy', 'min_samples_split': 7, 'n_estimators': 80, 'warm_start': False}\n",
      "0.822 (+/-0.092) for {'bootstrap': False, 'criterion': 'entropy', 'min_samples_split': 7, 'n_estimators': 90, 'warm_start': True}\n",
      "0.818 (+/-0.094) for {'bootstrap': False, 'criterion': 'entropy', 'min_samples_split': 7, 'n_estimators': 90, 'warm_start': False}\n",
      "0.815 (+/-0.099) for {'bootstrap': False, 'criterion': 'entropy', 'min_samples_split': 7, 'n_estimators': 100, 'warm_start': True}\n",
      "0.818 (+/-0.096) for {'bootstrap': False, 'criterion': 'entropy', 'min_samples_split': 7, 'n_estimators': 100, 'warm_start': False}\n",
      "0.823 (+/-0.095) for {'bootstrap': False, 'criterion': 'entropy', 'min_samples_split': 7, 'n_estimators': 120, 'warm_start': True}\n",
      "0.820 (+/-0.088) for {'bootstrap': False, 'criterion': 'entropy', 'min_samples_split': 7, 'n_estimators': 120, 'warm_start': False}\n",
      "0.815 (+/-0.098) for {'bootstrap': False, 'criterion': 'entropy', 'min_samples_split': 7, 'n_estimators': 140, 'warm_start': True}\n",
      "0.817 (+/-0.093) for {'bootstrap': False, 'criterion': 'entropy', 'min_samples_split': 7, 'n_estimators': 140, 'warm_start': False}\n",
      "0.816 (+/-0.096) for {'bootstrap': False, 'criterion': 'entropy', 'min_samples_split': 7, 'n_estimators': 160, 'warm_start': True}\n",
      "0.820 (+/-0.092) for {'bootstrap': False, 'criterion': 'entropy', 'min_samples_split': 7, 'n_estimators': 160, 'warm_start': False}\n",
      "0.820 (+/-0.096) for {'bootstrap': False, 'criterion': 'entropy', 'min_samples_split': 7, 'n_estimators': 180, 'warm_start': True}\n",
      "0.819 (+/-0.086) for {'bootstrap': False, 'criterion': 'entropy', 'min_samples_split': 7, 'n_estimators': 180, 'warm_start': False}\n",
      "0.815 (+/-0.089) for {'bootstrap': False, 'criterion': 'entropy', 'min_samples_split': 7, 'n_estimators': 200, 'warm_start': True}\n",
      "0.819 (+/-0.102) for {'bootstrap': False, 'criterion': 'entropy', 'min_samples_split': 7, 'n_estimators': 200, 'warm_start': False}\n",
      "0.822 (+/-0.092) for {'bootstrap': False, 'criterion': 'entropy', 'min_samples_split': 8, 'n_estimators': 60, 'warm_start': True}\n",
      "0.817 (+/-0.090) for {'bootstrap': False, 'criterion': 'entropy', 'min_samples_split': 8, 'n_estimators': 60, 'warm_start': False}\n",
      "0.818 (+/-0.096) for {'bootstrap': False, 'criterion': 'entropy', 'min_samples_split': 8, 'n_estimators': 70, 'warm_start': True}\n",
      "0.820 (+/-0.097) for {'bootstrap': False, 'criterion': 'entropy', 'min_samples_split': 8, 'n_estimators': 70, 'warm_start': False}\n",
      "0.816 (+/-0.093) for {'bootstrap': False, 'criterion': 'entropy', 'min_samples_split': 8, 'n_estimators': 80, 'warm_start': True}\n",
      "0.823 (+/-0.081) for {'bootstrap': False, 'criterion': 'entropy', 'min_samples_split': 8, 'n_estimators': 80, 'warm_start': False}\n",
      "0.826 (+/-0.086) for {'bootstrap': False, 'criterion': 'entropy', 'min_samples_split': 8, 'n_estimators': 90, 'warm_start': True}\n",
      "0.818 (+/-0.093) for {'bootstrap': False, 'criterion': 'entropy', 'min_samples_split': 8, 'n_estimators': 90, 'warm_start': False}\n",
      "0.819 (+/-0.086) for {'bootstrap': False, 'criterion': 'entropy', 'min_samples_split': 8, 'n_estimators': 100, 'warm_start': True}\n",
      "0.825 (+/-0.088) for {'bootstrap': False, 'criterion': 'entropy', 'min_samples_split': 8, 'n_estimators': 100, 'warm_start': False}\n",
      "0.819 (+/-0.090) for {'bootstrap': False, 'criterion': 'entropy', 'min_samples_split': 8, 'n_estimators': 120, 'warm_start': True}\n",
      "0.829 (+/-0.067) for {'bootstrap': False, 'criterion': 'entropy', 'min_samples_split': 8, 'n_estimators': 120, 'warm_start': False}\n",
      "0.823 (+/-0.088) for {'bootstrap': False, 'criterion': 'entropy', 'min_samples_split': 8, 'n_estimators': 140, 'warm_start': True}\n",
      "0.826 (+/-0.078) for {'bootstrap': False, 'criterion': 'entropy', 'min_samples_split': 8, 'n_estimators': 140, 'warm_start': False}\n",
      "0.817 (+/-0.087) for {'bootstrap': False, 'criterion': 'entropy', 'min_samples_split': 8, 'n_estimators': 160, 'warm_start': True}\n",
      "0.822 (+/-0.083) for {'bootstrap': False, 'criterion': 'entropy', 'min_samples_split': 8, 'n_estimators': 160, 'warm_start': False}\n",
      "0.818 (+/-0.101) for {'bootstrap': False, 'criterion': 'entropy', 'min_samples_split': 8, 'n_estimators': 180, 'warm_start': True}\n",
      "0.823 (+/-0.088) for {'bootstrap': False, 'criterion': 'entropy', 'min_samples_split': 8, 'n_estimators': 180, 'warm_start': False}\n",
      "0.823 (+/-0.086) for {'bootstrap': False, 'criterion': 'entropy', 'min_samples_split': 8, 'n_estimators': 200, 'warm_start': True}\n",
      "0.820 (+/-0.089) for {'bootstrap': False, 'criterion': 'entropy', 'min_samples_split': 8, 'n_estimators': 200, 'warm_start': False}\n",
      "0.825 (+/-0.086) for {'bootstrap': False, 'criterion': 'entropy', 'min_samples_split': 9, 'n_estimators': 60, 'warm_start': True}\n",
      "0.816 (+/-0.075) for {'bootstrap': False, 'criterion': 'entropy', 'min_samples_split': 9, 'n_estimators': 60, 'warm_start': False}\n",
      "0.819 (+/-0.085) for {'bootstrap': False, 'criterion': 'entropy', 'min_samples_split': 9, 'n_estimators': 70, 'warm_start': True}\n",
      "0.826 (+/-0.081) for {'bootstrap': False, 'criterion': 'entropy', 'min_samples_split': 9, 'n_estimators': 70, 'warm_start': False}\n",
      "0.824 (+/-0.078) for {'bootstrap': False, 'criterion': 'entropy', 'min_samples_split': 9, 'n_estimators': 80, 'warm_start': True}\n",
      "0.825 (+/-0.080) for {'bootstrap': False, 'criterion': 'entropy', 'min_samples_split': 9, 'n_estimators': 80, 'warm_start': False}\n",
      "0.825 (+/-0.083) for {'bootstrap': False, 'criterion': 'entropy', 'min_samples_split': 9, 'n_estimators': 90, 'warm_start': True}\n",
      "0.820 (+/-0.089) for {'bootstrap': False, 'criterion': 'entropy', 'min_samples_split': 9, 'n_estimators': 90, 'warm_start': False}\n",
      "0.822 (+/-0.086) for {'bootstrap': False, 'criterion': 'entropy', 'min_samples_split': 9, 'n_estimators': 100, 'warm_start': True}\n",
      "0.820 (+/-0.088) for {'bootstrap': False, 'criterion': 'entropy', 'min_samples_split': 9, 'n_estimators': 100, 'warm_start': False}\n",
      "0.817 (+/-0.093) for {'bootstrap': False, 'criterion': 'entropy', 'min_samples_split': 9, 'n_estimators': 120, 'warm_start': True}\n",
      "0.820 (+/-0.091) for {'bootstrap': False, 'criterion': 'entropy', 'min_samples_split': 9, 'n_estimators': 120, 'warm_start': False}\n",
      "0.822 (+/-0.087) for {'bootstrap': False, 'criterion': 'entropy', 'min_samples_split': 9, 'n_estimators': 140, 'warm_start': True}\n",
      "0.825 (+/-0.084) for {'bootstrap': False, 'criterion': 'entropy', 'min_samples_split': 9, 'n_estimators': 140, 'warm_start': False}\n",
      "0.825 (+/-0.084) for {'bootstrap': False, 'criterion': 'entropy', 'min_samples_split': 9, 'n_estimators': 160, 'warm_start': True}\n",
      "0.829 (+/-0.089) for {'bootstrap': False, 'criterion': 'entropy', 'min_samples_split': 9, 'n_estimators': 160, 'warm_start': False}\n",
      "0.822 (+/-0.090) for {'bootstrap': False, 'criterion': 'entropy', 'min_samples_split': 9, 'n_estimators': 180, 'warm_start': True}\n",
      "0.823 (+/-0.090) for {'bootstrap': False, 'criterion': 'entropy', 'min_samples_split': 9, 'n_estimators': 180, 'warm_start': False}\n",
      "0.825 (+/-0.083) for {'bootstrap': False, 'criterion': 'entropy', 'min_samples_split': 9, 'n_estimators': 200, 'warm_start': True}\n",
      "0.822 (+/-0.086) for {'bootstrap': False, 'criterion': 'entropy', 'min_samples_split': 9, 'n_estimators': 200, 'warm_start': False}\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.88      0.90      0.89       114\n",
      "         1.0       0.82      0.78      0.80        64\n",
      "\n",
      "    accuracy                           0.86       178\n",
      "   macro avg       0.85      0.84      0.85       178\n",
      "weighted avg       0.86      0.86      0.86       178\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "tuned_parameters = [{ 'n_estimators':[60,70,80,90,100,120,140,160,180,200], 'criterion':['gini','entropy'],\n",
    "      'warm_start':[True, False], 'bootstrap':[True, False],'min_samples_split':[2,3,4,5,6,7,8,9]}\n",
    "                    ]\n",
    "\n",
    "\n",
    "print()\n",
    "\n",
    "clf = GridSearchCV(\n",
    "    RandomForestClassifier(), tuned_parameters, scoring='accuracy', cv=10\n",
    ")\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best parameters set found on development set:\")\n",
    "print()\n",
    "print(clf.best_params_)\n",
    "print()\n",
    "print(\"Grid scores on development set:\")\n",
    "print()\n",
    "means = clf.cv_results_['mean_test_score']\n",
    "stds = clf.cv_results_['std_test_score']\n",
    "for mean, std, params in zip(means, stds, clf.cv_results_['params']):\n",
    "    print(\"%0.3f (+/-%0.03f) for %r\"\n",
    "          % (mean, std * 2, params))\n",
    "print()\n",
    "\n",
    "print(\"Detailed classification report:\")\n",
    "print()\n",
    "print(\"The model is trained on the full development set.\")\n",
    "print(\"The scores are computed on the full evaluation set.\")\n",
    "print()\n",
    "y_true, y_pred = y_test, clf.predict(X_test)\n",
    "print(classification_report(y_true, y_pred))\n",
    "print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8wNpUvSRTwVl"
   },
   "source": [
    "### Cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "wW3nAhoYS0Yg",
    "outputId": "b1faf670-9c67-407a-cfb9-97228ff84da6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.835069\n"
     ]
    }
   ],
   "source": [
    "clf = RandomForestClassifier(bootstrap= True, criterion= 'gini', min_samples_split= 8, n_estimators= 180, warm_start= False)\n",
    "score=cross_validate(clf, X, y, cv=10, scoring=\"accuracy\")[\"test_score\"].mean()\n",
    "print(f\"{score:.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "p6z2PsaYMo4v"
   },
   "source": [
    "### Generating Predicion Result for submission in .csv format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VxWUIGMIvY7k"
   },
   "outputs": [],
   "source": [
    "df2 = pd.read_csv(url2)\n",
    "clf = RandomForestClassifier(bootstrap= True, criterion= 'gini', min_samples_split= 8, n_estimators= 180, warm_start= False)\n",
    "clf.fit(X, y)\n",
    "pred=clf.predict(X_test2)\n",
    "pd.DataFrame({\"PassengerId\": df2[\"PassengerId\"], \"Survived\": pred}).to_csv(\"RandomForestClassifier_submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FOJEYnfyCM0L"
   },
   "source": [
    "![alt text](https://raw.githubusercontent.com/zyzhang1130/CE9010/master/Titanic/RandomForest.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "csM_ArJuXjLr"
   },
   "source": [
    "## XGBoost Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "n39Lrvs8Xyu4"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 679
    },
    "colab_type": "code",
    "id": "TVyKTASLX5i-",
    "outputId": "8b1b1006-6f1d-4eed-e069-5258e108ad98"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_search.py:823: FutureWarning:\n",
      "\n",
      "The parameter 'iid' is deprecated in 0.22 and will be removed in 0.24.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "coss validation results {'mean_fit_time': array([0.41868615, 0.42174573, 0.4636878 , 0.70192904, 0.67201667,\n",
      "       0.61961665, 0.93390512, 0.80480742, 0.70481453, 1.08129082,\n",
      "       0.86310353, 0.63918233]), 'std_fit_time': array([0.02233087, 0.01785338, 0.01080505, 0.02454552, 0.02674497,\n",
      "       0.0341387 , 0.15101574, 0.07040121, 0.15885518, 0.12221958,\n",
      "       0.05393578, 0.07546581]), 'mean_score_time': array([0.02239423, 0.00688744, 0.00698676, 0.01178517, 0.01662512,\n",
      "       0.00748129, 0.00846801, 0.00689321, 0.00783014, 0.00812707,\n",
      "       0.01432238, 0.0042695 ]), 'std_score_time': array([0.0074922 , 0.00096934, 0.00283873, 0.00715047, 0.0030997 ,\n",
      "       0.00223604, 0.00185373, 0.00198884, 0.00223366, 0.00219941,\n",
      "       0.00523321, 0.00135888]), 'param_max_depth': masked_array(data=[3, 3, 3, 5, 5, 5, 7, 7, 7, 9, 9, 9],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'param_min_child_weight': masked_array(data=[1, 3, 5, 1, 3, 5, 1, 3, 5, 1, 3, 5],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'params': [{'max_depth': 3, 'min_child_weight': 1}, {'max_depth': 3, 'min_child_weight': 3}, {'max_depth': 3, 'min_child_weight': 5}, {'max_depth': 5, 'min_child_weight': 1}, {'max_depth': 5, 'min_child_weight': 3}, {'max_depth': 5, 'min_child_weight': 5}, {'max_depth': 7, 'min_child_weight': 1}, {'max_depth': 7, 'min_child_weight': 3}, {'max_depth': 7, 'min_child_weight': 5}, {'max_depth': 9, 'min_child_weight': 1}, {'max_depth': 9, 'min_child_weight': 3}, {'max_depth': 9, 'min_child_weight': 5}], 'split0_test_score': array([0.82953612, 0.82697044, 0.82122332, 0.84020936, 0.82614943,\n",
      "       0.83025452, 0.84000411, 0.84195402, 0.83210181, 0.84554598,\n",
      "       0.8452381 , 0.82984401]), 'split1_test_score': array([0.79505337, 0.80593186, 0.8102422 , 0.7944376 , 0.80131363,\n",
      "       0.80613711, 0.78807471, 0.79618227, 0.80654762, 0.78602217,\n",
      "       0.79833744, 0.80839491]), 'split2_test_score': array([0.91191223, 0.90992685, 0.90532915, 0.91410658, 0.90950888,\n",
      "       0.90365726, 0.90950888, 0.91473354, 0.90888192, 0.90595611,\n",
      "       0.91347962, 0.90741902]), 'split3_test_score': array([0.85057471, 0.86081505, 0.86792059, 0.84597701, 0.8539185 ,\n",
      "       0.86886102, 0.85141066, 0.85579937, 0.86091954, 0.84806688,\n",
      "       0.86060606, 0.86363636]), 'split4_test_score': array([0.85496262, 0.8674211 , 0.87406561, 0.85454734, 0.87385797,\n",
      "       0.87531146, 0.85371678, 0.87655731, 0.8744809 , 0.84644934,\n",
      "       0.87697259, 0.87323505]), 'mean_test_score': array([0.84840781, 0.85421306, 0.85575617, 0.84985558, 0.85294968,\n",
      "       0.85684427, 0.84854303, 0.8570453 , 0.85658636, 0.84640809,\n",
      "       0.85892676, 0.85650587]), 'std_test_score': array([0.03816624, 0.03576395, 0.03522706, 0.03828694, 0.03747419,\n",
      "       0.03451124, 0.03868115, 0.03909542, 0.03514879, 0.03793659,\n",
      "       0.03784952, 0.03449167]), 'rank_test_score': array([11,  7,  6,  9,  8,  3, 10,  2,  4, 12,  1,  5], dtype=int32)}\n",
      "best parameters {'max_depth': 9, 'min_child_weight': 3}\n",
      "best score 0.8589267618908758\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "model = XGBClassifier(learning_rate =0.1,\n",
    " n_estimators=1000,\n",
    " max_depth=10,\n",
    " min_child_weight=3,\n",
    " gamma=0,\n",
    " subsample=0.8,\n",
    " colsample_bytree=0.8,\n",
    " objective= 'binary:logistic',\n",
    " nthread=4,\n",
    " scale_pos_weight=1,\n",
    " seed=27)\n",
    "\n",
    "param_test1 = {\n",
    " 'max_depth':range(3,10,2),\n",
    " 'min_child_weight':range(1,6,2)\n",
    "}\n",
    "gsearch1 = GridSearchCV(estimator = XGBClassifier( learning_rate =0.1, n_estimators=140, max_depth=5,\n",
    " min_child_weight=1, gamma=0, subsample=0.8, colsample_bytree=0.8,\n",
    " objective= 'binary:logistic', nthread=4, scale_pos_weight=1, seed=27), \n",
    " param_grid = param_test1, scoring='roc_auc',n_jobs=4,iid=False, cv=5)\n",
    "gsearch1.fit(X_train,y_train)\n",
    "print('coss validation results',gsearch1.cv_results_ )\n",
    "print()\n",
    "print('best parameters',gsearch1.best_params_)\n",
    "print()\n",
    "print('best score',gsearch1.best_score_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 523
    },
    "colab_type": "code",
    "id": "Tjp3OVed6mjg",
    "outputId": "1cefd4af-dbd1-48cd-d6df-2b507d234e4d"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_search.py:823: FutureWarning:\n",
      "\n",
      "The parameter 'iid' is deprecated in 0.22 and will be removed in 0.24.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "coss validation results {'mean_fit_time': array([0.92014089, 0.87254848, 0.77533321, 0.97191906, 0.86867752,\n",
      "       0.76766458, 1.01229377, 0.85765433, 0.64589429]), 'std_fit_time': array([0.04079175, 0.03909655, 0.03449356, 0.0732732 , 0.02433322,\n",
      "       0.1217465 , 0.04318948, 0.01926955, 0.10747002]), 'mean_score_time': array([0.01254563, 0.01127682, 0.01024442, 0.00755224, 0.01465964,\n",
      "       0.00669146, 0.00992737, 0.01069221, 0.00542397]), 'std_score_time': array([0.00605097, 0.00665723, 0.00527317, 0.00276047, 0.0068149 ,\n",
      "       0.00181474, 0.00281513, 0.00507771, 0.00243942]), 'param_max_depth': masked_array(data=[8, 8, 8, 9, 9, 9, 10, 10, 10],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'param_min_child_weight': masked_array(data=[2, 3, 4, 2, 3, 4, 2, 3, 4],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'params': [{'max_depth': 8, 'min_child_weight': 2}, {'max_depth': 8, 'min_child_weight': 3}, {'max_depth': 8, 'min_child_weight': 4}, {'max_depth': 9, 'min_child_weight': 2}, {'max_depth': 9, 'min_child_weight': 3}, {'max_depth': 9, 'min_child_weight': 4}, {'max_depth': 10, 'min_child_weight': 2}, {'max_depth': 10, 'min_child_weight': 3}, {'max_depth': 10, 'min_child_weight': 4}], 'split0_test_score': array([0.83682266, 0.84585386, 0.82758621, 0.83682266, 0.8452381 ,\n",
      "       0.8316913 , 0.84154351, 0.83990148, 0.8316913 ]), 'split1_test_score': array([0.80100575, 0.79269294, 0.8034688 , 0.80038998, 0.79833744,\n",
      "       0.80470033, 0.80141626, 0.79772167, 0.79874795]), 'split2_test_score': array([0.907628  , 0.91347962, 0.9092999 , 0.91264368, 0.91347962,\n",
      "       0.90658307, 0.91577847, 0.90804598, 0.90658307]), 'split3_test_score': array([0.85329154, 0.86018809, 0.85705329, 0.85809822, 0.86060606,\n",
      "       0.85663532, 0.85412748, 0.86123302, 0.85788924]), 'split4_test_score': array([0.8674211 , 0.87967193, 0.87219684, 0.86077658, 0.87697259,\n",
      "       0.87468854, 0.86783638, 0.87967193, 0.87406561]), 'mean_test_score': array([0.85323381, 0.85837729, 0.85392101, 0.85374622, 0.85892676,\n",
      "       0.85485971, 0.85614042, 0.85731482, 0.85379543]), 'std_test_score': array([0.03509161, 0.0399106 , 0.03646803, 0.03652553, 0.03784952,\n",
      "       0.03499823, 0.03716275, 0.03726502, 0.03669603]), 'rank_test_score': array([9, 2, 6, 8, 1, 5, 4, 3, 7], dtype=int32)}\n",
      "\n",
      "best parameters {'max_depth': 9, 'min_child_weight': 3}\n",
      "\n",
      "best score 0.8589267618908758\n"
     ]
    }
   ],
   "source": [
    "param_test2 = {\n",
    " 'max_depth':[8,9,10],\n",
    " 'min_child_weight':[2,3,4]\n",
    "}\n",
    "gsearch2 = GridSearchCV(estimator = XGBClassifier( learning_rate=0.1, n_estimators=140, max_depth=5,\n",
    " min_child_weight=2, gamma=0, subsample=0.8, colsample_bytree=0.8,\n",
    " objective= 'binary:logistic', nthread=4, scale_pos_weight=1,seed=27), \n",
    " param_grid = param_test2, scoring='roc_auc',n_jobs=4,iid=False, cv=5)\n",
    "gsearch2.fit(X_train,y_train)\n",
    "print('coss validation results',gsearch2.cv_results_ )\n",
    "print()\n",
    "print('best parameters',gsearch2.best_params_)\n",
    "print()\n",
    "print('best score',gsearch2.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "11T0GWcxT0kc"
   },
   "source": [
    "### Cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "FSBu6ghHTCcD",
    "outputId": "6274cf88-4b43-4aee-c321-8cfa8a229ff1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.804732\n"
     ]
    }
   ],
   "source": [
    "clf = XGBClassifier(learning_rate =0.1,\n",
    " n_estimators=1000,\n",
    " max_depth=9,\n",
    " min_child_weight=3,\n",
    " gamma=0,\n",
    " subsample=0.8,\n",
    " colsample_bytree=0.8,\n",
    " objective= 'binary:logistic',\n",
    " nthread=4,\n",
    " scale_pos_weight=1,\n",
    " seed=27)\n",
    "score=cross_validate(clf, X, y, cv=10, scoring=\"accuracy\")[\"test_score\"].mean()\n",
    "print(f\"{score:.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RDspTPIzMrRn"
   },
   "source": [
    "### Generating Predicion Result for submission in .csv format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5aP8M_tlwBik"
   },
   "outputs": [],
   "source": [
    "df2 = pd.read_csv(url2)\n",
    "clf = XGBClassifier(learning_rate =0.1,\n",
    " n_estimators=1000,\n",
    " max_depth=9,\n",
    " min_child_weight=3,\n",
    " gamma=0,\n",
    " subsample=0.8,\n",
    " colsample_bytree=0.8,\n",
    " objective= 'binary:logistic',\n",
    " nthread=4,\n",
    " scale_pos_weight=1,\n",
    " seed=27)\n",
    "clf.fit(X, y)\n",
    "pred=clf.predict(X_test2)\n",
    "pd.DataFrame({\"PassengerId\": df2[\"PassengerId\"], \"Survived\": pred}).to_csv(\"XGBoost_submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ec_DkXhgVRM3"
   },
   "source": [
    "![alt text](https://raw.githubusercontent.com/zyzhang1130/CE9010/master/Titanic/XGBoost.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "H9RkWmmhXIZ4"
   },
   "source": [
    "# Ensembel Learning Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "a-VWXbApXY5C"
   },
   "source": [
    "We use selected models with selected parameters to form ensemble classifiers. The ensemble classifiers are cross validated with 10-fold cross validation and with the all the data which have labels. After some trial and errors we realized that the optimal hyperparameters selected from grid search may not correspond to the best submission score. Our guess is that the 'optimal hyper-parameters' could be actually overfitting to the training data. Therefore, there are some changes in the hyper-parameter settings.The result from grid search can be used for reference instead of the absolute standard."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2NofEOJiD9L2"
   },
   "source": [
    "On a side notes, since thr API of AdaBoost classifier and random forest classifier are directly given in the scikit-learn library, despite the fact the technically these two are ensemble learning models as well, we already evaluated them in the previous secion."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "81avrvc6YatF"
   },
   "source": [
    "## Bagging Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pHTQVQP24YYR"
   },
   "source": [
    "For this bagging classifer we use self-defined base classifier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "2DcGjBrmhrYx",
    "outputId": "5c4cfe3b-47d9-47b5-da04-e26020cfbc5a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.797990\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "\n",
    "bclf= BaggingClassifier(LogisticRegression(C=0.123456789, solver=\"lbfgs\", max_iter=5000), random_state=0, warm_start=False,bootstrap=True, bootstrap_features=True, n_estimators= 500)\n",
    "\n",
    "\n",
    "score=cross_validate(bclf, X, y, cv=10, scoring=\"accuracy\")[\"test_score\"].mean()\n",
    "print(f\"{score:.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0-ihWAjC_BQW"
   },
   "source": [
    "### Generating Predicion Result for submission in .csv format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oUVSfth5_MPP"
   },
   "outputs": [],
   "source": [
    "df2 = pd.read_csv(url2)\n",
    "bclf.fit(X, y)\n",
    "pred=bclf.predict(X_test2)\n",
    "pd.DataFrame({\"PassengerId\": df2[\"PassengerId\"], \"Survived\": pred}).to_csv(\"Bagging2_submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wczf3YXdz5ry"
   },
   "source": [
    "![alt text](https://raw.githubusercontent.com/zyzhang1130/CE9010/master/Titanic/bagging2.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "unBxlpyqW3es"
   },
   "source": [
    "## Stacking Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jAN2uGTXW_pD"
   },
   "source": [
    "We use 3-fold cross valisation to evaluate the accuacy of the stacking classifier. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "ae4rijLqH4Tb",
    "outputId": "abb392ba-363a-4f15-da3a-c398d2a6e1fe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.819338\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import StackingClassifier\n",
    "from sklearn.model_selection import cross_validate\n",
    "base_learners  = [('1_1',SVC(gamma=2, C=1,probability=True)),     \n",
    "                  ('1_2',DecisionTreeClassifier(max_depth=8)),     \n",
    "                  ('1_3',MLPClassifier(alpha=1, max_iter=1000)),     \n",
    "                  ('1_4', KNeighborsClassifier(n_neighbors=7,weights='distance')),     \n",
    "                  ('1_5', BaggingClassifier(DecisionTreeClassifier(max_depth=5), n_estimators=10, random_state=0, warm_start=True)),     \n",
    "                  ('1_6',GaussianProcessClassifier(0.949**2 * RBF(length_scale=1))),     \n",
    "                  ('1_7',GradientBoostingClassifier(n_estimators=100, learning_rate=1.0,max_depth=1, random_state=0))]     \n",
    "stack_clf = StackingClassifier(estimators=base_learners,\n",
    "                          final_estimator=LogisticRegression(C=0.123456789, solver=\"lbfgs\", max_iter=5000),  \n",
    "                          cv=10)\n",
    "\n",
    "\n",
    "score=cross_validate(stack_clf, X, y, cv=10, scoring=\"accuracy\")[\"test_score\"].mean()\n",
    "print(f\"{score:.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "thIy_zY6_vRH"
   },
   "source": [
    "### Generating Predicion Result for submission in .csv format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Mnps3ioZ_2DS"
   },
   "outputs": [],
   "source": [
    "df2 = pd.read_csv(url2)\n",
    "stack_clf.fit(X, y)\n",
    "pred=stack_clf.predict(X_test2)\n",
    "pd.DataFrame({\"PassengerId\": df2[\"PassengerId\"], \"Survived\": pred}).to_csv(\"stacking_submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PKGYulZQ44Ht"
   },
   "source": [
    "### Kaggle Submission Score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GTlYMpuV3_VS"
   },
   "source": [
    "![alt text](https://raw.githubusercontent.com/zyzhang1130/CE9010/master/Titanic/stacking.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "28ZgEy7JaSEi"
   },
   "source": [
    "We observed from trail and error that it is not necessary that the based classifiers that individually perform better will give better score when stacked together. We think of the following possible causes: \n",
    "1. Stacking classifier requires the its base classifiers to be at non-correlate as possible. We assume this condition is fulfilled by that fact that these machine learning models are developed based on different mathematical ideals. However, amongst all base classifiers, some classfiers might tend to be more correlated to others. For example, random forest is by its own aready an emsemble classifier which is built from decision trees. Therefore, by definition it cannot be independent from decision trees. In such case, even if both can achieve very good prediction results separetely, if put as base classifiers as the same time this stacking classifier might be outperformed by other choices of base classifiers.\n",
    "This could happened between other based classifiers as well, but their correlation will be difficult to see.\n",
    "\n",
    "2. Stacking classifiers also requires each based classifier is better than a random classifier in terms of prediction accuracy. We believe this condition is definitely satisfied as we have already tested the base classifiers individually.\n",
    "\n",
    "3. It could also be the case that some based classifier, when used together, will cause the stacking classifier to overfit more towards the training data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rEno1_MgYbM9"
   },
   "source": [
    "## Voting Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BSjS1gTVYb6y"
   },
   "source": [
    "We use 3-fold cross valisation to evaluate the accuacy of the stacking classifier. Soft voting scheme (predicts the class label based on the argmax of the sums of the predicted probabilities) is adopted since it gives a better prediction result. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "UYHgukfTYaek",
    "outputId": "f237cd54-0767-4dc4-9b45-4593c15c40b6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.821598\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "base_learners  = [('1_1',SVC(gamma=2, C=1,probability=True)),\n",
    "                  ('1_2',DecisionTreeClassifier(max_depth=8)),\n",
    "                  ('1_3',MLPClassifier(alpha=1, max_iter=1000)),\n",
    "                  ('1_4', KNeighborsClassifier(n_neighbors=7,weights='distance')),\n",
    "                  ('1_5', BaggingClassifier(DecisionTreeClassifier(max_depth=5), n_estimators=10, random_state=0, warm_start=True)),\n",
    "                  ('1_6',GaussianProcessClassifier(0.949**2 * RBF(length_scale=1))),\n",
    "                  ('1_7',GradientBoostingClassifier(n_estimators=100, learning_rate=1.0,max_depth=1, random_state=0)) ]\n",
    "v_clf = VotingClassifier(estimators=base_learners,voting='soft')\n",
    "\n",
    "score=cross_validate(v_clf, X, y, cv=10, scoring=\"accuracy\")[\"test_score\"].mean()\n",
    "print(f\"{score:.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "i-c5ZKJeA-bJ"
   },
   "source": [
    "### Generating Predicion Result for submission in .csv format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4005f1mbBCDC"
   },
   "outputs": [],
   "source": [
    "df2 = pd.read_csv(url2)\n",
    "v_clf.fit(X, y)\n",
    "pred=v_clf.predict(X_test2)\n",
    "pd.DataFrame({\"PassengerId\": df2[\"PassengerId\"], \"Survived\": pred}).to_csv(\"voting_submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "aYRAbL-Z5ukN"
   },
   "source": [
    "### Kaggle Submission Score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fV0oKXYZ5yJr"
   },
   "source": [
    "![alt text](https://raw.githubusercontent.com/zyzhang1130/CE9010/master/Titanic/voting.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pS-76Wc9d9SS"
   },
   "source": [
    "The issue with stacking classidier exists for the voting classidier as well (optimal classifiers may not give optimal result when used together as base classifier). And we reckon the cause could be the same as well. Through multiple testing, we notice that soft voting classifier in general out performs stacking classsifier given the same base classifiers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HI8hEj526FKy"
   },
   "source": [
    "# Kaggle Leader Board Ranking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fBlELTwI6Kss"
   },
   "source": [
    "We chose the best classifiers among all the trained ones: voting classifiers. Its score 0.81339 corresponds to 568th-713th positions on the public leaderboard (top 2.96% to top 3.72% on the leaderboard)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7ixGlEJ9GAWY"
   },
   "source": [
    "# Observations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ujymllTLGEAL"
   },
   "source": [
    "1. The actual submission score is lower than the cross-validation score for all classifiers. This is expected as overfitting always exists.\n",
    "\n",
    "2. When tuned carefully and appropriately, ensemble learning methods can outperform individual machine learning models. \n",
    "\n",
    "3. According to theory, ensemble methods always outperform the individual classifiers as long as the 2 necessary conditions:\n",
    "\n",
    "The base classifiers are independent of each other\n",
    "\n",
    "The base classifiers should do better than a random classifier \n",
    "\n",
    "   are satisfied. However, during the trial and error, we noticed that it is actually quite common that the ensemble methods performance was lower than that of the best individual classifier used as one of the base classifiers. This sugguests that the based classifiers with lower accuracy comprimosed the best classifier instead of helping to improve the overall accuacy.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "m0uFk30BJj1q"
   },
   "source": [
    "# Attempt with Principal Component Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_C-Gd_19JrfO"
   },
   "source": [
    "We applied Principal Component Analysis on the preprocessed data in the hope that it could find the most important linear combinations of features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 297
    },
    "colab_type": "code",
    "id": "Y7QsuDzvSXt6",
    "outputId": "c4f5fb9b-674d-46a9-82d9-adf4360f42a0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Percentage of data variances captured by all 15 principal directions')"
      ]
     },
     "execution_count": 23,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import scipy.linalg as la\n",
    "from scipy.sparse.linalg import eigsh\n",
    "import time\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "def EVD(X):\n",
    "    s, U = np.linalg.eig(X)\n",
    "    #s, U = eigsh(X,k=10000)\n",
    "    idx = s.argsort()[::-1] # decreasing order\n",
    "    return s[idx], U[:,idx]\n",
    "  \n",
    "X -= X.mean(axis=0)\n",
    "X /= np.std(X,axis=0)\n",
    "cov = X.T.dot(X) / X.shape[0]\n",
    "t = time.time()\n",
    "s, U = EVD(cov)\n",
    "elapsed = time.time() - t\n",
    "s, U = np.real(s), np.real(U)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(s[:]/np.sum(s))\n",
    "plt.title('Percentage of data variances captured by all 15 principal directions')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 33
    },
    "colab_type": "code",
    "id": "lNxTXjQ6TWfO",
    "outputId": "9a33f582-dce5-4c3d-ab30-5912d90f80b2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15, 15)"
      ]
     },
     "execution_count": 24,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cov.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sa0tXrL7_-UF"
   },
   "source": [
    "## Feature Importance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SSHjEVjx8w0B"
   },
   "source": [
    "By observing the eigenvectors with the largest and the second largest variance, we can tell the importance of each original features by comparing the absolute value of it each component. This is because the important new features (top few principal components) are composed by the linear combination of the original features/bases and those original bases with larger magnitude contributed the most of these impact. We focus on those entries with magnitude larger than 0.3."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gIqVl_5Tp6nF"
   },
   "source": [
    "### First Principal Component"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 67
    },
    "colab_type": "code",
    "id": "Dy-VMdemO7xY",
    "outputId": "3698e363-6589-4830-cb0a-672dc55f6b76"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.50673939  0.14345671 -0.22631347  0.00597827 -0.05491334 -0.38756222\n",
      " -0.03493063 -0.11518565 -0.28103787 -0.29322774 -0.18845802 -0.16007677\n",
      " -0.03174686 -0.00837895  0.52582331]\n"
     ]
    }
   ],
   "source": [
    "print(U[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 67
    },
    "colab_type": "code",
    "id": "DIlMN1Ia93MH",
    "outputId": "d9f366e4-4165-4869-acec-01ad3e2640dd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.52582331 0.50673939 0.38756222 0.29322774 0.28103787 0.22631347\n",
      " 0.18845802 0.16007677 0.14345671 0.11518565 0.05491334 0.03493063\n",
      " 0.03174686 0.00837895 0.00597827]\n"
     ]
    }
   ],
   "source": [
    "sortedarray=np.flip(np.sort(abs(U[:,0])))\n",
    "print(sortedarray)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YspNNXuyDyYc"
   },
   "source": [
    "Find the index of the important original features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 33
    },
    "colab_type": "code",
    "id": "ujd0QO4yAeVZ",
    "outputId": "f2a2080c-8f63-43ff-f3ff-4c7c60a58375"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([14]),)"
      ]
     },
     "execution_count": 27,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.where(np.isclose(abs(U[:,0]), sortedarray[0]) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 197
    },
    "colab_type": "code",
    "id": "fsMUOi8O-xRr",
    "outputId": "053e6ab9-c2b2-4803-e134-fbb5c0804887"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>Cabin_A</th>\n",
       "      <th>Cabin_B</th>\n",
       "      <th>Cabin_C</th>\n",
       "      <th>Cabin_D</th>\n",
       "      <th>Cabin_E</th>\n",
       "      <th>Cabin_F</th>\n",
       "      <th>Cabin_G</th>\n",
       "      <th>Cabin_U</th>\n",
       "      <th>Survived</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pclass  Sex   Age  SibSp  ...  Cabin_F  Cabin_G  Cabin_U  Survived\n",
       "0       3    1  22.0      1  ...        0        0        1         0\n",
       "1       1    0  38.0      1  ...        0        0        0         1\n",
       "2       3    0  26.0      0  ...        0        0        1         1\n",
       "3       1    0  35.0      1  ...        0        0        0         1\n",
       "4       3    1  35.0      0  ...        0        0        1         0\n",
       "\n",
       "[5 rows x 16 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 33
    },
    "colab_type": "code",
    "id": "7Fla69QlX7gz",
    "outputId": "e5f6159e-5281-4af5-81fa-cf7fdc06d9ec"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "204\n"
     ]
    }
   ],
   "source": [
    "Cabin_NaN_number=list(df.Cabin_U).count(0)\n",
    "print(Cabin_NaN_number)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HCfMU6_H--KN"
   },
   "source": [
    "Since 0.52582331 corresponds to the NaN one-hot-encoded label for 'Cabin number', and there is a large portion of the passengers (204 out of 891) whose Cabin numbers are missing. It makes sense if we have the following postulate: for the passengers who did not survive, it is much more difficult to determine their Cabin numbers. If that is true, then there would be a lot of passengers whose Cabin number could not be determined, since the majority of them did not survive. This agrees with the fact that there are large amount of NaN in 'Cabin number' features for both training set and test set. Therefore, it is reasoonable that the NaN one-hot-encoded label for 'Cabin number' is strongly correlated to the survival rate, hence the large eigenvalue magnitude."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 33
    },
    "colab_type": "code",
    "id": "rclJ-BhTDvyq",
    "outputId": "355fef6c-947c-4080-bb50-4f8425624c3b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([5]),)"
      ]
     },
     "execution_count": 30,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.where(np.isclose(abs(U[:,0]), sortedarray[2]) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "l_Q8bb1Tap13"
   },
   "source": [
    "The second largest value 0.50673939 corresponds to the feature 'Ticket class'. It does make sense as the higher class passenger is likely to get to access of evacuation facilities with relative ease. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 33
    },
    "colab_type": "code",
    "id": "tizOV_CWtHl9",
    "outputId": "19d3b3bc-d3a6-44b6-cead-fc6a96380fbb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0]),)"
      ]
     },
     "execution_count": 31,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.where(np.isclose(abs(U[:,0]), sortedarray[1]) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xGSLJ79-taH0"
   },
   "source": [
    "The third largest value 0.38756222 corresponds to the feature 'Passenger fare'. Evidently, this feature is strongly correlated to the feature 'Ticket class'. Hence, for the sake reason it is impactful on survival rate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "21T9Z4UZqJv0"
   },
   "source": [
    "### Second Principal Component"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 67
    },
    "colab_type": "code",
    "id": "kAAslJp-oXv1",
    "outputId": "ae2d1244-87f3-49a8-e157-cbec5c594ab8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.10412088 -0.3505967  -0.35280509  0.53698197  0.56179944  0.25143205\n",
      " -0.02725813 -0.17857488  0.07431078  0.03700066 -0.07783418 -0.10362747\n",
      "  0.03947718  0.12092155  0.04563582]\n"
     ]
    }
   ],
   "source": [
    "print(U[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 67
    },
    "colab_type": "code",
    "id": "_0E29fvNodwj",
    "outputId": "10fbc018-c349-4caa-eb90-4e7003a7ef30"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.56179944 0.53698197 0.35280509 0.3505967  0.25143205 0.17857488\n",
      " 0.12092155 0.10412088 0.10362747 0.07783418 0.07431078 0.04563582\n",
      " 0.03947718 0.03700066 0.02725813]\n"
     ]
    }
   ],
   "source": [
    "sortedarray2=np.flip(np.sort(abs(U[:,1])))\n",
    "print(sortedarray2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 33
    },
    "colab_type": "code",
    "id": "ou-ZDFWxpX4U",
    "outputId": "bf859285-e295-458d-bd7d-cfac5bf8a302"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([4]),)"
      ]
     },
     "execution_count": 35,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.where(np.isclose(abs(U[:,1]), sortedarray2[0]) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pCDlUl6-q9gJ"
   },
   "source": [
    "The 1st important original feature here is no. of parents / children aboard the Titanic. From the Data Exploration section we know that ages has strong correlation with survivalbility. On the other hand those with parents / childern has more family members to take care of during the escape. This will also affect the survivability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 33
    },
    "colab_type": "code",
    "id": "SW224hoqphZq",
    "outputId": "1fdfe4d7-b28c-44ae-b982-e6c115829b1c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([3]),)"
      ]
     },
     "execution_count": 36,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.where(np.isclose(abs(U[:,1]), sortedarray2[1]) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JO46mQLWrbGy"
   },
   "source": [
    "The 2nd important original feature here is no. of siblings / spouses aboard the Titanic. It is imagineable that during the escape, thise with more familiy memebers need to take care of each other and this will also affect the survivability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 33
    },
    "colab_type": "code",
    "id": "qtkr6B-6plzt",
    "outputId": "ce0f6abf-63b1-4c79-a966-b210fb0f9850"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([2]),)"
      ]
     },
     "execution_count": 37,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.where(np.isclose(abs(U[:,1]), sortedarray2[2]) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bdX-wewTr-pD"
   },
   "source": [
    "The 3rd important original feature here is age. For the same reason as the 1st important original feature it is also has a strong impact on survivability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 33
    },
    "colab_type": "code",
    "id": "e_aAhsH9pqfI",
    "outputId": "5b540129-b24c-4f73-8cf4-e1202ec2fab6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1]),)"
      ]
     },
     "execution_count": 38,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.where(np.isclose(abs(U[:,1]), sortedarray2[3]) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZwsYshm3sx2B"
   },
   "source": [
    "The 4th important original fearure here is sex. Again, from the Data Exploration we know that female is much higher survival rate than male. Hence, this feature is also impactful."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9WtPYGECU6fO"
   },
   "source": [
    "## New representation in the eigenspace:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gYW0jGqEU4lc"
   },
   "outputs": [],
   "source": [
    "n1 = data.shape[0]\n",
    "n2 = data.shape[1]\n",
    "new_X=np.zeros((n1,n2-1))\n",
    "for i in range(n1):\n",
    "  for j in range(n2-1):\n",
    "    new_X[i,j]=X[i,:].dot(U[:,j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "SNQlrXpkW7NP",
    "outputId": "7dd124e0-92ba-41a2-edfc-2746eea63008"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(891, 15)"
      ]
     },
     "execution_count": 478,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "N2Xb3TB_XXwp",
    "outputId": "cde64e17-70b9-4530-a2cf-faa67ccb9328"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15,)"
      ]
     },
     "execution_count": 479,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "46nlGNj9UQWe"
   },
   "source": [
    "We now scale each new features by its eigenvalues to reflect is importance in training: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZefGJO_AUMa7"
   },
   "outputs": [],
   "source": [
    "for j in range(n2-1):\n",
    "    new_X[:,j]=new_X[:,j]*s[j]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SOp9Fy1GNmFG"
   },
   "source": [
    "Now we use by far the best model we have to test on the modified dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "5ceSXyRtN19v",
    "outputId": "936c00ea-dba7-4909-c300-70ff0d89b07d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.818202\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "base_learners  = [     ('1_1',SVC(gamma=2, C=1,probability=True)),\n",
    "                  ('1_2',DecisionTreeClassifier(max_depth=8)),\n",
    "                  ('1_3',MLPClassifier(alpha=1, max_iter=1000)),\n",
    "                  ('1_4', KNeighborsClassifier(n_neighbors=7,weights='distance')),\n",
    "                  ('1_5', BaggingClassifier(DecisionTreeClassifier(max_depth=5), n_estimators=10, random_state=0, warm_start=True)),\n",
    "                  ('1_6',GaussianProcessClassifier(0.949**2 * RBF(length_scale=1))),\n",
    "                  ('1_7',GradientBoostingClassifier(n_estimators=100, learning_rate=1.0,max_depth=1, random_state=0)) ]\n",
    "v_clf = VotingClassifier(estimators=base_learners,voting='soft')\n",
    "\n",
    "score=cross_validate(v_clf, new_X, y, cv=10, scoring=\"accuracy\")[\"test_score\"].mean()\n",
    "print(f\"{score:.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cOsOxSXvzmS6"
   },
   "source": [
    "New representation for test data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vgQ5A39TyErH"
   },
   "outputs": [],
   "source": [
    "n1 = data2.shape[0]\n",
    "n2 = data2.shape[1]\n",
    "new_X_test2=np.zeros((n1,n2))\n",
    "for i in range(n1):\n",
    "  for j in range(n2-1):\n",
    "    new_X_test2[i,j]=X_test2[i,:].dot(U[:,j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "U4bXimjRx_xz"
   },
   "outputs": [],
   "source": [
    "df2 = pd.read_csv(url2)\n",
    "v_clf.fit(new_X, y)\n",
    "pred=v_clf.predict(new_X_test2)\n",
    "pd.DataFrame({\"PassengerId\": df2[\"PassengerId\"], \"Survived\": pred}).to_csv(\"pca_voting_submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "eHt1Y5Lr1Cmy"
   },
   "source": [
    "![alt text](https://raw.githubusercontent.com/zyzhang1130/CE9010/master/Titanic/pca_voting.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "aT-00Ypf1PJN"
   },
   "source": [
    "It turns out that in reality, using eigenvalues of covariacne matrix to scale the feature did not give a better prediction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uYLWr6B1hrB0"
   },
   "source": [
    "# Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Pjk2pcF23SBr"
   },
   "source": [
    "Through this data science challenge project, we have learnt that:\n",
    "1. The overall pipeline for doing a data sceince project;\n",
    "2. Preprocessing: How to select relevant features and effectively encode each type of feature;\n",
    "3. Machine learning: how to use a variety of machine learning models from scikit-learn library as well as select appropriate models and tune their hyperparameters during training.\n",
    "4. Evaluation: how to evaluate the prediction results by certain metrics.\n",
    "5. Analysis: how to infer from the prediction result about certain properties of the data, and how to use such knowledge improve encoding methods. \n",
    "6. Platform: familiarized with Kaggle competition and the entire pipeline of participating in its challenge. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GlAG16Fpe3QE"
   },
   "source": [
    "## Challenges Encounterd:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "aUe4aX-7Cqrx"
   },
   "source": [
    "\n",
    "1. Trial and error is the theme of applying machine learning techniques to solve prediction problems. Throughout the entire process, each step involves trial and error. This is through educated guess, expertise and experience that this process could be shortened. For example, by observing the characteristics of the features of the given data, many encoding methods could be eliminated and a few be shortlisted to do testing.\n",
    "2. Parameter tuning is a tedious and time consuming process. Patience is needed to get the better hyperparameters.\n",
    "3. It is usual that something unexpected will happen at the deployment stage such that the theories for idealistic situations do not apply. In these cases, one needs to be adaptive and think of alternatives to fix the issues.  \n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Untitled1.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
